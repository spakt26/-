{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sONpqynRanVD"
   },
   "source": [
    "# Содержание "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Text summarization](#ch1)\n",
    "    - [Описание набора данных](#ch2)\n",
    "    - [Extractive methods](#ch3)\n",
    "        - [Word frequency method](#ch4)\n",
    "        - [TextRank](#ch5)\n",
    "        - [ClusterRank](#ch6)\n",
    "        - [LSA](#ch7)\n",
    "        - [KLSum](#ch8)\n",
    "        - [MEAD](#ch9)\n",
    "    - [Abstractive methods](#ch10)\n",
    "        - [BERT](#ch11)\n",
    "        - [GPT-2](#ch12)\n",
    "        - [XLNet](#ch13)\n",
    "        - [T5 with fine-tuning](#ch14)\n",
    "- [Speech Recognition](#ch15)\n",
    "    - [Обработка звука](#ch16)\n",
    "    - [Google speech to text](#ch17)\n",
    "    - [wav2vec](#ch18)\n",
    "    - [IBM Watson](#ch19)\n",
    "    - [Метрики распознавания речи](#ch20)\n",
    "- [Комбинация алгоритма распознавания речи и суммаризации](#ch21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Суммаризация текста  <a class=\"anchor\" id=\"ch1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_cX_NY5anVT"
   },
   "source": [
    "## Описание набора данных  + сохранение файлов в отдельные csv <a class=\"anchor\" id=\"ch2\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве данных для верификации моделей возьмем AMI Meeting Corpus, содержащий 100 часов звукозаписей, транскрипты, разделенные по говорящим и рефераты к ним - экстрактивный и абстрактивный. Примерно треть данных состоит из искусственно составленных сценариев совещаний от команды дизайнеров, а остальная часть - реально проходящие в деловом центре переговоры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WN-hBqL0bsvt"
   },
   "source": [
    "Пример текстового файла: ES2002a.transcript.txt, первые две буквы это страна, в котором записывалось данное совещание, одно совещание состоит из 4 частей: a, b, c и d.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXUWW70yanVU"
   },
   "outputs": [],
   "source": [
    "test = open('ami-transcripts/ES2002a.transcript.txt', \"r\", errors = 'ignore')\n",
    "transcript = test.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "anBpVjQWanVV",
    "outputId": "4b00d33e-3cc0-4d60-9cea-7fff9ca3b3e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Um I'm Craig and I'm User Interface. Yeah. Well, my favourite animal would be a monkey. Then they're small cute and furry, and uh when planet of the apes becomes real, I'm gonna be up there with them. Yeah. I know um My parents went out and bought um remote controls because um they got fed up of having four or five different remote controls for each things the house. So um for them it was just how many devices control. Uh.\\nMm-hmm. Great. And I'm Andrew and I'm uh our marketing expert. Mm-hmm. Mm-hmm. Yeah, that's that's it. Yeah. I will go. That's fine. Alright. So This one here, right? Okay. Very nice. Alright. My favourite animal is like A beagle. Um charac favourite characteristics of it? Is that right? Uh, right, well basically um high priority for any animal for me is that they be willing to take a lot of physical affection from their family. And, yeah that they have lots of personality and uh be fit and in robust good health. So this is blue. Blue beagle. My family's beagle. I coulda told you a whole lot more about beagles. Boy, let me tell you. Impressionist. Alright. Mm. Superb sketch, by the way. Yep. I see a dog in there. Yep. Now I see a rooster. What kind is it? Is he aware that th it's his own cha tail he's chasing? Hmm. Probably when he was little he got lots of attention for doing it and has forever been conditioned. 'Kay. Um, can we just go over that again? Uh, so bas at twel Alright, yeah. Okay. So cost like production cost is twelve fifty, but selling price is is that wholesale or retail? Like on the shelf. Our sale our sale anyway. Yeah, okay okay. Okay. Mm-hmm. Alright. Yes. Mm-hmm. Mm-hmm. Well right away I'm wondering if there's um th th uh, like with D_V_D_ players, if there are zones. Um f frequencies or something um as well as uh characters, um different uh keypad styles and s symbols. Um. I don't know. Yeah. Yeah. Yeah. And then a and then al the other thing international is on top of the price. I'm thinking the price might might appeal to a certain market in one region, whereas in another it'll be different, so Just a chara just a characteristic of the Just Or just like, basic product podi positioning, the twenty five Euro remote control might be a big hit in London, might not be such a big hit in Greece, who knows, something like that, yeah. Yep. Right away I'm making some kind of assumptions about what what information we're given here, thinking, 'kay trendy probably means something other than just basic, something other than just standard. Um so I'm wondering right away, is selling twenty five Euros, is that sort of the thi is this gonna to be like the premium product kinda thing or Uh-huh. Mm-hmm. Yep. Yeah, I'd say so, yeah. No. Yeah, yeah. Mm-hmm. Do we have any other background information on like how that compares to other other Yeah. Mm-hmm. Yeah, interesting thing about discussing um production of a remote control for me is that l as you point out, I just don't think of remote controls as somethin something people consciously assess in their purchasing habits. It's just like getting shoelaces with shoes or something. It just comes along. Do you know what I mean? Like so sort of like how do you I I mean one one way of looking at it would be, well the people producing television sets, maybe they have to buy remote controls. Or another way is maybe people who have T_V_ sets are really fed up with their remote control and they really want a better one or something. But Right. Right. Okay so Right, so in function one of the priorities might be to combine as many uses I think so. Yeah, yeah. Yeah. Well like um, maybe what we could use is a sort of like a example of a successful other piece technology is palm palm pilots. They're gone from being just like little sort of scribble boards to cameras, M_P_ three players, telephones, everything, agenda. So, like, I wonder if we might add something new to the to the remote control market, such as the lighting in your house, or um Yeah, yeah. An Yeah. Like, p personally for me, at home I've I've combined the um the audio video of my television set and my D_V_D_ player and my C_D_ player. So they w all work actually function together but I have different remote controls for each of them. So it's sort of ironic that that then they're in there um you know, the sound and everything it's just one system. But each one's got its own little part. Mm. Mm. Mm. Mm-hmm. Mm-hmm. Yeah. Yeah. That's just really good id Yep. Uh, sure. I remember when the first remote control my my family had was on a cable. Actually had a cable between it and the T_V_ and big like buttons that sort of like, like on a blender or something. And um, you know, when I think about what they are now, it's better, but actually it's still kind of, I dunno, like a massive junky thing on the table. Maybe we could think about how, could be more, you know, streamlined. S Something like that, yeah. Or whatever would be technologically reasonable. 'Cause it could b it could it could be that f it could be that functionally that doesn't make it any better, but that just the appeal of of not having You know, these days there's a r pe things in people's homes are becoming more and more like chic, you know. Um, nicer materials and might be be worth exploring anyway. Okay. Um. Before we wrap up, just to make sure we're all on the same page here, um, do we We were given sort of an example of a coffee machine or something, right? Well, um are we at ma right now on the assumption that our television remote control may have features which go beyond the television? Or are we keeping sort of like a a design commitment to television features? I I don't know. Yep. Yeah, sure. Okay. Okay, yeah. Okay. Okay. Okay. Alright.\\nOkay. Right. Um well this is the kick-off meeting for our our project. Um and um this is just what we're gonna be doing over the next twenty five minutes. Um so first of all, just to kind of make sure that we all know each other, I'm Laura and I'm the project manager. Do you want to introduce yourself again? Okay. Great. Okay. Um so we're designing a new remote control and um Oh I have to record who's here actually. So that's David, Andrew and Craig, isn't it? And you all arrived on time. Um yeah so des uh design a new remote control. Um, as you can see it's supposed to be original, trendy and user friendly. Um so that's kind of our our brief, as it were. Um and so there are three different stages to the design. Um I'm not really sure what what you guys have already received um in your emails. What did you get? Mm-hmm. Is that what everybody got? Okay. Um. So we're gonna have like individual work and then a meeting about it. And repeat that process three times. Um and at this point we get try out the whiteboard over there. Um. So uh you get to draw your favourite animal and sum up your favourite characteristics of it. So who would like to go first? Very good. Mm-hmm. Yeah. Yeah. Right. Lovely. Right. You can take as long over this as you like, because we haven't got an awful lot to discuss. Ok oh we do we do. Don't feel like you're in a rush, anyway. Ach why not We might have to get you up again then. I don't know what mine is. I'm gonna have to think on the spot now. Is that a whale? Ah. Okay. God, I still don't know what I'm gonna write about. Um. I was gonna choose a dog as well. But I'll just draw a different kind of dog. M my favourite animal is my own dog at home. Um That doesn't really look like him, actually. He looks more like a pig, actually. Ah well. Do you? Oh that's very good of you. Uh. Um he's a mixture of uh various things. Um and what do I like about him, um That's just to suggest that his tail wags. Um he's very friendly and cheery and always pleased to see you, and very kind of affectionate and um uh and he's quite quite wee as well so you know he can doesn't take up too much space. Um and uh And he does a funny thing where he chases his tail as well, which is quite amusing, so It is. I think it is. He only does it after he's had his dinner and um he'll just all of a sudden just get up and start chasing his tail 'round the living room. Yeah, so uh Yeah, maybe. Maybe. Right, um where did you find this? Just down here? Yeah. Okay. Um what are we doing next? Uh um. Okay, uh we now need to discuss the project finance. Um so according to the brief um we're gonna be selling this remote control for twenty five Euro, um and we're aiming to make fifty million Euro. Um so we're gonna be selling this on an international scale. And uh we don't want it to cost any more than uh twelve fifty Euros, so fifty percent of the selling price. Sure. All together. Um I dunno. I imagine That's a good question. I imagine it probably is our sale actually because it's probably up to the the um the retailer to uh sell it for whatever price they want. Um. But I I don't know, I mean do you think the fact that it's going to be sold internationally will have a bearing on how we design it at all? Think it will? Um. Hmm. Oh yeah, regions and stuff, yeah. Yeah. Okay. Yeah. Well for a remote control, do you think that will be I suppose it's depends on how complicated our remote control is. Yeah, yeah. Okay. What, just like in terms of like the wealth of the country? Like how much money people have to spend on things like? Aye, I see what you mean, yeah. Marketing. Good marketing thoughts. Oh gosh, I should be writing all this down. Um. Mm. Yeah. Yeah, yeah. Like how much does, you know, a remote control cost. Well twenty five Euro, I mean that's um that's about like eighteen pounds or something, isn't it? Or no, is it as much as that? Sixteen seventeen eighteen pounds. Um, I dunno, I've never bought a remote control, so I don't know how how good a remote control that would get you. Um. But yeah, I suppose it has to look kind of cool and gimmicky. Um right, okay. Let me just scoot on ahead here. Okay. Um well d Does anybody have anything to add to uh to the finance issue at all? Thin No, actually. That would be useful, though, wouldn't it, if you knew like what your money would get you now. Mm-hmm. Yeah, yeah. Oh. Five minutes to end of meeting. Oh, okay. We're a bit behind. Yeah. Right, so do you think that should be like a main design aim of our remote control d you know, do your your satellite and your regular telly and your V_C_R_ and everything? Mm-hmm. Yeah. Or even like, you know, notes about um what you wanna watch. Like you might put in there oh I want to watch such and such and look a Oh that's a good idea. So extra functionalities. Mm-hmm. Hmm. Um okay, uh I'd wel we're gonna have to wrap up pretty quickly in the next couple of minutes. Um I'll just check we've nothing else. Okay. Um so anything else anybody wants to add about what they don't like about remote controls they've used, what they would really like to be part of this new one at all? You keep losing them. Okay. Yeah. W You get those ones where you can, if you like, whistle or make a really high pitched noise they beep. There I mean is that something we'd want to include, do you think? Dunno. Okay maybe. My goodness. Still feels quite primitive. Maybe like a touch screen or something? Okay. Uh-huh, okay. Well I guess that's up to our industrial designer. It looks better. Yeah. Okay. Okay. Right, well um so just to wrap up, the next meeting's gonna be in thirty minutes. So that's about um about ten to twelve by my watch. Um so inbetween now and then, um as the industrial designer, you're gonna be working on you know the actual working design of it so y you know what you're doing there. Um for user interface, technical functions, I guess that's you know like what we've been talking about, what it'll actually do. Um and uh marketing executive, you'll be just thinking about what it actually what, you know, what requirements it has to has to fulfil and you'll all get instructions emailed to you, I guess. Um. Yeah, so it's th the functional design stage is next, I guess. And uh and that's the end of the meeting. So I got that little message a lot sooner than I thought I would, so Mm-hmm. Uh-huh, yeah. Th Okay, well just very quickly 'cause this we're supposed to finish now. Um I guess that's up to us, I mean you probably want some kind of unique selling point of it, so um, you know Yeah. Mm-hmm. Yeah. Okay. Right, okay, we'll that's that's the end of the meeting, then. Um. So, uh thank you all for coming.\\nHi, I'm David and I'm supposed to be an industrial designer. Um, I just got the project announcement about what the project is. Designing a remote control. That's about it, didn't get anything else. Did you get the same thing? Cool. There's too much gear. Okay. Can't draw. Um. Yeah. Um, well anyway, I don't know, it's just the first animal I can think off the top of my head. Um. Yes. Big reason is 'cause I'm allergic to most animals. Allergic to animal fur, so um fish was a natural choice. Um, yeah, and I kind of like whales. They come in and go eat everything in sight. And they're quite harmless and mild and interesting. Tail's a bit big, I think. It's an after dinner dog then. Hmm. It does make sense from maybe the design point of view 'cause you have more complicated characters like European languages, then you need more buttons. So, possibly. Hmm. Yeah. And you keep losing them. Finding them is really a pain, you know. I mean it's usually quite small, or when you want it right, it slipped behind the couch or it's kicked under the table. You know. Yep. Mm-hmm. I think one factor would be production cost. Because there's a cap there, so um depends on how much you can cram into that price. Um. I think that that's the main factor. Cool.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6mLS2IpanVV"
   },
   "outputs": [],
   "source": [
    "test2 = open('extractive/ES2002a.extsumm.txt', \"r\", errors = 'ignore')\n",
    "transcript_sum = test2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHWkb4TGanVW",
    "outputId": "ee099615-03f7-420f-fb7e-1505e0316ebc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Um well this is the kick-off meeting for our our project . so we're designing a new remote control and um Um , as you can see it's supposed to be original , trendy and user friendly . Um and so there are three different stages to the design . So we're gonna have like individual work and then a meeting about it . And repeat that process three times . So uh you get to draw your favourite animal and sum up your favourite characteristics of it . My favourite animal is like A beagle . Uh , right , well basically um high priority for any animal for me is that they be willing to take a lot of physical affection from their family . And , yeah that they have lots of personality Well Then they're small cute and furry , and I kind of like whales . They come in and go eat everything in sight . M my favourite animal is my own dog at home . Um he's very friendly and cheery and always pleased to see you , Um so according to the brief um we're gonna be selling this remote control for twenty five Euro , And uh we don't want it to cost any more than uh twelve fifty Euros , so fifty percent of the selling price . but selling price is is that wholesale or retail ? I imagine it probably is our sale actually because it's probably up to the the um the retailer to uh sell it for whatever price they want . Um . I mean do you think the fact that it's going to be sold internationally will have a bearing on how we design it at all ? Well right away I'm wondering if there's um th th uh , like with D_V_D_ players , if there are zones . um as well as uh characters , um different uh keypad styles and s symbols . 'cause you have more complicated characters like European languages , then you need more buttons . I'm thinking the price might might appeal to a certain market in one region , whereas in another it'll be different , so thinking , 'kay trendy probably means something other than just basic , Like how much does , you know , a remote control cost . Well twenty five Euro , I mean that's um that's about like eighteen pounds or something , thi is this gonna to be like the premium product kinda thing or so I don't know how how good a remote control that would get you . Um . But yeah , I suppose it has to look kind of cool and gimmicky . I just don't think of remote controls as somethin something people consciously assess in their purchasing habits . I I mean one one way of looking at it would be , well the people producing television sets , maybe they have to buy remote controls . Or another way is maybe people who have T_V_ sets are really fed up with their remote control and they really want a better one or something . My parents went out and bought um remote controls because um they got fed up of having four or five different remote controls for each things the house . So um for them it was just how many devices control . So extra functionalities . So , like , I wonder if we might add something new to the to the remote control market , so in function one of the priorities might be to combine as many uses Right , so do you think that should be like a main design aim of our remote control d you know , do your your satellite and your regular telly and your V_C_R_ and everything ? maybe what we could use is a sort of like a example of a successful other piece technology is palm palm pilots . You keep losing them . W You get those ones where you can , if you like , whistle or make a really high pitched noise they beep . Maybe we could think about how , could be more , you know , streamlined . S Maybe like a touch screen or something ? Or whatever would be technologically reasonable . Um so inbetween now and then , um as the industrial designer , you're gonna be working on you know the actual working design of it Um for user interface , technical functions , Um and uh marketing executive , you'll be just thinking about what it actually what , you know , what requirements it has to has to fulfil Yeah , so it's th the functional design stage is next , I guess . are we at ma right now on the assumption that our television remote control may have features which go beyond the television ? Or are we keeping sort of like a a design commitment to television features ? I think one factor would be production cost . I mean you probably want some kind of unique selling point of it , \""
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLiUMackanVW",
    "outputId": "9d56c071-f953-4a7c-eca8-7b231feba5fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transription: 13676\n",
      "The length of the summary of the transcription: 4318\n"
     ]
    }
   ],
   "source": [
    "print('The length of the transription: {}'.format(len(transcript)))\n",
    "print('The length of the summary of the transcription: {}'.format(len(transcript_sum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhqMJFT5bsvv"
   },
   "source": [
    "Создадим 2 отдельных датасета для extractive методов и abstarctive методов с соотвественными им аудиофайлами. В датасете будет содержаться название файлов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYDAxGJlbsvw",
    "outputId": "99fcfcbf-95b6-4364-b6b1-37a00086555c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TS3007d.extsumm.txt',\n",
       " 'ES2010d.extsumm.txt',\n",
       " 'IS1008a.extsumm.txt',\n",
       " 'ES2005d.extsumm.txt',\n",
       " 'IS1005b.extsumm.txt',\n",
       " 'ES2002d.extsumm.txt',\n",
       " 'IS1002b.extsumm.txt',\n",
       " 'TS3012d.extsumm.txt',\n",
       " 'ES2004a.extsumm.txt',\n",
       " 'ES2012c.extsumm.txt',\n",
       " 'TS3005c.extsumm.txt',\n",
       " 'ES2003a.extsumm.txt',\n",
       " 'ES2015c.extsumm.txt',\n",
       " 'ES2009b.extsumm.txt',\n",
       " 'IS1009d.extsumm.txt',\n",
       " 'TS3006a.extsumm.txt',\n",
       " 'TS3010c.extsumm.txt',\n",
       " 'ES2016a.extsumm.txt',\n",
       " 'ES2007c.extsumm.txt',\n",
       " 'ES2011a.extsumm.txt',\n",
       " 'IS1009a.extsumm.txt',\n",
       " 'ES2003d.extsumm.txt',\n",
       " 'IS1003b.extsumm.txt',\n",
       " 'ES2004d.extsumm.txt',\n",
       " 'IS1004b.extsumm.txt',\n",
       " 'ES2011d.extsumm.txt',\n",
       " 'ES2016d.extsumm.txt',\n",
       " 'TS3006d.extsumm.txt',\n",
       " 'ES2010a.extsumm.txt',\n",
       " 'ES2006c.extsumm.txt',\n",
       " 'TS3011c.extsumm.txt',\n",
       " 'TS3007a.extsumm.txt',\n",
       " 'TS3012a.extsumm.txt',\n",
       " 'ES2014c.extsumm.txt',\n",
       " 'ES2002a.extsumm.txt',\n",
       " 'TS3004c.extsumm.txt',\n",
       " 'ES2013c.extsumm.txt',\n",
       " 'ES2005a.extsumm.txt',\n",
       " 'TS3003c.extsumm.txt',\n",
       " 'ES2008b.extsumm.txt',\n",
       " 'IS1008d.extsumm.txt',\n",
       " 'TS3009c.extsumm.txt',\n",
       " 'ES2008a.extsumm.txt',\n",
       " 'IS1002d.extsumm.txt',\n",
       " 'ES2002b.extsumm.txt',\n",
       " 'TS3012b.extsumm.txt',\n",
       " 'ES2005b.extsumm.txt',\n",
       " 'ES2010b.extsumm.txt',\n",
       " 'TS3007b.extsumm.txt',\n",
       " 'IS1007c.extsumm.txt',\n",
       " 'IS1000c.extsumm.txt',\n",
       " 'IS1003a.extsumm.txt',\n",
       " 'IS1004a.extsumm.txt',\n",
       " 'IS1009b.extsumm.txt',\n",
       " 'ES2009d.extsumm.txt',\n",
       " 'ES2016b.extsumm.txt',\n",
       " 'TS3006b.extsumm.txt',\n",
       " 'ES2011b.extsumm.txt',\n",
       " 'ES2009a.extsumm.txt',\n",
       " 'TS3008c.extsumm.txt',\n",
       " 'IS1004d.extsumm.txt',\n",
       " 'ES2004b.extsumm.txt',\n",
       " 'IS1003d.extsumm.txt',\n",
       " 'ES2003b.extsumm.txt',\n",
       " 'IS1005a.extsumm.txt',\n",
       " 'IS1008b.extsumm.txt',\n",
       " 'ES2008d.extsumm.txt',\n",
       " 'IS1001c.extsumm.txt',\n",
       " 'IS1006c.extsumm.txt',\n",
       " 'TS3003b.extsumm.txt',\n",
       " 'ES2013b.extsumm.txt',\n",
       " 'TS3004b.extsumm.txt',\n",
       " 'ES2014b.extsumm.txt',\n",
       " 'ES2008c.extsumm.txt',\n",
       " 'TS3009a.extsumm.txt',\n",
       " 'IS1001d.extsumm.txt',\n",
       " 'TS3011b.extsumm.txt',\n",
       " 'IS1006d.extsumm.txt',\n",
       " 'ES2006b.extsumm.txt',\n",
       " 'IS1000a.extsumm.txt',\n",
       " 'IS1007a.extsumm.txt',\n",
       " 'TS3008d.extsumm.txt',\n",
       " 'IS1004c.extsumm.txt',\n",
       " 'IS1003c.extsumm.txt',\n",
       " 'IS1007d.extsumm.txt',\n",
       " 'ES2007b.extsumm.txt',\n",
       " 'TS3010b.extsumm.txt',\n",
       " 'IS1000d.extsumm.txt',\n",
       " 'ES2015b.extsumm.txt',\n",
       " 'TS3005b.extsumm.txt',\n",
       " 'ES2012b.extsumm.txt',\n",
       " 'TS3008a.extsumm.txt',\n",
       " 'ES2009c.extsumm.txt',\n",
       " 'TS3009d.extsumm.txt',\n",
       " 'IS1002c.extsumm.txt',\n",
       " 'IS1005c.extsumm.txt',\n",
       " 'IS1006a.extsumm.txt',\n",
       " 'IS1001a.extsumm.txt',\n",
       " 'ES2006d.extsumm.txt',\n",
       " 'IS1006b.extsumm.txt',\n",
       " 'IS1001b.extsumm.txt',\n",
       " 'TS3011d.extsumm.txt',\n",
       " 'TS3004d.extsumm.txt',\n",
       " 'ES2014d.extsumm.txt',\n",
       " 'TS3003d.extsumm.txt',\n",
       " 'ES2013d.extsumm.txt',\n",
       " 'IS1008c.extsumm.txt',\n",
       " 'TS3008b.extsumm.txt',\n",
       " 'ES2003c.extsumm.txt',\n",
       " 'TS3005a.extsumm.txt',\n",
       " 'ES2015a.extsumm.txt',\n",
       " 'ES2004c.extsumm.txt',\n",
       " 'ES2012a.extsumm.txt',\n",
       " 'ES2007a.extsumm.txt',\n",
       " 'ES2011c.extsumm.txt',\n",
       " 'TS3006c.extsumm.txt',\n",
       " 'ES2016c.extsumm.txt',\n",
       " 'TS3010a.extsumm.txt',\n",
       " 'ES2012d.extsumm.txt',\n",
       " 'ES2015d.extsumm.txt',\n",
       " 'TS3005d.extsumm.txt',\n",
       " 'IS1009c.extsumm.txt',\n",
       " 'TS3010d.extsumm.txt',\n",
       " 'IS1000b.extsumm.txt',\n",
       " 'ES2007d.extsumm.txt',\n",
       " 'IS1007b.extsumm.txt',\n",
       " 'TS3011a.extsumm.txt',\n",
       " 'TS3007c.extsumm.txt',\n",
       " 'ES2010c.extsumm.txt',\n",
       " 'ES2006a.extsumm.txt',\n",
       " 'TS3009b.extsumm.txt',\n",
       " 'ES2013a.extsumm.txt',\n",
       " 'TS3003a.extsumm.txt',\n",
       " 'ES2005c.extsumm.txt',\n",
       " 'ES2014a.extsumm.txt',\n",
       " 'TS3004a.extsumm.txt',\n",
       " 'ES2002c.extsumm.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "folder_ext = 'extractive'\n",
    "ext = [x[2] for x in os.walk(folder_ext)][0]\n",
    "ext_summaries_files = []\n",
    "for i in ext:\n",
    "    ext_summaries_files.append('extractive/' + i)\n",
    "ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xirtyngKbsvw",
    "outputId": "43c93205-9680-48b0-d933-ec159ccbed87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ami-transcripts/TS3007d.transcript.txt',\n",
       " 'ami-transcripts/ES2010d.transcript.txt',\n",
       " 'ami-transcripts/IS1008a.transcript.txt',\n",
       " 'ami-transcripts/ES2005d.transcript.txt',\n",
       " 'ami-transcripts/IS1005b.transcript.txt',\n",
       " 'ami-transcripts/ES2002d.transcript.txt',\n",
       " 'ami-transcripts/IS1002b.transcript.txt',\n",
       " 'ami-transcripts/TS3012d.transcript.txt',\n",
       " 'ami-transcripts/ES2004a.transcript.txt',\n",
       " 'ami-transcripts/ES2012c.transcript.txt',\n",
       " 'ami-transcripts/TS3005c.transcript.txt',\n",
       " 'ami-transcripts/ES2003a.transcript.txt',\n",
       " 'ami-transcripts/ES2015c.transcript.txt',\n",
       " 'ami-transcripts/ES2009b.transcript.txt',\n",
       " 'ami-transcripts/IS1009d.transcript.txt',\n",
       " 'ami-transcripts/TS3006a.transcript.txt',\n",
       " 'ami-transcripts/TS3010c.transcript.txt',\n",
       " 'ami-transcripts/ES2016a.transcript.txt',\n",
       " 'ami-transcripts/ES2007c.transcript.txt',\n",
       " 'ami-transcripts/ES2011a.transcript.txt',\n",
       " 'ami-transcripts/IS1009a.transcript.txt',\n",
       " 'ami-transcripts/ES2003d.transcript.txt',\n",
       " 'ami-transcripts/IS1003b.transcript.txt',\n",
       " 'ami-transcripts/ES2004d.transcript.txt',\n",
       " 'ami-transcripts/IS1004b.transcript.txt',\n",
       " 'ami-transcripts/ES2011d.transcript.txt',\n",
       " 'ami-transcripts/ES2016d.transcript.txt',\n",
       " 'ami-transcripts/TS3006d.transcript.txt',\n",
       " 'ami-transcripts/ES2010a.transcript.txt',\n",
       " 'ami-transcripts/ES2006c.transcript.txt',\n",
       " 'ami-transcripts/TS3011c.transcript.txt',\n",
       " 'ami-transcripts/TS3007a.transcript.txt',\n",
       " 'ami-transcripts/TS3012a.transcript.txt',\n",
       " 'ami-transcripts/ES2014c.transcript.txt',\n",
       " 'ami-transcripts/ES2002a.transcript.txt',\n",
       " 'ami-transcripts/TS3004c.transcript.txt',\n",
       " 'ami-transcripts/ES2013c.transcript.txt',\n",
       " 'ami-transcripts/ES2005a.transcript.txt',\n",
       " 'ami-transcripts/TS3003c.transcript.txt',\n",
       " 'ami-transcripts/ES2008b.transcript.txt',\n",
       " 'ami-transcripts/IS1008d.transcript.txt',\n",
       " 'ami-transcripts/TS3009c.transcript.txt',\n",
       " 'ami-transcripts/ES2008a.transcript.txt',\n",
       " 'ami-transcripts/IS1002d.transcript.txt',\n",
       " 'ami-transcripts/ES2002b.transcript.txt',\n",
       " 'ami-transcripts/TS3012b.transcript.txt',\n",
       " 'ami-transcripts/ES2005b.transcript.txt',\n",
       " 'ami-transcripts/ES2010b.transcript.txt',\n",
       " 'ami-transcripts/TS3007b.transcript.txt',\n",
       " 'ami-transcripts/IS1007c.transcript.txt',\n",
       " 'ami-transcripts/IS1000c.transcript.txt',\n",
       " 'ami-transcripts/IS1003a.transcript.txt',\n",
       " 'ami-transcripts/IS1004a.transcript.txt',\n",
       " 'ami-transcripts/IS1009b.transcript.txt',\n",
       " 'ami-transcripts/ES2009d.transcript.txt',\n",
       " 'ami-transcripts/ES2016b.transcript.txt',\n",
       " 'ami-transcripts/TS3006b.transcript.txt',\n",
       " 'ami-transcripts/ES2011b.transcript.txt',\n",
       " 'ami-transcripts/ES2009a.transcript.txt',\n",
       " 'ami-transcripts/TS3008c.transcript.txt',\n",
       " 'ami-transcripts/IS1004d.transcript.txt',\n",
       " 'ami-transcripts/ES2004b.transcript.txt',\n",
       " 'ami-transcripts/IS1003d.transcript.txt',\n",
       " 'ami-transcripts/ES2003b.transcript.txt',\n",
       " 'ami-transcripts/IS1005a.transcript.txt',\n",
       " 'ami-transcripts/IS1008b.transcript.txt',\n",
       " 'ami-transcripts/ES2008d.transcript.txt',\n",
       " 'ami-transcripts/IS1001c.transcript.txt',\n",
       " 'ami-transcripts/IS1006c.transcript.txt',\n",
       " 'ami-transcripts/TS3003b.transcript.txt',\n",
       " 'ami-transcripts/ES2013b.transcript.txt',\n",
       " 'ami-transcripts/TS3004b.transcript.txt',\n",
       " 'ami-transcripts/ES2014b.transcript.txt',\n",
       " 'ami-transcripts/ES2008c.transcript.txt',\n",
       " 'ami-transcripts/TS3009a.transcript.txt',\n",
       " 'ami-transcripts/IS1001d.transcript.txt',\n",
       " 'ami-transcripts/TS3011b.transcript.txt',\n",
       " 'ami-transcripts/IS1006d.transcript.txt',\n",
       " 'ami-transcripts/ES2006b.transcript.txt',\n",
       " 'ami-transcripts/IS1000a.transcript.txt',\n",
       " 'ami-transcripts/IS1007a.transcript.txt',\n",
       " 'ami-transcripts/TS3008d.transcript.txt',\n",
       " 'ami-transcripts/IS1004c.transcript.txt',\n",
       " 'ami-transcripts/IS1003c.transcript.txt',\n",
       " 'ami-transcripts/IS1007d.transcript.txt',\n",
       " 'ami-transcripts/ES2007b.transcript.txt',\n",
       " 'ami-transcripts/TS3010b.transcript.txt',\n",
       " 'ami-transcripts/IS1000d.transcript.txt',\n",
       " 'ami-transcripts/ES2015b.transcript.txt',\n",
       " 'ami-transcripts/TS3005b.transcript.txt',\n",
       " 'ami-transcripts/ES2012b.transcript.txt',\n",
       " 'ami-transcripts/TS3008a.transcript.txt',\n",
       " 'ami-transcripts/ES2009c.transcript.txt',\n",
       " 'ami-transcripts/TS3009d.transcript.txt',\n",
       " 'ami-transcripts/IS1002c.transcript.txt',\n",
       " 'ami-transcripts/IS1005c.transcript.txt',\n",
       " 'ami-transcripts/IS1006a.transcript.txt',\n",
       " 'ami-transcripts/IS1001a.transcript.txt',\n",
       " 'ami-transcripts/ES2006d.transcript.txt',\n",
       " 'ami-transcripts/IS1006b.transcript.txt',\n",
       " 'ami-transcripts/IS1001b.transcript.txt',\n",
       " 'ami-transcripts/TS3011d.transcript.txt',\n",
       " 'ami-transcripts/TS3004d.transcript.txt',\n",
       " 'ami-transcripts/ES2014d.transcript.txt',\n",
       " 'ami-transcripts/TS3003d.transcript.txt',\n",
       " 'ami-transcripts/ES2013d.transcript.txt',\n",
       " 'ami-transcripts/IS1008c.transcript.txt',\n",
       " 'ami-transcripts/TS3008b.transcript.txt',\n",
       " 'ami-transcripts/ES2003c.transcript.txt',\n",
       " 'ami-transcripts/TS3005a.transcript.txt',\n",
       " 'ami-transcripts/ES2015a.transcript.txt',\n",
       " 'ami-transcripts/ES2004c.transcript.txt',\n",
       " 'ami-transcripts/ES2012a.transcript.txt',\n",
       " 'ami-transcripts/ES2007a.transcript.txt',\n",
       " 'ami-transcripts/ES2011c.transcript.txt',\n",
       " 'ami-transcripts/TS3006c.transcript.txt',\n",
       " 'ami-transcripts/ES2016c.transcript.txt',\n",
       " 'ami-transcripts/TS3010a.transcript.txt',\n",
       " 'ami-transcripts/ES2012d.transcript.txt',\n",
       " 'ami-transcripts/ES2015d.transcript.txt',\n",
       " 'ami-transcripts/TS3005d.transcript.txt',\n",
       " 'ami-transcripts/IS1009c.transcript.txt',\n",
       " 'ami-transcripts/TS3010d.transcript.txt',\n",
       " 'ami-transcripts/IS1000b.transcript.txt',\n",
       " 'ami-transcripts/ES2007d.transcript.txt',\n",
       " 'ami-transcripts/IS1007b.transcript.txt',\n",
       " 'ami-transcripts/TS3011a.transcript.txt',\n",
       " 'ami-transcripts/TS3007c.transcript.txt',\n",
       " 'ami-transcripts/ES2010c.transcript.txt',\n",
       " 'ami-transcripts/ES2006a.transcript.txt',\n",
       " 'ami-transcripts/TS3009b.transcript.txt',\n",
       " 'ami-transcripts/ES2013a.transcript.txt',\n",
       " 'ami-transcripts/TS3003a.transcript.txt',\n",
       " 'ami-transcripts/ES2005c.transcript.txt',\n",
       " 'ami-transcripts/ES2014a.transcript.txt',\n",
       " 'ami-transcripts/TS3004a.transcript.txt',\n",
       " 'ami-transcripts/ES2002c.transcript.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_transc = 'ami-transcripts'\n",
    "fol_trans = [x[2] for x in os.walk(folder_transc)]\n",
    "ext_sum_trans = []\n",
    "for i in ext:\n",
    "    ext_sum_trans.append('ami-transcripts/' + i[ : i.find(\".\")] + '.transcript.txt' )\n",
    "ext_sum_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGDmyrlJbsvx",
    "outputId": "230eea71-f13b-4a9e-d64a-918c416cebe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstractive/ES2015a.abssumm.txt',\n",
       " 'abstractive/TS3005a.abssumm.txt',\n",
       " 'abstractive/ES2003c.abssumm.txt',\n",
       " 'abstractive/ES2012a.abssumm.txt',\n",
       " 'abstractive/ES2004c.abssumm.txt',\n",
       " 'abstractive/TS3008b.abssumm.txt',\n",
       " 'abstractive/ES2011c.abssumm.txt',\n",
       " 'abstractive/ES2007a.abssumm.txt',\n",
       " 'abstractive/TS3010a.abssumm.txt',\n",
       " 'abstractive/ES2016c.abssumm.txt',\n",
       " 'abstractive/TS3006c.abssumm.txt',\n",
       " 'abstractive/IB4005.abssumm.txt',\n",
       " 'abstractive/IB4010.abssumm.txt',\n",
       " 'abstractive/ES2006d.abssumm.txt',\n",
       " 'abstractive/IS1006b.abssumm.txt',\n",
       " 'abstractive/TS3011d.abssumm.txt',\n",
       " 'abstractive/IS1001b.abssumm.txt',\n",
       " 'abstractive/IS1008c.abssumm.txt',\n",
       " 'abstractive/ES2014d.abssumm.txt',\n",
       " 'abstractive/TS3004d.abssumm.txt',\n",
       " 'abstractive/ES2013d.abssumm.txt',\n",
       " 'abstractive/TS3003d.abssumm.txt',\n",
       " 'abstractive/TS3007c.abssumm.txt',\n",
       " 'abstractive/TS3011a.abssumm.txt',\n",
       " 'abstractive/ES2006a.abssumm.txt',\n",
       " 'abstractive/ES2010c.abssumm.txt',\n",
       " 'abstractive/ES2005c.abssumm.txt',\n",
       " 'abstractive/TS3003a.abssumm.txt',\n",
       " 'abstractive/ES2013a.abssumm.txt',\n",
       " 'abstractive/ES2002c.abssumm.txt',\n",
       " 'abstractive/TS3004a.abssumm.txt',\n",
       " 'abstractive/TS3012c.abssumm.txt',\n",
       " 'abstractive/ES2014a.abssumm.txt',\n",
       " 'abstractive/TS3009b.abssumm.txt',\n",
       " 'abstractive/IS1009c.abssumm.txt',\n",
       " 'abstractive/ES2012d.abssumm.txt',\n",
       " 'abstractive/TS3005d.abssumm.txt',\n",
       " 'abstractive/ES2015d.abssumm.txt',\n",
       " 'abstractive/IS1000b.abssumm.txt',\n",
       " 'abstractive/TS3010d.abssumm.txt',\n",
       " 'abstractive/ES2007d.abssumm.txt',\n",
       " 'abstractive/IS1007b.abssumm.txt',\n",
       " 'abstractive/IS1000a.abssumm.txt',\n",
       " 'abstractive/IS1007a.abssumm.txt',\n",
       " 'abstractive/IB4003.abssumm.txt',\n",
       " 'abstractive/IS1004c.abssumm.txt',\n",
       " 'abstractive/IS1003c.abssumm.txt',\n",
       " 'abstractive/TS3008d.abssumm.txt',\n",
       " 'abstractive/ES2008c.abssumm.txt',\n",
       " 'abstractive/TS3009a.abssumm.txt',\n",
       " 'abstractive/ES2013b.abssumm.txt',\n",
       " 'abstractive/TS3003b.abssumm.txt',\n",
       " 'abstractive/ES2014b.abssumm.txt',\n",
       " 'abstractive/TS3004b.abssumm.txt',\n",
       " 'abstractive/TS3011b.abssumm.txt',\n",
       " 'abstractive/IS1001d.abssumm.txt',\n",
       " 'abstractive/IS1006d.abssumm.txt',\n",
       " 'abstractive/ES2006b.abssumm.txt',\n",
       " 'abstractive/IS1002c.abssumm.txt',\n",
       " 'abstractive/IS1005c.abssumm.txt',\n",
       " 'abstractive/TS3009d.abssumm.txt',\n",
       " 'abstractive/IS1006a.abssumm.txt',\n",
       " 'abstractive/IS1001a.abssumm.txt',\n",
       " 'abstractive/IS1007d.abssumm.txt',\n",
       " 'abstractive/ES2007b.abssumm.txt',\n",
       " 'abstractive/IS1000d.abssumm.txt',\n",
       " 'abstractive/TS3010b.abssumm.txt',\n",
       " 'abstractive/TS3008a.abssumm.txt',\n",
       " 'abstractive/ES2009c.abssumm.txt',\n",
       " 'abstractive/TS3005b.abssumm.txt',\n",
       " 'abstractive/ES2015b.abssumm.txt',\n",
       " 'abstractive/ES2012b.abssumm.txt',\n",
       " 'abstractive/IS1007c.abssumm.txt',\n",
       " 'abstractive/IS1000c.abssumm.txt',\n",
       " 'abstractive/IS1009b.abssumm.txt',\n",
       " 'abstractive/ES2009d.abssumm.txt',\n",
       " 'abstractive/IS1003a.abssumm.txt',\n",
       " 'abstractive/IS1004a.abssumm.txt',\n",
       " 'abstractive/TS3012b.abssumm.txt',\n",
       " 'abstractive/IS1002d.abssumm.txt',\n",
       " 'abstractive/ES2002b.abssumm.txt',\n",
       " 'abstractive/ES2005b.abssumm.txt',\n",
       " 'abstractive/TS3009c.abssumm.txt',\n",
       " 'abstractive/ES2008a.abssumm.txt',\n",
       " 'abstractive/ES2010b.abssumm.txt',\n",
       " 'abstractive/TS3007b.abssumm.txt',\n",
       " 'abstractive/IS1008b.abssumm.txt',\n",
       " 'abstractive/ES2008d.abssumm.txt',\n",
       " 'abstractive/IS1005a.abssumm.txt',\n",
       " 'abstractive/IB4011.abssumm.txt',\n",
       " 'abstractive/IS1001c.abssumm.txt',\n",
       " 'abstractive/IS1006c.abssumm.txt',\n",
       " 'abstractive/TS3006b.abssumm.txt',\n",
       " 'abstractive/ES2016b.abssumm.txt',\n",
       " 'abstractive/ES2011b.abssumm.txt',\n",
       " 'abstractive/IS1004d.abssumm.txt',\n",
       " 'abstractive/ES2004b.abssumm.txt',\n",
       " 'abstractive/IS1003d.abssumm.txt',\n",
       " 'abstractive/ES2003b.abssumm.txt',\n",
       " 'abstractive/ES2009a.abssumm.txt',\n",
       " 'abstractive/TS3008c.abssumm.txt',\n",
       " 'abstractive/ES2009b.abssumm.txt',\n",
       " 'abstractive/IS1009d.abssumm.txt',\n",
       " 'abstractive/ES2012c.abssumm.txt',\n",
       " 'abstractive/ES2004a.abssumm.txt',\n",
       " 'abstractive/ES2015c.abssumm.txt',\n",
       " 'abstractive/ES2003a.abssumm.txt',\n",
       " 'abstractive/TS3005c.abssumm.txt',\n",
       " 'abstractive/ES2016a.abssumm.txt',\n",
       " 'abstractive/TS3010c.abssumm.txt',\n",
       " 'abstractive/TS3006a.abssumm.txt',\n",
       " 'abstractive/ES2011a.abssumm.txt',\n",
       " 'abstractive/ES2007c.abssumm.txt',\n",
       " 'abstractive/TS3007d.abssumm.txt',\n",
       " 'abstractive/ES2010d.abssumm.txt',\n",
       " 'abstractive/ES2005d.abssumm.txt',\n",
       " 'abstractive/IS1005b.abssumm.txt',\n",
       " 'abstractive/TS3012d.abssumm.txt',\n",
       " 'abstractive/ES2002d.abssumm.txt',\n",
       " 'abstractive/IS1002b.abssumm.txt',\n",
       " 'abstractive/IS1008a.abssumm.txt',\n",
       " 'abstractive/ES2006c.abssumm.txt',\n",
       " 'abstractive/ES2010a.abssumm.txt',\n",
       " 'abstractive/TS3007a.abssumm.txt',\n",
       " 'abstractive/TS3011c.abssumm.txt',\n",
       " 'abstractive/ES2008b.abssumm.txt',\n",
       " 'abstractive/IS1008d.abssumm.txt',\n",
       " 'abstractive/TS3004c.abssumm.txt',\n",
       " 'abstractive/ES2002a.abssumm.txt',\n",
       " 'abstractive/ES2014c.abssumm.txt',\n",
       " 'abstractive/TS3012a.abssumm.txt',\n",
       " 'abstractive/TS3003c.abssumm.txt',\n",
       " 'abstractive/ES2005a.abssumm.txt',\n",
       " 'abstractive/ES2013c.abssumm.txt',\n",
       " 'abstractive/ES2003d.abssumm.txt',\n",
       " 'abstractive/IS1003b.abssumm.txt',\n",
       " 'abstractive/ES2004d.abssumm.txt',\n",
       " 'abstractive/IS1004b.abssumm.txt',\n",
       " 'abstractive/IS1009a.abssumm.txt',\n",
       " 'abstractive/ES2011d.abssumm.txt',\n",
       " 'abstractive/TS3006d.abssumm.txt',\n",
       " 'abstractive/ES2016d.abssumm.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_abs = 'abstractive'\n",
    "abs_ = [x[2] for x in os.walk(folder_abs)]\n",
    "abs_summaries_files = []\n",
    "for i in abs_[0]:\n",
    "    abs_summaries_files.append('abstractive/' + i)\n",
    "abs_summaries_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsUQXqXcbsvx",
    "outputId": "5cc8f699-68ef-434f-c4ac-a680f4486648"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ami-transcripts/ES2015a.transcript.txt',\n",
       " 'ami-transcripts/TS3005a.transcript.txt',\n",
       " 'ami-transcripts/ES2003c.transcript.txt',\n",
       " 'ami-transcripts/ES2012a.transcript.txt',\n",
       " 'ami-transcripts/ES2004c.transcript.txt',\n",
       " 'ami-transcripts/TS3008b.transcript.txt',\n",
       " 'ami-transcripts/ES2011c.transcript.txt',\n",
       " 'ami-transcripts/ES2007a.transcript.txt',\n",
       " 'ami-transcripts/TS3010a.transcript.txt',\n",
       " 'ami-transcripts/ES2016c.transcript.txt',\n",
       " 'ami-transcripts/TS3006c.transcript.txt',\n",
       " 'ami-transcripts/IB4005.transcript.txt',\n",
       " 'ami-transcripts/IB4010.transcript.txt',\n",
       " 'ami-transcripts/ES2006d.transcript.txt',\n",
       " 'ami-transcripts/IS1006b.transcript.txt',\n",
       " 'ami-transcripts/TS3011d.transcript.txt',\n",
       " 'ami-transcripts/IS1001b.transcript.txt',\n",
       " 'ami-transcripts/IS1008c.transcript.txt',\n",
       " 'ami-transcripts/ES2014d.transcript.txt',\n",
       " 'ami-transcripts/TS3004d.transcript.txt',\n",
       " 'ami-transcripts/ES2013d.transcript.txt',\n",
       " 'ami-transcripts/TS3003d.transcript.txt',\n",
       " 'ami-transcripts/TS3007c.transcript.txt',\n",
       " 'ami-transcripts/TS3011a.transcript.txt',\n",
       " 'ami-transcripts/ES2006a.transcript.txt',\n",
       " 'ami-transcripts/ES2010c.transcript.txt',\n",
       " 'ami-transcripts/ES2005c.transcript.txt',\n",
       " 'ami-transcripts/TS3003a.transcript.txt',\n",
       " 'ami-transcripts/ES2013a.transcript.txt',\n",
       " 'ami-transcripts/ES2002c.transcript.txt',\n",
       " 'ami-transcripts/TS3004a.transcript.txt',\n",
       " 'ami-transcripts/TS3012c.transcript.txt',\n",
       " 'ami-transcripts/ES2014a.transcript.txt',\n",
       " 'ami-transcripts/TS3009b.transcript.txt',\n",
       " 'ami-transcripts/IS1009c.transcript.txt',\n",
       " 'ami-transcripts/ES2012d.transcript.txt',\n",
       " 'ami-transcripts/TS3005d.transcript.txt',\n",
       " 'ami-transcripts/ES2015d.transcript.txt',\n",
       " 'ami-transcripts/IS1000b.transcript.txt',\n",
       " 'ami-transcripts/TS3010d.transcript.txt',\n",
       " 'ami-transcripts/ES2007d.transcript.txt',\n",
       " 'ami-transcripts/IS1007b.transcript.txt',\n",
       " 'ami-transcripts/IS1000a.transcript.txt',\n",
       " 'ami-transcripts/IS1007a.transcript.txt',\n",
       " 'ami-transcripts/IB4003.transcript.txt',\n",
       " 'ami-transcripts/IS1004c.transcript.txt',\n",
       " 'ami-transcripts/IS1003c.transcript.txt',\n",
       " 'ami-transcripts/TS3008d.transcript.txt',\n",
       " 'ami-transcripts/ES2008c.transcript.txt',\n",
       " 'ami-transcripts/TS3009a.transcript.txt',\n",
       " 'ami-transcripts/ES2013b.transcript.txt',\n",
       " 'ami-transcripts/TS3003b.transcript.txt',\n",
       " 'ami-transcripts/ES2014b.transcript.txt',\n",
       " 'ami-transcripts/TS3004b.transcript.txt',\n",
       " 'ami-transcripts/TS3011b.transcript.txt',\n",
       " 'ami-transcripts/IS1001d.transcript.txt',\n",
       " 'ami-transcripts/IS1006d.transcript.txt',\n",
       " 'ami-transcripts/ES2006b.transcript.txt',\n",
       " 'ami-transcripts/IS1002c.transcript.txt',\n",
       " 'ami-transcripts/IS1005c.transcript.txt',\n",
       " 'ami-transcripts/TS3009d.transcript.txt',\n",
       " 'ami-transcripts/IS1006a.transcript.txt',\n",
       " 'ami-transcripts/IS1001a.transcript.txt',\n",
       " 'ami-transcripts/IS1007d.transcript.txt',\n",
       " 'ami-transcripts/ES2007b.transcript.txt',\n",
       " 'ami-transcripts/IS1000d.transcript.txt',\n",
       " 'ami-transcripts/TS3010b.transcript.txt',\n",
       " 'ami-transcripts/TS3008a.transcript.txt',\n",
       " 'ami-transcripts/ES2009c.transcript.txt',\n",
       " 'ami-transcripts/TS3005b.transcript.txt',\n",
       " 'ami-transcripts/ES2015b.transcript.txt',\n",
       " 'ami-transcripts/ES2012b.transcript.txt',\n",
       " 'ami-transcripts/IS1007c.transcript.txt',\n",
       " 'ami-transcripts/IS1000c.transcript.txt',\n",
       " 'ami-transcripts/IS1009b.transcript.txt',\n",
       " 'ami-transcripts/ES2009d.transcript.txt',\n",
       " 'ami-transcripts/IS1003a.transcript.txt',\n",
       " 'ami-transcripts/IS1004a.transcript.txt',\n",
       " 'ami-transcripts/TS3012b.transcript.txt',\n",
       " 'ami-transcripts/IS1002d.transcript.txt',\n",
       " 'ami-transcripts/ES2002b.transcript.txt',\n",
       " 'ami-transcripts/ES2005b.transcript.txt',\n",
       " 'ami-transcripts/TS3009c.transcript.txt',\n",
       " 'ami-transcripts/ES2008a.transcript.txt',\n",
       " 'ami-transcripts/ES2010b.transcript.txt',\n",
       " 'ami-transcripts/TS3007b.transcript.txt',\n",
       " 'ami-transcripts/IS1008b.transcript.txt',\n",
       " 'ami-transcripts/ES2008d.transcript.txt',\n",
       " 'ami-transcripts/IS1005a.transcript.txt',\n",
       " 'ami-transcripts/IB4011.transcript.txt',\n",
       " 'ami-transcripts/IS1001c.transcript.txt',\n",
       " 'ami-transcripts/IS1006c.transcript.txt',\n",
       " 'ami-transcripts/TS3006b.transcript.txt',\n",
       " 'ami-transcripts/ES2016b.transcript.txt',\n",
       " 'ami-transcripts/ES2011b.transcript.txt',\n",
       " 'ami-transcripts/IS1004d.transcript.txt',\n",
       " 'ami-transcripts/ES2004b.transcript.txt',\n",
       " 'ami-transcripts/IS1003d.transcript.txt',\n",
       " 'ami-transcripts/ES2003b.transcript.txt',\n",
       " 'ami-transcripts/ES2009a.transcript.txt',\n",
       " 'ami-transcripts/TS3008c.transcript.txt',\n",
       " 'ami-transcripts/ES2009b.transcript.txt',\n",
       " 'ami-transcripts/IS1009d.transcript.txt',\n",
       " 'ami-transcripts/ES2012c.transcript.txt',\n",
       " 'ami-transcripts/ES2004a.transcript.txt',\n",
       " 'ami-transcripts/ES2015c.transcript.txt',\n",
       " 'ami-transcripts/ES2003a.transcript.txt',\n",
       " 'ami-transcripts/TS3005c.transcript.txt',\n",
       " 'ami-transcripts/ES2016a.transcript.txt',\n",
       " 'ami-transcripts/TS3010c.transcript.txt',\n",
       " 'ami-transcripts/TS3006a.transcript.txt',\n",
       " 'ami-transcripts/ES2011a.transcript.txt',\n",
       " 'ami-transcripts/ES2007c.transcript.txt',\n",
       " 'ami-transcripts/TS3007d.transcript.txt',\n",
       " 'ami-transcripts/ES2010d.transcript.txt',\n",
       " 'ami-transcripts/ES2005d.transcript.txt',\n",
       " 'ami-transcripts/IS1005b.transcript.txt',\n",
       " 'ami-transcripts/TS3012d.transcript.txt',\n",
       " 'ami-transcripts/ES2002d.transcript.txt',\n",
       " 'ami-transcripts/IS1002b.transcript.txt',\n",
       " 'ami-transcripts/IS1008a.transcript.txt',\n",
       " 'ami-transcripts/ES2006c.transcript.txt',\n",
       " 'ami-transcripts/ES2010a.transcript.txt',\n",
       " 'ami-transcripts/TS3007a.transcript.txt',\n",
       " 'ami-transcripts/TS3011c.transcript.txt',\n",
       " 'ami-transcripts/ES2008b.transcript.txt',\n",
       " 'ami-transcripts/IS1008d.transcript.txt',\n",
       " 'ami-transcripts/TS3004c.transcript.txt',\n",
       " 'ami-transcripts/ES2002a.transcript.txt',\n",
       " 'ami-transcripts/ES2014c.transcript.txt',\n",
       " 'ami-transcripts/TS3012a.transcript.txt',\n",
       " 'ami-transcripts/TS3003c.transcript.txt',\n",
       " 'ami-transcripts/ES2005a.transcript.txt',\n",
       " 'ami-transcripts/ES2013c.transcript.txt',\n",
       " 'ami-transcripts/ES2003d.transcript.txt',\n",
       " 'ami-transcripts/IS1003b.transcript.txt',\n",
       " 'ami-transcripts/ES2004d.transcript.txt',\n",
       " 'ami-transcripts/IS1004b.transcript.txt',\n",
       " 'ami-transcripts/IS1009a.transcript.txt',\n",
       " 'ami-transcripts/ES2011d.transcript.txt',\n",
       " 'ami-transcripts/TS3006d.transcript.txt',\n",
       " 'ami-transcripts/ES2016d.transcript.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_transc = 'ami-transcripts'\n",
    "fol_trans = [x[2] for x in os.walk(folder_transc)]\n",
    "abs_sum_trans = []\n",
    "for i in abs_[0]:\n",
    "    abs_sum_trans.append('ami-transcripts/' + i[ : i.find(\".\")] + '.transcript.txt' )\n",
    "abs_sum_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAYhSnk1bsvy"
   },
   "source": [
    "Составим датафрейм с 2 столбцами: текст и реферат к нему "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "uBUnM7Enbsvy",
    "outputId": "6f76fbd4-5cce-48fd-9b8c-bd58f0e74c75"
   },
   "outputs": [],
   "source": [
    "# extractive\n",
    "# summaries\n",
    "import pandas as pd\n",
    "summaries_extractive = []\n",
    "for i in ext_summaries_files:\n",
    "    test1 = open(i, \"r\", errors = 'ignore')\n",
    "    transcript1 = test1.read()\n",
    "    summaries_extractive.append(transcript1)\n",
    "# texts\n",
    "text_extractive = []\n",
    "for j in ext_sum_trans:\n",
    "    test2 = open(j, \"r\", errors = 'ignore')\n",
    "    transcript2 = test2.read()\n",
    "    text_extractive.append(transcript2)\n",
    "df_extractive = pd.DataFrame({'extractive_text': text_extractive, 'extractive_summary': summaries_extractive})\n",
    "df_extractive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISMwHWS4bsvz"
   },
   "outputs": [],
   "source": [
    "df_extractive.to_csv('extractive_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aFyQN5zbsvz",
    "outputId": "fdfbba73-5061-4779-fac1-6f76377fa529"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstractive_text</th>\n",
       "      <th>abstarctive_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Okay okay Okay. Hello. Okay. My name's Poppy. ...</td>\n",
       "      <td>The project manager opens the meeting by intro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning. Sorry? Yeah, busy job. Good morn...</td>\n",
       "      <td>The project manager acquainted the team with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alright, yeah. crack on. Okay so we'll start o...</td>\n",
       "      <td>The project manager recapped the decisions mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right w welcome to the the first meeting of uh...</td>\n",
       "      <td>The project manager opens the meeting by welco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oops. Mm. After lunch. Yeah. Mm-hmm. Mm-hmm. '...</td>\n",
       "      <td>The Project Manager reviewed the decisions fro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    abstractive_text  \\\n",
       "0  Okay okay Okay. Hello. Okay. My name's Poppy. ...   \n",
       "1  Good morning. Sorry? Yeah, busy job. Good morn...   \n",
       "2  Alright, yeah. crack on. Okay so we'll start o...   \n",
       "3  Right w welcome to the the first meeting of uh...   \n",
       "4  Oops. Mm. After lunch. Yeah. Mm-hmm. Mm-hmm. '...   \n",
       "\n",
       "                                 abstarctive_summary  \n",
       "0  The project manager opens the meeting by intro...  \n",
       "1  The project manager acquainted the team with t...  \n",
       "2  The project manager recapped the decisions mad...  \n",
       "3  The project manager opens the meeting by welco...  \n",
       "4  The Project Manager reviewed the decisions fro...  "
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extractive\n",
    "# summaries\n",
    "import pandas as pd\n",
    "summaries_extractive = []\n",
    "for i in abs_summaries_files:\n",
    "    test1 = open(i, \"r\", errors = 'ignore')\n",
    "    transcript1 = test1.read()\n",
    "    summaries_extractive.append(transcript1)\n",
    "# texts\n",
    "text_extractive = []\n",
    "for j in abs_sum_trans:\n",
    "    test2 = open(j, \"r\", errors = 'ignore')\n",
    "    transcript2 = test2.read()\n",
    "    text_extractive.append(transcript2)\n",
    "df_abstractive = pd.DataFrame({'abstractive_text': text_extractive, 'abstarctive_summary': summaries_extractive})\n",
    "df_abstractive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHRZFlzJbsvz"
   },
   "outputs": [],
   "source": [
    "df_abstractive.to_csv('abstractive_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkYa8xboanVX"
   },
   "source": [
    "## Обработка текста "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLn4PZRKanVX",
    "outputId": "6d501be3-dc51-4d3a-bab5-2948d4380eee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import re, numpy as np, pandas as pd\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "stopwords_english = stopwords.words('english')\n",
    "stopwords_english.append('um')\n",
    "stopwords_english.append('Hmm')\n",
    "stopwords_english.append('Um')\n",
    "stopwords_english.append('okay')\n",
    "stopwords_english.append('uh')\n",
    "stopwords_english.append('Yeah')\n",
    "stopwords_english.append('yeah')\n",
    "stopwords_english.append('Mm')\n",
    "stopwords_english.append('well')\n",
    "stopwords_english.append('Well')\n",
    "stopwords_english.append('hmm')\n",
    "stopwords_english.append('weve')\n",
    "stopwords_english.append('ive')\n",
    "stopwords_english.append('yep')\n",
    "stopwords_english.append('alright')\n",
    "stopwords_english.append('Alright')\n",
    "stopwords_english.append('mm')\n",
    "stopwords_english.append('kay')\n",
    "stopwords_english.append('gosh')\n",
    "stopwords_english.append('like')\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXutK62BanVY",
    "outputId": "cd6a3191-8b50-4028-c74c-fb866913ff9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Um I'm Craig and I'm User Interface. Yeah. Well, my favourite animal would be a monkey. Then they're small cute and furry, and uh when planet of the apes becomes real, I'm gonna be up there with them. Yeah. I know um My parents went out and bought um remote controls because um they got fed up of having four or five different remote controls for each things the house. So um for them it was just how many devices control. Uh.Mm-hmm. Great. And I'm Andrew and I'm uh our marketing expert. Mm-hmm. Mm-hmm. Yeah, that's that's it. Yeah. I will go. That's fine. Alright. So This one here, right? Okay. Very nice. Alright. My favourite animal is like A beagle. Um charac favourite characteristics of it? Is that right? Uh, right, well basically um high priority for any animal for me is that they be willing to take a lot of physical affection from their family. And, yeah that they have lots of personality and uh be fit and in robust good health. So this is blue. Blue beagle. My family's beagle. I coulda told you a whole lot more about beagles. Boy, let me tell you. Impressionist. Alright. Mm. Superb sketch, by the way. Yep. I see a dog in there. Yep. Now I see a rooster. What kind is it? Is he aware that th it's his own cha tail he's chasing? Hmm. Probably when he was little he got lots of attention for doing it and has forever been conditioned. 'Kay. Um, can we just go over that again? Uh, so bas at twel Alright, yeah. Okay. So cost like production cost is twelve fifty, but selling price is is that wholesale or retail? Like on the shelf. Our sale our sale anyway. Yeah, okay okay. Okay. Mm-hmm. Alright. Yes. Mm-hmm. Mm-hmm. Well right away I'm wondering if there's um th th uh, like with D_V_D_ players, if there are zones. Um f frequencies or something um as well as uh characters, um different uh keypad styles and s symbols. Um. I don't know. Yeah. Yeah. Yeah. And then a and then al the other thing international is on top of the price. I'm thinking the price might might appeal to a certain market in one region, whereas in another it'll be different, so Just a chara just a characteristic of the Just Or just like, basic product podi positioning, the twenty five Euro remote control might be a big hit in London, might not be such a big hit in Greece, who knows, something like that, yeah. Yep. Right away I'm making some kind of assumptions about what what information we're given here, thinking, 'kay trendy probably means something other than just basic, something other than just standard. Um so I'm wondering right away, is selling twenty five Euros, is that sort of the thi is this gonna to be like the premium product kinda thing or Uh-huh. Mm-hmm. Yep. Yeah, I'd say so, yeah. No. Yeah, yeah. Mm-hmm. Do we have any other background information on like how that compares to other other Yeah. Mm-hmm. Yeah, interesting thing about discussing um production of a remote control for me is that l as you point out, I just don't think of remote controls as somethin something people consciously assess in their purchasing habits. It's just like getting shoelaces with shoes or something. It just comes along. Do you know what I mean? Like so sort of like how do you I I mean one one way of looking at it would be, well the people producing television sets, maybe they have to buy remote controls. Or another way is maybe people who have T_V_ sets are really fed up with their remote control and they really want a better one or something. But Right. Right. Okay so Right, so in function one of the priorities might be to combine as many uses I think so. Yeah, yeah. Yeah. Well like um, maybe what we could use is a sort of like a example of a successful other piece technology is palm palm pilots. They're gone from being just like little sort of scribble boards to cameras, M_P_ three players, telephones, everything, agenda. So, like, I wonder if we might add something new to the to the remote control market, such as the lighting in your house, or um Yeah, yeah. An Yeah. Like, p personally for me, at home I've I've combined the um the audio video of my television set and my D_V_D_ player and my C_D_ player. So they w all work actually function together but I have different remote controls for each of them. So it's sort of ironic that that then they're in there um you know, the sound and everything it's just one system. But each one's got its own little part. Mm. Mm. Mm. Mm-hmm. Mm-hmm. Yeah. Yeah. That's just really good id Yep. Uh, sure. I remember when the first remote control my my family had was on a cable. Actually had a cable between it and the T_V_ and big like buttons that sort of like, like on a blender or something. And um, you know, when I think about what they are now, it's better, but actually it's still kind of, I dunno, like a massive junky thing on the table. Maybe we could think about how, could be more, you know, streamlined. S Something like that, yeah. Or whatever would be technologically reasonable. 'Cause it could b it could it could be that f it could be that functionally that doesn't make it any better, but that just the appeal of of not having You know, these days there's a r pe things in people's homes are becoming more and more like chic, you know. Um, nicer materials and might be be worth exploring anyway. Okay. Um. Before we wrap up, just to make sure we're all on the same page here, um, do we We were given sort of an example of a coffee machine or something, right? Well, um are we at ma right now on the assumption that our television remote control may have features which go beyond the television? Or are we keeping sort of like a a design commitment to television features? I I don't know. Yep. Yeah, sure. Okay. Okay, yeah. Okay. Okay. Okay. Alright.Okay. Right. Um well this is the kick-off meeting for our our project. Um and um this is just what we're gonna be doing over the next twenty five minutes. Um so first of all, just to kind of make sure that we all know each other, I'm Laura and I'm the project manager. Do you want to introduce yourself again? Okay. Great. Okay. Um so we're designing a new remote control and um Oh I have to record who's here actually. So that's David, Andrew and Craig, isn't it? And you all arrived on time. Um yeah so des uh design a new remote control. Um, as you can see it's supposed to be original, trendy and user friendly. Um so that's kind of our our brief, as it were. Um and so there are three different stages to the design. Um I'm not really sure what what you guys have already received um in your emails. What did you get? Mm-hmm. Is that what everybody got? Okay. Um. So we're gonna have like individual work and then a meeting about it. And repeat that process three times. Um and at this point we get try out the whiteboard over there. Um. So uh you get to draw your favourite animal and sum up your favourite characteristics of it. So who would like to go first? Very good. Mm-hmm. Yeah. Yeah. Right. Lovely. Right. You can take as long over this as you like, because we haven't got an awful lot to discuss. Ok oh we do we do. Don't feel like you're in a rush, anyway. Ach why not We might have to get you up again then. I don't know what mine is. I'm gonna have to think on the spot now. Is that a whale? Ah. Okay. God, I still don't know what I'm gonna write about. Um. I was gonna choose a dog as well. But I'll just draw a different kind of dog. M my favourite animal is my own dog at home. Um That doesn't really look like him, actually. He looks more like a pig, actually. Ah well. Do you? Oh that's very good of you. Uh. Um he's a mixture of uh various things. Um and what do I like about him, um That's just to suggest that his tail wags. Um he's very friendly and cheery and always pleased to see you, and very kind of affectionate and um uh and he's quite quite wee as well so you know he can doesn't take up too much space. Um and uh And he does a funny thing where he chases his tail as well, which is quite amusing, so It is. I think it is. He only does it after he's had his dinner and um he'll just all of a sudden just get up and start chasing his tail 'round the living room. Yeah, so uh Yeah, maybe. Maybe. Right, um where did you find this? Just down here? Yeah. Okay. Um what are we doing next? Uh um. Okay, uh we now need to discuss the project finance. Um so according to the brief um we're gonna be selling this remote control for twenty five Euro, um and we're aiming to make fifty million Euro. Um so we're gonna be selling this on an international scale. And uh we don't want it to cost any more than uh twelve fifty Euros, so fifty percent of the selling price. Sure. All together. Um I dunno. I imagine That's a good question. I imagine it probably is our sale actually because it's probably up to the the um the retailer to uh sell it for whatever price they want. Um. But I I don't know, I mean do you think the fact that it's going to be sold internationally will have a bearing on how we design it at all? Think it will? Um. Hmm. Oh yeah, regions and stuff, yeah. Yeah. Okay. Yeah. Well for a remote control, do you think that will be I suppose it's depends on how complicated our remote control is. Yeah, yeah. Okay. What, just like in terms of like the wealth of the country? Like how much money people have to spend on things like? Aye, I see what you mean, yeah. Marketing. Good marketing thoughts. Oh gosh, I should be writing all this down. Um. Mm. Yeah. Yeah, yeah. Like how much does, you know, a remote control cost. Well twenty five Euro, I mean that's um that's about like eighteen pounds or something, isn't it? Or no, is it as much as that? Sixteen seventeen eighteen pounds. Um, I dunno, I've never bought a remote control, so I don't know how how good a remote control that would get you. Um. But yeah, I suppose it has to look kind of cool and gimmicky. Um right, okay. Let me just scoot on ahead here. Okay. Um well d Does anybody have anything to add to uh to the finance issue at all? Thin No, actually. That would be useful, though, wouldn't it, if you knew like what your money would get you now. Mm-hmm. Yeah, yeah. Oh. Five minutes to end of meeting. Oh, okay. We're a bit behind. Yeah. Right, so do you think that should be like a main design aim of our remote control d you know, do your your satellite and your regular telly and your V_C_R_ and everything? Mm-hmm. Yeah. Or even like, you know, notes about um what you wanna watch. Like you might put in there oh I want to watch such and such and look a Oh that's a good idea. So extra functionalities. Mm-hmm. Hmm. Um okay, uh I'd wel we're gonna have to wrap up pretty quickly in the next couple of minutes. Um I'll just check we've nothing else. Okay. Um so anything else anybody wants to add about what they don't like about remote controls they've used, what they would really like to be part of this new one at all? You keep losing them. Okay. Yeah. W You get those ones where you can, if you like, whistle or make a really high pitched noise they beep. There I mean is that something we'd want to include, do you think? Dunno. Okay maybe. My goodness. Still feels quite primitive. Maybe like a touch screen or something? Okay. Uh-huh, okay. Well I guess that's up to our industrial designer. It looks better. Yeah. Okay. Okay. Right, well um so just to wrap up, the next meeting's gonna be in thirty minutes. So that's about um about ten to twelve by my watch. Um so inbetween now and then, um as the industrial designer, you're gonna be working on you know the actual working design of it so y you know what you're doing there. Um for user interface, technical functions, I guess that's you know like what we've been talking about, what it'll actually do. Um and uh marketing executive, you'll be just thinking about what it actually what, you know, what requirements it has to has to fulfil and you'll all get instructions emailed to you, I guess. Um. Yeah, so it's th the functional design stage is next, I guess. And uh and that's the end of the meeting. So I got that little message a lot sooner than I thought I would, so Mm-hmm. Uh-huh, yeah. Th Okay, well just very quickly 'cause this we're supposed to finish now. Um I guess that's up to us, I mean you probably want some kind of unique selling point of it, so um, you know Yeah. Mm-hmm. Yeah. Okay. Right, okay, we'll that's that's the end of the meeting, then. Um. So, uh thank you all for coming.Hi, I'm David and I'm supposed to be an industrial designer. Um, I just got the project announcement about what the project is. Designing a remote control. That's about it, didn't get anything else. Did you get the same thing? Cool. There's too much gear. Okay. Can't draw. Um. Yeah. Um, well anyway, I don't know, it's just the first animal I can think off the top of my head. Um. Yes. Big reason is 'cause I'm allergic to most animals. Allergic to animal fur, so um fish was a natural choice. Um, yeah, and I kind of like whales. They come in and go eat everything in sight. And they're quite harmless and mild and interesting. Tail's a bit big, I think. It's an after dinner dog then. Hmm. It does make sense from maybe the design point of view 'cause you have more complicated characters like European languages, then you need more buttons. So, possibly. Hmm. Yeah. And you keep losing them. Finding them is really a pain, you know. I mean it's usually quite small, or when you want it right, it slipped behind the couch or it's kicked under the table. You know. Yep. Mm-hmm. I think one factor would be production cost. Because there's a cap there, so um depends on how much you can cram into that price. Um. I think that that's the main factor. Cool.\""
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# убираем знак новой строки \n",
    "a2 = transcript.replace(\"\\n\", \"\")\n",
    "a = a2.replace(\"\\ \", \" \")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fer3xj7EanVY"
   },
   "outputs": [],
   "source": [
    "# убираем знаки препинания из текста \n",
    "text =[]\n",
    "split_regex = re.compile(r'[.|!|?|…]')\n",
    "sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "for s in sentences:\n",
    "    text.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yV8B7eLxanVZ",
    "outputId": "7ef102c5-d5ce-4232-a454-9ed98e515bfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Um I'm Craig and I'm User Interface\",\n",
       " 'Yeah',\n",
       " 'Well, my favourite animal would be a monkey',\n",
       " \"Then they're small cute and furry, and uh when planet of the apes becomes real, I'm gonna be up there with them\",\n",
       " 'Yeah',\n",
       " 'I know um My parents went out and bought um remote controls because um they got fed up of having four or five different remote controls for each things the house',\n",
       " 'So um for them it was just how many devices control',\n",
       " 'Uh',\n",
       " 'Mm-hmm',\n",
       " 'Great',\n",
       " \"And I'm Andrew and I'm uh our marketing expert\",\n",
       " 'Mm-hmm',\n",
       " 'Mm-hmm',\n",
       " \"Yeah, that's that's it\",\n",
       " 'Yeah',\n",
       " 'I will go',\n",
       " \"That's fine\",\n",
       " 'Alright',\n",
       " 'So This one here, right',\n",
       " 'Okay',\n",
       " 'Very nice',\n",
       " 'Alright',\n",
       " 'My favourite animal is like A beagle',\n",
       " 'Um charac favourite characteristics of it',\n",
       " 'Is that right',\n",
       " 'Uh, right, well basically um high priority for any animal for me is that they be willing to take a lot of physical affection from their family',\n",
       " 'And, yeah that they have lots of personality and uh be fit and in robust good health',\n",
       " 'So this is blue',\n",
       " 'Blue beagle',\n",
       " \"My family's beagle\",\n",
       " 'I coulda told you a whole lot more about beagles',\n",
       " 'Boy, let me tell you',\n",
       " 'Impressionist',\n",
       " 'Alright',\n",
       " 'Mm',\n",
       " 'Superb sketch, by the way',\n",
       " 'Yep',\n",
       " 'I see a dog in there',\n",
       " 'Yep',\n",
       " 'Now I see a rooster',\n",
       " 'What kind is it',\n",
       " \"Is he aware that th it's his own cha tail he's chasing\",\n",
       " 'Hmm',\n",
       " 'Probably when he was little he got lots of attention for doing it and has forever been conditioned',\n",
       " \"'Kay\",\n",
       " 'Um, can we just go over that again',\n",
       " 'Uh, so bas at twel Alright, yeah',\n",
       " 'Okay',\n",
       " 'So cost like production cost is twelve fifty, but selling price is is that wholesale or retail',\n",
       " 'Like on the shelf',\n",
       " 'Our sale our sale anyway',\n",
       " 'Yeah, okay okay',\n",
       " 'Okay',\n",
       " 'Mm-hmm',\n",
       " 'Alright',\n",
       " 'Yes',\n",
       " 'Mm-hmm',\n",
       " 'Mm-hmm',\n",
       " \"Well right away I'm wondering if there's um th th uh, like with D_V_D_ players, if there are zones\",\n",
       " 'Um f frequencies or something um as well as uh characters, um different uh keypad styles and s symbols',\n",
       " 'Um',\n",
       " \"I don't know\",\n",
       " 'Yeah',\n",
       " 'Yeah',\n",
       " 'Yeah',\n",
       " 'And then a and then al the other thing international is on top of the price',\n",
       " \"I'm thinking the price might might appeal to a certain market in one region, whereas in another it'll be different, so Just a chara just a characteristic of the Just Or just like, basic product podi positioning, the twenty five Euro remote control might be a big hit in London, might not be such a big hit in Greece, who knows, something like that, yeah\",\n",
       " 'Yep',\n",
       " \"Right away I'm making some kind of assumptions about what what information we're given here, thinking, 'kay trendy probably means something other than just basic, something other than just standard\",\n",
       " \"Um so I'm wondering right away, is selling twenty five Euros, is that sort of the thi is this gonna to be like the premium product kinda thing or Uh-huh\",\n",
       " 'Mm-hmm',\n",
       " 'Yep',\n",
       " \"Yeah, I'd say so, yeah\",\n",
       " 'No',\n",
       " 'Yeah, yeah',\n",
       " 'Mm-hmm',\n",
       " 'Do we have any other background information on like how that compares to other other Yeah',\n",
       " 'Mm-hmm',\n",
       " \"Yeah, interesting thing about discussing um production of a remote control for me is that l as you point out, I just don't think of remote controls as somethin something people consciously assess in their purchasing habits\",\n",
       " \"It's just like getting shoelaces with shoes or something\",\n",
       " 'It just comes along',\n",
       " 'Do you know what I mean',\n",
       " 'Like so sort of like how do you I I mean one one way of looking at it would be, well the people producing television sets, maybe they have to buy remote controls',\n",
       " 'Or another way is maybe people who have T_V_ sets are really fed up with their remote control and they really want a better one or something',\n",
       " 'But Right',\n",
       " 'Right',\n",
       " 'Okay so Right, so in function one of the priorities might be to combine as many uses I think so',\n",
       " 'Yeah, yeah',\n",
       " 'Yeah',\n",
       " 'Well like um, maybe what we could use is a sort of like a example of a successful other piece technology is palm palm pilots',\n",
       " \"They're gone from being just like little sort of scribble boards to cameras, M_P_ three players, telephones, everything, agenda\",\n",
       " 'So, like, I wonder if we might add something new to the to the remote control market, such as the lighting in your house, or um Yeah, yeah',\n",
       " 'An Yeah',\n",
       " \"Like, p personally for me, at home I've I've combined the um the audio video of my television set and my D_V_D_ player and my C_D_ player\",\n",
       " 'So they w all work actually function together but I have different remote controls for each of them',\n",
       " \"So it's sort of ironic that that then they're in there um you know, the sound and everything it's just one system\",\n",
       " \"But each one's got its own little part\",\n",
       " 'Mm',\n",
       " 'Mm',\n",
       " 'Mm',\n",
       " 'Mm-hmm',\n",
       " 'Mm-hmm',\n",
       " 'Yeah',\n",
       " 'Yeah',\n",
       " \"That's just really good id Yep\",\n",
       " 'Uh, sure',\n",
       " 'I remember when the first remote control my my family had was on a cable',\n",
       " 'Actually had a cable between it and the T_V_ and big like buttons that sort of like, like on a blender or something',\n",
       " \"And um, you know, when I think about what they are now, it's better, but actually it's still kind of, I dunno, like a massive junky thing on the table\",\n",
       " 'Maybe we could think about how, could be more, you know, streamlined',\n",
       " 'S Something like that, yeah',\n",
       " 'Or whatever would be technologically reasonable',\n",
       " \"'Cause it could b it could it could be that f it could be that functionally that doesn't make it any better, but that just the appeal of of not having You know, these days there's a r pe things in people's homes are becoming more and more like chic, you know\",\n",
       " 'Um, nicer materials and might be be worth exploring anyway',\n",
       " 'Okay',\n",
       " 'Um',\n",
       " \"Before we wrap up, just to make sure we're all on the same page here, um, do we We were given sort of an example of a coffee machine or something, right\",\n",
       " 'Well, um are we at ma right now on the assumption that our television remote control may have features which go beyond the television',\n",
       " 'Or are we keeping sort of like a a design commitment to television features',\n",
       " \"I I don't know\",\n",
       " 'Yep',\n",
       " 'Yeah, sure',\n",
       " 'Okay',\n",
       " 'Okay, yeah',\n",
       " 'Okay',\n",
       " 'Okay',\n",
       " 'Okay',\n",
       " 'Alright',\n",
       " 'Okay',\n",
       " 'Right',\n",
       " 'Um well this is the kick-off meeting for our our project',\n",
       " \"Um and um this is just what we're gonna be doing over the next twenty five minutes\",\n",
       " \"Um so first of all, just to kind of make sure that we all know each other, I'm Laura and I'm the project manager\",\n",
       " 'Do you want to introduce yourself again',\n",
       " 'Okay',\n",
       " 'Great',\n",
       " 'Okay',\n",
       " \"Um so we're designing a new remote control and um Oh I have to record who's here actually\",\n",
       " \"So that's David, Andrew and Craig, isn't it\",\n",
       " 'And you all arrived on time',\n",
       " 'Um yeah so des uh design a new remote control',\n",
       " \"Um, as you can see it's supposed to be original, trendy and user friendly\",\n",
       " \"Um so that's kind of our our brief, as it were\",\n",
       " 'Um and so there are three different stages to the design',\n",
       " \"Um I'm not really sure what what you guys have already received um in your emails\",\n",
       " 'What did you get',\n",
       " 'Mm-hmm',\n",
       " 'Is that what everybody got',\n",
       " 'Okay',\n",
       " 'Um',\n",
       " \"So we're gonna have like individual work and then a meeting about it\",\n",
       " 'And repeat that process three times',\n",
       " 'Um and at this point we get try out the whiteboard over there',\n",
       " 'Um',\n",
       " 'So uh you get to draw your favourite animal and sum up your favourite characteristics of it',\n",
       " 'So who would like to go first',\n",
       " 'Very good',\n",
       " 'Mm-hmm',\n",
       " 'Yeah',\n",
       " 'Yeah',\n",
       " 'Right',\n",
       " 'Lovely',\n",
       " 'Right',\n",
       " \"You can take as long over this as you like, because we haven't got an awful lot to discuss\",\n",
       " 'Ok oh we do we do',\n",
       " \"Don't feel like you're in a rush, anyway\",\n",
       " 'Ach why not We might have to get you up again then',\n",
       " \"I don't know what mine is\",\n",
       " \"I'm gonna have to think on the spot now\",\n",
       " 'Is that a whale',\n",
       " 'Ah',\n",
       " 'Okay',\n",
       " \"God, I still don't know what I'm gonna write about\",\n",
       " 'Um',\n",
       " 'I was gonna choose a dog as well',\n",
       " \"But I'll just draw a different kind of dog\",\n",
       " 'M my favourite animal is my own dog at home',\n",
       " \"Um That doesn't really look like him, actually\",\n",
       " 'He looks more like a pig, actually',\n",
       " 'Ah well',\n",
       " 'Do you',\n",
       " \"Oh that's very good of you\",\n",
       " 'Uh',\n",
       " \"Um he's a mixture of uh various things\",\n",
       " \"Um and what do I like about him, um That's just to suggest that his tail wags\",\n",
       " \"Um he's very friendly and cheery and always pleased to see you, and very kind of affectionate and um uh and he's quite quite wee as well so you know he can doesn't take up too much space\",\n",
       " 'Um and uh And he does a funny thing where he chases his tail as well, which is quite amusing, so It is',\n",
       " 'I think it is',\n",
       " \"He only does it after he's had his dinner and um he'll just all of a sudden just get up and start chasing his tail 'round the living room\",\n",
       " 'Yeah, so uh Yeah, maybe',\n",
       " 'Maybe',\n",
       " 'Right, um where did you find this',\n",
       " 'Just down here',\n",
       " 'Yeah',\n",
       " 'Okay',\n",
       " 'Um what are we doing next',\n",
       " 'Uh um',\n",
       " 'Okay, uh we now need to discuss the project finance',\n",
       " \"Um so according to the brief um we're gonna be selling this remote control for twenty five Euro, um and we're aiming to make fifty million Euro\",\n",
       " \"Um so we're gonna be selling this on an international scale\",\n",
       " \"And uh we don't want it to cost any more than uh twelve fifty Euros, so fifty percent of the selling price\",\n",
       " 'Sure',\n",
       " 'All together',\n",
       " 'Um I dunno',\n",
       " \"I imagine That's a good question\",\n",
       " \"I imagine it probably is our sale actually because it's probably up to the the um the retailer to uh sell it for whatever price they want\",\n",
       " 'Um',\n",
       " \"But I I don't know, I mean do you think the fact that it's going to be sold internationally will have a bearing on how we design it at all\",\n",
       " 'Think it will',\n",
       " 'Um',\n",
       " 'Hmm',\n",
       " 'Oh yeah, regions and stuff, yeah',\n",
       " 'Yeah',\n",
       " 'Okay',\n",
       " 'Yeah',\n",
       " \"Well for a remote control, do you think that will be I suppose it's depends on how complicated our remote control is\",\n",
       " 'Yeah, yeah',\n",
       " 'Okay',\n",
       " 'What, just like in terms of like the wealth of the country',\n",
       " 'Like how much money people have to spend on things like',\n",
       " 'Aye, I see what you mean, yeah',\n",
       " 'Marketing',\n",
       " 'Good marketing thoughts',\n",
       " 'Oh gosh, I should be writing all this down',\n",
       " 'Um',\n",
       " 'Mm',\n",
       " 'Yeah',\n",
       " 'Yeah, yeah',\n",
       " 'Like how much does, you know, a remote control cost',\n",
       " \"Well twenty five Euro, I mean that's um that's about like eighteen pounds or something, isn't it\",\n",
       " 'Or no, is it as much as that',\n",
       " 'Sixteen seventeen eighteen pounds',\n",
       " \"Um, I dunno, I've never bought a remote control, so I don't know how how good a remote control that would get you\",\n",
       " 'Um',\n",
       " 'But yeah, I suppose it has to look kind of cool and gimmicky',\n",
       " 'Um right, okay',\n",
       " 'Let me just scoot on ahead here',\n",
       " 'Okay',\n",
       " 'Um well d Does anybody have anything to add to uh to the finance issue at all',\n",
       " 'Thin No, actually',\n",
       " \"That would be useful, though, wouldn't it, if you knew like what your money would get you now\",\n",
       " 'Mm-hmm',\n",
       " 'Yeah, yeah',\n",
       " 'Oh',\n",
       " 'Five minutes to end of meeting',\n",
       " 'Oh, okay',\n",
       " \"We're a bit behind\",\n",
       " 'Yeah',\n",
       " 'Right, so do you think that should be like a main design aim of our remote control d you know, do your your satellite and your regular telly and your V_C_R_ and everything',\n",
       " 'Mm-hmm',\n",
       " 'Yeah',\n",
       " 'Or even like, you know, notes about um what you wanna watch',\n",
       " \"Like you might put in there oh I want to watch such and such and look a Oh that's a good idea\",\n",
       " 'So extra functionalities',\n",
       " 'Mm-hmm',\n",
       " 'Hmm',\n",
       " \"Um okay, uh I'd wel we're gonna have to wrap up pretty quickly in the next couple of minutes\",\n",
       " \"Um I'll just check we've nothing else\",\n",
       " 'Okay',\n",
       " \"Um so anything else anybody wants to add about what they don't like about remote controls they've used, what they would really like to be part of this new one at all\",\n",
       " 'You keep losing them',\n",
       " 'Okay',\n",
       " 'Yeah',\n",
       " 'W You get those ones where you can, if you like, whistle or make a really high pitched noise they beep',\n",
       " \"There I mean is that something we'd want to include, do you think\",\n",
       " 'Dunno',\n",
       " 'Okay maybe',\n",
       " 'My goodness',\n",
       " 'Still feels quite primitive',\n",
       " 'Maybe like a touch screen or something',\n",
       " 'Okay',\n",
       " 'Uh-huh, okay',\n",
       " \"Well I guess that's up to our industrial designer\",\n",
       " 'It looks better',\n",
       " 'Yeah',\n",
       " 'Okay',\n",
       " 'Okay',\n",
       " \"Right, well um so just to wrap up, the next meeting's gonna be in thirty minutes\",\n",
       " \"So that's about um about ten to twelve by my watch\",\n",
       " \"Um so inbetween now and then, um as the industrial designer, you're gonna be working on you know the actual working design of it so y you know what you're doing there\",\n",
       " \"Um for user interface, technical functions, I guess that's you know like what we've been talking about, what it'll actually do\",\n",
       " \"Um and uh marketing executive, you'll be just thinking about what it actually what, you know, what requirements it has to has to fulfil and you'll all get instructions emailed to you, I guess\",\n",
       " 'Um',\n",
       " \"Yeah, so it's th the functional design stage is next, I guess\",\n",
       " \"And uh and that's the end of the meeting\",\n",
       " 'So I got that little message a lot sooner than I thought I would, so Mm-hmm',\n",
       " 'Uh-huh, yeah',\n",
       " \"Th Okay, well just very quickly 'cause this we're supposed to finish now\",\n",
       " \"Um I guess that's up to us, I mean you probably want some kind of unique selling point of it, so um, you know Yeah\",\n",
       " 'Mm-hmm',\n",
       " 'Yeah',\n",
       " 'Okay',\n",
       " \"Right, okay, we'll that's that's the end of the meeting, then\",\n",
       " 'Um',\n",
       " 'So, uh thank you all for coming',\n",
       " \"Hi, I'm David and I'm supposed to be an industrial designer\",\n",
       " 'Um, I just got the project announcement about what the project is',\n",
       " 'Designing a remote control',\n",
       " \"That's about it, didn't get anything else\",\n",
       " 'Did you get the same thing',\n",
       " 'Cool',\n",
       " \"There's too much gear\",\n",
       " 'Okay',\n",
       " \"Can't draw\",\n",
       " 'Um',\n",
       " 'Yeah',\n",
       " \"Um, well anyway, I don't know, it's just the first animal I can think off the top of my head\",\n",
       " 'Um',\n",
       " 'Yes',\n",
       " \"Big reason is 'cause I'm allergic to most animals\",\n",
       " 'Allergic to animal fur, so um fish was a natural choice',\n",
       " 'Um, yeah, and I kind of like whales',\n",
       " 'They come in and go eat everything in sight',\n",
       " \"And they're quite harmless and mild and interesting\",\n",
       " \"Tail's a bit big, I think\",\n",
       " \"It's an after dinner dog then\",\n",
       " 'Hmm',\n",
       " \"It does make sense from maybe the design point of view 'cause you have more complicated characters like European languages, then you need more buttons\",\n",
       " 'So, possibly',\n",
       " 'Hmm',\n",
       " 'Yeah',\n",
       " 'And you keep losing them',\n",
       " 'Finding them is really a pain, you know',\n",
       " \"I mean it's usually quite small, or when you want it right, it slipped behind the couch or it's kicked under the table\",\n",
       " 'You know',\n",
       " 'Yep',\n",
       " 'Mm-hmm',\n",
       " 'I think one factor would be production cost',\n",
       " \"Because there's a cap there, so um depends on how much you can cram into that price\",\n",
       " 'Um',\n",
       " \"I think that that's the main factor\",\n",
       " 'Cool']"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8ARByqRHanVZ"
   },
   "outputs": [],
   "source": [
    "# убираем ненужные символы и делим предложение на слова\n",
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxH5y-y_anVa",
    "outputId": "3db882a0-0f9a-4c51-da5a-be53f2736320"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['um', 'im', 'craig', 'and', 'im', 'user', 'interface'],\n",
       " ['yeah'],\n",
       " ['well', 'my', 'favourite', 'animal', 'would', 'be', 'monkey'],\n",
       " ['then',\n",
       "  'theyre',\n",
       "  'small',\n",
       "  'cute',\n",
       "  'and',\n",
       "  'furry',\n",
       "  'and',\n",
       "  'uh',\n",
       "  'when',\n",
       "  'planet',\n",
       "  'of',\n",
       "  'the',\n",
       "  'apes',\n",
       "  'becomes',\n",
       "  'real',\n",
       "  'im',\n",
       "  'gonna',\n",
       "  'be',\n",
       "  'up',\n",
       "  'there',\n",
       "  'with',\n",
       "  'them'],\n",
       " ['yeah'],\n",
       " ['know',\n",
       "  'um',\n",
       "  'my',\n",
       "  'parents',\n",
       "  'went',\n",
       "  'out',\n",
       "  'and',\n",
       "  'bought',\n",
       "  'um',\n",
       "  'remote',\n",
       "  'controls',\n",
       "  'because',\n",
       "  'um',\n",
       "  'they',\n",
       "  'got',\n",
       "  'fed',\n",
       "  'up',\n",
       "  'of',\n",
       "  'having',\n",
       "  'four',\n",
       "  'or',\n",
       "  'five',\n",
       "  'different',\n",
       "  'remote',\n",
       "  'controls',\n",
       "  'for',\n",
       "  'each',\n",
       "  'things',\n",
       "  'the',\n",
       "  'house'],\n",
       " ['so',\n",
       "  'um',\n",
       "  'for',\n",
       "  'them',\n",
       "  'it',\n",
       "  'was',\n",
       "  'just',\n",
       "  'how',\n",
       "  'many',\n",
       "  'devices',\n",
       "  'control'],\n",
       " ['uh'],\n",
       " ['mm', 'hmm'],\n",
       " ['great'],\n",
       " ['and', 'im', 'andrew', 'and', 'im', 'uh', 'our', 'marketing', 'expert'],\n",
       " ['mm', 'hmm'],\n",
       " ['mm', 'hmm'],\n",
       " ['yeah', 'thats', 'thats', 'it'],\n",
       " ['yeah'],\n",
       " ['will', 'go'],\n",
       " ['thats', 'fine'],\n",
       " ['alright'],\n",
       " ['so', 'this', 'one', 'here', 'right'],\n",
       " ['okay'],\n",
       " ['very', 'nice'],\n",
       " ['alright'],\n",
       " ['my', 'favourite', 'animal', 'is', 'like', 'beagle'],\n",
       " ['um', 'charac', 'favourite', 'characteristics', 'of', 'it'],\n",
       " ['is', 'that', 'right'],\n",
       " ['uh',\n",
       "  'right',\n",
       "  'well',\n",
       "  'basically',\n",
       "  'um',\n",
       "  'high',\n",
       "  'priority',\n",
       "  'for',\n",
       "  'any',\n",
       "  'animal',\n",
       "  'for',\n",
       "  'me',\n",
       "  'is',\n",
       "  'that',\n",
       "  'they',\n",
       "  'be',\n",
       "  'willing',\n",
       "  'to',\n",
       "  'take',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'physical',\n",
       "  'affection',\n",
       "  'from',\n",
       "  'their',\n",
       "  'family'],\n",
       " ['and',\n",
       "  'yeah',\n",
       "  'that',\n",
       "  'they',\n",
       "  'have',\n",
       "  'lots',\n",
       "  'of',\n",
       "  'personality',\n",
       "  'and',\n",
       "  'uh',\n",
       "  'be',\n",
       "  'fit',\n",
       "  'and',\n",
       "  'in',\n",
       "  'robust',\n",
       "  'good',\n",
       "  'health'],\n",
       " ['so', 'this', 'is', 'blue'],\n",
       " ['blue', 'beagle'],\n",
       " ['my', 'familys', 'beagle'],\n",
       " ['coulda', 'told', 'you', 'whole', 'lot', 'more', 'about', 'beagles'],\n",
       " ['boy', 'let', 'me', 'tell', 'you'],\n",
       " ['impressionist'],\n",
       " ['alright'],\n",
       " ['mm'],\n",
       " ['superb', 'sketch', 'by', 'the', 'way'],\n",
       " ['yep'],\n",
       " ['see', 'dog', 'in', 'there'],\n",
       " ['yep'],\n",
       " ['now', 'see', 'rooster'],\n",
       " ['what', 'kind', 'is', 'it'],\n",
       " ['is',\n",
       "  'he',\n",
       "  'aware',\n",
       "  'that',\n",
       "  'th',\n",
       "  'its',\n",
       "  'his',\n",
       "  'own',\n",
       "  'cha',\n",
       "  'tail',\n",
       "  'hes',\n",
       "  'chasing'],\n",
       " ['hmm'],\n",
       " ['probably',\n",
       "  'when',\n",
       "  'he',\n",
       "  'was',\n",
       "  'little',\n",
       "  'he',\n",
       "  'got',\n",
       "  'lots',\n",
       "  'of',\n",
       "  'attention',\n",
       "  'for',\n",
       "  'doing',\n",
       "  'it',\n",
       "  'and',\n",
       "  'has',\n",
       "  'forever',\n",
       "  'been',\n",
       "  'conditioned'],\n",
       " ['kay'],\n",
       " ['um', 'can', 'we', 'just', 'go', 'over', 'that', 'again'],\n",
       " ['uh', 'so', 'bas', 'at', 'twel', 'alright', 'yeah'],\n",
       " ['okay'],\n",
       " ['so',\n",
       "  'cost',\n",
       "  'like',\n",
       "  'production',\n",
       "  'cost',\n",
       "  'is',\n",
       "  'twelve',\n",
       "  'fifty',\n",
       "  'but',\n",
       "  'selling',\n",
       "  'price',\n",
       "  'is',\n",
       "  'is',\n",
       "  'that',\n",
       "  'wholesale',\n",
       "  'or',\n",
       "  'retail'],\n",
       " ['like', 'on', 'the', 'shelf'],\n",
       " ['our', 'sale', 'our', 'sale', 'anyway'],\n",
       " ['yeah', 'okay', 'okay'],\n",
       " ['okay'],\n",
       " ['mm', 'hmm'],\n",
       " ['alright'],\n",
       " ['yes'],\n",
       " ['mm', 'hmm'],\n",
       " ['mm', 'hmm'],\n",
       " ['well',\n",
       "  'right',\n",
       "  'away',\n",
       "  'im',\n",
       "  'wondering',\n",
       "  'if',\n",
       "  'theres',\n",
       "  'um',\n",
       "  'th',\n",
       "  'th',\n",
       "  'uh',\n",
       "  'like',\n",
       "  'with',\n",
       "  'd_v_d_',\n",
       "  'players',\n",
       "  'if',\n",
       "  'there',\n",
       "  'are',\n",
       "  'zones'],\n",
       " ['um',\n",
       "  'frequencies',\n",
       "  'or',\n",
       "  'something',\n",
       "  'um',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'uh',\n",
       "  'characters',\n",
       "  'um',\n",
       "  'different',\n",
       "  'uh',\n",
       "  'keypad',\n",
       "  'styles',\n",
       "  'and',\n",
       "  'symbols'],\n",
       " ['um'],\n",
       " ['dont', 'know'],\n",
       " ['yeah'],\n",
       " ['yeah'],\n",
       " ['yeah'],\n",
       " ['and',\n",
       "  'then',\n",
       "  'and',\n",
       "  'then',\n",
       "  'al',\n",
       "  'the',\n",
       "  'other',\n",
       "  'thing',\n",
       "  'international',\n",
       "  'is',\n",
       "  'on',\n",
       "  'top',\n",
       "  'of',\n",
       "  'the',\n",
       "  'price'],\n",
       " ['im',\n",
       "  'thinking',\n",
       "  'the',\n",
       "  'price',\n",
       "  'might',\n",
       "  'might',\n",
       "  'appeal',\n",
       "  'to',\n",
       "  'certain',\n",
       "  'market',\n",
       "  'in',\n",
       "  'one',\n",
       "  'region',\n",
       "  'whereas',\n",
       "  'in',\n",
       "  'another',\n",
       "  'itll',\n",
       "  'be',\n",
       "  'different',\n",
       "  'so',\n",
       "  'just',\n",
       "  'chara',\n",
       "  'just',\n",
       "  'characteristic',\n",
       "  'of',\n",
       "  'the',\n",
       "  'just',\n",
       "  'or',\n",
       "  'just',\n",
       "  'like',\n",
       "  'basic',\n",
       "  'product',\n",
       "  'podi',\n",
       "  'positioning',\n",
       "  'the',\n",
       "  'twenty',\n",
       "  'five',\n",
       "  'euro',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'might',\n",
       "  'be',\n",
       "  'big',\n",
       "  'hit',\n",
       "  'in',\n",
       "  'london',\n",
       "  'might',\n",
       "  'not',\n",
       "  'be',\n",
       "  'such',\n",
       "  'big',\n",
       "  'hit',\n",
       "  'in',\n",
       "  'greece',\n",
       "  'who',\n",
       "  'knows',\n",
       "  'something',\n",
       "  'like',\n",
       "  'that',\n",
       "  'yeah'],\n",
       " ['yep'],\n",
       " ['right',\n",
       "  'away',\n",
       "  'im',\n",
       "  'making',\n",
       "  'some',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'assumptions',\n",
       "  'about',\n",
       "  'what',\n",
       "  'what',\n",
       "  'information',\n",
       "  'were',\n",
       "  'given',\n",
       "  'here',\n",
       "  'thinking',\n",
       "  'kay',\n",
       "  'trendy',\n",
       "  'probably',\n",
       "  'means',\n",
       "  'something',\n",
       "  'other',\n",
       "  'than',\n",
       "  'just',\n",
       "  'basic',\n",
       "  'something',\n",
       "  'other',\n",
       "  'than',\n",
       "  'just',\n",
       "  'standard'],\n",
       " ['um',\n",
       "  'so',\n",
       "  'im',\n",
       "  'wondering',\n",
       "  'right',\n",
       "  'away',\n",
       "  'is',\n",
       "  'selling',\n",
       "  'twenty',\n",
       "  'five',\n",
       "  'euros',\n",
       "  'is',\n",
       "  'that',\n",
       "  'sort',\n",
       "  'of',\n",
       "  'the',\n",
       "  'thi',\n",
       "  'is',\n",
       "  'this',\n",
       "  'gonna',\n",
       "  'to',\n",
       "  'be',\n",
       "  'like',\n",
       "  'the',\n",
       "  'premium',\n",
       "  'product',\n",
       "  'kinda',\n",
       "  'thing',\n",
       "  'or',\n",
       "  'uh',\n",
       "  'huh'],\n",
       " ['mm', 'hmm'],\n",
       " ['yep'],\n",
       " ['yeah', 'id', 'say', 'so', 'yeah'],\n",
       " ['no'],\n",
       " ['yeah', 'yeah'],\n",
       " ['mm', 'hmm'],\n",
       " ['do',\n",
       "  'we',\n",
       "  'have',\n",
       "  'any',\n",
       "  'other',\n",
       "  'background',\n",
       "  'information',\n",
       "  'on',\n",
       "  'like',\n",
       "  'how',\n",
       "  'that',\n",
       "  'compares',\n",
       "  'to',\n",
       "  'other',\n",
       "  'other',\n",
       "  'yeah'],\n",
       " ['mm', 'hmm'],\n",
       " ['yeah',\n",
       "  'interesting',\n",
       "  'thing',\n",
       "  'about',\n",
       "  'discussing',\n",
       "  'um',\n",
       "  'production',\n",
       "  'of',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'for',\n",
       "  'me',\n",
       "  'is',\n",
       "  'that',\n",
       "  'as',\n",
       "  'you',\n",
       "  'point',\n",
       "  'out',\n",
       "  'just',\n",
       "  'dont',\n",
       "  'think',\n",
       "  'of',\n",
       "  'remote',\n",
       "  'controls',\n",
       "  'as',\n",
       "  'somethin',\n",
       "  'something',\n",
       "  'people',\n",
       "  'consciously',\n",
       "  'assess',\n",
       "  'in',\n",
       "  'their',\n",
       "  'purchasing',\n",
       "  'habits'],\n",
       " ['its',\n",
       "  'just',\n",
       "  'like',\n",
       "  'getting',\n",
       "  'shoelaces',\n",
       "  'with',\n",
       "  'shoes',\n",
       "  'or',\n",
       "  'something'],\n",
       " ['it', 'just', 'comes', 'along'],\n",
       " ['do', 'you', 'know', 'what', 'mean'],\n",
       " ['like',\n",
       "  'so',\n",
       "  'sort',\n",
       "  'of',\n",
       "  'like',\n",
       "  'how',\n",
       "  'do',\n",
       "  'you',\n",
       "  'mean',\n",
       "  'one',\n",
       "  'one',\n",
       "  'way',\n",
       "  'of',\n",
       "  'looking',\n",
       "  'at',\n",
       "  'it',\n",
       "  'would',\n",
       "  'be',\n",
       "  'well',\n",
       "  'the',\n",
       "  'people',\n",
       "  'producing',\n",
       "  'television',\n",
       "  'sets',\n",
       "  'maybe',\n",
       "  'they',\n",
       "  'have',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'remote',\n",
       "  'controls'],\n",
       " ['or',\n",
       "  'another',\n",
       "  'way',\n",
       "  'is',\n",
       "  'maybe',\n",
       "  'people',\n",
       "  'who',\n",
       "  'have',\n",
       "  't_v_',\n",
       "  'sets',\n",
       "  'are',\n",
       "  'really',\n",
       "  'fed',\n",
       "  'up',\n",
       "  'with',\n",
       "  'their',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'and',\n",
       "  'they',\n",
       "  'really',\n",
       "  'want',\n",
       "  'better',\n",
       "  'one',\n",
       "  'or',\n",
       "  'something'],\n",
       " ['but', 'right'],\n",
       " ['right'],\n",
       " ['okay',\n",
       "  'so',\n",
       "  'right',\n",
       "  'so',\n",
       "  'in',\n",
       "  'function',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'priorities',\n",
       "  'might',\n",
       "  'be',\n",
       "  'to',\n",
       "  'combine',\n",
       "  'as',\n",
       "  'many',\n",
       "  'uses',\n",
       "  'think',\n",
       "  'so'],\n",
       " ['yeah', 'yeah'],\n",
       " ['yeah'],\n",
       " ['well',\n",
       "  'like',\n",
       "  'um',\n",
       "  'maybe',\n",
       "  'what',\n",
       "  'we',\n",
       "  'could',\n",
       "  'use',\n",
       "  'is',\n",
       "  'sort',\n",
       "  'of',\n",
       "  'like',\n",
       "  'example',\n",
       "  'of',\n",
       "  'successful',\n",
       "  'other',\n",
       "  'piece',\n",
       "  'technology',\n",
       "  'is',\n",
       "  'palm',\n",
       "  'palm',\n",
       "  'pilots'],\n",
       " ['theyre',\n",
       "  'gone',\n",
       "  'from',\n",
       "  'being',\n",
       "  'just',\n",
       "  'like',\n",
       "  'little',\n",
       "  'sort',\n",
       "  'of',\n",
       "  'scribble',\n",
       "  'boards',\n",
       "  'to',\n",
       "  'cameras',\n",
       "  'm_p_',\n",
       "  'three',\n",
       "  'players',\n",
       "  'telephones',\n",
       "  'everything',\n",
       "  'agenda'],\n",
       " ['so',\n",
       "  'like',\n",
       "  'wonder',\n",
       "  'if',\n",
       "  'we',\n",
       "  'might',\n",
       "  'add',\n",
       "  'something',\n",
       "  'new',\n",
       "  'to',\n",
       "  'the',\n",
       "  'to',\n",
       "  'the',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'market',\n",
       "  'such',\n",
       "  'as',\n",
       "  'the',\n",
       "  'lighting',\n",
       "  'in',\n",
       "  'your',\n",
       "  'house',\n",
       "  'or',\n",
       "  'um',\n",
       "  'yeah',\n",
       "  'yeah'],\n",
       " ['an', 'yeah'],\n",
       " ['like',\n",
       "  'personally',\n",
       "  'for',\n",
       "  'me',\n",
       "  'at',\n",
       "  'home',\n",
       "  'ive',\n",
       "  'ive',\n",
       "  'combined',\n",
       "  'the',\n",
       "  'um',\n",
       "  'the',\n",
       "  'audio',\n",
       "  'video',\n",
       "  'of',\n",
       "  'my',\n",
       "  'television',\n",
       "  'set',\n",
       "  'and',\n",
       "  'my',\n",
       "  'd_v_d_',\n",
       "  'player',\n",
       "  'and',\n",
       "  'my',\n",
       "  'c_d_',\n",
       "  'player'],\n",
       " ['so',\n",
       "  'they',\n",
       "  'all',\n",
       "  'work',\n",
       "  'actually',\n",
       "  'function',\n",
       "  'together',\n",
       "  'but',\n",
       "  'have',\n",
       "  'different',\n",
       "  'remote',\n",
       "  'controls',\n",
       "  'for',\n",
       "  'each',\n",
       "  'of',\n",
       "  'them'],\n",
       " ['so',\n",
       "  'its',\n",
       "  'sort',\n",
       "  'of',\n",
       "  'ironic',\n",
       "  'that',\n",
       "  'that',\n",
       "  'then',\n",
       "  'theyre',\n",
       "  'in',\n",
       "  'there',\n",
       "  'um',\n",
       "  'you',\n",
       "  'know',\n",
       "  'the',\n",
       "  'sound',\n",
       "  'and',\n",
       "  'everything',\n",
       "  'its',\n",
       "  'just',\n",
       "  'one',\n",
       "  'system'],\n",
       " ['but', 'each', 'ones', 'got', 'its', 'own', 'little', 'part'],\n",
       " ['mm'],\n",
       " ['mm'],\n",
       " ['mm'],\n",
       " ['mm', 'hmm'],\n",
       " ['mm', 'hmm'],\n",
       " ['yeah'],\n",
       " ['yeah'],\n",
       " ['thats', 'just', 'really', 'good', 'id', 'yep'],\n",
       " ['uh', 'sure'],\n",
       " ['remember',\n",
       "  'when',\n",
       "  'the',\n",
       "  'first',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'my',\n",
       "  'my',\n",
       "  'family',\n",
       "  'had',\n",
       "  'was',\n",
       "  'on',\n",
       "  'cable'],\n",
       " ['actually',\n",
       "  'had',\n",
       "  'cable',\n",
       "  'between',\n",
       "  'it',\n",
       "  'and',\n",
       "  'the',\n",
       "  't_v_',\n",
       "  'and',\n",
       "  'big',\n",
       "  'like',\n",
       "  'buttons',\n",
       "  'that',\n",
       "  'sort',\n",
       "  'of',\n",
       "  'like',\n",
       "  'like',\n",
       "  'on',\n",
       "  'blender',\n",
       "  'or',\n",
       "  'something'],\n",
       " ['and',\n",
       "  'um',\n",
       "  'you',\n",
       "  'know',\n",
       "  'when',\n",
       "  'think',\n",
       "  'about',\n",
       "  'what',\n",
       "  'they',\n",
       "  'are',\n",
       "  'now',\n",
       "  'its',\n",
       "  'better',\n",
       "  'but',\n",
       "  'actually',\n",
       "  'its',\n",
       "  'still',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'dunno',\n",
       "  'like',\n",
       "  'massive',\n",
       "  'junky',\n",
       "  'thing',\n",
       "  'on',\n",
       "  'the',\n",
       "  'table'],\n",
       " ['maybe',\n",
       "  'we',\n",
       "  'could',\n",
       "  'think',\n",
       "  'about',\n",
       "  'how',\n",
       "  'could',\n",
       "  'be',\n",
       "  'more',\n",
       "  'you',\n",
       "  'know',\n",
       "  'streamlined'],\n",
       " ['something', 'like', 'that', 'yeah'],\n",
       " ['or', 'whatever', 'would', 'be', 'technologically', 'reasonable'],\n",
       " ['cause',\n",
       "  'it',\n",
       "  'could',\n",
       "  'it',\n",
       "  'could',\n",
       "  'it',\n",
       "  'could',\n",
       "  'be',\n",
       "  'that',\n",
       "  'it',\n",
       "  'could',\n",
       "  'be',\n",
       "  'that',\n",
       "  'functionally',\n",
       "  'that',\n",
       "  'doesnt',\n",
       "  'make',\n",
       "  'it',\n",
       "  'any',\n",
       "  'better',\n",
       "  'but',\n",
       "  'that',\n",
       "  'just',\n",
       "  'the',\n",
       "  'appeal',\n",
       "  'of',\n",
       "  'of',\n",
       "  'not',\n",
       "  'having',\n",
       "  'you',\n",
       "  'know',\n",
       "  'these',\n",
       "  'days',\n",
       "  'theres',\n",
       "  'pe',\n",
       "  'things',\n",
       "  'in',\n",
       "  'peoples',\n",
       "  'homes',\n",
       "  'are',\n",
       "  'becoming',\n",
       "  'more',\n",
       "  'and',\n",
       "  'more',\n",
       "  'like',\n",
       "  'chic',\n",
       "  'you',\n",
       "  'know'],\n",
       " ['um',\n",
       "  'nicer',\n",
       "  'materials',\n",
       "  'and',\n",
       "  'might',\n",
       "  'be',\n",
       "  'be',\n",
       "  'worth',\n",
       "  'exploring',\n",
       "  'anyway'],\n",
       " ['okay'],\n",
       " ['um'],\n",
       " ['before',\n",
       "  'we',\n",
       "  'wrap',\n",
       "  'up',\n",
       "  'just',\n",
       "  'to',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'were',\n",
       "  'all',\n",
       "  'on',\n",
       "  'the',\n",
       "  'same',\n",
       "  'page',\n",
       "  'here',\n",
       "  'um',\n",
       "  'do',\n",
       "  'we',\n",
       "  'we',\n",
       "  'were',\n",
       "  'given',\n",
       "  'sort',\n",
       "  'of',\n",
       "  'an',\n",
       "  'example',\n",
       "  'of',\n",
       "  'coffee',\n",
       "  'machine',\n",
       "  'or',\n",
       "  'something',\n",
       "  'right'],\n",
       " ['well',\n",
       "  'um',\n",
       "  'are',\n",
       "  'we',\n",
       "  'at',\n",
       "  'ma',\n",
       "  'right',\n",
       "  'now',\n",
       "  'on',\n",
       "  'the',\n",
       "  'assumption',\n",
       "  'that',\n",
       "  'our',\n",
       "  'television',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'may',\n",
       "  'have',\n",
       "  'features',\n",
       "  'which',\n",
       "  'go',\n",
       "  'beyond',\n",
       "  'the',\n",
       "  'television'],\n",
       " ['or',\n",
       "  'are',\n",
       "  'we',\n",
       "  'keeping',\n",
       "  'sort',\n",
       "  'of',\n",
       "  'like',\n",
       "  'design',\n",
       "  'commitment',\n",
       "  'to',\n",
       "  'television',\n",
       "  'features'],\n",
       " ['dont', 'know'],\n",
       " ['yep'],\n",
       " ['yeah', 'sure'],\n",
       " ['okay'],\n",
       " ['okay', 'yeah'],\n",
       " ['okay'],\n",
       " ['okay'],\n",
       " ['okay'],\n",
       " ['alright'],\n",
       " ['okay'],\n",
       " ['right'],\n",
       " ['um',\n",
       "  'well',\n",
       "  'this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'kick',\n",
       "  'off',\n",
       "  'meeting',\n",
       "  'for',\n",
       "  'our',\n",
       "  'our',\n",
       "  'project'],\n",
       " ['um',\n",
       "  'and',\n",
       "  'um',\n",
       "  'this',\n",
       "  'is',\n",
       "  'just',\n",
       "  'what',\n",
       "  'were',\n",
       "  'gonna',\n",
       "  'be',\n",
       "  'doing',\n",
       "  'over',\n",
       "  'the',\n",
       "  'next',\n",
       "  'twenty',\n",
       "  'five',\n",
       "  'minutes'],\n",
       " ['um',\n",
       "  'so',\n",
       "  'first',\n",
       "  'of',\n",
       "  'all',\n",
       "  'just',\n",
       "  'to',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'that',\n",
       "  'we',\n",
       "  'all',\n",
       "  'know',\n",
       "  'each',\n",
       "  'other',\n",
       "  'im',\n",
       "  'laura',\n",
       "  'and',\n",
       "  'im',\n",
       "  'the',\n",
       "  'project',\n",
       "  'manager'],\n",
       " ['do', 'you', 'want', 'to', 'introduce', 'yourself', 'again'],\n",
       " ['okay'],\n",
       " ['great'],\n",
       " ['okay'],\n",
       " ['um',\n",
       "  'so',\n",
       "  'were',\n",
       "  'designing',\n",
       "  'new',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'and',\n",
       "  'um',\n",
       "  'oh',\n",
       "  'have',\n",
       "  'to',\n",
       "  'record',\n",
       "  'whos',\n",
       "  'here',\n",
       "  'actually'],\n",
       " ['so', 'thats', 'david', 'andrew', 'and', 'craig', 'isnt', 'it'],\n",
       " ['and', 'you', 'all', 'arrived', 'on', 'time'],\n",
       " ['um', 'yeah', 'so', 'des', 'uh', 'design', 'new', 'remote', 'control'],\n",
       " ['um',\n",
       "  'as',\n",
       "  'you',\n",
       "  'can',\n",
       "  'see',\n",
       "  'its',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'original',\n",
       "  'trendy',\n",
       "  'and',\n",
       "  'user',\n",
       "  'friendly'],\n",
       " ['um',\n",
       "  'so',\n",
       "  'thats',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'our',\n",
       "  'our',\n",
       "  'brief',\n",
       "  'as',\n",
       "  'it',\n",
       "  'were'],\n",
       " ['um',\n",
       "  'and',\n",
       "  'so',\n",
       "  'there',\n",
       "  'are',\n",
       "  'three',\n",
       "  'different',\n",
       "  'stages',\n",
       "  'to',\n",
       "  'the',\n",
       "  'design'],\n",
       " ['um',\n",
       "  'im',\n",
       "  'not',\n",
       "  'really',\n",
       "  'sure',\n",
       "  'what',\n",
       "  'what',\n",
       "  'you',\n",
       "  'guys',\n",
       "  'have',\n",
       "  'already',\n",
       "  'received',\n",
       "  'um',\n",
       "  'in',\n",
       "  'your',\n",
       "  'emails'],\n",
       " ['what', 'did', 'you', 'get'],\n",
       " ['mm', 'hmm'],\n",
       " ['is', 'that', 'what', 'everybody', 'got'],\n",
       " ['okay'],\n",
       " ['um'],\n",
       " ['so',\n",
       "  'were',\n",
       "  'gonna',\n",
       "  'have',\n",
       "  'like',\n",
       "  'individual',\n",
       "  'work',\n",
       "  'and',\n",
       "  'then',\n",
       "  'meeting',\n",
       "  'about',\n",
       "  'it'],\n",
       " ['and', 'repeat', 'that', 'process', 'three', 'times'],\n",
       " ['um',\n",
       "  'and',\n",
       "  'at',\n",
       "  'this',\n",
       "  'point',\n",
       "  'we',\n",
       "  'get',\n",
       "  'try',\n",
       "  'out',\n",
       "  'the',\n",
       "  'whiteboard',\n",
       "  'over',\n",
       "  'there'],\n",
       " ['um'],\n",
       " ['so',\n",
       "  'uh',\n",
       "  'you',\n",
       "  'get',\n",
       "  'to',\n",
       "  'draw',\n",
       "  'your',\n",
       "  'favourite',\n",
       "  'animal',\n",
       "  'and',\n",
       "  'sum',\n",
       "  'up',\n",
       "  'your',\n",
       "  'favourite',\n",
       "  'characteristics',\n",
       "  'of',\n",
       "  'it'],\n",
       " ['so', 'who', 'would', 'like', 'to', 'go', 'first'],\n",
       " ['very', 'good'],\n",
       " ['mm', 'hmm'],\n",
       " ['yeah'],\n",
       " ['yeah'],\n",
       " ['right'],\n",
       " ['lovely'],\n",
       " ['right'],\n",
       " ['you',\n",
       "  'can',\n",
       "  'take',\n",
       "  'as',\n",
       "  'long',\n",
       "  'over',\n",
       "  'this',\n",
       "  'as',\n",
       "  'you',\n",
       "  'like',\n",
       "  'because',\n",
       "  'we',\n",
       "  'havent',\n",
       "  'got',\n",
       "  'an',\n",
       "  'awful',\n",
       "  'lot',\n",
       "  'to',\n",
       "  'discuss'],\n",
       " ['ok', 'oh', 'we', 'do', 'we', 'do'],\n",
       " ['dont', 'feel', 'like', 'youre', 'in', 'rush', 'anyway'],\n",
       " ['ach',\n",
       "  'why',\n",
       "  'not',\n",
       "  'we',\n",
       "  'might',\n",
       "  'have',\n",
       "  'to',\n",
       "  'get',\n",
       "  'you',\n",
       "  'up',\n",
       "  'again',\n",
       "  'then'],\n",
       " ['dont', 'know', 'what', 'mine', 'is'],\n",
       " ['im', 'gonna', 'have', 'to', 'think', 'on', 'the', 'spot', 'now'],\n",
       " ['is', 'that', 'whale'],\n",
       " ['ah'],\n",
       " ['okay'],\n",
       " ['god', 'still', 'dont', 'know', 'what', 'im', 'gonna', 'write', 'about'],\n",
       " ['um'],\n",
       " ['was', 'gonna', 'choose', 'dog', 'as', 'well'],\n",
       " ['but', 'ill', 'just', 'draw', 'different', 'kind', 'of', 'dog'],\n",
       " ['my', 'favourite', 'animal', 'is', 'my', 'own', 'dog', 'at', 'home'],\n",
       " ['um', 'that', 'doesnt', 'really', 'look', 'like', 'him', 'actually'],\n",
       " ['he', 'looks', 'more', 'like', 'pig', 'actually'],\n",
       " ['ah', 'well'],\n",
       " ['do', 'you'],\n",
       " ['oh', 'thats', 'very', 'good', 'of', 'you'],\n",
       " ['uh'],\n",
       " ['um', 'hes', 'mixture', 'of', 'uh', 'various', 'things'],\n",
       " ['um',\n",
       "  'and',\n",
       "  'what',\n",
       "  'do',\n",
       "  'like',\n",
       "  'about',\n",
       "  'him',\n",
       "  'um',\n",
       "  'thats',\n",
       "  'just',\n",
       "  'to',\n",
       "  'suggest',\n",
       "  'that',\n",
       "  'his',\n",
       "  'tail',\n",
       "  'wags'],\n",
       " ['um',\n",
       "  'hes',\n",
       "  'very',\n",
       "  'friendly',\n",
       "  'and',\n",
       "  'cheery',\n",
       "  'and',\n",
       "  'always',\n",
       "  'pleased',\n",
       "  'to',\n",
       "  'see',\n",
       "  'you',\n",
       "  'and',\n",
       "  'very',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'affectionate',\n",
       "  'and',\n",
       "  'um',\n",
       "  'uh',\n",
       "  'and',\n",
       "  'hes',\n",
       "  'quite',\n",
       "  'quite',\n",
       "  'wee',\n",
       "  'as',\n",
       "  'well',\n",
       "  'so',\n",
       "  'you',\n",
       "  'know',\n",
       "  'he',\n",
       "  'can',\n",
       "  'doesnt',\n",
       "  'take',\n",
       "  'up',\n",
       "  'too',\n",
       "  'much',\n",
       "  'space'],\n",
       " ['um',\n",
       "  'and',\n",
       "  'uh',\n",
       "  'and',\n",
       "  'he',\n",
       "  'does',\n",
       "  'funny',\n",
       "  'thing',\n",
       "  'where',\n",
       "  'he',\n",
       "  'chases',\n",
       "  'his',\n",
       "  'tail',\n",
       "  'as',\n",
       "  'well',\n",
       "  'which',\n",
       "  'is',\n",
       "  'quite',\n",
       "  'amusing',\n",
       "  'so',\n",
       "  'it',\n",
       "  'is'],\n",
       " ['think', 'it', 'is'],\n",
       " ['he',\n",
       "  'only',\n",
       "  'does',\n",
       "  'it',\n",
       "  'after',\n",
       "  'hes',\n",
       "  'had',\n",
       "  'his',\n",
       "  'dinner',\n",
       "  'and',\n",
       "  'um',\n",
       "  'hell',\n",
       "  'just',\n",
       "  'all',\n",
       "  'of',\n",
       "  'sudden',\n",
       "  'just',\n",
       "  'get',\n",
       "  'up',\n",
       "  'and',\n",
       "  'start',\n",
       "  'chasing',\n",
       "  'his',\n",
       "  'tail',\n",
       "  'round',\n",
       "  'the',\n",
       "  'living',\n",
       "  'room'],\n",
       " ['yeah', 'so', 'uh', 'yeah', 'maybe'],\n",
       " ['maybe'],\n",
       " ['right', 'um', 'where', 'did', 'you', 'find', 'this'],\n",
       " ['just', 'down', 'here'],\n",
       " ['yeah'],\n",
       " ['okay'],\n",
       " ['um', 'what', 'are', 'we', 'doing', 'next'],\n",
       " ['uh', 'um'],\n",
       " ['okay',\n",
       "  'uh',\n",
       "  'we',\n",
       "  'now',\n",
       "  'need',\n",
       "  'to',\n",
       "  'discuss',\n",
       "  'the',\n",
       "  'project',\n",
       "  'finance'],\n",
       " ['um',\n",
       "  'so',\n",
       "  'according',\n",
       "  'to',\n",
       "  'the',\n",
       "  'brief',\n",
       "  'um',\n",
       "  'were',\n",
       "  'gonna',\n",
       "  'be',\n",
       "  'selling',\n",
       "  'this',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'for',\n",
       "  'twenty',\n",
       "  'five',\n",
       "  'euro',\n",
       "  'um',\n",
       "  'and',\n",
       "  'were',\n",
       "  'aiming',\n",
       "  'to',\n",
       "  'make',\n",
       "  'fifty',\n",
       "  'million',\n",
       "  'euro'],\n",
       " ['um',\n",
       "  'so',\n",
       "  'were',\n",
       "  'gonna',\n",
       "  'be',\n",
       "  'selling',\n",
       "  'this',\n",
       "  'on',\n",
       "  'an',\n",
       "  'international',\n",
       "  'scale'],\n",
       " ['and',\n",
       "  'uh',\n",
       "  'we',\n",
       "  'dont',\n",
       "  'want',\n",
       "  'it',\n",
       "  'to',\n",
       "  'cost',\n",
       "  'any',\n",
       "  'more',\n",
       "  'than',\n",
       "  'uh',\n",
       "  'twelve',\n",
       "  'fifty',\n",
       "  'euros',\n",
       "  'so',\n",
       "  'fifty',\n",
       "  'percent',\n",
       "  'of',\n",
       "  'the',\n",
       "  'selling',\n",
       "  'price'],\n",
       " ['sure'],\n",
       " ['all', 'together'],\n",
       " ['um', 'dunno'],\n",
       " ['imagine', 'thats', 'good', 'question'],\n",
       " ['imagine',\n",
       "  'it',\n",
       "  'probably',\n",
       "  'is',\n",
       "  'our',\n",
       "  'sale',\n",
       "  'actually',\n",
       "  'because',\n",
       "  'its',\n",
       "  'probably',\n",
       "  'up',\n",
       "  'to',\n",
       "  'the',\n",
       "  'the',\n",
       "  'um',\n",
       "  'the',\n",
       "  'retailer',\n",
       "  'to',\n",
       "  'uh',\n",
       "  'sell',\n",
       "  'it',\n",
       "  'for',\n",
       "  'whatever',\n",
       "  'price',\n",
       "  'they',\n",
       "  'want'],\n",
       " ['um'],\n",
       " ['but',\n",
       "  'dont',\n",
       "  'know',\n",
       "  'mean',\n",
       "  'do',\n",
       "  'you',\n",
       "  'think',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'its',\n",
       "  'going',\n",
       "  'to',\n",
       "  'be',\n",
       "  'sold',\n",
       "  'internationally',\n",
       "  'will',\n",
       "  'have',\n",
       "  'bearing',\n",
       "  'on',\n",
       "  'how',\n",
       "  'we',\n",
       "  'design',\n",
       "  'it',\n",
       "  'at',\n",
       "  'all'],\n",
       " ['think', 'it', 'will'],\n",
       " ['um'],\n",
       " ['hmm'],\n",
       " ['oh', 'yeah', 'regions', 'and', 'stuff', 'yeah'],\n",
       " ['yeah'],\n",
       " ['okay'],\n",
       " ['yeah'],\n",
       " ['well',\n",
       "  'for',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'do',\n",
       "  'you',\n",
       "  'think',\n",
       "  'that',\n",
       "  'will',\n",
       "  'be',\n",
       "  'suppose',\n",
       "  'its',\n",
       "  'depends',\n",
       "  'on',\n",
       "  'how',\n",
       "  'complicated',\n",
       "  'our',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'is'],\n",
       " ['yeah', 'yeah'],\n",
       " ['okay'],\n",
       " ['what',\n",
       "  'just',\n",
       "  'like',\n",
       "  'in',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'like',\n",
       "  'the',\n",
       "  'wealth',\n",
       "  'of',\n",
       "  'the',\n",
       "  'country'],\n",
       " ['like',\n",
       "  'how',\n",
       "  'much',\n",
       "  'money',\n",
       "  'people',\n",
       "  'have',\n",
       "  'to',\n",
       "  'spend',\n",
       "  'on',\n",
       "  'things',\n",
       "  'like'],\n",
       " ['aye', 'see', 'what', 'you', 'mean', 'yeah'],\n",
       " ['marketing'],\n",
       " ['good', 'marketing', 'thoughts'],\n",
       " ['oh', 'gosh', 'should', 'be', 'writing', 'all', 'this', 'down'],\n",
       " ['um'],\n",
       " ['mm'],\n",
       " ['yeah'],\n",
       " ['yeah', 'yeah'],\n",
       " ['like', 'how', 'much', 'does', 'you', 'know', 'remote', 'control', 'cost'],\n",
       " ['well',\n",
       "  'twenty',\n",
       "  'five',\n",
       "  'euro',\n",
       "  'mean',\n",
       "  'thats',\n",
       "  'um',\n",
       "  'thats',\n",
       "  'about',\n",
       "  'like',\n",
       "  'eighteen',\n",
       "  'pounds',\n",
       "  'or',\n",
       "  'something',\n",
       "  'isnt',\n",
       "  'it'],\n",
       " ['or', 'no', 'is', 'it', 'as', 'much', 'as', 'that'],\n",
       " ['sixteen', 'seventeen', 'eighteen', 'pounds'],\n",
       " ['um',\n",
       "  'dunno',\n",
       "  'ive',\n",
       "  'never',\n",
       "  'bought',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'so',\n",
       "  'dont',\n",
       "  'know',\n",
       "  'how',\n",
       "  'how',\n",
       "  'good',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'that',\n",
       "  'would',\n",
       "  'get',\n",
       "  'you'],\n",
       " ['um'],\n",
       " ['but',\n",
       "  'yeah',\n",
       "  'suppose',\n",
       "  'it',\n",
       "  'has',\n",
       "  'to',\n",
       "  'look',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'cool',\n",
       "  'and',\n",
       "  'gimmicky'],\n",
       " ['um', 'right', 'okay'],\n",
       " ['let', 'me', 'just', 'scoot', 'on', 'ahead', 'here'],\n",
       " ['okay'],\n",
       " ['um',\n",
       "  'well',\n",
       "  'does',\n",
       "  'anybody',\n",
       "  'have',\n",
       "  'anything',\n",
       "  'to',\n",
       "  'add',\n",
       "  'to',\n",
       "  'uh',\n",
       "  'to',\n",
       "  'the',\n",
       "  'finance',\n",
       "  'issue',\n",
       "  'at',\n",
       "  'all'],\n",
       " ['thin', 'no', 'actually'],\n",
       " ['that',\n",
       "  'would',\n",
       "  'be',\n",
       "  'useful',\n",
       "  'though',\n",
       "  'wouldnt',\n",
       "  'it',\n",
       "  'if',\n",
       "  'you',\n",
       "  'knew',\n",
       "  'like',\n",
       "  'what',\n",
       "  'your',\n",
       "  'money',\n",
       "  'would',\n",
       "  'get',\n",
       "  'you',\n",
       "  'now'],\n",
       " ['mm', 'hmm'],\n",
       " ['yeah', 'yeah'],\n",
       " ['oh'],\n",
       " ['five', 'minutes', 'to', 'end', 'of', 'meeting'],\n",
       " ['oh', 'okay'],\n",
       " ['were', 'bit', 'behind'],\n",
       " ['yeah'],\n",
       " ['right',\n",
       "  'so',\n",
       "  'do',\n",
       "  'you',\n",
       "  'think',\n",
       "  'that',\n",
       "  'should',\n",
       "  'be',\n",
       "  'like',\n",
       "  'main',\n",
       "  'design',\n",
       "  'aim',\n",
       "  'of',\n",
       "  'our',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'you',\n",
       "  'know',\n",
       "  'do',\n",
       "  'your',\n",
       "  'your',\n",
       "  'satellite',\n",
       "  'and',\n",
       "  'your',\n",
       "  'regular',\n",
       "  'telly',\n",
       "  'and',\n",
       "  'your',\n",
       "  'v_c_r_',\n",
       "  'and',\n",
       "  'everything'],\n",
       " ['mm', 'hmm'],\n",
       " ['yeah'],\n",
       " ['or',\n",
       "  'even',\n",
       "  'like',\n",
       "  'you',\n",
       "  'know',\n",
       "  'notes',\n",
       "  'about',\n",
       "  'um',\n",
       "  'what',\n",
       "  'you',\n",
       "  'wanna',\n",
       "  'watch'],\n",
       " ['like',\n",
       "  'you',\n",
       "  'might',\n",
       "  'put',\n",
       "  'in',\n",
       "  'there',\n",
       "  'oh',\n",
       "  'want',\n",
       "  'to',\n",
       "  'watch',\n",
       "  'such',\n",
       "  'and',\n",
       "  'such',\n",
       "  'and',\n",
       "  'look',\n",
       "  'oh',\n",
       "  'thats',\n",
       "  'good',\n",
       "  'idea'],\n",
       " ['so', 'extra', 'functionalities'],\n",
       " ['mm', 'hmm'],\n",
       " ['hmm'],\n",
       " ['um',\n",
       "  'okay',\n",
       "  'uh',\n",
       "  'id',\n",
       "  'wel',\n",
       "  'were',\n",
       "  'gonna',\n",
       "  'have',\n",
       "  'to',\n",
       "  'wrap',\n",
       "  'up',\n",
       "  'pretty',\n",
       "  'quickly',\n",
       "  'in',\n",
       "  'the',\n",
       "  'next',\n",
       "  'couple',\n",
       "  'of',\n",
       "  'minutes'],\n",
       " ['um', 'ill', 'just', 'check', 'weve', 'nothing', 'else'],\n",
       " ['okay'],\n",
       " ['um',\n",
       "  'so',\n",
       "  'anything',\n",
       "  'else',\n",
       "  'anybody',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'add',\n",
       "  'about',\n",
       "  'what',\n",
       "  'they',\n",
       "  'dont',\n",
       "  'like',\n",
       "  'about',\n",
       "  'remote',\n",
       "  'controls',\n",
       "  'theyve',\n",
       "  'used',\n",
       "  'what',\n",
       "  'they',\n",
       "  'would',\n",
       "  'really',\n",
       "  'like',\n",
       "  'to',\n",
       "  'be',\n",
       "  'part',\n",
       "  'of',\n",
       "  'this',\n",
       "  'new',\n",
       "  'one',\n",
       "  'at',\n",
       "  'all'],\n",
       " ['you', 'keep', 'losing', 'them'],\n",
       " ['okay'],\n",
       " ['yeah'],\n",
       " ['you',\n",
       "  'get',\n",
       "  'those',\n",
       "  'ones',\n",
       "  'where',\n",
       "  'you',\n",
       "  'can',\n",
       "  'if',\n",
       "  'you',\n",
       "  'like',\n",
       "  'whistle',\n",
       "  'or',\n",
       "  'make',\n",
       "  'really',\n",
       "  'high',\n",
       "  'pitched',\n",
       "  'noise',\n",
       "  'they',\n",
       "  'beep'],\n",
       " ['there',\n",
       "  'mean',\n",
       "  'is',\n",
       "  'that',\n",
       "  'something',\n",
       "  'wed',\n",
       "  'want',\n",
       "  'to',\n",
       "  'include',\n",
       "  'do',\n",
       "  'you',\n",
       "  'think'],\n",
       " ['dunno'],\n",
       " ['okay', 'maybe'],\n",
       " ['my', 'goodness'],\n",
       " ['still', 'feels', 'quite', 'primitive'],\n",
       " ['maybe', 'like', 'touch', 'screen', 'or', 'something'],\n",
       " ['okay'],\n",
       " ['uh', 'huh', 'okay'],\n",
       " ['well', 'guess', 'thats', 'up', 'to', 'our', 'industrial', 'designer'],\n",
       " ['it', 'looks', 'better'],\n",
       " ['yeah'],\n",
       " ['okay'],\n",
       " ['okay'],\n",
       " ['right',\n",
       "  'well',\n",
       "  'um',\n",
       "  'so',\n",
       "  'just',\n",
       "  'to',\n",
       "  'wrap',\n",
       "  'up',\n",
       "  'the',\n",
       "  'next',\n",
       "  'meetings',\n",
       "  'gonna',\n",
       "  'be',\n",
       "  'in',\n",
       "  'thirty',\n",
       "  'minutes'],\n",
       " ['so',\n",
       "  'thats',\n",
       "  'about',\n",
       "  'um',\n",
       "  'about',\n",
       "  'ten',\n",
       "  'to',\n",
       "  'twelve',\n",
       "  'by',\n",
       "  'my',\n",
       "  'watch'],\n",
       " ['um',\n",
       "  'so',\n",
       "  'inbetween',\n",
       "  'now',\n",
       "  'and',\n",
       "  'then',\n",
       "  'um',\n",
       "  'as',\n",
       "  'the',\n",
       "  'industrial',\n",
       "  'designer',\n",
       "  'youre',\n",
       "  'gonna',\n",
       "  'be',\n",
       "  'working',\n",
       "  'on',\n",
       "  'you',\n",
       "  'know',\n",
       "  'the',\n",
       "  'actual',\n",
       "  'working',\n",
       "  'design',\n",
       "  'of',\n",
       "  'it',\n",
       "  'so',\n",
       "  'you',\n",
       "  'know',\n",
       "  'what',\n",
       "  'youre',\n",
       "  'doing',\n",
       "  'there'],\n",
       " ['um',\n",
       "  'for',\n",
       "  'user',\n",
       "  'interface',\n",
       "  'technical',\n",
       "  'functions',\n",
       "  'guess',\n",
       "  'thats',\n",
       "  'you',\n",
       "  'know',\n",
       "  'like',\n",
       "  'what',\n",
       "  'weve',\n",
       "  'been',\n",
       "  'talking',\n",
       "  'about',\n",
       "  'what',\n",
       "  'itll',\n",
       "  'actually',\n",
       "  'do'],\n",
       " ['um',\n",
       "  'and',\n",
       "  'uh',\n",
       "  'marketing',\n",
       "  'executive',\n",
       "  'youll',\n",
       "  'be',\n",
       "  'just',\n",
       "  'thinking',\n",
       "  'about',\n",
       "  'what',\n",
       "  'it',\n",
       "  'actually',\n",
       "  'what',\n",
       "  'you',\n",
       "  'know',\n",
       "  'what',\n",
       "  'requirements',\n",
       "  'it',\n",
       "  'has',\n",
       "  'to',\n",
       "  'has',\n",
       "  'to',\n",
       "  'fulfil',\n",
       "  'and',\n",
       "  'youll',\n",
       "  'all',\n",
       "  'get',\n",
       "  'instructions',\n",
       "  'emailed',\n",
       "  'to',\n",
       "  'you',\n",
       "  'guess'],\n",
       " ['um'],\n",
       " ['yeah',\n",
       "  'so',\n",
       "  'its',\n",
       "  'th',\n",
       "  'the',\n",
       "  'functional',\n",
       "  'design',\n",
       "  'stage',\n",
       "  'is',\n",
       "  'next',\n",
       "  'guess'],\n",
       " ['and', 'uh', 'and', 'thats', 'the', 'end', 'of', 'the', 'meeting'],\n",
       " ['so',\n",
       "  'got',\n",
       "  'that',\n",
       "  'little',\n",
       "  'message',\n",
       "  'lot',\n",
       "  'sooner',\n",
       "  'than',\n",
       "  'thought',\n",
       "  'would',\n",
       "  'so',\n",
       "  'mm',\n",
       "  'hmm'],\n",
       " ['uh', 'huh', 'yeah'],\n",
       " ['th',\n",
       "  'okay',\n",
       "  'well',\n",
       "  'just',\n",
       "  'very',\n",
       "  'quickly',\n",
       "  'cause',\n",
       "  'this',\n",
       "  'were',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'finish',\n",
       "  'now'],\n",
       " ['um',\n",
       "  'guess',\n",
       "  'thats',\n",
       "  'up',\n",
       "  'to',\n",
       "  'us',\n",
       "  'mean',\n",
       "  'you',\n",
       "  'probably',\n",
       "  'want',\n",
       "  'some',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'unique',\n",
       "  'selling',\n",
       "  'point',\n",
       "  'of',\n",
       "  'it',\n",
       "  'so',\n",
       "  'um',\n",
       "  'you',\n",
       "  'know',\n",
       "  'yeah'],\n",
       " ['mm', 'hmm'],\n",
       " ['yeah'],\n",
       " ['okay'],\n",
       " ['right',\n",
       "  'okay',\n",
       "  'well',\n",
       "  'thats',\n",
       "  'thats',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'the',\n",
       "  'meeting',\n",
       "  'then'],\n",
       " ['um'],\n",
       " ['so', 'uh', 'thank', 'you', 'all', 'for', 'coming'],\n",
       " ['hi',\n",
       "  'im',\n",
       "  'david',\n",
       "  'and',\n",
       "  'im',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'an',\n",
       "  'industrial',\n",
       "  'designer'],\n",
       " ['um',\n",
       "  'just',\n",
       "  'got',\n",
       "  'the',\n",
       "  'project',\n",
       "  'announcement',\n",
       "  'about',\n",
       "  'what',\n",
       "  'the',\n",
       "  'project',\n",
       "  'is'],\n",
       " ['designing', 'remote', 'control'],\n",
       " ['thats', 'about', 'it', 'didnt', 'get', 'anything', 'else'],\n",
       " ['did', 'you', 'get', 'the', 'same', 'thing'],\n",
       " ['cool'],\n",
       " ['theres', 'too', 'much', 'gear'],\n",
       " ['okay'],\n",
       " ['cant', 'draw'],\n",
       " ['um'],\n",
       " ['yeah'],\n",
       " ['um',\n",
       "  'well',\n",
       "  'anyway',\n",
       "  'dont',\n",
       "  'know',\n",
       "  'its',\n",
       "  'just',\n",
       "  'the',\n",
       "  'first',\n",
       "  'animal',\n",
       "  'can',\n",
       "  'think',\n",
       "  'off',\n",
       "  'the',\n",
       "  'top',\n",
       "  'of',\n",
       "  'my',\n",
       "  'head'],\n",
       " ['um'],\n",
       " ['yes'],\n",
       " ['big', 'reason', 'is', 'cause', 'im', 'allergic', 'to', 'most', 'animals'],\n",
       " ['allergic',\n",
       "  'to',\n",
       "  'animal',\n",
       "  'fur',\n",
       "  'so',\n",
       "  'um',\n",
       "  'fish',\n",
       "  'was',\n",
       "  'natural',\n",
       "  'choice'],\n",
       " ['um', 'yeah', 'and', 'kind', 'of', 'like', 'whales'],\n",
       " ['they', 'come', 'in', 'and', 'go', 'eat', 'everything', 'in', 'sight'],\n",
       " ['and', 'theyre', 'quite', 'harmless', 'and', 'mild', 'and', 'interesting'],\n",
       " ['tails', 'bit', 'big', 'think'],\n",
       " ['its', 'an', 'after', 'dinner', 'dog', 'then'],\n",
       " ['hmm'],\n",
       " ['it',\n",
       "  'does',\n",
       "  'make',\n",
       "  'sense',\n",
       "  'from',\n",
       "  'maybe',\n",
       "  'the',\n",
       "  'design',\n",
       "  'point',\n",
       "  'of',\n",
       "  'view',\n",
       "  'cause',\n",
       "  'you',\n",
       "  'have',\n",
       "  'more',\n",
       "  'complicated',\n",
       "  'characters',\n",
       "  'like',\n",
       "  'european',\n",
       "  'languages',\n",
       "  'then',\n",
       "  'you',\n",
       "  'need',\n",
       "  'more',\n",
       "  'buttons'],\n",
       " ['so', 'possibly'],\n",
       " ['hmm'],\n",
       " ['yeah'],\n",
       " ['and', 'you', 'keep', 'losing', 'them'],\n",
       " ['finding', 'them', 'is', 'really', 'pain', 'you', 'know'],\n",
       " ['mean',\n",
       "  'its',\n",
       "  'usually',\n",
       "  'quite',\n",
       "  'small',\n",
       "  'or',\n",
       "  'when',\n",
       "  'you',\n",
       "  'want',\n",
       "  'it',\n",
       "  'right',\n",
       "  'it',\n",
       "  'slipped',\n",
       "  'behind',\n",
       "  'the',\n",
       "  'couch',\n",
       "  'or',\n",
       "  'its',\n",
       "  'kicked',\n",
       "  'under',\n",
       "  'the',\n",
       "  'table'],\n",
       " ['you', 'know'],\n",
       " ['yep'],\n",
       " ['mm', 'hmm'],\n",
       " ['think', 'one', 'factor', 'would', 'be', 'production', 'cost'],\n",
       " ['because',\n",
       "  'theres',\n",
       "  'cap',\n",
       "  'there',\n",
       "  'so',\n",
       "  'um',\n",
       "  'depends',\n",
       "  'on',\n",
       "  'how',\n",
       "  'much',\n",
       "  'you',\n",
       "  'can',\n",
       "  'cram',\n",
       "  'into',\n",
       "  'that',\n",
       "  'price'],\n",
       " ['um'],\n",
       " ['think', 'that', 'thats', 'the', 'main', 'factor'],\n",
       " ['cool']]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = list(sent_to_words(text))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDqAWR2kanVg"
   },
   "outputs": [],
   "source": [
    "# убираем стоп-слова\n",
    "res_ = []\n",
    "s_ =[]\n",
    "for s in res:\n",
    "    for word in s:\n",
    "        if word not in stopwords_english:\n",
    "            s_.append(word)\n",
    "    res_.append(s_)\n",
    "    s_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K30Fm0kfanVg",
    "outputId": "6d0fce77-0f8f-427f-de2b-ebc4d08384a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['im', 'craig', 'im', 'user', 'interface'],\n",
       " [],\n",
       " ['favourite', 'animal', 'would', 'monkey'],\n",
       " ['theyre',\n",
       "  'small',\n",
       "  'cute',\n",
       "  'furry',\n",
       "  'planet',\n",
       "  'apes',\n",
       "  'becomes',\n",
       "  'real',\n",
       "  'im',\n",
       "  'gonna'],\n",
       " [],\n",
       " ['know',\n",
       "  'parents',\n",
       "  'went',\n",
       "  'bought',\n",
       "  'remote',\n",
       "  'controls',\n",
       "  'got',\n",
       "  'fed',\n",
       "  'four',\n",
       "  'five',\n",
       "  'different',\n",
       "  'remote',\n",
       "  'controls',\n",
       "  'things',\n",
       "  'house'],\n",
       " ['many', 'devices', 'control'],\n",
       " [],\n",
       " [],\n",
       " ['great'],\n",
       " ['im', 'andrew', 'im', 'marketing', 'expert'],\n",
       " [],\n",
       " [],\n",
       " ['thats', 'thats'],\n",
       " [],\n",
       " ['go'],\n",
       " ['thats', 'fine'],\n",
       " [],\n",
       " ['one', 'right'],\n",
       " [],\n",
       " ['nice'],\n",
       " [],\n",
       " ['favourite', 'animal', 'beagle'],\n",
       " ['charac', 'favourite', 'characteristics'],\n",
       " ['right'],\n",
       " ['right',\n",
       "  'basically',\n",
       "  'high',\n",
       "  'priority',\n",
       "  'animal',\n",
       "  'willing',\n",
       "  'take',\n",
       "  'lot',\n",
       "  'physical',\n",
       "  'affection',\n",
       "  'family'],\n",
       " ['lots', 'personality', 'fit', 'robust', 'good', 'health'],\n",
       " ['blue'],\n",
       " ['blue', 'beagle'],\n",
       " ['familys', 'beagle'],\n",
       " ['coulda', 'told', 'whole', 'lot', 'beagles'],\n",
       " ['boy', 'let', 'tell'],\n",
       " ['impressionist'],\n",
       " [],\n",
       " [],\n",
       " ['superb', 'sketch', 'way'],\n",
       " [],\n",
       " ['see', 'dog'],\n",
       " [],\n",
       " ['see', 'rooster'],\n",
       " ['kind'],\n",
       " ['aware', 'th', 'cha', 'tail', 'hes', 'chasing'],\n",
       " [],\n",
       " ['probably', 'little', 'got', 'lots', 'attention', 'forever', 'conditioned'],\n",
       " [],\n",
       " ['go'],\n",
       " ['bas', 'twel'],\n",
       " [],\n",
       " ['cost',\n",
       "  'production',\n",
       "  'cost',\n",
       "  'twelve',\n",
       "  'fifty',\n",
       "  'selling',\n",
       "  'price',\n",
       "  'wholesale',\n",
       "  'retail'],\n",
       " ['shelf'],\n",
       " ['sale', 'sale', 'anyway'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['yes'],\n",
       " [],\n",
       " [],\n",
       " ['right',\n",
       "  'away',\n",
       "  'im',\n",
       "  'wondering',\n",
       "  'theres',\n",
       "  'th',\n",
       "  'th',\n",
       "  'd_v_d_',\n",
       "  'players',\n",
       "  'zones'],\n",
       " ['frequencies',\n",
       "  'something',\n",
       "  'characters',\n",
       "  'different',\n",
       "  'keypad',\n",
       "  'styles',\n",
       "  'symbols'],\n",
       " [],\n",
       " ['dont', 'know'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['al', 'thing', 'international', 'top', 'price'],\n",
       " ['im',\n",
       "  'thinking',\n",
       "  'price',\n",
       "  'might',\n",
       "  'might',\n",
       "  'appeal',\n",
       "  'certain',\n",
       "  'market',\n",
       "  'one',\n",
       "  'region',\n",
       "  'whereas',\n",
       "  'another',\n",
       "  'itll',\n",
       "  'different',\n",
       "  'chara',\n",
       "  'characteristic',\n",
       "  'basic',\n",
       "  'product',\n",
       "  'podi',\n",
       "  'positioning',\n",
       "  'twenty',\n",
       "  'five',\n",
       "  'euro',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'might',\n",
       "  'big',\n",
       "  'hit',\n",
       "  'london',\n",
       "  'might',\n",
       "  'big',\n",
       "  'hit',\n",
       "  'greece',\n",
       "  'knows',\n",
       "  'something'],\n",
       " [],\n",
       " ['right',\n",
       "  'away',\n",
       "  'im',\n",
       "  'making',\n",
       "  'kind',\n",
       "  'assumptions',\n",
       "  'information',\n",
       "  'given',\n",
       "  'thinking',\n",
       "  'trendy',\n",
       "  'probably',\n",
       "  'means',\n",
       "  'something',\n",
       "  'basic',\n",
       "  'something',\n",
       "  'standard'],\n",
       " ['im',\n",
       "  'wondering',\n",
       "  'right',\n",
       "  'away',\n",
       "  'selling',\n",
       "  'twenty',\n",
       "  'five',\n",
       "  'euros',\n",
       "  'sort',\n",
       "  'thi',\n",
       "  'gonna',\n",
       "  'premium',\n",
       "  'product',\n",
       "  'kinda',\n",
       "  'thing',\n",
       "  'huh'],\n",
       " [],\n",
       " [],\n",
       " ['id', 'say'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['background', 'information', 'compares'],\n",
       " [],\n",
       " ['interesting',\n",
       "  'thing',\n",
       "  'discussing',\n",
       "  'production',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'point',\n",
       "  'dont',\n",
       "  'think',\n",
       "  'remote',\n",
       "  'controls',\n",
       "  'somethin',\n",
       "  'something',\n",
       "  'people',\n",
       "  'consciously',\n",
       "  'assess',\n",
       "  'purchasing',\n",
       "  'habits'],\n",
       " ['getting', 'shoelaces', 'shoes', 'something'],\n",
       " ['comes', 'along'],\n",
       " ['know', 'mean'],\n",
       " ['sort',\n",
       "  'mean',\n",
       "  'one',\n",
       "  'one',\n",
       "  'way',\n",
       "  'looking',\n",
       "  'would',\n",
       "  'people',\n",
       "  'producing',\n",
       "  'television',\n",
       "  'sets',\n",
       "  'maybe',\n",
       "  'buy',\n",
       "  'remote',\n",
       "  'controls'],\n",
       " ['another',\n",
       "  'way',\n",
       "  'maybe',\n",
       "  'people',\n",
       "  't_v_',\n",
       "  'sets',\n",
       "  'really',\n",
       "  'fed',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'really',\n",
       "  'want',\n",
       "  'better',\n",
       "  'one',\n",
       "  'something'],\n",
       " ['right'],\n",
       " ['right'],\n",
       " ['right',\n",
       "  'function',\n",
       "  'one',\n",
       "  'priorities',\n",
       "  'might',\n",
       "  'combine',\n",
       "  'many',\n",
       "  'uses',\n",
       "  'think'],\n",
       " [],\n",
       " [],\n",
       " ['maybe',\n",
       "  'could',\n",
       "  'use',\n",
       "  'sort',\n",
       "  'example',\n",
       "  'successful',\n",
       "  'piece',\n",
       "  'technology',\n",
       "  'palm',\n",
       "  'palm',\n",
       "  'pilots'],\n",
       " ['theyre',\n",
       "  'gone',\n",
       "  'little',\n",
       "  'sort',\n",
       "  'scribble',\n",
       "  'boards',\n",
       "  'cameras',\n",
       "  'm_p_',\n",
       "  'three',\n",
       "  'players',\n",
       "  'telephones',\n",
       "  'everything',\n",
       "  'agenda'],\n",
       " ['wonder',\n",
       "  'might',\n",
       "  'add',\n",
       "  'something',\n",
       "  'new',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'market',\n",
       "  'lighting',\n",
       "  'house'],\n",
       " [],\n",
       " ['personally',\n",
       "  'home',\n",
       "  'combined',\n",
       "  'audio',\n",
       "  'video',\n",
       "  'television',\n",
       "  'set',\n",
       "  'd_v_d_',\n",
       "  'player',\n",
       "  'c_d_',\n",
       "  'player'],\n",
       " ['work',\n",
       "  'actually',\n",
       "  'function',\n",
       "  'together',\n",
       "  'different',\n",
       "  'remote',\n",
       "  'controls'],\n",
       " ['sort', 'ironic', 'theyre', 'know', 'sound', 'everything', 'one', 'system'],\n",
       " ['ones', 'got', 'little', 'part'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['thats', 'really', 'good', 'id'],\n",
       " ['sure'],\n",
       " ['remember', 'first', 'remote', 'control', 'family', 'cable'],\n",
       " ['actually',\n",
       "  'cable',\n",
       "  't_v_',\n",
       "  'big',\n",
       "  'buttons',\n",
       "  'sort',\n",
       "  'blender',\n",
       "  'something'],\n",
       " ['know',\n",
       "  'think',\n",
       "  'better',\n",
       "  'actually',\n",
       "  'still',\n",
       "  'kind',\n",
       "  'dunno',\n",
       "  'massive',\n",
       "  'junky',\n",
       "  'thing',\n",
       "  'table'],\n",
       " ['maybe', 'could', 'think', 'could', 'know', 'streamlined'],\n",
       " ['something'],\n",
       " ['whatever', 'would', 'technologically', 'reasonable'],\n",
       " ['cause',\n",
       "  'could',\n",
       "  'could',\n",
       "  'could',\n",
       "  'could',\n",
       "  'functionally',\n",
       "  'doesnt',\n",
       "  'make',\n",
       "  'better',\n",
       "  'appeal',\n",
       "  'know',\n",
       "  'days',\n",
       "  'theres',\n",
       "  'pe',\n",
       "  'things',\n",
       "  'peoples',\n",
       "  'homes',\n",
       "  'becoming',\n",
       "  'chic',\n",
       "  'know'],\n",
       " ['nicer', 'materials', 'might', 'worth', 'exploring', 'anyway'],\n",
       " [],\n",
       " [],\n",
       " ['wrap',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'page',\n",
       "  'given',\n",
       "  'sort',\n",
       "  'example',\n",
       "  'coffee',\n",
       "  'machine',\n",
       "  'something',\n",
       "  'right'],\n",
       " ['right',\n",
       "  'assumption',\n",
       "  'television',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'may',\n",
       "  'features',\n",
       "  'go',\n",
       "  'beyond',\n",
       "  'television'],\n",
       " ['keeping', 'sort', 'design', 'commitment', 'television', 'features'],\n",
       " ['dont', 'know'],\n",
       " [],\n",
       " ['sure'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['right'],\n",
       " ['kick', 'meeting', 'project'],\n",
       " ['gonna', 'next', 'twenty', 'five', 'minutes'],\n",
       " ['first',\n",
       "  'kind',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'know',\n",
       "  'im',\n",
       "  'laura',\n",
       "  'im',\n",
       "  'project',\n",
       "  'manager'],\n",
       " ['want', 'introduce'],\n",
       " [],\n",
       " ['great'],\n",
       " [],\n",
       " ['designing', 'new', 'remote', 'control', 'oh', 'record', 'whos', 'actually'],\n",
       " ['thats', 'david', 'andrew', 'craig', 'isnt'],\n",
       " ['arrived', 'time'],\n",
       " ['des', 'design', 'new', 'remote', 'control'],\n",
       " ['see', 'supposed', 'original', 'trendy', 'user', 'friendly'],\n",
       " ['thats', 'kind', 'brief'],\n",
       " ['three', 'different', 'stages', 'design'],\n",
       " ['im', 'really', 'sure', 'guys', 'already', 'received', 'emails'],\n",
       " ['get'],\n",
       " [],\n",
       " ['everybody', 'got'],\n",
       " [],\n",
       " [],\n",
       " ['gonna', 'individual', 'work', 'meeting'],\n",
       " ['repeat', 'process', 'three', 'times'],\n",
       " ['point', 'get', 'try', 'whiteboard'],\n",
       " [],\n",
       " ['get', 'draw', 'favourite', 'animal', 'sum', 'favourite', 'characteristics'],\n",
       " ['would', 'go', 'first'],\n",
       " ['good'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['right'],\n",
       " ['lovely'],\n",
       " ['right'],\n",
       " ['take', 'long', 'havent', 'got', 'awful', 'lot', 'discuss'],\n",
       " ['ok', 'oh'],\n",
       " ['dont', 'feel', 'youre', 'rush', 'anyway'],\n",
       " ['ach', 'might', 'get'],\n",
       " ['dont', 'know', 'mine'],\n",
       " ['im', 'gonna', 'think', 'spot'],\n",
       " ['whale'],\n",
       " ['ah'],\n",
       " [],\n",
       " ['god', 'still', 'dont', 'know', 'im', 'gonna', 'write'],\n",
       " [],\n",
       " ['gonna', 'choose', 'dog'],\n",
       " ['ill', 'draw', 'different', 'kind', 'dog'],\n",
       " ['favourite', 'animal', 'dog', 'home'],\n",
       " ['doesnt', 'really', 'look', 'actually'],\n",
       " ['looks', 'pig', 'actually'],\n",
       " ['ah'],\n",
       " [],\n",
       " ['oh', 'thats', 'good'],\n",
       " [],\n",
       " ['hes', 'mixture', 'various', 'things'],\n",
       " ['thats', 'suggest', 'tail', 'wags'],\n",
       " ['hes',\n",
       "  'friendly',\n",
       "  'cheery',\n",
       "  'always',\n",
       "  'pleased',\n",
       "  'see',\n",
       "  'kind',\n",
       "  'affectionate',\n",
       "  'hes',\n",
       "  'quite',\n",
       "  'quite',\n",
       "  'wee',\n",
       "  'know',\n",
       "  'doesnt',\n",
       "  'take',\n",
       "  'much',\n",
       "  'space'],\n",
       " ['funny', 'thing', 'chases', 'tail', 'quite', 'amusing'],\n",
       " ['think'],\n",
       " ['hes',\n",
       "  'dinner',\n",
       "  'hell',\n",
       "  'sudden',\n",
       "  'get',\n",
       "  'start',\n",
       "  'chasing',\n",
       "  'tail',\n",
       "  'round',\n",
       "  'living',\n",
       "  'room'],\n",
       " ['maybe'],\n",
       " ['maybe'],\n",
       " ['right', 'find'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['next'],\n",
       " [],\n",
       " ['need', 'discuss', 'project', 'finance'],\n",
       " ['according',\n",
       "  'brief',\n",
       "  'gonna',\n",
       "  'selling',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'twenty',\n",
       "  'five',\n",
       "  'euro',\n",
       "  'aiming',\n",
       "  'make',\n",
       "  'fifty',\n",
       "  'million',\n",
       "  'euro'],\n",
       " ['gonna', 'selling', 'international', 'scale'],\n",
       " ['dont',\n",
       "  'want',\n",
       "  'cost',\n",
       "  'twelve',\n",
       "  'fifty',\n",
       "  'euros',\n",
       "  'fifty',\n",
       "  'percent',\n",
       "  'selling',\n",
       "  'price'],\n",
       " ['sure'],\n",
       " ['together'],\n",
       " ['dunno'],\n",
       " ['imagine', 'thats', 'good', 'question'],\n",
       " ['imagine',\n",
       "  'probably',\n",
       "  'sale',\n",
       "  'actually',\n",
       "  'probably',\n",
       "  'retailer',\n",
       "  'sell',\n",
       "  'whatever',\n",
       "  'price',\n",
       "  'want'],\n",
       " [],\n",
       " ['dont',\n",
       "  'know',\n",
       "  'mean',\n",
       "  'think',\n",
       "  'fact',\n",
       "  'going',\n",
       "  'sold',\n",
       "  'internationally',\n",
       "  'bearing',\n",
       "  'design'],\n",
       " ['think'],\n",
       " [],\n",
       " [],\n",
       " ['oh', 'regions', 'stuff'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['remote',\n",
       "  'control',\n",
       "  'think',\n",
       "  'suppose',\n",
       "  'depends',\n",
       "  'complicated',\n",
       "  'remote',\n",
       "  'control'],\n",
       " [],\n",
       " [],\n",
       " ['terms', 'wealth', 'country'],\n",
       " ['much', 'money', 'people', 'spend', 'things'],\n",
       " ['aye', 'see', 'mean'],\n",
       " ['marketing'],\n",
       " ['good', 'marketing', 'thoughts'],\n",
       " ['oh', 'writing'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['much', 'know', 'remote', 'control', 'cost'],\n",
       " ['twenty',\n",
       "  'five',\n",
       "  'euro',\n",
       "  'mean',\n",
       "  'thats',\n",
       "  'thats',\n",
       "  'eighteen',\n",
       "  'pounds',\n",
       "  'something',\n",
       "  'isnt'],\n",
       " ['much'],\n",
       " ['sixteen', 'seventeen', 'eighteen', 'pounds'],\n",
       " ['dunno',\n",
       "  'never',\n",
       "  'bought',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'dont',\n",
       "  'know',\n",
       "  'good',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'would',\n",
       "  'get'],\n",
       " [],\n",
       " ['suppose', 'look', 'kind', 'cool', 'gimmicky'],\n",
       " ['right'],\n",
       " ['let', 'scoot', 'ahead'],\n",
       " [],\n",
       " ['anybody', 'anything', 'add', 'finance', 'issue'],\n",
       " ['thin', 'actually'],\n",
       " ['would', 'useful', 'though', 'wouldnt', 'knew', 'money', 'would', 'get'],\n",
       " [],\n",
       " [],\n",
       " ['oh'],\n",
       " ['five', 'minutes', 'end', 'meeting'],\n",
       " ['oh'],\n",
       " ['bit', 'behind'],\n",
       " [],\n",
       " ['right',\n",
       "  'think',\n",
       "  'main',\n",
       "  'design',\n",
       "  'aim',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'know',\n",
       "  'satellite',\n",
       "  'regular',\n",
       "  'telly',\n",
       "  'v_c_r_',\n",
       "  'everything'],\n",
       " [],\n",
       " [],\n",
       " ['even', 'know', 'notes', 'wanna', 'watch'],\n",
       " ['might',\n",
       "  'put',\n",
       "  'oh',\n",
       "  'want',\n",
       "  'watch',\n",
       "  'look',\n",
       "  'oh',\n",
       "  'thats',\n",
       "  'good',\n",
       "  'idea'],\n",
       " ['extra', 'functionalities'],\n",
       " [],\n",
       " [],\n",
       " ['id',\n",
       "  'wel',\n",
       "  'gonna',\n",
       "  'wrap',\n",
       "  'pretty',\n",
       "  'quickly',\n",
       "  'next',\n",
       "  'couple',\n",
       "  'minutes'],\n",
       " ['ill', 'check', 'nothing', 'else'],\n",
       " [],\n",
       " ['anything',\n",
       "  'else',\n",
       "  'anybody',\n",
       "  'wants',\n",
       "  'add',\n",
       "  'dont',\n",
       "  'remote',\n",
       "  'controls',\n",
       "  'theyve',\n",
       "  'used',\n",
       "  'would',\n",
       "  'really',\n",
       "  'part',\n",
       "  'new',\n",
       "  'one'],\n",
       " ['keep', 'losing'],\n",
       " [],\n",
       " [],\n",
       " ['get',\n",
       "  'ones',\n",
       "  'whistle',\n",
       "  'make',\n",
       "  'really',\n",
       "  'high',\n",
       "  'pitched',\n",
       "  'noise',\n",
       "  'beep'],\n",
       " ['mean', 'something', 'wed', 'want', 'include', 'think'],\n",
       " ['dunno'],\n",
       " ['maybe'],\n",
       " ['goodness'],\n",
       " ['still', 'feels', 'quite', 'primitive'],\n",
       " ['maybe', 'touch', 'screen', 'something'],\n",
       " [],\n",
       " ['huh'],\n",
       " ['guess', 'thats', 'industrial', 'designer'],\n",
       " ['looks', 'better'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['right', 'wrap', 'next', 'meetings', 'gonna', 'thirty', 'minutes'],\n",
       " ['thats', 'ten', 'twelve', 'watch'],\n",
       " ['inbetween',\n",
       "  'industrial',\n",
       "  'designer',\n",
       "  'youre',\n",
       "  'gonna',\n",
       "  'working',\n",
       "  'know',\n",
       "  'actual',\n",
       "  'working',\n",
       "  'design',\n",
       "  'know',\n",
       "  'youre'],\n",
       " ['user',\n",
       "  'interface',\n",
       "  'technical',\n",
       "  'functions',\n",
       "  'guess',\n",
       "  'thats',\n",
       "  'know',\n",
       "  'talking',\n",
       "  'itll',\n",
       "  'actually'],\n",
       " ['marketing',\n",
       "  'executive',\n",
       "  'youll',\n",
       "  'thinking',\n",
       "  'actually',\n",
       "  'know',\n",
       "  'requirements',\n",
       "  'fulfil',\n",
       "  'youll',\n",
       "  'get',\n",
       "  'instructions',\n",
       "  'emailed',\n",
       "  'guess'],\n",
       " [],\n",
       " ['th', 'functional', 'design', 'stage', 'next', 'guess'],\n",
       " ['thats', 'end', 'meeting'],\n",
       " ['got', 'little', 'message', 'lot', 'sooner', 'thought', 'would'],\n",
       " ['huh'],\n",
       " ['th', 'quickly', 'cause', 'supposed', 'finish'],\n",
       " ['guess',\n",
       "  'thats',\n",
       "  'us',\n",
       "  'mean',\n",
       "  'probably',\n",
       "  'want',\n",
       "  'kind',\n",
       "  'unique',\n",
       "  'selling',\n",
       "  'point',\n",
       "  'know'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['right', 'thats', 'thats', 'end', 'meeting'],\n",
       " [],\n",
       " ['thank', 'coming'],\n",
       " ['hi', 'im', 'david', 'im', 'supposed', 'industrial', 'designer'],\n",
       " ['got', 'project', 'announcement', 'project'],\n",
       " ['designing', 'remote', 'control'],\n",
       " ['thats', 'didnt', 'get', 'anything', 'else'],\n",
       " ['get', 'thing'],\n",
       " ['cool'],\n",
       " ['theres', 'much', 'gear'],\n",
       " [],\n",
       " ['cant', 'draw'],\n",
       " [],\n",
       " [],\n",
       " ['anyway', 'dont', 'know', 'first', 'animal', 'think', 'top', 'head'],\n",
       " [],\n",
       " ['yes'],\n",
       " ['big', 'reason', 'cause', 'im', 'allergic', 'animals'],\n",
       " ['allergic', 'animal', 'fur', 'fish', 'natural', 'choice'],\n",
       " ['kind', 'whales'],\n",
       " ['come', 'go', 'eat', 'everything', 'sight'],\n",
       " ['theyre', 'quite', 'harmless', 'mild', 'interesting'],\n",
       " ['tails', 'bit', 'big', 'think'],\n",
       " ['dinner', 'dog'],\n",
       " [],\n",
       " ['make',\n",
       "  'sense',\n",
       "  'maybe',\n",
       "  'design',\n",
       "  'point',\n",
       "  'view',\n",
       "  'cause',\n",
       "  'complicated',\n",
       "  'characters',\n",
       "  'european',\n",
       "  'languages',\n",
       "  'need',\n",
       "  'buttons'],\n",
       " ['possibly'],\n",
       " [],\n",
       " [],\n",
       " ['keep', 'losing'],\n",
       " ['finding', 'really', 'pain', 'know'],\n",
       " ['mean',\n",
       "  'usually',\n",
       "  'quite',\n",
       "  'small',\n",
       "  'want',\n",
       "  'right',\n",
       "  'slipped',\n",
       "  'behind',\n",
       "  'couch',\n",
       "  'kicked',\n",
       "  'table'],\n",
       " ['know'],\n",
       " [],\n",
       " [],\n",
       " ['think', 'one', 'factor', 'would', 'production', 'cost'],\n",
       " ['theres', 'cap', 'depends', 'much', 'cram', 'price'],\n",
       " [],\n",
       " ['think', 'thats', 'main', 'factor'],\n",
       " ['cool']]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jfHSbmyKbsv3",
    "outputId": "a4ddddf1-6849-496a-bb3b-d41a8c2f0d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "# лемматизация \n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijIrYs3YanVh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_fin = []\n",
    "s_fin = []\n",
    "for s in res_:\n",
    "    for word in s:\n",
    "        s_fin.append(lemmatizer.lemmatize(word))\n",
    "    # проверка на пустой список \n",
    "    if s_fin != []:\n",
    "        res_fin.append(s_fin)\n",
    "    s_fin = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MP77s8pTanVi",
    "outputId": "56da2c64-baac-4197-e29a-5d11b4bf94c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['im', 'craig', 'im', 'user', 'interface'],\n",
       " ['favourite', 'animal', 'would', 'monkey'],\n",
       " ['theyre',\n",
       "  'small',\n",
       "  'cute',\n",
       "  'furry',\n",
       "  'planet',\n",
       "  'ape',\n",
       "  'becomes',\n",
       "  'real',\n",
       "  'im',\n",
       "  'gonna'],\n",
       " ['know',\n",
       "  'parent',\n",
       "  'went',\n",
       "  'bought',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'got',\n",
       "  'fed',\n",
       "  'four',\n",
       "  'five',\n",
       "  'different',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'thing',\n",
       "  'house'],\n",
       " ['many', 'device', 'control'],\n",
       " ['great'],\n",
       " ['im', 'andrew', 'im', 'marketing', 'expert'],\n",
       " ['thats', 'thats'],\n",
       " ['go'],\n",
       " ['thats', 'fine'],\n",
       " ['one', 'right'],\n",
       " ['nice'],\n",
       " ['favourite', 'animal', 'beagle'],\n",
       " ['charac', 'favourite', 'characteristic'],\n",
       " ['right'],\n",
       " ['right',\n",
       "  'basically',\n",
       "  'high',\n",
       "  'priority',\n",
       "  'animal',\n",
       "  'willing',\n",
       "  'take',\n",
       "  'lot',\n",
       "  'physical',\n",
       "  'affection',\n",
       "  'family'],\n",
       " ['lot', 'personality', 'fit', 'robust', 'good', 'health'],\n",
       " ['blue'],\n",
       " ['blue', 'beagle'],\n",
       " ['family', 'beagle'],\n",
       " ['coulda', 'told', 'whole', 'lot', 'beagle'],\n",
       " ['boy', 'let', 'tell'],\n",
       " ['impressionist'],\n",
       " ['superb', 'sketch', 'way'],\n",
       " ['see', 'dog'],\n",
       " ['see', 'rooster'],\n",
       " ['kind'],\n",
       " ['aware', 'th', 'cha', 'tail', 'he', 'chasing'],\n",
       " ['probably', 'little', 'got', 'lot', 'attention', 'forever', 'conditioned'],\n",
       " ['go'],\n",
       " ['ba', 'twel'],\n",
       " ['cost',\n",
       "  'production',\n",
       "  'cost',\n",
       "  'twelve',\n",
       "  'fifty',\n",
       "  'selling',\n",
       "  'price',\n",
       "  'wholesale',\n",
       "  'retail'],\n",
       " ['shelf'],\n",
       " ['sale', 'sale', 'anyway'],\n",
       " ['yes'],\n",
       " ['right',\n",
       "  'away',\n",
       "  'im',\n",
       "  'wondering',\n",
       "  'there',\n",
       "  'th',\n",
       "  'th',\n",
       "  'd_v_d_',\n",
       "  'player',\n",
       "  'zone'],\n",
       " ['frequency',\n",
       "  'something',\n",
       "  'character',\n",
       "  'different',\n",
       "  'keypad',\n",
       "  'style',\n",
       "  'symbol'],\n",
       " ['dont', 'know'],\n",
       " ['al', 'thing', 'international', 'top', 'price'],\n",
       " ['im',\n",
       "  'thinking',\n",
       "  'price',\n",
       "  'might',\n",
       "  'might',\n",
       "  'appeal',\n",
       "  'certain',\n",
       "  'market',\n",
       "  'one',\n",
       "  'region',\n",
       "  'whereas',\n",
       "  'another',\n",
       "  'itll',\n",
       "  'different',\n",
       "  'chara',\n",
       "  'characteristic',\n",
       "  'basic',\n",
       "  'product',\n",
       "  'podi',\n",
       "  'positioning',\n",
       "  'twenty',\n",
       "  'five',\n",
       "  'euro',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'might',\n",
       "  'big',\n",
       "  'hit',\n",
       "  'london',\n",
       "  'might',\n",
       "  'big',\n",
       "  'hit',\n",
       "  'greece',\n",
       "  'know',\n",
       "  'something'],\n",
       " ['right',\n",
       "  'away',\n",
       "  'im',\n",
       "  'making',\n",
       "  'kind',\n",
       "  'assumption',\n",
       "  'information',\n",
       "  'given',\n",
       "  'thinking',\n",
       "  'trendy',\n",
       "  'probably',\n",
       "  'mean',\n",
       "  'something',\n",
       "  'basic',\n",
       "  'something',\n",
       "  'standard'],\n",
       " ['im',\n",
       "  'wondering',\n",
       "  'right',\n",
       "  'away',\n",
       "  'selling',\n",
       "  'twenty',\n",
       "  'five',\n",
       "  'euro',\n",
       "  'sort',\n",
       "  'thi',\n",
       "  'gonna',\n",
       "  'premium',\n",
       "  'product',\n",
       "  'kinda',\n",
       "  'thing',\n",
       "  'huh'],\n",
       " ['id', 'say'],\n",
       " ['background', 'information', 'compare'],\n",
       " ['interesting',\n",
       "  'thing',\n",
       "  'discussing',\n",
       "  'production',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'point',\n",
       "  'dont',\n",
       "  'think',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'somethin',\n",
       "  'something',\n",
       "  'people',\n",
       "  'consciously',\n",
       "  'ass',\n",
       "  'purchasing',\n",
       "  'habit'],\n",
       " ['getting', 'shoelace', 'shoe', 'something'],\n",
       " ['come', 'along'],\n",
       " ['know', 'mean'],\n",
       " ['sort',\n",
       "  'mean',\n",
       "  'one',\n",
       "  'one',\n",
       "  'way',\n",
       "  'looking',\n",
       "  'would',\n",
       "  'people',\n",
       "  'producing',\n",
       "  'television',\n",
       "  'set',\n",
       "  'maybe',\n",
       "  'buy',\n",
       "  'remote',\n",
       "  'control'],\n",
       " ['another',\n",
       "  'way',\n",
       "  'maybe',\n",
       "  'people',\n",
       "  't_v_',\n",
       "  'set',\n",
       "  'really',\n",
       "  'fed',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'really',\n",
       "  'want',\n",
       "  'better',\n",
       "  'one',\n",
       "  'something'],\n",
       " ['right'],\n",
       " ['right'],\n",
       " ['right',\n",
       "  'function',\n",
       "  'one',\n",
       "  'priority',\n",
       "  'might',\n",
       "  'combine',\n",
       "  'many',\n",
       "  'us',\n",
       "  'think'],\n",
       " ['maybe',\n",
       "  'could',\n",
       "  'use',\n",
       "  'sort',\n",
       "  'example',\n",
       "  'successful',\n",
       "  'piece',\n",
       "  'technology',\n",
       "  'palm',\n",
       "  'palm',\n",
       "  'pilot'],\n",
       " ['theyre',\n",
       "  'gone',\n",
       "  'little',\n",
       "  'sort',\n",
       "  'scribble',\n",
       "  'board',\n",
       "  'camera',\n",
       "  'm_p_',\n",
       "  'three',\n",
       "  'player',\n",
       "  'telephone',\n",
       "  'everything',\n",
       "  'agenda'],\n",
       " ['wonder',\n",
       "  'might',\n",
       "  'add',\n",
       "  'something',\n",
       "  'new',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'market',\n",
       "  'lighting',\n",
       "  'house'],\n",
       " ['personally',\n",
       "  'home',\n",
       "  'combined',\n",
       "  'audio',\n",
       "  'video',\n",
       "  'television',\n",
       "  'set',\n",
       "  'd_v_d_',\n",
       "  'player',\n",
       "  'c_d_',\n",
       "  'player'],\n",
       " ['work',\n",
       "  'actually',\n",
       "  'function',\n",
       "  'together',\n",
       "  'different',\n",
       "  'remote',\n",
       "  'control'],\n",
       " ['sort', 'ironic', 'theyre', 'know', 'sound', 'everything', 'one', 'system'],\n",
       " ['one', 'got', 'little', 'part'],\n",
       " ['thats', 'really', 'good', 'id'],\n",
       " ['sure'],\n",
       " ['remember', 'first', 'remote', 'control', 'family', 'cable'],\n",
       " ['actually',\n",
       "  'cable',\n",
       "  't_v_',\n",
       "  'big',\n",
       "  'button',\n",
       "  'sort',\n",
       "  'blender',\n",
       "  'something'],\n",
       " ['know',\n",
       "  'think',\n",
       "  'better',\n",
       "  'actually',\n",
       "  'still',\n",
       "  'kind',\n",
       "  'dunno',\n",
       "  'massive',\n",
       "  'junky',\n",
       "  'thing',\n",
       "  'table'],\n",
       " ['maybe', 'could', 'think', 'could', 'know', 'streamlined'],\n",
       " ['something'],\n",
       " ['whatever', 'would', 'technologically', 'reasonable'],\n",
       " ['cause',\n",
       "  'could',\n",
       "  'could',\n",
       "  'could',\n",
       "  'could',\n",
       "  'functionally',\n",
       "  'doesnt',\n",
       "  'make',\n",
       "  'better',\n",
       "  'appeal',\n",
       "  'know',\n",
       "  'day',\n",
       "  'there',\n",
       "  'pe',\n",
       "  'thing',\n",
       "  'people',\n",
       "  'home',\n",
       "  'becoming',\n",
       "  'chic',\n",
       "  'know'],\n",
       " ['nicer', 'material', 'might', 'worth', 'exploring', 'anyway'],\n",
       " ['wrap',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'page',\n",
       "  'given',\n",
       "  'sort',\n",
       "  'example',\n",
       "  'coffee',\n",
       "  'machine',\n",
       "  'something',\n",
       "  'right'],\n",
       " ['right',\n",
       "  'assumption',\n",
       "  'television',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'may',\n",
       "  'feature',\n",
       "  'go',\n",
       "  'beyond',\n",
       "  'television'],\n",
       " ['keeping', 'sort', 'design', 'commitment', 'television', 'feature'],\n",
       " ['dont', 'know'],\n",
       " ['sure'],\n",
       " ['right'],\n",
       " ['kick', 'meeting', 'project'],\n",
       " ['gonna', 'next', 'twenty', 'five', 'minute'],\n",
       " ['first',\n",
       "  'kind',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'know',\n",
       "  'im',\n",
       "  'laura',\n",
       "  'im',\n",
       "  'project',\n",
       "  'manager'],\n",
       " ['want', 'introduce'],\n",
       " ['great'],\n",
       " ['designing', 'new', 'remote', 'control', 'oh', 'record', 'who', 'actually'],\n",
       " ['thats', 'david', 'andrew', 'craig', 'isnt'],\n",
       " ['arrived', 'time'],\n",
       " ['de', 'design', 'new', 'remote', 'control'],\n",
       " ['see', 'supposed', 'original', 'trendy', 'user', 'friendly'],\n",
       " ['thats', 'kind', 'brief'],\n",
       " ['three', 'different', 'stage', 'design'],\n",
       " ['im', 'really', 'sure', 'guy', 'already', 'received', 'email'],\n",
       " ['get'],\n",
       " ['everybody', 'got'],\n",
       " ['gonna', 'individual', 'work', 'meeting'],\n",
       " ['repeat', 'process', 'three', 'time'],\n",
       " ['point', 'get', 'try', 'whiteboard'],\n",
       " ['get', 'draw', 'favourite', 'animal', 'sum', 'favourite', 'characteristic'],\n",
       " ['would', 'go', 'first'],\n",
       " ['good'],\n",
       " ['right'],\n",
       " ['lovely'],\n",
       " ['right'],\n",
       " ['take', 'long', 'havent', 'got', 'awful', 'lot', 'discus'],\n",
       " ['ok', 'oh'],\n",
       " ['dont', 'feel', 'youre', 'rush', 'anyway'],\n",
       " ['ach', 'might', 'get'],\n",
       " ['dont', 'know', 'mine'],\n",
       " ['im', 'gonna', 'think', 'spot'],\n",
       " ['whale'],\n",
       " ['ah'],\n",
       " ['god', 'still', 'dont', 'know', 'im', 'gonna', 'write'],\n",
       " ['gonna', 'choose', 'dog'],\n",
       " ['ill', 'draw', 'different', 'kind', 'dog'],\n",
       " ['favourite', 'animal', 'dog', 'home'],\n",
       " ['doesnt', 'really', 'look', 'actually'],\n",
       " ['look', 'pig', 'actually'],\n",
       " ['ah'],\n",
       " ['oh', 'thats', 'good'],\n",
       " ['he', 'mixture', 'various', 'thing'],\n",
       " ['thats', 'suggest', 'tail', 'wag'],\n",
       " ['he',\n",
       "  'friendly',\n",
       "  'cheery',\n",
       "  'always',\n",
       "  'pleased',\n",
       "  'see',\n",
       "  'kind',\n",
       "  'affectionate',\n",
       "  'he',\n",
       "  'quite',\n",
       "  'quite',\n",
       "  'wee',\n",
       "  'know',\n",
       "  'doesnt',\n",
       "  'take',\n",
       "  'much',\n",
       "  'space'],\n",
       " ['funny', 'thing', 'chase', 'tail', 'quite', 'amusing'],\n",
       " ['think'],\n",
       " ['he',\n",
       "  'dinner',\n",
       "  'hell',\n",
       "  'sudden',\n",
       "  'get',\n",
       "  'start',\n",
       "  'chasing',\n",
       "  'tail',\n",
       "  'round',\n",
       "  'living',\n",
       "  'room'],\n",
       " ['maybe'],\n",
       " ['maybe'],\n",
       " ['right', 'find'],\n",
       " ['next'],\n",
       " ['need', 'discus', 'project', 'finance'],\n",
       " ['according',\n",
       "  'brief',\n",
       "  'gonna',\n",
       "  'selling',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'twenty',\n",
       "  'five',\n",
       "  'euro',\n",
       "  'aiming',\n",
       "  'make',\n",
       "  'fifty',\n",
       "  'million',\n",
       "  'euro'],\n",
       " ['gonna', 'selling', 'international', 'scale'],\n",
       " ['dont',\n",
       "  'want',\n",
       "  'cost',\n",
       "  'twelve',\n",
       "  'fifty',\n",
       "  'euro',\n",
       "  'fifty',\n",
       "  'percent',\n",
       "  'selling',\n",
       "  'price'],\n",
       " ['sure'],\n",
       " ['together'],\n",
       " ['dunno'],\n",
       " ['imagine', 'thats', 'good', 'question'],\n",
       " ['imagine',\n",
       "  'probably',\n",
       "  'sale',\n",
       "  'actually',\n",
       "  'probably',\n",
       "  'retailer',\n",
       "  'sell',\n",
       "  'whatever',\n",
       "  'price',\n",
       "  'want'],\n",
       " ['dont',\n",
       "  'know',\n",
       "  'mean',\n",
       "  'think',\n",
       "  'fact',\n",
       "  'going',\n",
       "  'sold',\n",
       "  'internationally',\n",
       "  'bearing',\n",
       "  'design'],\n",
       " ['think'],\n",
       " ['oh', 'region', 'stuff'],\n",
       " ['remote',\n",
       "  'control',\n",
       "  'think',\n",
       "  'suppose',\n",
       "  'depends',\n",
       "  'complicated',\n",
       "  'remote',\n",
       "  'control'],\n",
       " ['term', 'wealth', 'country'],\n",
       " ['much', 'money', 'people', 'spend', 'thing'],\n",
       " ['aye', 'see', 'mean'],\n",
       " ['marketing'],\n",
       " ['good', 'marketing', 'thought'],\n",
       " ['oh', 'writing'],\n",
       " ['much', 'know', 'remote', 'control', 'cost'],\n",
       " ['twenty',\n",
       "  'five',\n",
       "  'euro',\n",
       "  'mean',\n",
       "  'thats',\n",
       "  'thats',\n",
       "  'eighteen',\n",
       "  'pound',\n",
       "  'something',\n",
       "  'isnt'],\n",
       " ['much'],\n",
       " ['sixteen', 'seventeen', 'eighteen', 'pound'],\n",
       " ['dunno',\n",
       "  'never',\n",
       "  'bought',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'dont',\n",
       "  'know',\n",
       "  'good',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'would',\n",
       "  'get'],\n",
       " ['suppose', 'look', 'kind', 'cool', 'gimmicky'],\n",
       " ['right'],\n",
       " ['let', 'scoot', 'ahead'],\n",
       " ['anybody', 'anything', 'add', 'finance', 'issue'],\n",
       " ['thin', 'actually'],\n",
       " ['would', 'useful', 'though', 'wouldnt', 'knew', 'money', 'would', 'get'],\n",
       " ['oh'],\n",
       " ['five', 'minute', 'end', 'meeting'],\n",
       " ['oh'],\n",
       " ['bit', 'behind'],\n",
       " ['right',\n",
       "  'think',\n",
       "  'main',\n",
       "  'design',\n",
       "  'aim',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'know',\n",
       "  'satellite',\n",
       "  'regular',\n",
       "  'telly',\n",
       "  'v_c_r_',\n",
       "  'everything'],\n",
       " ['even', 'know', 'note', 'wanna', 'watch'],\n",
       " ['might',\n",
       "  'put',\n",
       "  'oh',\n",
       "  'want',\n",
       "  'watch',\n",
       "  'look',\n",
       "  'oh',\n",
       "  'thats',\n",
       "  'good',\n",
       "  'idea'],\n",
       " ['extra', 'functionality'],\n",
       " ['id',\n",
       "  'wel',\n",
       "  'gonna',\n",
       "  'wrap',\n",
       "  'pretty',\n",
       "  'quickly',\n",
       "  'next',\n",
       "  'couple',\n",
       "  'minute'],\n",
       " ['ill', 'check', 'nothing', 'else'],\n",
       " ['anything',\n",
       "  'else',\n",
       "  'anybody',\n",
       "  'want',\n",
       "  'add',\n",
       "  'dont',\n",
       "  'remote',\n",
       "  'control',\n",
       "  'theyve',\n",
       "  'used',\n",
       "  'would',\n",
       "  'really',\n",
       "  'part',\n",
       "  'new',\n",
       "  'one'],\n",
       " ['keep', 'losing'],\n",
       " ['get',\n",
       "  'one',\n",
       "  'whistle',\n",
       "  'make',\n",
       "  'really',\n",
       "  'high',\n",
       "  'pitched',\n",
       "  'noise',\n",
       "  'beep'],\n",
       " ['mean', 'something', 'wed', 'want', 'include', 'think'],\n",
       " ['dunno'],\n",
       " ['maybe'],\n",
       " ['goodness'],\n",
       " ['still', 'feel', 'quite', 'primitive'],\n",
       " ['maybe', 'touch', 'screen', 'something'],\n",
       " ['huh'],\n",
       " ['guess', 'thats', 'industrial', 'designer'],\n",
       " ['look', 'better'],\n",
       " ['right', 'wrap', 'next', 'meeting', 'gonna', 'thirty', 'minute'],\n",
       " ['thats', 'ten', 'twelve', 'watch'],\n",
       " ['inbetween',\n",
       "  'industrial',\n",
       "  'designer',\n",
       "  'youre',\n",
       "  'gonna',\n",
       "  'working',\n",
       "  'know',\n",
       "  'actual',\n",
       "  'working',\n",
       "  'design',\n",
       "  'know',\n",
       "  'youre'],\n",
       " ['user',\n",
       "  'interface',\n",
       "  'technical',\n",
       "  'function',\n",
       "  'guess',\n",
       "  'thats',\n",
       "  'know',\n",
       "  'talking',\n",
       "  'itll',\n",
       "  'actually'],\n",
       " ['marketing',\n",
       "  'executive',\n",
       "  'youll',\n",
       "  'thinking',\n",
       "  'actually',\n",
       "  'know',\n",
       "  'requirement',\n",
       "  'fulfil',\n",
       "  'youll',\n",
       "  'get',\n",
       "  'instruction',\n",
       "  'emailed',\n",
       "  'guess'],\n",
       " ['th', 'functional', 'design', 'stage', 'next', 'guess'],\n",
       " ['thats', 'end', 'meeting'],\n",
       " ['got', 'little', 'message', 'lot', 'sooner', 'thought', 'would'],\n",
       " ['huh'],\n",
       " ['th', 'quickly', 'cause', 'supposed', 'finish'],\n",
       " ['guess',\n",
       "  'thats',\n",
       "  'u',\n",
       "  'mean',\n",
       "  'probably',\n",
       "  'want',\n",
       "  'kind',\n",
       "  'unique',\n",
       "  'selling',\n",
       "  'point',\n",
       "  'know'],\n",
       " ['right', 'thats', 'thats', 'end', 'meeting'],\n",
       " ['thank', 'coming'],\n",
       " ['hi', 'im', 'david', 'im', 'supposed', 'industrial', 'designer'],\n",
       " ['got', 'project', 'announcement', 'project'],\n",
       " ['designing', 'remote', 'control'],\n",
       " ['thats', 'didnt', 'get', 'anything', 'else'],\n",
       " ['get', 'thing'],\n",
       " ['cool'],\n",
       " ['there', 'much', 'gear'],\n",
       " ['cant', 'draw'],\n",
       " ['anyway', 'dont', 'know', 'first', 'animal', 'think', 'top', 'head'],\n",
       " ['yes'],\n",
       " ['big', 'reason', 'cause', 'im', 'allergic', 'animal'],\n",
       " ['allergic', 'animal', 'fur', 'fish', 'natural', 'choice'],\n",
       " ['kind', 'whale'],\n",
       " ['come', 'go', 'eat', 'everything', 'sight'],\n",
       " ['theyre', 'quite', 'harmless', 'mild', 'interesting'],\n",
       " ['tail', 'bit', 'big', 'think'],\n",
       " ['dinner', 'dog'],\n",
       " ['make',\n",
       "  'sense',\n",
       "  'maybe',\n",
       "  'design',\n",
       "  'point',\n",
       "  'view',\n",
       "  'cause',\n",
       "  'complicated',\n",
       "  'character',\n",
       "  'european',\n",
       "  'language',\n",
       "  'need',\n",
       "  'button'],\n",
       " ['possibly'],\n",
       " ['keep', 'losing'],\n",
       " ['finding', 'really', 'pain', 'know'],\n",
       " ['mean',\n",
       "  'usually',\n",
       "  'quite',\n",
       "  'small',\n",
       "  'want',\n",
       "  'right',\n",
       "  'slipped',\n",
       "  'behind',\n",
       "  'couch',\n",
       "  'kicked',\n",
       "  'table'],\n",
       " ['know'],\n",
       " ['think', 'one', 'factor', 'would', 'production', 'cost'],\n",
       " ['there', 'cap', 'depends', 'much', 'cram', 'price'],\n",
       " ['think', 'thats', 'main', 'factor'],\n",
       " ['cool']]"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_Q82dbOanVi"
   },
   "outputs": [],
   "source": [
    "# функция, которая объединяет все выше сделанные действия  \n",
    "def preprocess(filename):\n",
    "    f = open(filename, \"r\") \n",
    "    a = f.read()\n",
    "    text =[]\n",
    "    split_regex = re.compile(r'[.|!|?|…]')\n",
    "    sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "    for s in sentences:\n",
    "        text.append(s)\n",
    "    res = list(sent_to_words(text))\n",
    "    res_ = []\n",
    "    s_ =[]\n",
    "    for s in res:\n",
    "        for word in s:\n",
    "            if word not in stopwords_english:\n",
    "                s_.append(word)\n",
    "        res_.append(s_)\n",
    "        s_ = []\n",
    "    res_fin = []\n",
    "    s_fin = []\n",
    "    for s in res_:\n",
    "        for word in s:\n",
    "            s_fin.append(lemmatizer.lemmatize(word))\n",
    "        if s_fin != []:\n",
    "            res_fin.append(s_fin)\n",
    "        s_fin = []\n",
    "    return res_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j9yl56FMbN6W",
    "outputId": "5763db22-81f1-448f-92d5-a574f572f79b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wod-V3vAanVj"
   },
   "outputs": [],
   "source": [
    "# загружаем нужные нам библиотеки \n",
    "import spacy \n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "punctuation += '\\n'\n",
    "from heapq import nlargest\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import networkx as nx\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B5loPiWanVj"
   },
   "source": [
    "## Extractive methods <a class=\"anchor\" id=\"ch3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyFrkFIQanVk"
   },
   "source": [
    "### Word frequency method  <a class=\"anchor\" id=\"ch4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3fqnq6zanVk"
   },
   "source": [
    "Рассмотрим алгоритм на примере одного файла. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "jHsPv9-qcSXH",
    "outputId": "8ed69032-a741-4a72-e6ac-88e9b9e7bbb8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>extractive_text</th>\n",
       "      <th>extractive_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Wouldn't wanna be Project Manager. Uh, what we...</td>\n",
       "      <td>Um , once again I'm uh gonna take minutes . Uh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Me too. Okay. Um here's the agenda for our las...</td>\n",
       "      <td>Okay . Um here's the agenda for our last meeti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oops. That's as far as it goes. Do you also do...</td>\n",
       "      <td>uh good morning everybody here . And uh I want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hmm. E excuse me I forgot my copy. No, not min...</td>\n",
       "      <td>Uh oh I've forgotten to mail you the minutes ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Okay, can I have the laptop over here, or? Oka...</td>\n",
       "      <td>Tod uh for this meeting I will take the notes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>Morning. Yep. My name's Frank. Thank you. Hmm,...</td>\n",
       "      <td>First I will introduce myself . I'm Bart , My ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>No. We should make a big sponge lemon, and the...</td>\n",
       "      <td>mailed you the minutes of the last meeting uh ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>Mm-hmm. Yeah. I'm Robin. I'm the Marketing Man...</td>\n",
       "      <td>Right Where we uh We have twenty five minutes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>Hello. Hello. You have to put it exactly on th...</td>\n",
       "      <td>Hello you all read what we are going to do or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "      <td>Yeah. Yeah, sure. It kinda does make sense, do...</td>\n",
       "      <td>I'll just just recap on the minutes from the l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  ...                                 extractive_summary\n",
       "0             0  ...  Um , once again I'm uh gonna take minutes . Uh...\n",
       "1             1  ...  Okay . Um here's the agenda for our last meeti...\n",
       "2             2  ...  uh good morning everybody here . And uh I want...\n",
       "3             3  ...  Uh oh I've forgotten to mail you the minutes ,...\n",
       "4             4  ...  Tod uh for this meeting I will take the notes ...\n",
       "..          ...  ...                                                ...\n",
       "132         132  ...  First I will introduce myself . I'm Bart , My ...\n",
       "133         133  ...  mailed you the minutes of the last meeting uh ...\n",
       "134         134  ...  Right Where we uh We have twenty five minutes ...\n",
       "135         135  ...  Hello you all read what we are going to do or ...\n",
       "136         136  ...  I'll just just recap on the minutes from the l...\n",
       "\n",
       "[137 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_extractive = pd.read_csv('/content/extractive_dataset.csv')\n",
    "df_extractive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIw7qdWWanVk"
   },
   "outputs": [],
   "source": [
    "a = open('ami-transcripts/EN2001a.transcript.txt', \"r\", errors = 'ignore')\n",
    "transcript_sum = a.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gCG_-OeanVl",
    "outputId": "8b61622f-8899-4b16-aa8b-fc468eb90088"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Kay. Gosh. 'Kay. Is there much more in it than he d Is there much more in it than he said yesterday? Mm. Hmm. Hmm? Yeah, now I'd say if for the prototype if we just like wherever possible p chunk in the stuff that we have um pre-annotated and stuff, and for the stuff that we don't have pre-annotated write like a stupid baseline, then we should probably be able to basically that means we focus on on the interface first sort of, so that we we take the the ready-made parts and just see how we get them work together in the interface the way we want and and then we have a working prototype. And then we can go back and replace pieces either by our own components or by more sophisticated compo po components of our own. So it's probably feasible. The thing is I'm away this weekend. So that's for me Oh yeah, um yeah. No. But also I might like the the similarity thing, like my just my matrix itself for my stuff, I c I I think I can do that fairly quickly because I have the algorithms. Yeah, I think today's meeting is really the one where we where we sort of settle down the data structure and as soon as we have that, uh probably like after today's meeting, we then actually need to well go back first of all and look at NITE X_M_L_ to see in how far that that which we want is compatible with that which NITE X_M_L_ offers us. And then just sort of everyone make sure everyone understand the interface. So I think if today we decide on what data we wanna have now, and and later, maybe even today, we go and look at NITE X_M_L_ or some of us look at NITE X_M_L_ in a bit more detail, just trying to make some sense of that code and see how does the representation work in their system. And then sort of with that knowledge we should be able to then say okay, that type of NITE X_M_L_ data we wanna load into it, and this is how everyone can access it, and then we should be able to go from there. No. I've looked looked at the documentation and n like seen enough to make me think that we want to use the NITE X_M_L_ framework because um they have a good a event model that synchronizes sort of the data and and every display element. So that takes a lot of work away from us. Sort of that would be a reason for staying within their framework and using their general classes. But beyond that I haven't looked at it at all, which is something we should really do. Who actually like for this whole discussion I mean, who of us is doing stuff that is happening on-line and who of us is doing stuff that's happening off-line? Like my data is coming c Hmm? Yeah. Okay. Okay. 'Kay. So basically apart from the display module, the i the display itself, we don't have an extremely high degree of interaction between sort of our modules that create the stuff and and the interface, so the interface is mainly while it's running just working on data that's just loaded from a file, I guess. There isn't Yeah, I know. Th Yeah, the search is I guess the search is sort of a strange beast anyway because for the search we're leaving the NITE X_M_L_ framework. Um but that's still sort of that's good. That means that at least like we don't have the type of situation where somebody has to do like a billion calculations on on data on-line. 'Cause that would make it a lot more like that would mean that our interface for the data would have to be a lot more careful about how it performs and and everything. And nobody is modifying that data at at on-line time at all it seems. Nobody's making any changes to the actual data on-line. So that's actually making it a lot easier. That basically means our browser really is a viewer mostly, which isn't doing much with the data except for sort of selecting a piece piece of it and and displaying it. Hmm? Well some parts relevant for the search, yes. I'd say so. Hmm? Yeah, but nobody of us is doing much of searching from the data in the on-line stage. And for all together, like the display itself, I think we are easier if we if it's sitting on the X_M_L_ than if it's sitting on the S_Q_L_ stuff, because if it's sitting on the X_M_L_, we have the the NITE X_M_L_ framework with all its functionality for synchronizing through all the different levels whenever there's a change, whenever something's moving forward and stuff. And we can just more or less look at their code, like how their player moves forward, and how that moving forward is represented in different windows and stuff. So I think in the actual browser itself I don't wanna sit on the S_Q_L_ if we can sit on the X_M_L_ because sitting on the X_M_L_ we have all we have so much help. And for y for like the p the calculations that we're doing apart from the search, it seems that everyone needs some special representations anyway. You mean our results? Yeah, in in the NITE X_M_L_ X_M_L_ format, so with their time stamps and stuff, so that it's easy to to tie together st things. What I'm like what we have to think about is if we go with this multi-level idea, like this idea that sort of if you start with a whole meeting series as one entity, as one thing that you display, as one whole sort of, that then the individual chunks of the individual meetings, whereas and then you can click on a meeting, and then sort of the meeting is the whole thing and the chunks are the individual segments, that means sort of we have multiple levels of of representation, which we probably If we if we do it this way like we f we have to discuss that if we do it this way, then we should probably find some abstraction model, so that the interface in the sense like deals with it as if it's same so that the interface doesn't really have to worry whether it's a meeting in the whole meeting series or a segment within a meeting, you know what I mean? And that's probably stuff that we have to sort of like process twice then. Like for example that like the summary of a meeting within the whole meeting corpus or meeting series y is meeting series a good word for that? I don't really know what how to call it. You know what I mean, like not not the whole corpus, but every meeting that has to do with one topic. Um so in in the meeting se series so that a summary for a meeting within the meeting series, are sort of compiled off-line by a summary module. And that is separate from a summary of a segment within a meeting. 'Cause I don't think we can So are we doing that at all levels? Are we um And just have different like fine-grainedness levels sort of. Mm. 'Kay. So the only thing that yeah, so the only thing that would happen basically if I double-click let's say from the whole meeting series on a single meeting, is that the zoom level changes. Like the th the start and the end position changes and the zoom level changes. I I thought we couldn't do that. Like I was under the impression that we couldn't do that because we couldn't load the data for all that. But I don't know, I mean that So I'm s not sure if I got it. I was Mm-hmm. Mm-hmm. Mm-hmm. Mm-hmm. Okay. So Okay. I wa I was just worried about the total memory complexity of it. But I I completely admit, I mean, I just sort of like th took that from some thing that Jonathan once said about not loading everything. But maybe I was just wrong about it. How many utterances w Yeah, and I w yeah. Yeah. Yeah. Yeah. So what we have is we would have a word. Like we would have words with some priority levels. And they would basically be because even the selection would would the summaries automatically feed from just how prioritized an individual word or how indiv uh prioritized an individual utterance is? Or i are the summaries sort of refined from it and made by a machine to make sentences and stuff? Or are they just sort of taking out the words with the highest priority and then the words of the second highest priority? And the u okay. Are we doing it on th the whole thing on the utterance level? Or are we doing it on word level, like the information density calculation? We I think we have start and end times for words actually, but it's yeah, but it m it might s but it might sound crazy in the player. We should really maybe we can do that together at some point today that we check out how the player works. But there's maybe some merit in altogether doing it on an utterance level in the end. So Yeah. Well but also about the displays, I mean the displays in the in the text body, in the in the latest draft that we had sort of we came up with the idea that it isn't displaying utterance for utterance, but it's also displaying uh a summarised version in you know, like below the below the graph, the part. Maybe Yeah, r Hmm? Oh yeah, f it's just like there there's like audio skimming and there's displayed skimming. Yeah. Ma maybe there's some merit of going altogether for utterance level and not even bother to calculate I mean if you have to do it internally, then you can do it. But maybe like not even store the importance levels for individual words and just sort of rank utterances as a whole. Hmm? Yeah. 'Cause it it might be better skimming and less memory required at the same time. And I mean if you if you know how to do it for individual words, then you can just in the worst case, if you can't find anything else, just sort of make the mean of the words over the utterance. You know what I mean? W it's it's Well what's the smallest chunk at the moment you're thinking of of assigning an importance measure to, is it a word or is it an utterance? So we're thinking of like maybe just storing it on a per utterance level. Because it's it's less stuff to store probably for Dave in the in the audio playing. And for in the display it's probably better if you have whole utterances than I don't know, like what it's like if you just take single words out of utterances. That probably doesn't make any sense at all, whereas if you just uh show important utterances but the utterance as a whole it makes more sense. So it doesn't actually make a difference for your algorithm, 'cause it just means that if you're working on a word level, then we just mean it over the utterance. They are on Oh so that's good anyway then, yeah. Because that makes it a lot easier than to t put it on utterance level. Oh yeah. No but I mean like how how Jasmine does it internally I don't know, but it's probably, yeah, you probably have to work on word levels for importance. But there should be ways of easily going from a word level to an utterance level. Okay. Yeah, prob Hmm. Well we do a pre-filtering of sort of the whole thing, sort of like but that, like the problem with that is it's easy to do in the text level. But that would mean it would still play the uh in your audio, unless we sort of also store what pieces we cut out for the audio. Yeah. I think before we can like answer that specific question how we c deal with that, it's probably good for us to look at what the audio player is capable of doing. Yes. So what do you mean by buffering? Like you think directly feeding But yeah, but not but not stored on the hard disk and then loaded in, but loaded in directly from memory. But it's probably a stream if it exists in Java, it would be probably some binary stream going in of some type. Okay, yeah. Okay. Okay, so I mean so that means that there's probably, even if you go on an per utterance level, there's still some merit on within utterances cutting out stuff which clearly isn't relevant at all, and that maybe also for the audio we'd have to do. So let's say we play the whole au phrase, but then in addition to that, we have some information that says minus that part of something. That's okay, that we can do. Yeah, maybe even I mean that's sort of that depends on how how advanced we get. If maybe if we realise that there's massive differences in in gain or in something, you can probably just make some simple simple normalization, but that really depends on how much time we have and and how much is necessary. Yeah, if like I d I don't know anything about audio and I have never seen the player. So if you find that the player accepts some n input from memory, and if it's easy to do, then I guess that's that's fairly doable. So but that means in the general structure we're actually quite lucky, so we we have we load into memory for the whole series of meetings just the utterances and rankings for the utterances and some information probably that says, well, the I guess that goes with the utterance, who's speaking. Because then we can also do the display about who's speaking. Yeah. But I'm I'm still confused 'cause I thought like that's just what Jonathan said we do c that we can't do, like load a massive document of that size. On the other hand The other hand, I mean it shouldn't be like should be like fifty mega-byte in RAM or something, it shouldn't be massive, should it? Actually fifty hundred megabyte is quite big in RAM. Just thinking, what's the simp so We do get an error message with the project if we load everything into the project with all the data they load. So we know that doesn't work. So our hope is essentially that we load less into it. What's this lazy loading thing, somebody explain lazy loading to me. Ah, okay. So that is that only by type of file. Like if if if the same thing is in different files, would it then maybe like, you know, if if utterances are split over three or ten or w hundred different files, is then a chance maybe that it doesn't try to load them all into memory at the same time, but just So why does it fail then in the first place? Then it shouldn't ever fail, because then it should never Yeah, but yeah, but um it uh it it failed right when you load it, right, the NITE X_M_L_ kit, so that's interesting. Hmm. Let's check that out. Um I'll p I'll probably ask Jonathan about it. So alternatively, if we realise we can't do the whole thing in one go, we can probably just process some sort of meta-data, you know what I mean, like sort of sort of for the whole series chunks representing the individual meetings or some Like something that represents the whole series in in a v in a structure very similar to the structure in which we represent individual um meetings, but with data sort of always combined from the whole series. so instead of having an single utterance that we display, it would probably be like that would be representing a whole um topic, a segment in a meeting. And sort of so that wi using the same data st Well, in a sense Uh I'm I'm thinking of in a sense of like creating a virtual a virtual meeting out of the whole meeting series, sort of. Yeah, sort of like off-line create a virtual meeting, which which basically treats the meeting series as if it was a meeting, and treats the individual meetings within the series as if they were segments, and treats the individual segments within meetings as if they were um utterances. You know, so we just sort of we shift it one level up. And in that way we could probably use the same algorithm and just like make vir like one or two ifs that say okay, if you are on a whole document uh a whole series level and that was a double-click, then don't just go into that um segment, but load a new file or something like it, but in general use the same algorithm. That would be an alternative if we can't actually load the whole thing and 'Cause also like even if we maybe this whole like maybe I'm worrying too much about the whole series in one thing display, because actually I mean probably users wouldn't view that one too often. Yeah, but I'm I'm still worried. Like for example for the display, if you actually if you want a display uh like for the whole series, the information density levels based on and and the f and the only granularity you have is individual utterances, that means you have to through every single utterance in a series of seventy hours of meetings. Yeah. Yeah, and if you make that structurally very similar to the the le like one level down, like the way how we uh store individual utterances and stuff, then maybe we can more or less use the same code and just make a few ifs and stuff. Yeah, so so but still so in in general we're having we're having utterances and they have a score. And that's as much as we really need. And of cou and they also have a time a time information of course. Hmm? And a and a s and a speaker information, yeah. Yeah, so an information which topic they're in, yeah. And and probably separate to that an information about the different topics like that Yeah. So so the skimming can work on that because the skimming just sort of sorts the utterances and puts as many in as it needs Yeah. Yeah, it'll it'll play them in some order in which they were set because otherwise it's gonna be more entertaining. Um but that that's enough data for the skimming and the the searching, so what the searching does is the searching leaves the whole framework, goes to the S_Q_L_ database and gets like basically in the end gets just a time marker for where that is, like that utterance that we are concerned with. And then we have to find I'm sure there's some way in in NITE X_M_L_ to just say set position to that time mark. And then it shifts the whole frame and it alerts every single element of the display and the display updates. Yeah, yeah. That we can ju yeah, but so so if if somethi so yeah. So if in that tree display somebody clicks on something Yeah, and then you sort of feed the time stamp to and the NITE X_M_L_ central manager, and that central manager alerts everything that's there, like alerts the skim like the the audio display, alerts the text display, alerts the visual display and says we have a new time frame and then they all sort of do their update routines with respect to the current level of zoom. So how much do they display, and starting position at where the or maybe the mid-position of it, I don't know, like w if start where the thing was found or if that thing wa was found it's in the middle of the part that we display, that I don't know. But that we can decide about, but a general sort of It's the same thing if like whether you play and it moves forward or whether you jump to a position through search, it's essentially for all the window handling, it's the same event. It's only that the event gets triggered by the search routine which sort of push that into NITE X_M_L_ and says please go there now. Why do we have to do it in memory? But that stuff's so I mean like the information is coming from off-line. So we probably we don't even have to change the utterance document, right, because the whole way, like the whole beauty of the NITE X_M_L_ is that it ties together lots of different files. So we can just create an additional X_M_L_ file which for every utterance like the utterances have I_D_s I presume, some references. So we just we tie uh p just a very short X_M_L_ file, which it's the only information it has that has whatever a number for for the um weight, for the information density, and we just tie that to the existing utterances and tie them to the existing speaker changes. Well otherwise we probably have to go over it and like add some integer that we just increment from top to bottom sort of to every utterance as an as an I_D_ some type. Or un or try to understand how NITE X_M_L_ I_D_s work and maybe there's some special route we have to follow when we use these I_D_s. It's alm hmm? Yeah, the the girl said the utterances themselves are not numbered at the moment. Okay. Okay. Okay. Yeah. So I guess that would be solvable if not. Mm-hmm. Sorry? Okay. Okay. Is that a board marker pen actually? Oh. That's just so like to make a list of all this stuff, or we probably can somebody can do it on paper. All these fancy pens. So what so the stuff we have we have utterances and speakers and weights for utterances. So for for every utterance sort of like the utterance has a speaker and a weight which is coming from outside. Or we just tie it to it. And there is segments, which hmm? Oh, so sorry um. Uh topic s topic segments I meant. Like they are they are a super-unit. So so the utterances are tied to topic segments. And if the time stamps are on a word level, then we b somehow have to extract time stamps for utterances where they start. W what segments now? Okay. Is the uh is that the same as utterances that is that the same as utterances that Mm-hmm. Mm-hmm. What so that's Oh. But that's one o one segment or is that two segments then? Yeah. Okay. Okay. So but but generally utterances is that which we just called uh sorry, segments is that which we just called utterances now. Like it's it's the sa it's sort of like one person's contribution at a time sort of thingy dingy. Okay, so yeah, so we have those, and and then we have some f field somewhere else which has topics. Yeah, and and a topic's basically they are just on the I_D_, probably with a start time or something, and and the utterances referenced to those topics I guess. So the topics don't contain any redundant thing of like showing the whole topic again, but they just sort of say a number and where they start and where they finish. And the utterances then say which topic they belong to. Yeah. No. But I was thinking of the topic segmentation now and and f for that there would only be one, right, because it's sort of like it's just a time window. Yeah. So if this lazy loading works, then this should definitely fit into I mean not memory then because it wouldn't all be in memory at the same time. So if we just have those sort of that information like a long list of all the utterances slash segments and like short or smaller lists which give weight to them. And even though probably if there's a lot of over-head in having two different files, we can probably merge the weights into it off-line. You know what I mean, like if if there's a lot of bureaucracy involved with having two different trees and whether one ties to the other because the one has the weight for the other, then it's probably quicker to just Yeah, I thought that was the whole beauty that like you can just make a new X_M_L_ file and sort of tie that to the other and and it tre Oh yeah. So no, I didn't I didn't mean tree. No. No. I meant just like handling two different files internally. Sort of c I was just thinking you know like if if the overhead for having the same amount of data coming from two d files instead of from one file is massive then it would probably be for us easy to just like off-line put the the weight into into the file that has the segments, uh yeah, segments slash utterances already. But that we can figure out I mean if it's going horrendously wrong. Yeah. Yeah. Yeah, no, we'd we'd be completely using like the whole infrastructure and basically just I mean the main difference really between our project and theirs really is that we load a different part of the data. But otherwise we're doing it the same way that they are doing it. So we just we're sort of running different types of queries on it. We in a sense we I think we are running queries, it's not just about um what we load and what we don't load, but we're l running queries in the sense that we dynamically select by by weights, don't we? That we have to check how fast that is, like to say give us all the ones that whether that works with their query language, whether that's too many results and whether we shou You know, if 'cause if it i let's say I mean if if their query language is strange and if it would return b ten million results and it can't handle it, then we can just write our individual components in the way that they know which what the threshold is. So they still get all the data and just they internally say oh no, this is less than three and I'm not gonna display it or something. Hmm? Yeah. No. I'm just thinking for this whole thing of like a different level, sort of cutting out different different pieces, whether we do that through a query where we say give us everything that's ab above this and this weight, or whether we skip the same infrastructure, but every individual module like the player and the display say like they still get sort of all the different utterances, uh all the different pieces, but they say oh, this piece I leave out, because it's below the current threshold level. When do we need the one for the meet Okay. Yeah, I guess for the so when we have the display, will we display the whole series. Then if we have for the individual topic segments within the meetings if we have ready calculated disp um measures, then we don't have to sort of extract that data from the individual utterances. Yeah, and that's also fairly easy to store along with our segments, isn't it. For the segments, are we extracting some type of title for them that we craft with some fancy algorithm or manually or we're just taking the single most highly valued key-word utterance for the segment heading? Hmm. Hmm. It's probably like in in the end probably it wouldn't be the best thing if it's just the high most highly ranked phrase or key-word because like for example for an introduction that would most definitely not be anything that has any title anywhere similar to introduction or something. Yeah. Also like for this part, maybe if we go over it with named entity in the end, if I mean w if one of the people doing DIL has some named entity code to spare, and just like at least for the for sort of for finding topics, titles for for segments, just take a named entity which has a really high, what's it called, D_F_I_D_F_, whatever. 'Cause you'd probably be quite likely if they're talking about a conference or a person, that that would be a named entity which is very highly fr um frequented in that part. Yeah, he said they're quite sparse. So that basically was don't bother basing too much of your general calculation on it. But like especially if they're sparse, probably individual named entities which describe what a what a segment is about would probably be quite good. Like if there's some name of some conference, they would could probably say that name of the conference quite often, even though he's right that they make indirect references to it. Anyway Sorry? So you're doing that on a on a per word level. Okay. Okay. Okay, cool. I was just wondering where you had the corpus from at the moment. So it it seems that the data structure isn't a big problem and that basically we don't have to have all these massive discussions of how we exactly interact with the data structure because most of our work isn't done with that data structure in memory in the browser, but it's just done off-line and everyone can ha represent it anyway they want as long as they sort of store it in a useful X_M_L_ representation in the end. So like Yeah, that would mean understanding the NITE X_M_L_ X_M_L_ sort of format in a lot more detail. We should I think we should just have a long session in the computer room together and like now that we know a bit more what we want, take a closer look at NITE X_M_L_. Mm-hmm. Mm-hmm. Good. Yeah, I haven't looked at this stuff much at all. Yeah. Yeah. Who's who's sort of doing the the the central coordination of of of the browser application now? Like Hmm? Yeah, or but also like all these elements like like the loading and, yeah, integration and and like handling the data loading and stuff. Nah. I'm sort of like I think I'll take over the display, just because I've started with a bit and found it found it doable. So somebody should sort of be the one person who's who understands most about what's t centrally going on with with the with the project, like with the with the browser as a whole and where the data comes in and Any volunteers? It's also a complicated one. Yeah. I know but uh b I guess we can do it like several people together, it's probably just those people have to work together a lot and very closely and just make sure that they're always f understand what the other one is doing. Yeah, or or ready-made versions of them for that matter and Yeah, but I think actually like at the moment the integration comes first, I mean it's sort of at the moment the building the browser comes first, and then only comes the creating new sophisticated data chunks, because that's sort of the whole thing about having a prototype system which is more or less working on on chunk data. But it at least we have the framework in which we can then test everything and and look at everything. 'Cause before we have that, it's gonna be very difficult for anyone to really see how much the work that they're doing is making sense because you just well I guess you can see something from the data that you have in your individual X_M_L_ s files files that you create, but it would be nice to have some basic system which just displays some stuff. Or just adapt like their like just sort of go from their system and and adapt that piece for piece and see how we could how we could arran like adapt it to our system. Does anyone want to like just sit with me and like play for three hours with NITE X_M_L_ at some point? Uh I wouldn't like to be 'cause I'd like to go to the gym. I'm theoretically free. But if there's any time t hmm? You have nothing no free time on Wednesday. Hmm. Nine 'til twelve and then nothi you have or you Hmm? Anytime Wednesday afternoon I'd be cool, I think. Yo, Forrest Hill, whatever one's easier to discuss stuff, I don't know. I'm not biased. Okay. What time do you wanna do? Okay, so I'll just meet you in in eighteen a in the afternoon. I guess at the moment nobody critically depends on like the NITE X_M_L_ stuff working right now, right? Like at the moment you can all do your stuff and I can do my L_S_A_ stuff. And I can even do the display to a vast degree without actually having their supplying framework working. So it's not that crucial. Yeah, actually I need the raw text as well. Yeah, but I was I was I was more thinking of the sort of the the whole browser framework as a running programme now. Yeah, I think we all need the raw text in different in different flavours, don't we? But number within the X_M_L_ context. Are they spoken numbers? Like do they look like they're utterances numbers? There's the number task, isn't there. That's part of the whole thing. Hmm? Okay. Hmm. Yeah, we have to probably cut that out anyway for our project, I don't know. It's probably gonna screw up a lot of our data otherwise. If Not sure if it what it does to document It would probably make the yeah, if if you have segments for that, probably the Okay. Uh I'm just thinking like it pro it pro probably like the L_S_A_ would perform quite well on it. It would probably find another number task quite easily seeing that it's a constrained vocabulary with a high co-occurrence of the same nine words. So that wou ten word. Hmm? Yeah. I think it's also something that they they said the numbers in order, right? Yeah, I think it's it the it sounded like they wanted to check out how well they were doing with overlapping and stuff, because basically it's like they're reading them at different speeds, but you know in which order they are said. Anyway. ICSI has some reasons for doing it. They must have been pissed off saying like numbers at the end of every meeting. Um Dave, if you would or actually for well, if you're doing I_D_F_s or you whatever you call your your frequencies, I always mix up the name, uh you need some dictionary for that at some point though, like you need to have some representation of a word as not not that specific occurrence of that word token, but of of of a given word form. Because you're making counts for word forms, right? Yeah, so we should work together on that, because I need a dictionary as well. Okay. 'Kay. Okay. Didn't you say that the o the ord Yeah, but for I'm just wondering for the whole thing. Does somebody wo who was it of you two who said that um there's some programme which spits out a dictionary probably with frequencies? Okay. Is anyone of you for the for the document frequency over total frequency, you gonna have total frequencies of words then with that, right? Like over the whole corpus sort of. Or W using which tool are you talking about? Be careful with that. Like my experience with the British National Corpus was that there's far more word types than you ever think because anything that's sort of unusual generally is a new word type. Like any typo or any strange thing where they put two words together. And also any number as a word type of its own. So you can easily end up with hundred thousands of words when you didn't expect them. So generally dictionaries can grow bigger then you think they do. Well you can probably also you can probably pre-filter like with regular expressions even just say if it consists of only dig digits, then skip it, or even if it consists any special characters, then skip it because it's probably something with a dot in between, which is usually not something you wanna have and What I did, for my project I just ignored the hundred most frequent words, because they actually end up all being articles and and everything and stuff. So we need like several of us need a dictionary. Am I the only one who needs it with frequencies? Am I the only one who needs it with frequencies? Or Frequencies. Yeah. Well I guess as soon as we have the raw text, we can probably just start with the Java hash map and like just hash map over it and see how far we get. I mean we can probably on a machine with a few hundred megabyte RAM you can go quite far. You can write it on beefy. So even if it goes wrong and even if it has a million words be Oh yeah, burning it on a like we should be able to burn the whole corpus, just the X_ hmm? Ah I see, I asked support about that two days ago. In the Informatics building there oh sorry, in in Appleton Tower five the ones closest t two machines closest to the support office. So I presume oh wait, I have the exact email. I think he's talking about sort of the ones that Yeah, if you if you enter the big room, in the right-hand corner, I think. Um the thing is like you can only burn from the local file-system. So if it's from s well actually I think if it's mounted, you can directly burn from there, but the problem is I have my data on beefy and so I have to get it into the local temp directory and burn it from there. But you can burn it from there. Uh we looked that up and I for we looked that up and I forgot. Yeah yeah. No, you you we should be able to get it at I don't think it was I don't think it was a gigabyte. Hmm. See I would off I would offer you to to get it on this one, and then um like copy it. But you know what I figured out, I'm quicker down-loading over broad-band into my computer than using this hard disk. There's something strange about the way how they access the hard disk, how they mount it, which is unfortunate. Hmm. What operating system do you have? Okay. Wh what connection do you have at home? Yeah. So if anyone of us gets it, we can then just use an ext hmm? Yeah, burn it to C_D_ or, yeah, put it on on hard disk, whatever. Question is if you're not quicker if you uh because you should get massive compression out of that. Like fifty percent or something with a good algorithm. So if you could compress it and just put it into a temp directory. Like The temp the temps usually have for gigabyte three or two. The temps, yeah. I do like I mean there's not guarantee that anything stays there, but overnight it'll stay. And I think the temps usually have. Ah yeah, but that would have to be the temp directory off the machine you can S_S_H_ into directory of S_S_H_. Yeah, they wou they'd they'd probably hate you for doing it. But They'd probably they'd like you more if you S_S_H_ uh into another computer, compress it there and then sort of copy it into the into the gateway machine. They have um if you S_S_ hey, you know, if you if you S_S_H_ and they have this big warning about doing nothing at all in the gateway machine. Yeah. To your home machine. I haven't I haven't figured out how to tunnel through the gateway into another machine yet. It's not it's not easy definitely. That's why I end up sort of copying stuff into the temp directory at the gateway machine. Sorry if this is boring everybody else. This is just details and how to get stuff home from what we can probably just look at that together when we're meeting. I'm sorry. Mm-hmm. Well yeah. As soon as somebody gives me the raw text of the whole thing, I can probably just implement like a five line Java hash table frequency dictionary builder and see Oh, did you not say frequencies f of words in the whole sorry, did uh So you'd you Yeah, you'd have to count it yourself, yeah. Oh, you don't wanna have different counts for each chunk, but just like sort of for for something from old chunks. Oh yeah, no, that's yeah, so once I write an ar like w if I write like an algorithm which does a hash um table dictionary with frequency from a raw text, then the raw text can be anything. So how far are we g uh how f how far are you getting raw text out of it do you think? Okay, well that's good, because for the dictionary the order doesn't make a difference, does it? So yeah, so um I'll get that from you and I'll write the hash table which goes over that and creates a dictionary file. So for the dictionary, is it okay if I do, whatever, word blank frequency or something? Just p could everybody sort of start from that? I mean I guess we can Yeah, I I need frequency as well. Well I think we might have a lot in common what we calculate because I for my latent semantic analysis need like counts of words within a document, uh within a a segment actually, within a topic segment. Can I convert these probabilities back into frequencies? Okay. Oh, so that's what f Rainbow does, because that's what L_S_A_ builds on. Like it builds a f a document by frequency matrix. So I could probably get that. Even though but I already have I already have my code to build it up myself. No, don't bother. I have my code already. Um Yeah, so Dave, you said you need the frequency counts actually for per document, would you say, not for the whole thing? It more and more appears to me that if we if we scrap the notion of the meeting as an individual thing and sort of ju see meetings as as topic segments and have sort of like hierarchical topic segmentation instead, then it's b like a more coherent framework. Wait, are we are we using this um for the for the for the do for the weighting in the end now, this this measure you're calculating? Because if we're doing Like I think for for the information density we uh we should calculate it on the lowest level, not on the highest. But like 'cause Yeah, but w it don't you have to like go sort of like for in a document versus the whole thing? Isn't that how it works that you c look look at r I don't think that's a good idea because isn't it like that we expect th there to change over i b with the different topic segments more? That they talk about something different in each different topic segment. 'Cause that's what relative term frequency is about, that like in some context they're talking more about a certain word than in general. So that would more be the the topic segments then. I don't know. Yeah. Yeah. Yeah. So I'm just wondering if there's ways to abandon the whole concept of of meetings and sort of but just not really treating separate meetings as too much of a separate entity. But But on algorithmic level, whether we actually whether there's some way to just represent meetings as as topics. Hmm. That's not really what I meant. But I think I have to think more about what I meant. Um g I'm confused about everything. Yeah. I'm I'm not so concerned about the m a meeting plus something else, I'm more talking about like, yeah, the keeping keeping the same algorithm and the same way of handling it and just saying like just this this topic here i uh it happens to be like a whole meeting and it has sort of sub-topics, so just that sort of topics a hierarchical concept where like a topic where there can be super-topics and topics, and the super-topics are in the end what the meetings are, but in general at some level super-topics are treated like like topics. Hmm. Mm I'm not really sure what I want. So sorry, could describe that again, the Mm-hmm. Mm-hmm. Mm-hmm. So that would be the series as a whole. That would be sort of m meetings, yeah. Yeah. I'm a I'm a I'm a bit brain-damaged at the moment, but I think I'll just sit together with you again and and go through it again. Hmm. So so I'll is th it like is this and this structurally then always identical? So that we can that we can treat it with the same algorithm or Yeah, I'm also not sure how we can go from from bottom-up. I have always thought it's like more that oh, whatever, I'm a can't think of it at the moment. Probably this is all too complicated worrying about that at that moment anyway. Now have have we have we decided anything, are we doing anything? S Wednesday we are meeting and looking at their at their implementation in some more detail to actually understand what's going on. We had two things from their stuff just to make sure that we are like understand it, we understand it enough to to m modify it. Yep. How would we do that? By just making like it w read write for everyone. 'Kay, who has most free space on their Same here. Well we alternatively we can probably just make another directory on the beefy scratch space. I mean that's where I'm having gigabytes and gigabytes of stuff at the moment. No. No. Yeah. But I think if he sends to the I think if he sends to the port he'd probably be in a better position. Yeah. Hmm. I think he said yes to that. I think uh that was like in when we were still in the seminar room, I asked that once or like ask is it possible to get it off and nobody said like people were discussing about the technical practicalities, but nobody said anything about al being allowed to or not allowed to. I mean, we have access to it here and I guess it probably means that we we can't give it to anybody else. But but if they give us access to it here o sitting on a DICE machine, then there shouldn't be a reason why we shouldn't be able to use it on our laptop. I personally don't have too many friends who would be too keen on getting it anyway. I have that really excited pirate copied thing. It annotated meeting data. Huh. Wait, wait, wait. Um sorry. Yeah, sorry. What I just realised, we should really t keep different serieses completely separate for virtually all purposes. Just let's be careful about that, because like the the ICSI corpus isn't isn't one meeting series, it's several meeting series with different people meeting for completely different things. For each meeting. Alright. Okay, but like let's just be careful that whatever we sort of we merge together, that like the highest level of merging, it's not the whole ICSI corpus but individual series.. I think we might actually I think That's probably be somewhere like well or something like it. Um I think we might just get away with for the whole project just like looking at only one series and just doing within one series. I mean you can do everything you want in one series. Oh yeah, let's take that. Is the is the data always clearly split up by different series? Uh like is it easy to just pick one Okay. Okay. Okay. Okay. So at at every level everyone has to be careful to really just take even at the highest level, just take stuff from one series and not merge stuff from different series together because they would probably be just majorly messy. Yeah, so so t so like if even if we make one single text file which has the whole corpus, sort of our corpus, that would still be from one series only. Wou but it what you're producing at the moment is like individual text files that sort of have the raw text for a whole a meeting as a whole or Mm-hmm. Yeah. 'Kay. Um so is is anybody creating an uh a real raw text thing at the moment, like which is just the words? Yeah, tha 'cause that's what I'm gonna need as well. But i but if there uh b aren't like so it's it's start and end times just for the file. Like is it just the first and the last line? Or is it for every single thing in So what do you mean by just not print out that? Okay. If you're into it, can you make a text file which just like makes just the words? 'Kay. Do you want it straight flowing, 'cause I would need something that marks the end of uh of uh is is yours segmented by topics then that like is there any information that you have to the topic, to the automated topic topic segmentation? Oh then I need something different later anyway. Okay, but for now, if you c Okay. You're gonna put that as an output of yours, the segmentation. Okay, so for now can you create like sort of just uh a dump which is pure text, just pure text so that I can get a dictionary and you can work on that for your topic segmentation. And Or for for the series. But I can but I can also deal with separate files, I mean I can just write the algorithm that it loads all files in a directory or something. But I mean if you But if you can put it in one single mega-file, that would be quite useful for me. Even though for you, wouldn't it be easier if you had different files because then you sort of know like Yeah. So give m give me different files as long as like it m if you could name them in a way that is easy to enumerate over them, like whatever, one two three four five or something. Or just anything that I can Yeah. Is is it something that's easily enu like to enumerate over? Is it some just some ordered pattern? Okay, cool. Okay, cool. Yeah. In the right order. It's just a wish list. Orders. When do you think you'll have um like a primitive segmentation by some ready-made topic segmentation by some ready-made tool ready? Okay. Okay, cool. 'Cause I'll need that then when it's done. Okay. Mm-hmm. What's what's nine megabyte? The the That sounds quite reasonable. That's nine nine characters over okay. Okay. Okay. That is for are we are we picking one particular series at the moment? Or Yes. Okay. Yeah. Yeah, I guess we can probably process the data for all different series and then check which series is the best for the presentation. It sounds quite reasonable, nine megabyte. I mean if you think if it's r roughly a million words and nine characters per word sounds realisti Yeah. Yes, I'm gonna build a dictionary then from that. Like just a list of the words that maybe a list of the words with the frequencies or a list of the words sorted alphabetically or numerically. What what does anyone want? Does this there any wishes for dictionaries? So I'll create a dictionary. Add add the structure, yeah. And then the actual file we can probably like copy from your home directory or something like it. Yeah yeah, but I'm sa I'm saying for the whole thing in the end. Then like the big thing we probably shouldn't do by email. Yeah. Oh, from the time I get the file I can do that in an afternoon, the next sort of the next morning. Oh, you mean how long processing time it takes. Ah, it's a it's a bog standard algorithm. I've I've sort of I've written it for for DIL just in half an hour or something similar. It's just you put them in a hash table and and say well if it exists already in the hash table then you increase the count by one and I'll probably implement some filter for filtering out numbers or something. Really? How do you do that? Okay, well I don't know any Perl. I mean if anyone wants to do a Perl script for that that does it does it nicely, I uh I've no problem with that. I but I think I have the Java code virtually ready because for DIL I wrote something very similar. Like for DIL I wrote something that counts the the different occurrences of all the tags um Sorry? The hash table? Uh I've never serialized anything. Wouldn't that be absolutely massive though? And then seriali and then write the serialization to a file. So you want like a se like a file which is the serialization of a hash table. Okay. Yeah. I I'll I'll check if I understand how it works. I mean otherwise I can give you the code for loading a dictionary. Give you my my it's just it's it's sort of it's a line break separated file, you know. Yeah. Yeah, I'll see if I understand how to serialize. There's a there's a serialise command so that gives me one mega mother of a s Yeah, but do they automatically write to the file anyway I'll I'll figure that out. We don't have to Yes, is that pretty much pretty much it? So Dave and me look at how NITE X_M_L_ works and we're Hmm. I'll build a dictionary as soon as I get the text. And yeah, so that When do we have to meet again then with this? How are we gonna do a demonstrator next week? My God. No no, not demonstrate, but like didn't you say that uh didn't we sort of agree that it would be useful to have a demonstrator of it, like some primitive thing working next week. That's gotta be very prototype. Mm-hmm. Ah well, let's go. Sorry. I feel like like hanging mid-air and not really like finding a point where you can get your teeth into it and start working properly and so it's all so fuzzy the whole Yeah, but it at the moment but at the moment it's also an implementational level. Like with the data structures, I'm just like over these vague ideas of some trees, I'm f Yeah. It's just we are half-way through the project time table. That's just what freaks me out. Um\\nYeah. Yeah, I mean if we just want to have um some data for the user face, could even be random data. Uh mm mm Yeah, I'm Hmm. Yes. Hmm yes. Hmm. I'm not so sure. I I thought we would just have like um one big summary um with all the uh different importance levels um displayed on it. And depending on what our um zoom level is, we just display a part of it. And we would have one very big thing off-line. And from that we would just select what we are displaying. Yes. So for example you would um give a high value to those um sequences you want to display in the meeting series summary. And you just cut off. That was what I sh I thought, yeah. I thought. But I think the m difference might be that we want just want to have um the words. And that's not so much what he meant with not possibly loading everything was that you m um load all the uh annotation stuff, all the sound files, all In Um I r I I'm getting quite lost um at the moment because um w what's um our difference between the um se um uh the importance measure and the skimming? I mean, do we do both or is it the same thing? Okay. So but when when we talk about summaries you talk about this uh abo about skimming and not about Yeah. Yeah right, isn't that the skimming? Isn't that the skimming? Yeah, but it use the same data. Yeah. A And, yeah, I think we also thought about combining that measure with um the measures I get from um s uh hot-spots and so on. So that would also be on utterance level, I think. I think. Yes, sure. Yes. Yes, right. Oops, it does. So I define baseline and what it loads? For example it loads all the utterances and so on, but it doesn't load um the discourse acts and for example not the and what's what else there? Not the summaries. It only loads those on demand. Y you mean that you um basically split up th the big thing into um different summaries. For example that you have a very um top-level um summary and a separate file for for each level. Mm-hmm. Yes. N Uh no no, it's f for No, you're right. Yeah. It's for Um No, I I think we would just take the segments that are already that were Yeah, there's um this segments file. Um you know, the X_M_L_ segments. Oh. That I don't know. Yeah, that's um Mm-hmm. There there are time stamps um for, well, segments um and for th um segments is for example when when you look at the data, what is displayed in one line. What when when you look at it in the hmm? I think so. Isn't Um for ex um I I compared it with what I did for the pause um duration extraction. Um and basically it's uh words that are uttered in a sequence without pauses. But sometimes um however there are um short pauses in it and they're indicated by square brackets pause or something in the data. Um someti uh but uh the annotators decided what was one segment and what wasn't. I think so. Yeah, but um I think for some annotations um an uttera ca utterance can have several um types. For example for the dialogue acts and so on. Okay. Yeah, that should be for Yeah. Should be, yeah. Yes, but that's Yeah, everything that's a word has a sti time stamp. That's at the end. That's at the end, I think, her time. Yeah, maybe. Didn't have a look at our meetings. Uh I I think it wouldn't as it occurs I mean it would be it occurs in every meeting. So And I think it even has uh its own annotation, like digits or something. So that should be really easy to cut out. Yeah. I'm sure. Ah it's just to test the system, I think. So Mm they have to read numbers from Uh I didn't have a look at that. So They Mm-hmm. Uh th yeah. 'Kay. Um I just um wondered, so who's uh then doing um the frequencies on on the words, because I'm I think I will also um I could also make use of it um for the agreement and disagreement thing. Because I um I in my outline I talked about um using the um discourse acts first, and um then in the chunks of text I found looking for word patterns and so on. So um I would for example need the um most freq um frequent words. So if you cut off all that, I'd won't be use or Yeah, I I but I need it for my chunks then. I would You know? Yeah, but I'd uh I would like to look at the frequency of words in my um in the regions of text I found out to be interesting. So I wouldn't need it. It it would have to be re-calculated only for my segments. Huh? Uh uh mm. I think it would be, you know, l as as big at as the hot-spot annotation things. That's quite small, yeah, that's some utterances. Yes. Yeah, yeah. So I would probably just concatenate all my um text chunks and then let's say m I will run over it. Yes. Yes, definitely. Yeah, right. Ye M Um Jasmine, uh um what is um the text you're extracting uh looking like then at the end? Because um I I think it's actually very similar to what I did for my um speaker um uh extraction and I think I would ch perhaps have to change two lines of codes to get you um for each meeting a file that says fr from um this millisecond to this millisecond there was this sequence of words. And so on. So that's just changing two lines of code. And it would give you that. So Um yeah. So far I extracted um the dura durations. But it's from the words file. So I could just um contatenate concatenate um the words instead of the durations, and it should I mean Should be very straight-forward. I can try to do it and send it to you. Pe and you have a look at it, will it make sense for what you want. Yeah, uh p I mean it I just let it run over all the files. So Yes. I just ordered. Uh I ordered according to the um starting times of the utterances. What do you mean by diffe Yeah, I mean t I I have one what I give you would be one file for each meeting. Yeah, not for each meeting series. I didn't do that yet. Yeah, one group, yeah. Yeah, I mean there's one series that has just one meeting. Yes. Um the you you the data is of the form you have um three identification letter. So B_E_D_ or B_B_D_ or something, and that's always the same group. And then after that there's um a number like O_O_ one, O_O_ two. So, it's a Yeah, but that's that's really quite easy to see because they're named. Yes. But I I mean as um the start uh start times um start for each meeting at zero, you could just probably just um add the um final second time to the next meeting and so on and just put it all together. But then we would have to change um the information about who on which channel it was set, um to by which person it was set. And that is actually stored in another X_M_L_ document. Yeah, I w would then just not print out the um start and end times. No, it's for every single word. Or for every single utterance. Yeah, that depends on what you want. Yeah, but I do it with Perl, it's just string manipulation. So I would I mean I would just Sure. No, I didn't do a sea no. And you would want that all in one file for all the corpus? Or For the series. Yeah, I can directly put it into uh just like So uh only words um per meeting series. Uh-huh. Yes. Yeah, they will just I will just take I would uh take over the names they have anyway. Yeah, yeah. Yeah, one series has the um same three starting letters. So So only words and words and times. And you Yeah, you want it ordered. Okay. Okay, anybody Um ord base dot times. Yeah, and do you want Yeah, sometimes they're contained in one another. So Just after th mm-hmm. 'Kay. Ordered. Only words. Um and I think um for all the corpus, it's just from I know from other times, it's um nine megami byte to have I mean should be should be similar to have the words. Should be. Na um all the words together um for all the meetings. That's what I'm guessing that's, you know, um what I because nine mega-byte is what I got for when I said for every um utterance, this is goes from there to there and takes takes seconds. Oh. Yeah, I mean I'm it doing it for all of it. Doesn't matter. Yeah, I mean I hope it will be the same for the words. It's just what I I Mm-hmm. Mm. So so um I will probably send um just one file of the first meeting um to all those who need it so that you can have a look whether that's what you want. Yeah, I mean if it's just for one meeting, it's really not too big. Yeah. What do we have to demonstrate?\\nThe basic word importance is off-line as well. The combined measure might not be if we want to wait what the user has typed in into the search. Yeah. I'm not quite so what it did you want to do it, i you just wanted to assign Uh I thought about words. Mm. Mm okay. Yeah, but how about those words which don't carry any meaning at all, the um and uhs and something like that. Because if we if we average average over over a whole utterance all the words, and there are quite unimportant words in there, but quite important words as well, I think we should just disregard the the Okay. Alright. Yeah. But there is no I_D_ for an utterance I think. It's just for individual words. So how do we do that then? We for utterances as well. I think it's just for one word. So we have to Yeah. Uh I'm not quite sure, I have only seen that the uh the individual words have got an I_D_. Yeah. You always could have a look at the time stamps and then take the ones that uh belong together to form an utterance. Yeah, if they are already, there's it's easy but it would be possible. Uh yeah. Okay. You s uh you said you are currently in uh implementing the idea. What exactly are you computing? Okay. Okay. Mm-hmm. Mm-hmm. Yeah, I w I w I would need the raw text pretty soon because I have to find out um how I have to put the segments into bins. And then yeah. No, that's not necessary. Yes, I did. But um I've only just got the notes. I have to still have uh to order everything by the time and Yeah, I think it's quite easy after the Yeah. Yeah. So uh Mm-hmm. Yeah, b I uh w that's what I was uh thought. That you just combine them and then order the time stamps accordingly. Okay. Um what I found out was that there are quite a lot of things without without s time stamps in the beginning. Yeah, and uh X_M_L_ files. Yeah, that's just an I_D_ or something. I don't know. Just numbers. Yes, but what are the other things that's uh some kind of number? F maybe the file number or something that is in the beginning. What is that? Do you know? Um I think there are quite a lot of numbers in the beginning where n there is no time stamp for the numbers. It's Think they say um quite a lot of numbers and before that, uh um there's this number. Was it Yeah, there i are numbers in the um the W_ tag, but there are no time stamps. Yeah. Yeah, in the beginning as well sometimes, I think. At least I saw some. Yeah. Yeah. But what it is it actually that numbers? Okay, so but there are no time stamps annotated to that. It's it's quite strange. And also um there are different um combinations of letters. B_R_E_ and something like that. Is it everything ordered are the time stamps global or uh are they local at any point? Okay. Yeah, it's Rainbow. It's um I think it's just the dictionary in the first place. But Um no, I have to bin it up and so I will only have counts for each each bin or something. It's because um Rainbow is a text classification system. And I think it's not possible to have just one class. That's the problem. Maybe we could Yeah sure, you sure, we could do that, but I don't that makes sense. If we need just frequencies, maybe we should just calculate them by using Perl or something. I don't know. Yeah, it's quite easy to just count and s or sort them by um frequency. Just using a Perl script. Is it too big? Yeah. Hmm. I don't know how you how many terms you can handle in Perl. Mm yeah. Uh I can get all the raw text, but it has to be ordered still. So No, it isn't. Um it's in what is implemented in Rainbow is information gain, and I'm not quite sure how they calculate that. Yeah. Uh that's what Rainbow does. I think you j can just get probabilities for a certain words for each document. Certain Um we would have to look at that. Mm-hmm. Oh. Yeah, that's what I thought as well, that you that probably the the topic segment level is the most um informative for the words. Yeah, that's the problem. I don't know. Mm-hmm. So shall we sit together tomorrow then as well? Uh Okay. Um, yeah, w would it be best? At the moment it's it's just lines of Mm-hmm. Um Okay. So um you'd do you extract the words, the raw text, as well? Uh Okay. Mm-hmm. Print out. Okay. Okay, that Okay. So have we already extracted from all the files? Yeah. Did you also order Mm-hmm. Hmm. Hmm. Okay. Uh I don't need the times, I just need the words. But um Yeah, in the right order. Yes. Yeah, that doesn't matter too much, I think. Hmm. Mm-hmm. How long would it take to make the frequency counts with a Java hash table? Yeah. No, how long you would have to program something. Okay. Mm. Because it's quite easy in Perl as well, it's just a line of code for counting all the words and yeah, it's it's by hashes. Yeah. Yeah. 'Kay.\\nI I dry-read it the last time.. Next week. Yeah. Yeah. No. Uh mine's gonna be mostly using the off-line. But the actual stuff it's doing will be on-line. But it won't be very um processor intensive or memory intensive, I don't think. Don't think so. Yeah. Are we still gonna go for dumping it into a database? Are we still gonna dump it into a database? 'Cause if we are, I reckon we should all read our classes out of the database. It'll be so much easier. Well if we're gonna dump the part of it into a database anyway, we might as well dump all the fields we want into the database, calculate everything from there. Then we don't even have to worry that much about the underlying X_M_L_ representation. We can just query it. Well if we're gonna do that, we should try and store everything in in an X_M_L_ format as well. Yeah. Yeah. Well we don't even need to do that, 'cause if we got our information density calculated off-line, so all we do is treat the whole lot as one massive document. I mean they'll it's not gonna be so big that we can't load in a information density for every utterance. And we can just summarise based on that. I think you can do it on-line. I don't think there's really much point in doing like that when it's just gonna feed off in the end the information density measure basically. And that's all calculated off-line. So what you're really doing is sorting a list, is the p computationally hard part of it. Well like the ideas we're calculating are information density all off-line first for every utterance in the whole corpus, right? So what you do is you say if you're looking at a series of meetings, you just say well our whole document comprises of all these stuck together. And then all you have to do is sort them by j information density. Like maybe weighted with the search terms, and then extract them. I don't think it's too slow to do on-line, to be honest. Is that Yeah. Well, on the utterance level I was thinking. So the utterances with the highest like mean information density. Well the trouble with doing it on the word level is if you want the audio to synch up, you've got no way of getting in and extracting just that word. I mean it's impossible. For every single word? Oh, okay. Yeah. I don't think that will do it. We'll have to buffer it. Well the skimming's gonna use the importance. But like at first it's just gonna be I_D_F_. Well mostly skimming, yeah. Yeah. Well the nice thing about that is it will automatically be in sentences. Well more or less. So it will make more sense, and if you get just extract words. Yeah. I see it. But it'll need to be calculated at word level though because otherwise there won't be enough occurrences of the terms to make any meaningful sense. Yeah. Yeah, I reckon you can just mean it over the sentence. I think we should filter them. Maybe we should have like um a cut-off. So it a w word only gets a value if it's above a certain threshold. So anything that has less than say nought point five importance gets assigned to zero. Yeah, that's the other th Yeah. I think we'll have to buffer the audio. But I don't think it will be very hard. I think it would be like an hour or two's work. Like just build an another f wave file essentially. Yeah, I mean I bet there would be packages In memory, yeah. So just like unp there's bound to be like a media wave object or something like that. And just build one in memory. I don't know. I have no idea. But it must have like classes for dealing with files. And if it has classes for concatenating files, you can do it in memory. So Well what I think I might try and build is basically a class that you just feed it a linked list of um different wave-forms, and it will just string them all together with maybe, I don't know, tenth of a second silence in between each one or something like that. Normalise it, yeah. Oh yeah, yeah, we'll need that. We also really wanna be able to search by who's speaking as well. It doesn't matter, 'cause all the calculation's done off-line. That's easy. You just like create a new X_M_L_ document in memory. I don't think it's really that much of a problem because if it's too big, what we can do is just well all the off-line stuff doesn't really matter. And all we can do is just process a bit at a time. Like for summarisation, say we wanted a hundred utterances in the summary, just look at the meeting, take the top one hundred utterances in each other meeting. If it scores higher than the ones already in the summary so far, just replace them. And then you only have to process one meeting at a time. Okay, so maybe we should build a b store a mean measure for the segments and meetings as well? And speaker. Speaker and um topic segmenting we'll need as well. Yeah. Well yeah, and then it'll f preserve the order when it's displayed the Yeah. Yeah. Yeah, I think so. So we should basically make our own X_M_L_ document in memory that everyone's um module changes that, rather than the underlying data. And then have that X_M_L_ uh NITE X_M_L_ document tied to the interface. Well, you can make it in a file if you want. Mm-hmm. They are utterances, aren't they? The segments are utterances, aren't they? Yeah. Alright, okay. Well, that's easy. Well it's close enough, isn't it? It may not be exact every time, but it's a so sort of size we're looking for. Yeah, yeah. Yeah. But why don't we just write it as a new X_M_L_ file? Can NITE handle just loading arbitrary uh new like attributes and stuff? I mean, I would have thought they'd make it able to. Yeah. So why do we need to have two X_M_L_ trees in memory at once? The other thing is that would mean we'd be using their parser as well, which means we wouldn't have to parse anything, which be quite nice. 'Cause their parser is probably much faster than anything we've come up with anyway. Yeah, I mean we can process it in chunks if it gets too big basically. We can just process it all in chunks if it gets too big to load it into memory. I think we probably want to store Sorry. I think we probably want to store um a hierarchical information density as well. So like an informan mation density score for each meeting and each topic segment. 'Cause otherwise we'd be recalculating the same thing over and over and over again. Yeah. And that will obviously make it much easier to display. Well it may not for the whole meeting, but like Yeah, exactly. Yeah. Well, we can start off like that. Well I was gonna start off I've v got sort of half-way through implementing one that does just I_D_F_. And then just I can change that to work on whatever. Yeah. And it should be weighted by stuff like the hot spots and um the key-words in the search and stuff like that. Did he not say something about named entities? So I thought he said there wasn't very many. Yeah. Yeah. It's not T_F_I_D_F_, it's just inverse document frequency. 'Cause it's really easy to do basically. There's just like for a baseline really. Well, I'm half-way through. It's not working yet, but it will do. Um yeah. And then averaging it over the utterances. But it's not like um related to the corpus at all. It's just working on an arbitrary text file at the moment. No. It would be useful to know how everyone's gonna store their things though. Yeah. Yeah. Well I've got like a few hours free. Like after this. It's the most boring task. Yeah. Or at least um simple versions of them. So maybe we should try doing something really simple, like just displaying a whole meeting. And like just being able to scroll through it or something like that. Yeah. Are you free after this? How about Friday then. 'Cause I'm off all Friday. Uh Wednesday I've got a nine 'til twelve. Yeah, nothing in the afternoon. I've got nothing in the afternoon. So Okay. So you ha yeah. Where about, just in Appleton Tower? Uh I'll be in um the Appleton Tower anyway. Um well I'll be there from twelve. I've got some other stuff that needs done on Matlab, so if you're not there at twelve, I can just work on that. So Yeah. Why w Yeah. I'm just building a dictionary. Oh, mine's just gonna use the um hash map one in um Java. 'Cause I'm only gonna do it on small documents. It's just like bef until the information density is up and running. Just something to get give me something to work with. So it's only gonna use quite small documents, you see, to start with. Why does it need to be classified into like different segments? Can we just fill a second class with junk that we don't care about? Like, I don't know, copies of Shakespeare or something. 'Cause if what we're looking for is the um frequency statistics, I don't see how that would be changed by the classification. I the Well there maybe another tool available? Yeah. Um I can't remember who's got it. Might be WordNet. But one of these big corpuses has a list of stop words that you can download and they're just basically lists of really uninteresting boring words that we could filter out before we do that. It's like that's one the papers I read, that's um one things they did right at the beginning is they've got this big s stop-list and they just ignore all of those throughout the experiment. Yeah, I it would be useful for me as well. It uh I think that'd be useful for me as well. Yeah. Yeah. Well all you really wanna do is look into getting some sub-set of the ICSI corpus off the DICE machines. 'Cause I hate working on DICE. It's awful. Like so I can use my home machine. ha has a C_D_ burner though. has a C_D_ burner. Yeah. The right-hand corner, far right. Yeah. How big is it without um the WAV files and stuff? 'Cause I could just say at um going over S_C_P_ one night and just leave it going all night if I had to. It's yeah, I mean the wave data are obviously not gonna get off there completely. Really? Oh right? I'll see if I can S_C_P_ it, I suppose. I've got a Linux box and a Windows box. So Broad-band. Put it on to C_D_. I can if I get down I can put to C_D_. Yeah. I'm not sure if there's enough space. Is how much do we get? Really? Okay. Yeah, but I can do it from that session, can't I? You can compress it from a remote session and S_C_P_ it from the same session? Do you think? Yeah. Oh no no, I was thinking of SSHing just into some machine and then just SCPing it from there. Yeah. I mean it has to go through the gateway. But Can you not do that? Mm, I see. Yeah. So you could just But th first, uh how big are the chunks? How big are the chunks you're looking at? So quite small then. So you could just um you could use just the same thing we used to build the big dictionary. You just do that on-line 'cause that won't take long to build a little dictionary that big, will it. I mean just use the same tool that we use. Yeah. Yeah. It doesn't need ordered, no. Um well that's the t are you using T_F_I_D_F_ for the information density? Alright, okay. Like 'cause frequency would be useful, I think. But um depending on the context, the size, and what we consider a document in the sense of calculating T_F_I_D_F_ is gonna change. Which might need thinking about. I think it would be useful, yeah. Well you need the raw frequency as well. But um you also need how many times things occur within each document. And um what we consider a document's gonna depend on our context, I think. 'Cause if we're looking at the whole lot of meetings, we'll consider each meeting a document in sort of terms of this algorithm. And if we're viewing like say just a small topic segment you might look at even each utterance as a small document. Yeah, but the thing is um It's gonna need some th th thought of how we Actually maybe it doesn't actually matter. Maybe if you just do it once at the highest level, it it will be fine. But I was just thinking it might be difficult to calculate the T_F_I_D_F_ off-line for all the different levels we might want. 'Cause if we're gonna allow disjoint segments for example, then how are we gonna know what's gonna be in context at any given time? But I suppose if you just did it globally, treating a meeting as a document, it'd probably still be work out fine, because you'd only be comparing to ones within the context. Uh I don't know, I thought were you gonna use that in the end? The information density. Oh sorry, that's what I mean. Like um yeah, for each word or whatever, but across the whole lot is what I mean by highest level. Like across the whole corpus. Yeah, but you'd probably look at each meeting as a document. Mm possibly. Are they big enough to get anything meaningful out of? Well yeah, that is not it's not an issue. You just concatenate an X_M_L_ file together. but we still want to have like a notion of meetings for the user. Yeah, sure. Yeah, you just like whatever you want to look at, you just jam together into an X_M_L_ file and that's your meeting, even though bits of it may come from all over the place or whatever. I mean I don't see why that's really a big problem. So basically what you're saying is you can take an arbitrary amount of data and process it with the same algorithm. It doesn't matter conceptually what that data is. It could be a meeting. it could be two utterances. it could be a meeting plus half a meeting from somewhere else. I don't think it's very difficult though. I mean what you do is you just build an X_M_L_ file, and if you want it to get down to the utterances, you'd go to the leaves. And then if you wanted the next level up, you'd go to the parents of those and like just go from like the leaves inwards towards the branch to build up things like um you know, when you click on a segment, it's gonna have like words or whatever that are important. As long as like the algorithms are designed um with it in mind, I don't think it's a very big problem. Well like say you had um like say for a meeting, right, you've got like uh say a hierarchy that looks quite big, like this. And like the utterances come off of here maybe. Then when whatever your algorithm is doing, as long as when you're working with utterances, you go for all the leaves, like then if you need something next up, so like a topic segment, you'd go to here. But if you were looking at say this one, so only went like this. Right, so you it's same, you'd start with the leaves, and you go oh, I want a topic segment. So I go one layer up. See, and then if you're working with just a topic segment in there, it's the only thing you have to worry about. And like each time you want a higher level, you just need to go up the tree. And as long as your algorithm respects that, then we can just process any arbitrary X_M_L_ file with whatever hierarchical structure we want. A meeting, say, and that would be a topic segment. So I think as long as you build an algorithm that respects whatever structure's in the file, rather than imposing its own structure Well no, it doesn't have to be. But I mean it could be as many nodes as you want. Like this one could be deeper maybe, say. So then you'd start with all your utterances here, and when you go up to get topic segments, you go to here here here here here here here. That might be a bit confusing though 'cause you have things on different levels. Well Wednesday. Yeah. Yeah. So we'll see if we can get like a mini-browser just displays two things synched together of some kind. Yeah. Yeah. It'd be useful. I don't know who you see about that though. I d have no idea. I've probably got a reasonable amount because um everything on my DICE account can actually be deleted 'cause I store it all at home as well. Is that guaranteed to stay, the Maybe you should send a support form. Just say we want some web space. Listen to. Yeah. 'Cause that'd be really useful is if we had a big directory. Especially for transferring stuff. Having said that, are we allowed to take a copy of the ICSI corpus? Something we should probably ask before we do it.. Okay. Okay. No, me neither. Might be funny to see what is summarised the whole corpus as anyway. I think it'd be very useful. But We can just change the code. Is that it? That's quite good. Yeah. I could just use it with the frequency, I think, until the information density thing's finished. That would be really useful. If you're doing it in Java, could you um serialize the output as well as writing it to a file? If you're doing it in Java, could you serialize the um dictionary, yeah, as well as writing it to a file? It's really easy. I don't see why it'd be any more massive than the file. Yeah. It just saves you parsing the um file representation of it. And now 'cause I would be using it in Java anyway. So I'd just be building the data structure again. Yeah, but it seems like a bit silly to be parsing it over and over again kinda thing. I would've thought that um I think all the collections and things implement serializable already. I think they might do. Tonight I'll try and um I'll either work some more on uh the T_F_I_D_F_ summarizer or do the audio thing. Yeah. Do we have to demonstrate something next week? Yeah. Yeah, I know. I think it's 'cause we had to specify it ourselves that it's not as um like focus the specification of most um work we have to do. Yeah. Once we start doing it it will all become more or less obvious I think anyway.\\nOkay. Does anyone want to see uh Steve's feedback from the specification? Right. Not really, um just what he's talking about, like duplication of effort and Like duplication of effort and stuff, and um yeah, he was saying that we should maybe uh think about having a prototype for week six, which is next week. Yeah. So we should probably prioritize our packages. Mm. Yeah. Yeah. Hmm. Has has anyone actually looked at the Java code for the, huh? Hmm. Yeah, I think so. Yeah, I I don't know about the search functionality, that might be online. Depends how it's gonna work. Yeah. Mm-hmm. Yeah, that makes sense. Hmm. Hmm. Yeah, you just concatenate them together. Hmm. Yeah. It just means it loads on demand. It only loads when it needs a particular type of file. Like when it's being accessed. Yeah, I think that's the idea, it just loads the particular ones it needs. But if you were doing a search over the whole corpus you'd have to load them all. Hmm. Mm. Hmm. Yeah, we do not want it in to develop a little tree display as well for multiple results. Yeah, but that'd be quite easy to do. You just need to find the time stamp. Yeah. Yeah. Yeah, I think I think those segments for each utterance are split up. Think so. Yeah, I'm pretty sure it's already there. Pretty sure that's already there. The the utterances are numbered. Hmm. Yeah, I think so. Ye that's the impression I get, yeah. Oh. Hmm. Ye Mm. Yeah, uh Right. Okay. Topics, yeah. Yeah, I think that's the right one. Hmm. Hmm. Mm-hmm. Mm. Hmm. Yeah, that'd be much more efficient to do that. Yeah. Hmm. Hmm. Yeah, you're able to do that in Java, yeah? Yeah. Huh. Hmm. Yeah, I've had a b I've had a look at the the topic segments, how it's stored. And then yeah, th those are few per meeting, and it um well, it gives a time stamp and inside each one there's uh the actual like utterance segments. And the list of them that occurred. And they're all numbered. Um so that's where that's stored. Yeah, so I guess um if I'm gonna be segmenting it with a L_C_ seg then that's like same format I'd want to um put it back out in so it'd be equivalent. Well, like the integration. What do you mean, integration? Hmm. I don't know. I don't think anyone's been allocated to do that yet. Yeah, yeah. Yeah, definitely. Hmm, yeah. Yeah, it c could be difficult, yeah. Yeah. Well I guess the important thing is to get the crucial m modules built. Ye yeah. Yeah, and then Yeah, and then we'll maybe have to prioritize somebody into just integrating it. Mm-hmm. Yeah, I think so. Uh yeah. Hmm. Yeah, yeah. Jasmine, I thought you just said that you'd uh looked at extracting the text. Yeah. So you you said you did it in Python, yeah? Yeah, did you use uh b the X_L_ uh X_M_L_ parser in Python? Right. Yeah, sounds pretty good. So um 'cause, yeah, I was having a look in it a look at it as well and I noticed the um the speakers are all in that separate file? So did did you have to combine them all and and then re-order them? Yeah. Ye yeah, c Right. Yeah, so that's approach um well, I was going to do. So yeah, we may as well collaborate. In the word files? I'm not sure I what you mean. Oh right. Hmm. Hmm. Mm I thought they were local to th a particular meeting. Hmm. Mm is there anything else we should discuss? Yeah, should we not have like a group directory or something where we can put all our code in and that kinda thing? Hmm. I've gotten mm hardly any Hmm. Yeah, we can ask Steve if um we can get space. Yeah, uh we could do that. Yeah, I'm sure he had to deal with that last year. Yeah. Hmm. That sounds good. Hmm. Hmm. Yeah, that's what I'm gonna need. Yes. Yeah, it's just mo changing it a bit. Yeah. No, but uh that's what M_L_C_ seg does. It it marks the end of each segment. Yeah. Yeah. Oh. Yeah. Yeah, for me it's better if they're by meeting. Then that'll be really easy to do once they've got the raw text. It's just a case of running the script. Yeah, I mean hopefully this week. Alright. And we could Don't know. Suppose we're just getting on with all our components. So I know. Wa Yeah. Yeah, he suggested that we could have an uh initial prototype. I know, I'd b I'd be surprised if we can get anything working by next week. Alright.\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3U0_21manVl",
    "outputId": "9698c588-b3ca-4c88-9967-b4c8547a2bdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'\",\n",
       " 'Kay',\n",
       " '.',\n",
       " 'Gosh',\n",
       " '.',\n",
       " \"'\",\n",
       " 'Kay',\n",
       " '.',\n",
       " 'Is',\n",
       " 'there',\n",
       " 'much',\n",
       " 'more',\n",
       " 'in',\n",
       " 'it',\n",
       " 'than',\n",
       " 'he',\n",
       " 'd',\n",
       " 'Is',\n",
       " 'there',\n",
       " 'much',\n",
       " 'more',\n",
       " 'in',\n",
       " 'it',\n",
       " 'than',\n",
       " 'he',\n",
       " 'said',\n",
       " 'yesterday',\n",
       " '?',\n",
       " 'Mm',\n",
       " '.',\n",
       " 'Hmm',\n",
       " '.',\n",
       " 'Hmm',\n",
       " '?',\n",
       " 'Yeah',\n",
       " ',',\n",
       " 'now',\n",
       " 'I',\n",
       " \"'d\",\n",
       " 'say',\n",
       " 'if',\n",
       " 'for',\n",
       " 'the',\n",
       " 'prototype',\n",
       " 'if',\n",
       " 'we',\n",
       " 'just',\n",
       " 'like',\n",
       " 'wherever',\n",
       " 'possible',\n",
       " 'p',\n",
       " 'chunk',\n",
       " 'in',\n",
       " 'the',\n",
       " 'stuff',\n",
       " 'that',\n",
       " 'we',\n",
       " 'have',\n",
       " 'um',\n",
       " 'pre',\n",
       " '-',\n",
       " 'annotated',\n",
       " 'and',\n",
       " 'stuff',\n",
       " ',',\n",
       " 'and',\n",
       " 'for',\n",
       " 'the',\n",
       " 'stuff',\n",
       " 'that',\n",
       " 'we',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'have',\n",
       " 'pre',\n",
       " '-',\n",
       " 'annotated',\n",
       " 'write',\n",
       " 'like',\n",
       " 'a',\n",
       " 'stupid',\n",
       " 'baseline',\n",
       " ',',\n",
       " 'then',\n",
       " 'we',\n",
       " 'should',\n",
       " 'probably',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'basically',\n",
       " 'that',\n",
       " 'means',\n",
       " 'we',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'on',\n",
       " 'the',\n",
       " 'interface',\n",
       " 'first',\n",
       " 'sort',\n",
       " 'of',\n",
       " ',',\n",
       " 'so',\n",
       " 'that',\n",
       " 'we',\n",
       " 'we',\n",
       " 'take',\n",
       " 'the',\n",
       " 'the',\n",
       " 'ready',\n",
       " '-',\n",
       " 'made',\n",
       " 'parts',\n",
       " 'and',\n",
       " 'just',\n",
       " 'see',\n",
       " 'how',\n",
       " 'we',\n",
       " 'get',\n",
       " 'them',\n",
       " 'work',\n",
       " 'together',\n",
       " 'in',\n",
       " 'the',\n",
       " 'interface',\n",
       " 'the',\n",
       " 'way',\n",
       " 'we',\n",
       " 'want',\n",
       " 'and',\n",
       " 'and',\n",
       " 'then',\n",
       " 'we',\n",
       " 'have',\n",
       " 'a',\n",
       " 'working',\n",
       " 'prototype',\n",
       " '.',\n",
       " 'And',\n",
       " 'then',\n",
       " 'we',\n",
       " 'can',\n",
       " 'go',\n",
       " 'back',\n",
       " 'and',\n",
       " 'replace',\n",
       " 'pieces',\n",
       " 'either',\n",
       " 'by',\n",
       " 'our',\n",
       " 'own',\n",
       " 'components',\n",
       " 'or',\n",
       " 'by',\n",
       " 'more',\n",
       " 'sophisticated',\n",
       " 'compo',\n",
       " 'po',\n",
       " 'components',\n",
       " 'of',\n",
       " 'our',\n",
       " 'own',\n",
       " '.',\n",
       " 'So',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'probably',\n",
       " 'feasible',\n",
       " '.',\n",
       " 'The',\n",
       " 'thing',\n",
       " 'is',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'away',\n",
       " 'this',\n",
       " 'weekend',\n",
       " '.',\n",
       " 'So',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'for',\n",
       " 'me',\n",
       " 'Oh',\n",
       " 'yeah',\n",
       " ',',\n",
       " 'um',\n",
       " 'yeah',\n",
       " '.',\n",
       " 'No',\n",
       " '.',\n",
       " 'But',\n",
       " 'also',\n",
       " 'I',\n",
       " 'might',\n",
       " 'like',\n",
       " 'the',\n",
       " 'the',\n",
       " 'similarity',\n",
       " 'thing',\n",
       " ',',\n",
       " 'like',\n",
       " 'my',\n",
       " 'just',\n",
       " 'my',\n",
       " 'matrix',\n",
       " 'itself',\n",
       " 'for',\n",
       " 'my',\n",
       " 'stuff',\n",
       " ',',\n",
       " 'I',\n",
       " 'c',\n",
       " 'I',\n",
       " 'I',\n",
       " 'think',\n",
       " 'I',\n",
       " 'can',\n",
       " 'do',\n",
       " 'that',\n",
       " 'fairly',\n",
       " 'quickly',\n",
       " 'because',\n",
       " 'I',\n",
       " 'have',\n",
       " 'the',\n",
       " 'algorithms',\n",
       " '.',\n",
       " 'Yeah',\n",
       " ',',\n",
       " 'I',\n",
       " 'think',\n",
       " 'today',\n",
       " \"'s\",\n",
       " 'meeting',\n",
       " 'is',\n",
       " 'really',\n",
       " 'the',\n",
       " 'one',\n",
       " 'where',\n",
       " 'we',\n",
       " 'where',\n",
       " 'we',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'settle',\n",
       " 'down',\n",
       " 'the',\n",
       " 'data',\n",
       " 'structure',\n",
       " 'and',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'we',\n",
       " 'have',\n",
       " 'that',\n",
       " ',',\n",
       " 'uh',\n",
       " 'probably',\n",
       " 'like',\n",
       " 'after',\n",
       " 'today',\n",
       " \"'s\",\n",
       " 'meeting',\n",
       " ',',\n",
       " 'we',\n",
       " 'then',\n",
       " 'actually',\n",
       " 'need',\n",
       " 'to',\n",
       " 'well',\n",
       " 'go',\n",
       " 'back',\n",
       " 'first',\n",
       " 'of',\n",
       " 'all',\n",
       " 'and',\n",
       " 'look',\n",
       " 'at',\n",
       " 'NITE',\n",
       " 'X_M_L',\n",
       " '_',\n",
       " 'to',\n",
       " 'see',\n",
       " 'in',\n",
       " 'how',\n",
       " 'far',\n",
       " 'that',\n",
       " 'that',\n",
       " 'which',\n",
       " 'we',\n",
       " 'want',\n",
       " 'is',\n",
       " 'compatible',\n",
       " 'with',\n",
       " 'that',\n",
       " 'which',\n",
       " 'NITE',\n",
       " 'X_M_L',\n",
       " '_',\n",
       " 'offers',\n",
       " 'us',\n",
       " '.',\n",
       " 'And',\n",
       " 'then',\n",
       " 'just',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'everyone',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'everyone',\n",
       " 'understand',\n",
       " 'the',\n",
       " 'interface',\n",
       " '.',\n",
       " 'So',\n",
       " 'I',\n",
       " 'think',\n",
       " 'if',\n",
       " 'today',\n",
       " 'we',\n",
       " 'decide',\n",
       " 'on',\n",
       " 'what',\n",
       " 'data',\n",
       " 'we',\n",
       " 'wanna',\n",
       " 'have',\n",
       " 'now',\n",
       " ',',\n",
       " 'and',\n",
       " 'and',\n",
       " 'later',\n",
       " ',',\n",
       " 'maybe',\n",
       " 'even',\n",
       " 'today',\n",
       " ',',\n",
       " 'we',\n",
       " 'go',\n",
       " 'and',\n",
       " 'look',\n",
       " 'at',\n",
       " 'NITE',\n",
       " 'X_M_L',\n",
       " '_',\n",
       " 'or',\n",
       " 'some',\n",
       " 'of',\n",
       " 'us',\n",
       " 'look',\n",
       " 'at',\n",
       " 'NITE',\n",
       " 'X_M_L',\n",
       " '_',\n",
       " 'in',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'more',\n",
       " 'detail',\n",
       " ',',\n",
       " 'just',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'make',\n",
       " 'some',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'that',\n",
       " 'code',\n",
       " 'and',\n",
       " 'see',\n",
       " 'how',\n",
       " 'does',\n",
       " 'the',\n",
       " 'representation',\n",
       " 'work',\n",
       " 'in',\n",
       " 'their',\n",
       " 'system',\n",
       " '.',\n",
       " 'And',\n",
       " 'then',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'with',\n",
       " 'that',\n",
       " 'knowledge',\n",
       " 'we',\n",
       " 'should',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'then',\n",
       " 'say',\n",
       " 'okay',\n",
       " ',',\n",
       " 'that',\n",
       " 'type',\n",
       " 'of',\n",
       " 'NITE',\n",
       " 'X_M_L',\n",
       " '_',\n",
       " 'data',\n",
       " 'we',\n",
       " 'wanna',\n",
       " 'load',\n",
       " 'into',\n",
       " 'it',\n",
       " ',',\n",
       " 'and',\n",
       " 'this',\n",
       " 'is',\n",
       " 'how',\n",
       " 'everyone',\n",
       " 'can',\n",
       " 'access',\n",
       " 'it',\n",
       " ',',\n",
       " 'and',\n",
       " 'then',\n",
       " 'we',\n",
       " 'should',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'go',\n",
       " 'from',\n",
       " 'there',\n",
       " '.',\n",
       " 'No',\n",
       " '.',\n",
       " 'I',\n",
       " \"'ve\",\n",
       " 'looked',\n",
       " 'looked',\n",
       " 'at',\n",
       " 'the',\n",
       " 'documentation',\n",
       " 'and',\n",
       " 'n',\n",
       " 'like',\n",
       " 'seen',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'make',\n",
       " 'me',\n",
       " 'think',\n",
       " 'that',\n",
       " 'we',\n",
       " 'want',\n",
       " 'to',\n",
       " 'use',\n",
       " 'the',\n",
       " 'NITE',\n",
       " 'X_M_L',\n",
       " '_',\n",
       " 'framework',\n",
       " 'because',\n",
       " 'um',\n",
       " 'they',\n",
       " 'have',\n",
       " 'a',\n",
       " 'good',\n",
       " 'a',\n",
       " 'event',\n",
       " 'model',\n",
       " 'that',\n",
       " 'synchronizes',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'the',\n",
       " 'data',\n",
       " 'and',\n",
       " 'and',\n",
       " 'every',\n",
       " 'display',\n",
       " 'element',\n",
       " '.',\n",
       " 'So',\n",
       " 'that',\n",
       " 'takes',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'work',\n",
       " 'away',\n",
       " 'from',\n",
       " 'us',\n",
       " '.',\n",
       " 'Sort',\n",
       " 'of',\n",
       " 'that',\n",
       " 'would',\n",
       " 'be',\n",
       " 'a',\n",
       " 'reason',\n",
       " 'for',\n",
       " 'staying',\n",
       " 'within',\n",
       " 'their',\n",
       " 'framework',\n",
       " 'and',\n",
       " 'using',\n",
       " 'their',\n",
       " 'general',\n",
       " 'classes',\n",
       " '.',\n",
       " 'But',\n",
       " 'beyond',\n",
       " 'that',\n",
       " 'I',\n",
       " 'have',\n",
       " \"n't\",\n",
       " 'looked',\n",
       " 'at',\n",
       " 'it',\n",
       " 'at',\n",
       " 'all',\n",
       " ',',\n",
       " 'which',\n",
       " 'is',\n",
       " 'something',\n",
       " 'we',\n",
       " 'should',\n",
       " 'really',\n",
       " 'do',\n",
       " '.',\n",
       " 'Who',\n",
       " 'actually',\n",
       " 'like',\n",
       " 'for',\n",
       " 'this',\n",
       " 'whole',\n",
       " 'discussion',\n",
       " 'I',\n",
       " 'mean',\n",
       " ',',\n",
       " 'who',\n",
       " 'of',\n",
       " 'us',\n",
       " 'is',\n",
       " 'doing',\n",
       " 'stuff',\n",
       " 'that',\n",
       " 'is',\n",
       " 'happening',\n",
       " 'on',\n",
       " '-',\n",
       " 'line',\n",
       " 'and',\n",
       " 'who',\n",
       " 'of',\n",
       " 'us',\n",
       " 'is',\n",
       " 'doing',\n",
       " 'stuff',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'happening',\n",
       " 'off',\n",
       " '-',\n",
       " 'line',\n",
       " '?',\n",
       " 'Like',\n",
       " 'my',\n",
       " 'data',\n",
       " 'is',\n",
       " 'coming',\n",
       " 'c',\n",
       " 'Hmm',\n",
       " '?',\n",
       " 'Yeah',\n",
       " '.',\n",
       " 'Okay',\n",
       " '.',\n",
       " 'Okay',\n",
       " '.',\n",
       " \"'\",\n",
       " 'Kay',\n",
       " '.',\n",
       " 'So',\n",
       " 'basically',\n",
       " 'apart',\n",
       " 'from',\n",
       " 'the',\n",
       " 'display',\n",
       " 'module',\n",
       " ',',\n",
       " 'the',\n",
       " 'i',\n",
       " 'the',\n",
       " 'display',\n",
       " 'itself',\n",
       " ',',\n",
       " 'we',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'have',\n",
       " 'an',\n",
       " 'extremely',\n",
       " 'high',\n",
       " 'degree',\n",
       " 'of',\n",
       " 'interaction',\n",
       " 'between',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'our',\n",
       " 'modules',\n",
       " 'that',\n",
       " 'create',\n",
       " 'the',\n",
       " 'stuff',\n",
       " 'and',\n",
       " 'and',\n",
       " 'the',\n",
       " 'interface',\n",
       " ',',\n",
       " 'so',\n",
       " 'the',\n",
       " 'interface',\n",
       " 'is',\n",
       " 'mainly',\n",
       " 'while',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'running',\n",
       " 'just',\n",
       " 'working',\n",
       " 'on',\n",
       " 'data',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'just',\n",
       " 'loaded',\n",
       " 'from',\n",
       " 'a',\n",
       " 'file',\n",
       " ',',\n",
       " 'I',\n",
       " 'guess',\n",
       " '.',\n",
       " 'There',\n",
       " 'is',\n",
       " \"n't\",\n",
       " 'Yeah',\n",
       " ',',\n",
       " 'I',\n",
       " 'know',\n",
       " '.',\n",
       " 'Th',\n",
       " 'Yeah',\n",
       " ',',\n",
       " 'the',\n",
       " 'search',\n",
       " 'is',\n",
       " 'I',\n",
       " 'guess',\n",
       " 'the',\n",
       " 'search',\n",
       " 'is',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'a',\n",
       " 'strange',\n",
       " 'beast',\n",
       " 'anyway',\n",
       " 'because',\n",
       " 'for',\n",
       " 'the',\n",
       " 'search',\n",
       " 'we',\n",
       " \"'re\",\n",
       " 'leaving',\n",
       " 'the',\n",
       " 'NITE',\n",
       " 'X_M_L',\n",
       " '_',\n",
       " 'framework',\n",
       " '.',\n",
       " 'Um',\n",
       " 'but',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'still',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'good',\n",
       " '.',\n",
       " 'That',\n",
       " 'means',\n",
       " 'that',\n",
       " 'at',\n",
       " 'least',\n",
       " 'like',\n",
       " 'we',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'have',\n",
       " 'the',\n",
       " 'type',\n",
       " 'of',\n",
       " 'situation',\n",
       " 'where',\n",
       " 'somebody',\n",
       " 'has',\n",
       " 'to',\n",
       " 'do',\n",
       " 'like',\n",
       " 'a',\n",
       " 'billion',\n",
       " 'calculations',\n",
       " 'on',\n",
       " 'on',\n",
       " 'data',\n",
       " 'on',\n",
       " '-',\n",
       " 'line',\n",
       " '.',\n",
       " \"'Cause\",\n",
       " 'that',\n",
       " 'would',\n",
       " 'make',\n",
       " 'it',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'more',\n",
       " 'like',\n",
       " 'that',\n",
       " 'would',\n",
       " 'mean',\n",
       " 'that',\n",
       " 'our',\n",
       " 'interface',\n",
       " 'for',\n",
       " 'the',\n",
       " 'data',\n",
       " 'would',\n",
       " 'have',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'more',\n",
       " 'careful',\n",
       " 'about',\n",
       " 'how',\n",
       " 'it',\n",
       " 'performs',\n",
       " 'and',\n",
       " 'and',\n",
       " 'everything',\n",
       " '.',\n",
       " 'And',\n",
       " 'nobody',\n",
       " 'is',\n",
       " 'modifying',\n",
       " 'that',\n",
       " 'data',\n",
       " 'at',\n",
       " 'at',\n",
       " 'on',\n",
       " '-',\n",
       " 'line',\n",
       " 'time',\n",
       " 'at',\n",
       " 'all',\n",
       " 'it',\n",
       " 'seems',\n",
       " '.',\n",
       " 'Nobody',\n",
       " \"'s\",\n",
       " 'making',\n",
       " 'any',\n",
       " 'changes',\n",
       " 'to',\n",
       " 'the',\n",
       " 'actual',\n",
       " 'data',\n",
       " 'on',\n",
       " '-',\n",
       " 'line',\n",
       " '.',\n",
       " 'So',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'actually',\n",
       " 'making',\n",
       " 'it',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'easier',\n",
       " '.',\n",
       " 'That',\n",
       " 'basically',\n",
       " 'means',\n",
       " 'our',\n",
       " 'browser',\n",
       " 'really',\n",
       " 'is',\n",
       " 'a',\n",
       " 'viewer',\n",
       " 'mostly',\n",
       " ',',\n",
       " 'which',\n",
       " 'is',\n",
       " \"n't\",\n",
       " 'doing',\n",
       " 'much',\n",
       " 'with',\n",
       " 'the',\n",
       " 'data',\n",
       " 'except',\n",
       " 'for',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'selecting',\n",
       " 'a',\n",
       " 'piece',\n",
       " 'piece',\n",
       " 'of',\n",
       " 'it',\n",
       " 'and',\n",
       " 'and',\n",
       " 'displaying',\n",
       " 'it',\n",
       " '.',\n",
       " 'Hmm',\n",
       " '?',\n",
       " 'Well',\n",
       " 'some',\n",
       " 'parts',\n",
       " 'relevant',\n",
       " 'for',\n",
       " 'the',\n",
       " 'search',\n",
       " ',',\n",
       " 'yes',\n",
       " '.',\n",
       " 'I',\n",
       " \"'d\",\n",
       " 'say',\n",
       " 'so',\n",
       " '.',\n",
       " 'Hmm',\n",
       " '?',\n",
       " 'Yeah',\n",
       " ',',\n",
       " 'but',\n",
       " 'nobody',\n",
       " 'of',\n",
       " 'us',\n",
       " 'is',\n",
       " 'doing',\n",
       " 'much',\n",
       " 'of',\n",
       " 'searching',\n",
       " 'from',\n",
       " 'the',\n",
       " 'data',\n",
       " 'in',\n",
       " 'the',\n",
       " 'on',\n",
       " '-',\n",
       " 'line',\n",
       " 'stage',\n",
       " '.',\n",
       " 'And',\n",
       " 'for',\n",
       " 'all',\n",
       " 'together',\n",
       " ',',\n",
       " 'like',\n",
       " 'the',\n",
       " 'display',\n",
       " 'itself',\n",
       " ',',\n",
       " 'I',\n",
       " 'think',\n",
       " 'we',\n",
       " 'are',\n",
       " 'easier',\n",
       " 'if',\n",
       " 'we',\n",
       " 'if',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'sitting',\n",
       " 'on',\n",
       " 'the',\n",
       " 'X_M_L',\n",
       " '_',\n",
       " 'than',\n",
       " 'if',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'sitting',\n",
       " 'on',\n",
       " 'the',\n",
       " 'S_Q_L',\n",
       " '_',\n",
       " 'stuff',\n",
       " ',',\n",
       " 'because',\n",
       " 'if',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'sitting',\n",
       " 'on',\n",
       " 'the',\n",
       " 'X_M_L',\n",
       " '_',\n",
       " ',',\n",
       " 'we',\n",
       " 'have',\n",
       " 'the',\n",
       " 'the',\n",
       " 'NITE',\n",
       " 'X_M_L',\n",
       " '_',\n",
       " 'framework',\n",
       " 'with',\n",
       " 'all',\n",
       " 'its',\n",
       " 'functionality',\n",
       " 'for',\n",
       " 'synchronizing',\n",
       " 'through',\n",
       " 'all',\n",
       " 'the',\n",
       " 'different',\n",
       " 'levels',\n",
       " 'whenever',\n",
       " 'there',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'change',\n",
       " ',',\n",
       " 'whenever',\n",
       " 'something',\n",
       " \"'s\",\n",
       " 'moving',\n",
       " 'forward',\n",
       " 'and',\n",
       " 'stuff',\n",
       " '.',\n",
       " 'And',\n",
       " 'we',\n",
       " 'can',\n",
       " 'just',\n",
       " 'more',\n",
       " 'or',\n",
       " 'less',\n",
       " 'look',\n",
       " 'at',\n",
       " 'their',\n",
       " 'code',\n",
       " ',',\n",
       " 'like',\n",
       " 'how',\n",
       " 'their',\n",
       " 'player',\n",
       " 'moves',\n",
       " 'forward',\n",
       " ',',\n",
       " 'and',\n",
       " 'how',\n",
       " 'that',\n",
       " 'moving',\n",
       " 'forward',\n",
       " 'is',\n",
       " 'represented',\n",
       " 'in',\n",
       " 'different',\n",
       " 'windows',\n",
       " 'and',\n",
       " 'stuff',\n",
       " '.',\n",
       " 'So',\n",
       " 'I',\n",
       " 'think',\n",
       " 'in',\n",
       " 'the',\n",
       " 'actual',\n",
       " 'browser',\n",
       " 'itself',\n",
       " 'I',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'wanna',\n",
       " 'sit',\n",
       " 'on',\n",
       " 'the',\n",
       " 'S_Q_L',\n",
       " ...]"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(transcript_sum)\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m45VrwneanVm"
   },
   "outputs": [],
   "source": [
    "word_freq = {}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords_english:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_freq.keys():\n",
    "                word_freq[word.text] = 1\n",
    "            else:\n",
    "                word_freq[word.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RUwfDzLanVm",
    "outputId": "bb6d7c41-09f2-4b46-ea7c-fb0369824a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'much': 26, 'said': 18, 'yesterday': 1, \"'d\": 43, 'say': 38, 'prototype': 6, 'wherever': 1, 'possible': 4, 'p': 7, 'chunk': 4, 'stuff': 45, 'pre': 4, 'annotated': 4, \"n't\": 149, 'write': 11, 'stupid': 1, 'baseline': 3, 'probably': 76, 'able': 10, 'basically': 21, 'means': 11, 'focus': 2, 'interface': 9, 'first': 12, 'sort': 89, 'take': 17, 'ready': 7, 'made': 5, 'parts': 2, 'see': 23, 'get': 36, 'work': 20, 'together': 24, 'way': 17, 'want': 41, 'working': 14, 'go': 30, 'back': 4, 'replace': 2, 'pieces': 4, 'either': 2, 'components': 4, 'sophisticated': 2, 'compo': 1, 'po': 1, \"'s\": 320, 'feasible': 1, 'thing': 50, \"'m\": 58, 'away': 3, 'weekend': 1, 'Oh': 29, 'also': 25, 'might': 18, 'similarity': 1, 'matrix': 2, 'c': 9, 'think': 110, 'fairly': 3, 'quickly': 1, 'algorithms': 2, 'today': 5, 'meeting': 66, 'really': 38, 'one': 73, 'settle': 1, 'data': 47, 'structure': 12, 'soon': 5, 'actually': 27, 'need': 40, 'look': 29, 'NITE': 22, 'X_M_L': 48, 'far': 9, 'compatible': 1, 'offers': 1, 'us': 13, 'everyone': 9, 'make': 31, 'sure': 21, 'understand': 8, 'decide': 2, 'wanna': 8, 'later': 2, 'maybe': 32, 'even': 23, 'bit': 8, 'detail': 3, 'trying': 1, 'sense': 15, 'code': 13, 'representation': 6, 'system': 9, 'knowledge': 1, 'type': 9, 'load': 19, 'access': 4, \"'ve\": 24, 'looked': 8, 'documentation': 1, 'n': 3, 'seen': 3, 'enough': 7, 'use': 20, 'framework': 9, 'good': 12, 'event': 3, 'model': 2, 'synchronizes': 1, 'every': 19, 'display': 29, 'element': 2, 'takes': 4, 'lot': 17, 'Sort': 2, 'would': 94, 'reason': 2, 'staying': 1, 'within': 16, 'using': 13, 'general': 8, 'classes': 4, 'beyond': 1, 'something': 53, 'whole': 68, 'discussion': 1, 'mean': 79, 'happening': 2, 'line': 30, 'coming': 4, 'apart': 2, 'module': 4, 'extremely': 1, 'high': 5, 'degree': 2, 'interaction': 1, 'modules': 2, 'create': 7, 'mainly': 1, 'running': 7, 'loaded': 3, 'file': 43, 'guess': 16, 'know': 57, 'Th': 1, 'search': 13, 'strange': 5, 'beast': 1, 'anyway': 16, \"'re\": 59, 'leaving': 1, 'still': 16, 'least': 5, 'situation': 1, 'somebody': 8, 'billion': 1, 'calculations': 2, \"'Cause\": 20, 'careful': 5, 'performs': 1, 'everything': 17, 'nobody': 5, 'modifying': 1, 'time': 43, 'seems': 4, 'Nobody': 1, 'making': 5, 'changes': 6, 'actual': 5, 'easier': 7, 'browser': 8, 'viewer': 1, 'mostly': 3, 'except': 1, 'selecting': 1, 'piece': 5, 'displaying': 5, 'relevant': 2, 'yes': 3, 'searching': 4, 'stage': 1, 'sitting': 5, 'S_Q_L': 3, 'functionality': 2, 'synchronizing': 1, 'different': 41, 'levels': 11, 'whenever': 2, 'change': 8, 'moving': 2, 'forward': 5, 'less': 10, 'player': 7, 'moves': 2, 'represented': 1, 'windows': 1, 'sit': 5, 'help': 1, 'needs': 7, 'special': 3, 'representations': 1, 'results': 4, 'format': 4, 'stamps': 10, 'easy': 20, 'tie': 6, 'st': 2, 'things': 13, 'multi': 1, 'level': 41, 'idea': 8, 'start': 21, 'series': 41, 'entity': 6, 'individual': 24, 'chunks': 12, 'meetings': 20, 'whereas': 2, 'click': 4, 'segments': 35, 'multiple': 2, 'f': 14, 'discuss': 3, 'find': 7, 'abstraction': 1, 'deals': 1, 'worry': 3, 'whether': 12, 'segment': 20, 'process': 9, 'twice': 1, 'example': 11, 'summary': 9, 'corpus': 18, 'word': 35, 'call': 2, 'topic': 34, 'se': 3, 'compiled': 1, 'separate': 8, 'fine': 3, 'grainedness': 1, 'happen': 1, 'double': 2, 'let': 9, 'single': 12, 'zoom': 4, 'th': 15, 'end': 23, 'position': 6, 'thought': 18, 'could': 36, 'impression': 2, 'got': 18, 'wa': 2, 'worried': 2, 'total': 3, 'memory': 18, 'complexity': 1, 'completely': 5, 'admit': 1, 'took': 1, 'Jonathan': 3, 'loading': 10, 'wrong': 3, 'many': 8, 'utterances': 48, 'w': 16, 'words': 54, 'priority': 3, 'selection': 1, 'summaries': 5, 'automatically': 3, 'feed': 4, 'prioritized': 2, 'indiv': 1, 'utterance': 37, 'refined': 1, 'machine': 11, 'sentences': 2, 'taking': 2, 'highest': 8, 'second': 4, 'u': 1, 'information': 27, 'density': 16, 'calculation': 3, 'times': 10, 'sound': 2, 'crazy': 1, 'point': 7, 'check': 6, 'works': 6, 'merit': 3, 'altogether': 2, 'displays': 4, 'text': 29, 'body': 1, 'latest': 1, 'draft': 1, 'came': 1, 'summarised': 2, 'version': 1, 'graph': 1, 'part': 10, 'Maybe': 5, 'r': 4, 'audio': 11, 'skimming': 12, 'displayed': 4, 'going': 9, 'bother': 3, 'calculate': 7, 'internally': 4, 'store': 12, 'importance': 8, 'rank': 1, 'better': 4, 'required': 1, 'worst': 1, 'case': 2, 'ca': 11, 'anything': 17, 'else': 8, 'W': 4, 'smallest': 1, 'moment': 19, 'thinking': 13, 'assigning': 1, 'measure': 7, 'storing': 1, 'per': 7, 'Dave': 4, 'playing': 1, 'show': 1, 'important': 4, 'makes': 5, 'difference': 5, 'algorithm': 15, \"'cause\": 16, 'put': 14, 'Jasmine': 3, 'ways': 2, 'easily': 4, 'prob': 1, 'filtering': 2, 'problem': 9, 'play': 5, 'unless': 1, 'cut': 6, 'answer': 1, 'specific': 2, 'question': 1, 'deal': 3, 'capable': 1, 'Yes': 22, 'buffering': 1, 'directly': 4, 'feeding': 1, 'stored': 4, 'hard': 6, 'disk': 4, 'stream': 2, 'exists': 2, 'Java': 11, 'binary': 1, 'cutting': 2, 'clearly': 2, 'au': 1, 'phrase': 2, 'addition': 1, 'says': 5, 'minus': 1, 'depends': 4, 'advanced': 1, 'realise': 2, 'massive': 9, 'differences': 1, 'gain': 2, 'simple': 4, 'normalization': 1, 'necessary': 2, 'never': 3, 'accepts': 1, 'input': 1, 'doable': 2, 'quite': 33, 'lucky': 1, 'rankings': 1, 'goes': 5, 'speaking': 3, 'confused': 2, 'document': 24, 'size': 3, 'hand': 4, 'fifty': 3, 'mega': 4, 'byte': 3, 'RAM': 3, 'Actually': 2, 'hundred': 7, 'megabyte': 4, 'big': 27, 'simp': 1, 'error': 1, 'message': 1, 'project': 8, 'hope': 2, 'essentially': 3, 'lazy': 3, 'explain': 1, 'Ah': 6, 'files': 21, 'split': 4, 'three': 7, 'ten': 3, 'chance': 1, 'try': 7, 'fail': 2, 'place': 3, 'ever': 2, 'failed': 1, 'right': 25, 'kit': 1, 'interesting': 2, 'Let': 1, \"'ll\": 38, 'ask': 4, 'alternatively': 2, 'meta': 1, 'representing': 2, 'represents': 1, 'v': 2, 'similar': 7, 'represent': 3, 'always': 8, 'combined': 2, 'instead': 4, 'wi': 1, 'creating': 3, 'virtual': 3, 'treats': 3, 'shift': 1, 'vir': 1, 'two': 20, 'ifs': 2, 'new': 8, 'alternative': 1, 'worrying': 2, 'users': 1, 'view': 1, 'often': 2, 'based': 2, 'granularity': 1, 'seventy': 1, 'hours': 3, 'structurally': 2, 'le': 1, 'score': 2, 'cou': 1, 'course': 1, 'speaker': 5, 'topics': 14, 'sorts': 1, 'puts': 1, 'order': 11, 'set': 5, 'otherwise': 7, 'gon': 35, 'na': 35, 'entertaining': 1, 'leaves': 5, 'database': 6, 'gets': 8, 'marker': 2, 'concerned': 2, 'mark': 1, 'shifts': 1, 'frame': 2, 'alerts': 5, 'updates': 1, 'ju': 2, 'somethi': 1, 'tree': 4, 'clicks': 1, 'stamp': 5, 'central': 3, 'manager': 2, 'skim': 1, 'visual': 1, 'update': 1, 'routines': 1, 'respect': 1, 'current': 2, 'starting': 3, 'mid': 2, 'found': 7, 'middle': 1, 'jump': 1, 'window': 2, 'handling': 4, 'triggered': 1, 'routine': 1, 'push': 1, 'please': 1, 'beauty': 2, 'ties': 2, 'lots': 1, 'additional': 1, 'I_D_s': 3, 'presume': 2, 'references': 2, 'short': 3, 'whatever': 17, 'number': 10, 'weight': 6, 'existing': 2, 'add': 3, 'integer': 1, 'increment': 1, 'top': 3, 'bottom': 2, 'I_D': 5, 'un': 1, 'route': 1, 'follow': 1, 'alm': 1, 'girl': 1, 'numbered': 3, 'solvable': 1, 'Sorry': 6, 'board': 1, 'pen': 1, 'list': 11, 'paper': 1, 'fancy': 2, 'pens': 1, 'speakers': 2, 'weights': 3, 'outside': 1, 'sorry': 9, 'meant': 5, 'super': 4, 'unit': 1, 'tied': 2, 'b': 11, 'somehow': 1, 'extract': 5, 'generally': 3, 'called': 3, 'sa': 2, 'person': 4, 'contribution': 1, 'thingy': 1, 'dingy': 1, 'field': 1, 'somewhere': 3, 'referenced': 1, 'contain': 1, 'redundant': 1, 'showing': 1, 'finish': 1, 'belong': 2, 'segmentation': 7, 'definitely': 5, 'fit': 1, 'long': 12, 'slash': 2, 'smaller': 1, 'lists': 2, 'give': 12, 'though': 13, 'head': 1, 'merge': 3, 'bureaucracy': 1, 'involved': 1, 'trees': 3, 'quicker': 3, 'tre': 1, 'overhead': 1, 'amount': 3, 'already': 12, 'figure': 2, 'horrendously': 1, 'infrastructure': 2, 'main': 1, 'types': 3, 'queries': 3, 'l': 2, 'dynamically': 1, 'select': 2, 'fast': 1, 'ones': 7, 'query': 4, 'language': 2, 'shou': 1, 'return': 1, 'million': 3, 'handle': 3, 'threshold': 3, 'oh': 6, 'ab': 1, 'skip': 3, 'leave': 2, 'meet': 3, 'calculated': 5, 'disp': 1, 'measures': 2, 'along': 1, 'extracting': 4, 'title': 2, 'craft': 1, 'manually': 1, 'highly': 3, 'valued': 1, 'key': 3, 'heading': 1, 'best': 3, 'ranked': 1, 'introduction': 2, 'anywhere': 1, 'Also': 1, 'named': 7, 'people': 5, 'DIL': 4, 'spare': 1, 'finding': 2, 'titles': 1, 'D_F_I_D_F': 1, 'likely': 1, 'talking': 6, 'conference': 3, 'fr': 2, 'frequented': 1, 'sparse': 2, 'basing': 1, 'especially': 1, 'entities': 2, 'describe': 2, 'name': 4, 'indirect': 1, 'Anyway': 2, 'cool': 5, 'wondering': 3, 'discussions': 1, 'exactly': 3, 'interact': 1, 'done': 5, 'ha': 3, 'useful': 12, 'understanding': 1, 'session': 4, 'computer': 3, 'room': 3, 'closer': 1, 'Good': 1, 'coordination': 1, 'application': 1, 'elements': 1, 'integration': 4, 'Nah': 1, 'started': 1, 'understands': 1, 'centrally': 1, 'comes': 4, 'volunteers': 1, 'complicated': 2, 'several': 4, 'closely': 1, 'versions': 2, 'matter': 7, 'building': 4, 'test': 2, 'difficult': 4, 'anyone': 9, 'nice': 3, 'basic': 2, 'adapt': 3, 'arran': 1, 'gym': 1, 'theoretically': 1, 'free': 5, 'nothing': 4, 'Wednesday': 5, 'Nine': 1, 'til': 2, 'twelve': 4, 'nothi': 1, 'Anytime': 1, 'afternoon': 5, 'Yo': 1, 'Forrest': 1, 'Hill': 1, 'biased': 1, 'eighteen': 1, 'critically': 1, 'L_S_A': 3, 'vast': 1, 'without': 5, 'supplying': 1, 'crucial': 2, 'raw': 14, 'programme': 2, 'flavours': 1, 'context': 6, 'spoken': 1, 'numbers': 12, 'task': 3, 'screw': 1, 'pro': 2, 'perform': 1, 'another': 8, 'seeing': 1, 'constrained': 1, 'vocabulary': 1, 'co': 1, 'occurrence': 2, 'nine': 9, 'wou': 2, 'sounded': 1, 'wanted': 4, 'overlapping': 1, 'reading': 1, 'speeds': 1, 'ICSI': 5, 'reasons': 1, 'must': 2, 'pissed': 1, 'saying': 5, 'I_D_F_s': 1, 'frequencies': 10, 'mix': 1, 'dictionary': 19, 'token': 1, 'given': 2, 'form': 4, 'counts': 7, 'forms': 2, 'ord': 2, 'wo': 5, 'spits': 1, 'frequency': 17, 'tool': 4, 'experience': 1, 'British': 1, 'National': 1, 'Corpus': 1, 'unusual': 1, 'typo': 1, 'thousands': 1, 'expect': 2, 'dictionaries': 2, 'grow': 1, 'bigger': 1, 'filter': 4, 'regular': 1, 'expressions': 1, 'consists': 2, 'dig': 1, 'digits': 2, 'characters': 3, 'dot': 2, 'usually': 3, 'ignored': 1, 'frequent': 2, 'articles': 1, 'Frequencies': 1, 'hash': 11, 'map': 3, 'beefy': 3, 'burning': 1, 'burn': 6, 'X': 1, 'asked': 2, 'support': 3, 'days': 1, 'ago': 1, 'Informatics': 1, 'Appleton': 3, 'Tower': 3, 'five': 4, 'closest': 2, 'machines': 2, 'office': 1, 'wait': 4, 'exact': 2, 'email': 2, 'enter': 1, 'corner': 2, 'local': 4, 'mounted': 1, 'temp': 5, 'directory': 10, 'forgot': 1, 'gigabyte': 2, 'See': 2, 'offer': 1, 'copy': 4, 'figured': 2, 'broad': 1, 'band': 2, 'mount': 1, 'unfortunate': 1, 'operating': 1, 'Wh': 1, 'connection': 1, 'home': 6, 'ext': 1, 'C_D': 5, 'Question': 1, 'compression': 1, 'percent': 1, 'compress': 3, 'temps': 3, 'guarantee': 1, 'stays': 1, 'overnight': 1, 'stay': 2, 'S_S_H': 4, 'hate': 2, 'gateway': 5, 'S_S': 1, 'hey': 1, 'warning': 1, 'tunnel': 1, 'yet': 4, 'copying': 1, 'boring': 3, 'everybody': 2, 'details': 1, 'gives': 3, 'implement': 3, 'table': 9, 'builder': 1, 'count': 3, 'old': 1, 'ar': 1, 'g': 2, 'getting': 6, 'creates': 1, 'blank': 1, 'common': 1, 'latent': 1, 'semantic': 1, 'analysis': 1, 'convert': 1, 'probabilities': 2, 'Rainbow': 5, 'builds': 2, 'Even': 2, 'build': 12, 'appears': 1, 'scrap': 1, 'notion': 2, 'hierarchical': 4, 'coherent': 1, 'Wait': 2, 'weighting': 1, 'calculating': 3, 'lowest': 1, 'versus': 1, 'talk': 3, 'relative': 1, 'term': 1, 'certain': 3, 'abandon': 1, 'concept': 2, 'treating': 2, 'algorithmic': 1, 'plus': 2, 'keeping': 2, 'happens': 1, 'sub': 2, 'treated': 1, 'brain': 1, 'damaged': 1, 'identical': 1, 'treat': 2, 'Probably': 1, 'decided': 2, 'looking': 10, 'implementation': 1, 'modify': 1, 'read': 5, 'space': 5, 'scratch': 1, 'gigabytes': 2, 'sends': 2, 'port': 1, 'seminar': 1, 'discussing': 1, 'technical': 1, 'practicalities': 1, 'al': 1, 'allowed': 3, 'anybody': 3, 'DICE': 4, 'laptop': 1, 'personally': 1, 'friends': 1, 'keen': 1, 'excited': 1, 'pirate': 1, 'copied': 1, 'Huh': 3, 'realised': 1, 'keep': 1, 'serieses': 1, 'virtually': 2, 'purposes': 1, 'merging': 1, '..': 3, 'pick': 1, 'majorly': 1, 'messy': 1, 'Wou': 1, 'producing': 1, 'real': 1, 'tha': 1, 'last': 3, 'print': 2, 'straight': 2, 'flowing': 1, 'marks': 2, 'segmented': 1, 'automated': 1, 'output': 2, 'dump': 4, 'pure': 2, 'loads': 7, 'enumerate': 2, 'four': 1, 'enu': 1, 'ordered': 7, 'pattern': 1, 'wish': 1, 'Orders': 1, 'primitive': 2, 'sounds': 5, 'reasonable': 3, 'picking': 1, 'particular': 4, 'presentation': 1, 'roughly': 1, 'realisti': 1, 'sorted': 1, 'alphabetically': 1, 'numerically': 1, 'wishes': 1, 'Add': 1, 'next': 10, 'morning': 1, 'processing': 1, 'bog': 1, 'standard': 1, 'written': 1, 'half': 5, 'hour': 2, 'increase': 1, 'Really': 3, 'Perl': 7, 'wants': 1, 'script': 3, 'nicely': 1, 'wrote': 2, 'occurrences': 2, 'tags': 1, 'serialized': 1, 'Would': 1, 'absolutely': 1, 'seriali': 1, 'serialization': 2, 'Give': 1, 'break': 1, 'separated': 1, 'serialize': 3, 'serialise': 1, 'command': 1, 'mother': 1, 'pretty': 5, 'demonstrator': 2, 'week': 8, 'God': 1, 'demonstrate': 3, 'agree': 1, 'ta': 1, 'feel': 1, 'hanging': 1, 'air': 1, 'teeth': 1, 'properly': 1, 'fuzzy': 1, 'implementational': 1, 'structures': 1, 'vague': 1, 'ideas': 2, 'freaks': 1, 'user': 3, 'face': 1, 'random': 1, 'depending': 2, 'value': 2, 'sequences': 1, 'sh': 1, 'possibly': 2, 'annotation': 3, 'lost': 1, 'abo': 1, 'combining': 1, 'hot': 3, 'spots': 2, 'Oops': 1, 'define': 1, 'discourse': 2, 'acts': 3, 'demand': 2, 'N': 1, 'ex': 1, 'compared': 1, 'pause': 2, 'duration': 1, 'extraction': 2, 'uttered': 1, 'sequence': 2, 'pauses': 2, 'sometimes': 3, 'however': 1, 'indicated': 1, 'square': 1, 'brackets': 1, 'someti': 1, 'annotators': 1, 'annotations': 1, 'uttera': 1, 'dialogue': 1, 'sti': 1, 'occurs': 2, 'wondered': 1, 'agreement': 1, 'disagreement': 1, 'outline': 1, 'talked': 1, 'patterns': 1, 'freq': 1, 'regions': 1, 'spot': 1, 'small': 6, 'concatenate': 4, 'run': 2, 'Ye': 5, 'ch': 1, 'perhaps': 1, 'lines': 3, 'codes': 1, 'millisecond': 2, 'changing': 2, 'extracted': 2, 'dura': 1, 'durations': 2, 'contatenate': 1, 'send': 3, 'Pe': 1, 'according': 1, 'diffe': 1, 'group': 3, 'identification': 1, 'letter': 1, 'B_E_D': 1, 'B_B_D': 1, 'O_O': 2, 'zero': 2, 'final': 1, 'channel': 1, 'string': 2, 'manipulation': 1, 'Sure': 1, 'sea': 1, 'huh': 2, 'names': 1, 'letters': 2, 'base': 1, 'contained': 1, 'Ordered': 1, 'megami': 1, 'Na': 1, 'guessing': 1, 'seconds': 1, 'typed': 1, 'assign': 1, 'carry': 1, 'meaning': 1, 'uhs': 1, 'average': 2, 'unimportant': 1, 'disregard': 1, 'currently': 1, 'implementing': 2, 'computing': 1, 'bins': 1, 'notes': 1, 'combine': 2, 'accordingly': 1, 'beginning': 5, 'kind': 2, 'F': 1, 'Think': 2, 'tag': 1, 'saw': 1, 'combinations': 1, 'B_R_E': 1, 'global': 1, 'bin': 2, 'classification': 2, 'class': 3, 'terms': 4, 'implemented': 1, 'j': 2, 'Certain': 1, 'informative': 1, 'shall': 1, 'tomorrow': 1, 'Print': 1, 'program': 1, 'counting': 1, 'hashes': 1, 'dry': 1, 'Next': 1, 'mine': 2, 'processor': 1, 'intensive': 2, 'dumping': 1, 'reckon': 2, 'fields': 1, 'underlying': 2, 'summarise': 1, 'sorting': 1, 'computationally': 1, 'comprises': 1, 'stuck': 1, 'weighted': 2, 'slow': 1, 'honest': 1, 'trouble': 1, 'synch': 1, 'impossible': 1, 'buffer': 2, 'I_D_F': 2, 'meaningful': 2, 'sentence': 1, 'nought': 1, 'assigned': 1, 'wave': 4, 'bet': 1, 'packages': 2, 'unp': 1, 'bound': 1, 'media': 1, 'object': 1, 'dealing': 1, 'concatenating': 1, 'linked': 1, 'tenth': 1, 'silence': 1, 'Normalise': 1, 'summarisation': 1, 'scores': 1, 'higher': 2, 'Speaker': 1, 'segmenting': 2, 'preserve': 1, 'rather': 2, 'close': 1, 'may': 4, 'arbitrary': 4, 'attributes': 1, 'parser': 3, 'parse': 1, 'faster': 1, 'come': 3, 'informan': 1, 'mation': 1, 'recalculating': 1, 'obviously': 2, 'T_F_I_D_F': 5, 'inverse': 1, 'averaging': 1, 'related': 1, 'scroll': 1, 'Friday': 2, 'Matlab': 1, 'documents': 2, 'bef': 1, 'classified': 1, 'fill': 1, 'junk': 1, 'care': 1, 'copies': 1, 'Shakespeare': 1, 'statistics': 1, 'changed': 1, 'available': 1, 'remember': 1, 'Might': 2, 'WordNet': 1, 'corpuses': 1, 'stop': 2, 'download': 1, 'uninteresting': 1, 'papers': 1, 'ignore': 1, 'throughout': 1, 'experiment': 1, 'awful': 1, 'burner': 2, 'WAV': 1, 'S_C_P': 3, 'night': 2, 'suppose': 2, 'Linux': 1, 'box': 2, 'Windows': 1, 'Broad': 1, 'Put': 1, 'remote': 1, 'SSHing': 1, 'SCPing': 1, 'used': 1, 'little': 2, 'consider': 3, 'occur': 1, 'depend': 1, 'viewing': 1, 'allow': 1, 'disjoint': 1, 'globally': 1, 'comparing': 1, 'across': 2, 'issue': 1, 'jam': 1, 'bits': 1, 'conceptually': 1, 'parents': 1, 'inwards': 1, 'towards': 1, 'branch': 1, 'designed': 1, 'mind': 1, 'hierarchy': 1, 'looks': 1, 'went': 1, 'Right': 5, 'layer': 1, 'respects': 2, 'imposing': 1, 'nodes': 1, 'deeper': 1, 'confusing': 1, 'mini': 1, 'synched': 1, 'account': 1, 'deleted': 1, 'guaranteed': 1, 'web': 1, 'Listen': 1, 'Especially': 1, 'transferring': 1, 'Something': 1, 'neither': 1, 'funny': 1, 'finished': 1, 'writing': 2, 'saves': 1, 'parsing': 2, 'silly': 1, 'kinda': 2, 'collections': 1, 'serializable': 1, 'Tonight': 1, 'summarizer': 1, 'specify': 1, 'specification': 2, 'become': 1, 'obvious': 1, 'Steve': 2, 'feedback': 1, 'duplication': 2, 'effort': 2, 'six': 1, 'prioritize': 2, 'online': 1, 'Depends': 1, 'accessed': 1, 'develop': 1, 'Pretty': 1, 'Topics': 1, 'efficient': 1, 'inside': 1, 'occurred': 1, 'L_C': 1, 'seg': 2, 'equivalent': 1, 'allocated': 1, 'built': 1, 'integrating': 1, 'Python': 2, 'X_L': 1, 'noticed': 1, 'approach': 1, 'collaborate': 1, 'gotten': 1, 'hardly': 1, 'year': 1, 'mo': 1, 'M_L_C': 1, 'hopefully': 1, 'Suppose': 1, 'Wa': 1, 'suggested': 1, 'initial': 1, 'surprised': 1}\n"
     ]
    }
   ],
   "source": [
    "print(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "io23c0hganVm"
   },
   "outputs": [],
   "source": [
    "max_freq = max(word_freq.values())\n",
    "for word in word_freq.keys():\n",
    "    word_freq[word] = word_freq[word]/max_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Z3UHHZianVm"
   },
   "outputs": [],
   "source": [
    "sentence_tokens = [sent for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFAbkqNSanVn",
    "outputId": "f2cf6ec1-b385-41a8-c294-17f6ae57ff28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kay.,\n",
       " Gosh. ',\n",
       " Kay.,\n",
       " Is there much more in it than he d,\n",
       " Is there much more in it than he said yesterday?,\n",
       " Mm.,\n",
       " Hmm.,\n",
       " Hmm?,\n",
       " Yeah, now I'd say if for the prototype if we just like wherever possible p chunk in the stuff that we have um pre-annotated and stuff, and for the stuff that we don't have pre-annotated write like a stupid baseline, then we should probably be able to basically that means we focus on on the interface first sort of, so that we we take the the ready-made parts and just see how we get them work together in the interface the way we want,\n",
       " and,\n",
       " and then we have a working prototype.,\n",
       " And then we can go back and replace pieces either by our own components or by more sophisticated compo po components of our own.,\n",
       " So it's probably feasible.,\n",
       " The thing is I'm away this weekend.,\n",
       " So that's for me,\n",
       " Oh yeah,,\n",
       " um,\n",
       " yeah.,\n",
       " No.,\n",
       " But also I might like the the similarity thing, like my just my matrix itself for my stuff,\n",
       " , I c,\n",
       " I,\n",
       " I think I can do that fairly quickly because I have the algorithms.,\n",
       " Yeah, I think today's meeting is really the one where we where we sort of settle down the data structure and as soon as we have that, uh probably like after today's meeting, we then actually need to well go back first of all and look at NITE X_M_L_ to see in how far that that which we want is compatible with that which NITE X_M_L_ offers us.,\n",
       " And then just sort of everyone make sure everyone understand the interface.,\n",
       " So I think if today we decide on what data we wanna have now,,\n",
       " and and later, maybe even today, we go and look at NITE X_M_L_ or some of us look at NITE X_M_L_ in a bit more detail, just trying to make some sense of that code and see how does the representation work in their system.,\n",
       " And then sort of with that knowledge we should be able to then say okay, that type of NITE X_M_L_ data we wanna load into it, and this is how everyone can access it, and then we should be able to go from there.,\n",
       " No.,\n",
       " I've looked looked at the documentation and n like seen enough to make me think that we want to use the NITE X_M_L_ framework because um they have a good a event model that synchronizes sort of the data,\n",
       " and and every display element.,\n",
       " So that takes a lot of work away from us.,\n",
       " Sort of that would be a reason for staying within their framework and using their general classes.,\n",
       " But beyond that I haven't looked at it at all, which is something we should really do.,\n",
       " Who actually like for this whole discussion I mean, who of us is doing stuff that is happening on-line and who of us is doing stuff that's happening off-line?,\n",
       " Like my data is coming c Hmm?,\n",
       " Yeah.,\n",
       " Okay.,\n",
       " Okay. ',\n",
       " Kay.,\n",
       " So basically apart from the display module, the i the display itself, we don't have an extremely high degree of interaction between sort of our modules that create the stuff,\n",
       " and and the interface, so the interface is mainly while it's running just working on data that's just loaded from a file, I guess.,\n",
       " There isn't Yeah, I know.,\n",
       " Th,\n",
       " Yeah, the search is,\n",
       " I guess the search is sort of a strange beast anyway because for the search we're leaving the NITE X_M_L_ framework.,\n",
       " Um but that's still sort of that's good.,\n",
       " That means that at least like we don't have the type of situation where somebody has to do like a billion calculations on on data on-line.,\n",
       " 'Cause that would make it a lot more like that,\n",
       " would mean that our interface for the data would have to be a lot more careful about how it performs and and everything.,\n",
       " And nobody is modifying that data at at on-line time at all it seems.,\n",
       " Nobody's making any changes to the actual data on-line.,\n",
       " So that's actually making it a lot easier.,\n",
       " That basically means our browser really is a viewer mostly, which isn't doing much with the data except for sort of selecting a piece piece of it and and displaying it.,\n",
       " Hmm?,\n",
       " Well some parts relevant for the search, yes.,\n",
       " I'd say so.,\n",
       " Hmm?,\n",
       " Yeah, but nobody of us is doing much of searching from the data in the on-line stage.,\n",
       " And for all together, like the display itself, I think we are easier if we if it's sitting on the X_M_L_ than if it's sitting on the S_Q_L_ stuff, because if it's sitting on the X_M_L_, we have the the NITE X_M_L_ framework with all its functionality for synchronizing through all the different levels whenever there's a change, whenever something's moving forward and stuff.,\n",
       " And we can just more or less look at their code, like how their player moves forward, and how that moving forward is represented in different windows and stuff.,\n",
       " So I think in the actual browser itself,\n",
       " I don't wanna sit on the S_Q_L_ if we can sit on the X_M_L_ because sitting on the X_M_L_ we have all we have so much help.,\n",
       " And for y for like the p the calculations that we're doing apart from the search, it seems that everyone needs some special representations anyway.,\n",
       " You mean our results?,\n",
       " Yeah, in in the NITE X_M_L_ X_M_L_ format, so with their time stamps and stuff, so that it's easy to to tie together st things.,\n",
       " What I'm like what we have to think about is if we go with this multi-level idea, like this idea that sort of if you start with a whole meeting series as one entity, as one thing that you display, as one whole sort of, that then the individual chunks of the individual meetings, whereas and then you can click on a meeting, and then sort of the meeting is the whole thing and the chunks are the individual segments, that means sort of we have multiple levels of of representation, which we probably If we if we do it this way like we f we have to discuss that if we do it this way, then we should probably find some abstraction model, so that the interface in the sense like deals with it as if it's same so that the interface doesn't really have to worry whether it's a meeting in the whole meeting series or a segment within a meeting,\n",
       " , you know what I mean?,\n",
       " And that's probably stuff that we have to sort of like process twice then.,\n",
       " Like for example that like the summary of a meeting within the whole meeting corpus or meeting series y is meeting series a good word for that?,\n",
       " I don't really know what how to call it.,\n",
       " You know what I mean, like not not the whole corpus, but every meeting that has to do with one topic.,\n",
       " Um so in in the meeting se series so that a summary for a meeting within the meeting series, are sort of compiled off-line by a summary module.,\n",
       " And that is separate from a summary of a segment within a meeting.,\n",
       " 'Cause I don't think we can So are we doing that at all levels?,\n",
       " Are we um And just have different like fine-grainedness levels sort of.,\n",
       " Mm. ',\n",
       " Kay.,\n",
       " So the only thing that,\n",
       " yeah, so,\n",
       " the only thing that would happen basically if I double-click let's say from the whole meeting series on a single meeting, is that the zoom level changes.,\n",
       " Like the th the start and the end position changes and the zoom level changes.,\n",
       " I,\n",
       " I thought we couldn't do that.,\n",
       " Like I was under the impression that we couldn't do that because we couldn't load the data for all that.,\n",
       " But I don't know,\n",
       " , I mean that So I'm s not sure if I got it.,\n",
       " I was Mm-hmm.,\n",
       " Mm-hmm.,\n",
       " Mm-hmm.,\n",
       " Mm-hmm.,\n",
       " Okay.,\n",
       " So,\n",
       " Okay.,\n",
       " I wa,\n",
       " I was just worried about the total memory complexity of it.,\n",
       " But I I completely admit, I mean,,\n",
       " I just sort of like th took that from some thing that Jonathan once said about not loading everything.,\n",
       " But maybe I was just wrong about it.,\n",
       " How many utterances,\n",
       " w,\n",
       " Yeah,,\n",
       " and I w,\n",
       " yeah.,\n",
       " Yeah.,\n",
       " Yeah.,\n",
       " Yeah.,\n",
       " So what we have is we would have a word.,\n",
       " Like we would have words with some priority levels.,\n",
       " And they would basically be because even the selection would would the summaries automatically feed from just how prioritized an individual word or how indiv uh prioritized an individual utterance is?,\n",
       " Or i are the summaries sort of refined from it and made by a machine to make sentences and stuff?,\n",
       " Or are they just sort of taking out the words with the highest priority and,\n",
       " then the words of the second highest priority?,\n",
       " And the u okay.,\n",
       " Are we doing it on th the whole thing on the utterance level?,\n",
       " Or are we doing it on word level, like the information density calculation?,\n",
       " We,\n",
       " I think we have start and end times for words actually, but it's yeah,,\n",
       " but it m,\n",
       " it might,\n",
       " s,\n",
       " but it might sound crazy in the player.,\n",
       " We should really maybe we can do that together at some point today that we check out how the player works.,\n",
       " But there's maybe some merit in altogether doing it on an utterance level in the end.,\n",
       " So Yeah.,\n",
       " Well but also about the displays, I mean the displays in the in the text body, in the in the latest draft that we had sort of we came up with the idea that it isn't displaying utterance for utterance, but it's also displaying uh a summarised version in you know, like below the below the graph, the part.,\n",
       " Maybe Yeah, r Hmm?,\n",
       " Oh yeah,,\n",
       " f,\n",
       " it's just like,\n",
       " there there's like audio skimming,\n",
       " and there's displayed skimming.,\n",
       " Yeah.,\n",
       " Ma,\n",
       " maybe there's some merit of going altogether for utterance level and not even bother to calculate,\n",
       " I mean if you have to do it internally, then you can do it.,\n",
       " But maybe like not even store the importance levels for individual words and just sort of rank utterances as a whole.,\n",
       " Hmm?,\n",
       " Yeah.,\n",
       " 'Cause it,\n",
       " it might be better skimming and less memory required at the same time.,\n",
       " And I mean if you if you know how to do it for individual words, then you can just in the worst case, if you can't find anything else, just sort of make the mean of the words over the utterance.,\n",
       " You know what I mean?,\n",
       " W,\n",
       " it's,\n",
       " it's,\n",
       " Well what's the smallest chunk at the moment you're thinking of of assigning an importance measure to, is it a word or is it an utterance?,\n",
       " So we're thinking of like maybe just storing it on a per utterance level.,\n",
       " Because it's it's less stuff to store probably for Dave in the in the audio playing.,\n",
       " And for in the display it's probably better if you have whole utterances than I don't know, like what it's like,\n",
       " if you just take single words out of utterances.,\n",
       " That probably doesn't make any sense at all, whereas if you just uh show important utterances but the utterance as a whole it makes more sense.,\n",
       " So it doesn't actually make a difference for your algorithm, 'cause it just means that if you're working on a word level, then we just mean it over the utterance.,\n",
       " They are on,\n",
       " Oh so that's good anyway then,,\n",
       " yeah.,\n",
       " Because that makes it a lot easier than to t put it on utterance level.,\n",
       " Oh yeah.,\n",
       " No,\n",
       " but I mean like how how Jasmine does it internally,\n",
       " I don't know,,\n",
       " but it's probably,,\n",
       " yeah, you probably have to work on word levels for importance.,\n",
       " But there should be ways of easily going from a word level to an utterance level.,\n",
       " Okay.,\n",
       " Yeah, prob Hmm.,\n",
       " Well we do a pre-filtering of sort of the whole thing, sort of like,\n",
       " but that, like the problem with that is,\n",
       " it's easy to do in the text level.,\n",
       " But that would mean it would still play the uh in your audio, unless we sort of also store what pieces we cut out for the audio.,\n",
       " Yeah.,\n",
       " I think before we can like answer that specific question how we c deal with that, it's probably good for us to look at what the audio player is capable of doing.,\n",
       " Yes.,\n",
       " So what do you mean by buffering?,\n",
       " Like you think directly feeding,\n",
       " But yeah,,\n",
       " but not but not stored on the hard disk and then loaded in, but loaded in directly from memory.,\n",
       " But it's probably a stream if it exists in Java, it would be probably some binary stream going in of some type.,\n",
       " Okay,,\n",
       " yeah.,\n",
       " Okay.,\n",
       " Okay, so I mean so that means that there's probably,,\n",
       " even if you go on an per utterance level, there's still some merit on within utterances cutting out stuff which clearly isn't relevant at all, and that maybe also for the audio we'd have to do.,\n",
       " So let's say we play the whole au phrase, but then in addition to that, we have some information that says minus that part of something.,\n",
       " That's okay, that we can do.,\n",
       " Yeah, maybe even I mean that's sort of that depends on how how advanced we get.,\n",
       " If maybe if we realise that there's massive differences in in gain or in something, you can probably just make some simple simple normalization, but that really depends on how much time we have and and how much is necessary.,\n",
       " Yeah, if like I d I don't know anything about audio,\n",
       " and I have never seen the player.,\n",
       " So if you find that the player accepts some n input from memory, and if it's easy to do, then I guess that's,\n",
       " that's fairly doable.,\n",
       " So but that means in the general structure we're actually quite lucky, so we we have we load into memory for the whole series of meetings just the utterances and rankings for the utterances and some information probably that says, well, the I guess that goes with the utterance, who's speaking.,\n",
       " Because then we can also do the display about who's speaking.,\n",
       " Yeah.,\n",
       " But I'm I'm still confused 'cause I thought like that's just what Jonathan said we do c that we can't do, like load a massive document of that size.,\n",
       " On the other hand The other hand, I mean it shouldn't be like should be like fifty mega-byte in RAM or something,\n",
       " , it shouldn't be massive, should it?,\n",
       " Actually fifty hundred megabyte is quite big in RAM.,\n",
       " Just thinking, what's the simp,\n",
       " so We do get an error message with the project if we load everything into the project with all the data they load.,\n",
       " So we know that doesn't work.,\n",
       " So our hope is essentially that we load less into it.,\n",
       " What's this lazy loading thing, somebody explain lazy loading to me.,\n",
       " Ah, okay.,\n",
       " So that is that only by type of file.,\n",
       " Like if if if the same thing is in different files, would it then maybe like, you know, if if utterances are split over three or ten or w hundred different files, is then a chance maybe that it doesn't try to load them all into memory at the same time, but just So why does it fail then in the first place?,\n",
       " Then it shouldn't ever fail,,\n",
       " because then it should never Yeah,,\n",
       " but yeah,,\n",
       " but um it uh it it failed right when you load it,,\n",
       " right, the NITE X_M_L_ kit, so that's interesting.,\n",
       " Hmm.,\n",
       " Let's check that out.,\n",
       " Um I'll p,\n",
       " I'll probably ask Jonathan about it.,\n",
       " So alternatively, if we realise we can't do the whole thing in one go, we can probably just process some sort of meta-data,\n",
       " , you know what I mean, like sort of sort of for the whole series chunks representing the individual meetings or some Like something that represents the whole series in in a v in a structure very similar to the structure in which we represent individual um meetings, but with data sort of always combined from the whole series.,\n",
       " so instead of having an single utterance that we display, it would probably be like that would be representing a whole um topic, a segment in a meeting.,\n",
       " And sort of so that wi using the same data st Well, in a sense,\n",
       " Uh I'm I'm thinking of in a sense of like creating a virtual a virtual meeting out of the whole meeting series, sort of.,\n",
       " Yeah, sort of like off-line create a virtual meeting, which which basically treats the meeting series as if it was a meeting, and treats the individual meetings within the series as if they were segments, and treats the individual segments within meetings as if they were um utterances.,\n",
       " You know, so we just sort of we shift it one level up.,\n",
       " And in that way we could probably use the same algorithm and just like make vir like one or two ifs that say okay, if you are on a whole document uh a whole series level and that was a double-click, then don't just go into that um segment, but load a new file or something like it, but in general use the same algorithm.,\n",
       " That would be an alternative if we can't actually load the whole thing and 'Cause also,\n",
       " like even if we maybe this whole like maybe I'm worrying too much about the whole series in one thing display, because actually I mean probably users wouldn't view that one too often.,\n",
       " Yeah,,\n",
       " but I'm,\n",
       " I'm still worried.,\n",
       " Like for example for the display, if you actually if you want a display uh like for the whole series, the information density levels based on and and the f and the only granularity you have is individual utterances, that means you have to through every single utterance in a series of seventy hours of meetings.,\n",
       " Yeah.,\n",
       " Yeah,,\n",
       " and if you make that structurally very similar to the the le like one level down, like the way how we uh store individual utterances and stuff, then maybe we can more or less use the same code and just make a few ifs and stuff.,\n",
       " Yeah,,\n",
       " so so but still so in in general we're having we're having utterances and they have a score.,\n",
       " And that's as much as we really need.,\n",
       " And of cou,\n",
       " and they also have a time a time information of course.,\n",
       " Hmm?,\n",
       " And a and a s and a speaker information,,\n",
       " yeah.,\n",
       " Yeah, so an information which topic they're in,\n",
       " , yeah.,\n",
       " And and probably separate to that an information about the different topics like that,\n",
       " Yeah.,\n",
       " So so the skimming can work on that because the skimming just sort of sorts the utterances and puts as many in as it needs,\n",
       " Yeah.,\n",
       " Yeah, it'll it'll play them in some order in which they were set because otherwise it's gonna be more entertaining.,\n",
       " Um but that that's enough data for the skimming and the the searching, so what the searching does is the searching leaves the whole framework, goes to the S_Q_L_ database and gets like basically in the end gets just a time marker for where that is, like that utterance that we are concerned with.,\n",
       " And then we have to find I'm sure there's some way in in NITE X_M_L_,\n",
       " to just say set position to that time mark.,\n",
       " And then it shifts the whole frame,\n",
       " and it alerts every single element of the display and the display updates.,\n",
       " Yeah,,\n",
       " yeah.,\n",
       " That we can,\n",
       " ju,\n",
       " yeah,,\n",
       " but so so if if somethi so,\n",
       " yeah.,\n",
       " So if in that tree display somebody clicks on something,\n",
       " Yeah,,\n",
       " and then you sort of feed the time stamp to and the NITE X_M_L_ central manager, and that central manager alerts everything that's there,\n",
       " , like alerts the skim like the the audio display, alerts the text display, alerts the visual display and says we have a new time frame,\n",
       " and then they all sort of do their update routines with respect to the current level of zoom.,\n",
       " So how much do they display, and starting position at where the or maybe the mid-position of it, I don't know, like w if start where the thing was found or if that thing wa was found it's in the middle of the part that we display, that I don't know.,\n",
       " But that we can decide about, but a general sort of It's the same thing if like whether you play and it moves forward or whether you jump to a position through search, it's essentially for all the window handling,\n",
       " , it's the same event.,\n",
       " It's only that the event gets triggered by the search routine which sort of push that into NITE X_M_L_ and says please go there now.,\n",
       " Why do we have to do it in memory?,\n",
       " But that stuff's,\n",
       " so I mean like the information is coming from off-line.,\n",
       " So we probably we don't even have to change the utterance document, right, because the whole way, like the whole beauty of the NITE X_M_L_ is that it ties together lots of different files.,\n",
       " So we can just create an additional X_M_L_ file which for every utterance like the utterances have I_D_s,\n",
       " I presume, some references.,\n",
       " So we just we tie uh p just a very short X_M_L_ file, which it's the only information it has,\n",
       " that has whatever a number for for the um weight, for the information density, and we just tie that to the existing utterances and tie them to the existing speaker changes.,\n",
       " Well otherwise we probably have to go over it and like add some integer that we just increment from top to bottom sort of to every utterance as an as an I_D_ some type.,\n",
       " Or un or try to understand how NITE X_M_L_ I_D_s work,\n",
       " and maybe there's some special route we have to follow when we use these I_D_s.,\n",
       " It's alm hmm?,\n",
       " Yeah, the the girl said the utterances themselves are not numbered at the moment.,\n",
       " Okay.,\n",
       " Okay.,\n",
       " Okay.,\n",
       " Yeah.,\n",
       " So I guess that would be solvable if not.,\n",
       " Mm-hmm.,\n",
       " Sorry?,\n",
       " Okay.,\n",
       " Okay.,\n",
       " Is that a board marker pen actually?,\n",
       " Oh.,\n",
       " That's just so like to make a list of all this stuff, or we probably can somebody can do it on paper.,\n",
       " All these fancy pens.,\n",
       " So what so the stuff we have we have utterances and speakers and weights for utterances.,\n",
       " So for for every utterance sort of like the utterance has a speaker and a weight which is coming from outside.,\n",
       " Or we just tie it to it.,\n",
       " And there is segments, which hmm?,\n",
       " Oh, so sorry um.,\n",
       " Uh topic s topic segments I meant.,\n",
       " Like they are they are a super-unit.,\n",
       " So so the utterances are tied to topic segments.,\n",
       " And if the time stamps are on a word level, then we b somehow have to extract time stamps for utterances where they start.,\n",
       " W what segments now?,\n",
       " Okay.,\n",
       " Is the uh is that the same as utterances that is that the same as utterances that Mm-hmm.,\n",
       " Mm-hmm.,\n",
       " What so that's Oh.,\n",
       " But that's one o one segment or is that two segments then?,\n",
       " Yeah.,\n",
       " Okay.,\n",
       " Okay.,\n",
       " So,\n",
       " but but generally utterances is that which we just called uh sorry, segments is that which we just called utterances now.,\n",
       " Like it's it's the sa,\n",
       " it's sort of like one person's contribution at a time sort of thingy dingy.,\n",
       " Okay, so yeah, so we have those, and and then we have some f field somewhere else which has topics.,\n",
       " Yeah,,\n",
       " and and a topic's basically they are just on the I_D_, probably with a start time or something, and and the utterances referenced to those topics I guess.,\n",
       " So the topics don't contain any redundant thing of like showing the whole topic again, but they just sort of say a number and where they start and where they finish.,\n",
       " And the utterances then say which topic they belong to.,\n",
       " Yeah.,\n",
       " No.,\n",
       " But I was thinking of the topic segmentation now and and f for that there would only be one, right, because it's sort of like it's just a time window.,\n",
       " Yeah.,\n",
       " So if this lazy loading works, then this should definitely fit into I mean not memory then because it wouldn't all be in memory at the same time.,\n",
       " So if we just have those sort of that information like a long list of all the utterances slash segments and like short or smaller lists which give weight to them.,\n",
       " And even though probably if there's a lot of over-head in having two different files, we can probably merge the weights into it off-line.,\n",
       " You know what I mean, like if if there's a lot of bureaucracy involved with having two different trees and whether one ties to the other because the one has the weight for the other, then it's probably quicker to,\n",
       " just Yeah, I thought that was the whole beauty that like you can just make a new X_M_L_ file and sort of tie that to the other,\n",
       " and,\n",
       " and it,\n",
       " tre,\n",
       " Oh yeah.,\n",
       " So no, I didn't I didn't mean tree.,\n",
       " No.,\n",
       " No.,\n",
       " I meant just like handling two different files internally.,\n",
       " Sort of c I was just thinking you know like if if the overhead for having the same amount of data coming from two d files instead of from one file is massive then it would probably be for us easy to just like off-line put the the weight into into the file that has the segments, uh yeah, segments slash utterances already.,\n",
       " But that we can figure out I mean if it's going horrendously wrong.,\n",
       " Yeah.,\n",
       " Yeah.,\n",
       " Yeah,,\n",
       " no, we'd we'd be completely using like the whole infrastructure and,\n",
       " basically just I mean the main difference really between our project and theirs really is that we load a different part of the data.,\n",
       " But otherwise we're doing it the same way that they are doing it.,\n",
       " So we just we're sort of running different types of queries on it.,\n",
       " We in a sense we,\n",
       " I think we are running queries, it's not just about um what we load and what we don't load, but we're l running queries in the sense that we dynamically select by by weights,\n",
       " , don't we?,\n",
       " That we have to check how fast that is, like to say give us all the ones that whether that works with their query language, whether that's too many results and whether we shou,\n",
       " You know, if 'cause,\n",
       " if it i let's say I mean if if their query language is strange and if it would return b ten million results and it can't handle it, then we can just write our individual components in the way that they know which what the threshold is.,\n",
       " So they still get all the data and just they internally say oh no, this is less than three,\n",
       " and I'm not gonna display it or something.,\n",
       " Hmm?,\n",
       " Yeah.,\n",
       " No.,\n",
       " I'm just thinking for this whole thing of like a different level, sort of cutting out different different pieces, whether we do that through a query where we say give us everything that's ab above this,\n",
       " and this weight, or whether we skip the same infrastructure, but every individual module like the player and the display say like they still get sort of all the different utterances, uh all the different pieces, but,\n",
       " they say oh, this piece I leave out, because it's below the current threshold level.,\n",
       " When do we need the one for the meet,\n",
       " Okay.,\n",
       " Yeah, I guess for the so when we have the display, will we display the whole series.,\n",
       " Then if we have for the individual topic segments within the meetings if we have ready calculated disp um measures, then we don't have to sort of extract that data from the individual utterances.,\n",
       " Yeah, and that's also fairly easy to store along with our segments, isn't it.,\n",
       " For the segments, are we extracting some type of title for them that we craft with some fancy algorithm or manually or we're just taking the single most highly valued key-word utterance for the segment heading?,\n",
       " Hmm.,\n",
       " Hmm.,\n",
       " It's probably like in in the end,\n",
       " probably it wouldn't be the best thing if it's just the high most highly ranked phrase or key-word because like for example for an introduction that would most definitely not be anything that has any title anywhere similar to introduction or something.,\n",
       " Yeah.,\n",
       " Also like for this part, maybe if we go over it with named entity in the end, if I mean w if one of the people doing DIL has some named entity code to spare, and just like at least for the for sort of for finding topics, titles for for segments, just take a named entity which has a really high, what's it called,,\n",
       " D_F_I_D_F_, whatever.,\n",
       " 'Cause you'd probably be quite likely if they're talking about a conference or a person, that that would be a named entity which is very highly fr um frequented in that part.,\n",
       " Yeah, he said they're quite sparse.,\n",
       " So that basically was don't bother basing too much of your general calculation on it.,\n",
       " But like especially if they're sparse, probably individual named entities which describe what a what a segment is about would probably be quite good.,\n",
       " Like if there's some name of some conference, they would could probably say that name of the conference quite often, even though he's right that they make indirect references to it.,\n",
       " Anyway,\n",
       " Sorry?,\n",
       " So you're doing that on a on a per word level.,\n",
       " Okay.,\n",
       " Okay.,\n",
       " Okay, cool.,\n",
       " I was just wondering where you had the corpus from at the moment.,\n",
       " So it it seems that the data structure isn't a big problem and that basically we don't have to have all these massive discussions of how we exactly interact with the data structure because most of our work isn't done with that data structure in memory in the browser, but it's just done off-line and everyone can ha represent it anyway,\n",
       " they want as long as they sort of store it in a useful X_M_L_ representation in the end.,\n",
       " So like Yeah, that would mean understanding the NITE,\n",
       " X_M_L,\n",
       " _ X_M_L_ sort of format in a lot more detail.,\n",
       " We should I think we should just have a long session in the computer room together and like now that we know a bit more what we want, take a closer look at NITE X_M_L_.,\n",
       " Mm-hmm.,\n",
       " Mm-hmm.,\n",
       " Good.,\n",
       " Yeah, I haven't looked at this stuff much at all.,\n",
       " Yeah.,\n",
       " Yeah.,\n",
       " Who's who's sort of doing the the the central coordination of of of the browser application now?,\n",
       " Like Hmm?,\n",
       " Yeah, or but also like all these elements like like the loading and, yeah, integration and and like handling the data loading and stuff.,\n",
       " Nah.,\n",
       " I'm sort of like,\n",
       " I think I'll take over the display, just because I've started with a bit and found it found it doable.,\n",
       " So somebody should sort of be the one person who's who understands most about what's t centrally going on with with the with the project, like with the with the browser as a whole and where the data comes in and Any volunteers?,\n",
       " It's also a complicated one.,\n",
       " Yeah.,\n",
       " I know,\n",
       " but uh b I guess we can do it like several people together,\n",
       " , it's probably just those people have to work together a lot and very closely and just make sure that they're always f,\n",
       " understand what the other one is doing.,\n",
       " Yeah, or or ready-made versions of them for that matter,\n",
       " and,\n",
       " Yeah,,\n",
       " but I think actually like at the moment the integration comes first,\n",
       " , I mean it's sort of at the moment,\n",
       " the building the browser comes first, and then only comes the creating new sophisticated data chunks, because that's sort of the whole thing about having a prototype system which is more or less working on on chunk data.,\n",
       " But it at least we have the framework in which we can then test everything and and look at everything.,\n",
       " 'Cause before we have that, it's gonna be very difficult for anyone to really see how much the work that they're doing is making sense because you just well I guess you can see something from the data that you have in your individual,\n",
       " X_M_L_ s files files that you create, but it would be nice to have some basic system which just displays some stuff.,\n",
       " Or just adapt like their like just sort of go from their system and and adapt that piece for piece and see how we could how we could arran like adapt it to our system.,\n",
       " Does anyone want to like just sit with me and like play for three hours with NITE X_M_L_ at some point?,\n",
       " Uh I wouldn't like to be 'cause I'd like to go to the gym.,\n",
       " I'm theoretically free.,\n",
       " But if there's any time t hmm?,\n",
       " You have nothing no free time on Wednesday.,\n",
       " Hmm.,\n",
       " Nine ',\n",
       " til twelve and then nothi you have or you Hmm?,\n",
       " Anytime Wednesday afternoon I'd be cool, I think.,\n",
       " Yo, Forrest Hill, whatever one's easier to discuss stuff, I don't know.,\n",
       " I'm not biased.,\n",
       " Okay.,\n",
       " What time do you wanna do?,\n",
       " Okay, so I'll just meet you in in eighteen a in the afternoon.,\n",
       " I guess at the moment nobody critically depends on like the NITE X_M_L_ stuff working right now, right?,\n",
       " Like at the moment you can all do your stuff,\n",
       " and I can do my L_S_A_ stuff.,\n",
       " And I can even do the display to a vast degree without actually having their supplying framework working.,\n",
       " So it's not that crucial.,\n",
       " Yeah, actually I need the raw text as well.,\n",
       " Yeah,,\n",
       " but I was,\n",
       " I was,\n",
       " I was more thinking of the sort of the the whole browser framework as a running programme now.,\n",
       " Yeah, I think we all need the raw text in different in different flavours, don't we?,\n",
       " But number within the X_M_L_ context.,\n",
       " Are they spoken numbers?,\n",
       " Like do they look like they're utterances numbers?,\n",
       " There's the number task, isn't there.,\n",
       " That's part of the whole thing.,\n",
       " Hmm?,\n",
       " Okay.,\n",
       " Hmm.,\n",
       " Yeah, we have to probably cut that out anyway for our project, I don't know.,\n",
       " It's probably gonna screw up a lot of our data otherwise.,\n",
       " If Not sure if it what it does to document,\n",
       " It would probably make the yeah,,\n",
       " if if you have segments for that, probably the Okay.,\n",
       " Uh I'm just thinking like it pro,\n",
       " it pro probably like the L_S_A_ would perform quite well on it.,\n",
       " It would probably find another number task quite easily seeing that it's a constrained vocabulary with a high co-occurrence of the same nine words.,\n",
       " So that wou ten word.,\n",
       " Hmm?,\n",
       " Yeah.,\n",
       " I think it's also something that they they said the numbers in order, right?,\n",
       " Yeah, I think it's it,\n",
       " the,\n",
       " it sounded like they wanted to check out how well they were doing with overlapping and stuff,,\n",
       " because basically it's like they're reading them at different speeds, but you know in which order they are said.,\n",
       " Anyway.,\n",
       " ICSI has some reasons for doing it.,\n",
       " They must have been pissed off saying like numbers at the end of every meeting.,\n",
       " Um Dave, if you would or actually for well, if you're doing I_D_F_s or you whatever you call your your frequencies, I always mix up the name, uh you need some dictionary for that at some point though, like you need to have some representation of a word as not not that specific occurrence of that word token, but of of of a given word form.,\n",
       " Because you're making counts for word forms, right?,\n",
       " Yeah, so we should work together on that, because I need a dictionary as well.,\n",
       " Okay. ',\n",
       " Kay.,\n",
       " Okay.,\n",
       " Didn't you say that the o,\n",
       " the ord,\n",
       " Yeah,,\n",
       " but for I'm just wondering for the whole thing.,\n",
       " Does somebody wo who was it of you two who said that um there's some programme which spits out a dictionary probably with frequencies?,\n",
       " Okay.,\n",
       " Is anyone of you for the for the document frequency over total frequency, you gonna have total frequencies of words then with that, right?,\n",
       " Like over the whole corpus sort of.,\n",
       " Or W using which tool are you talking about?,\n",
       " Be careful with that.,\n",
       " Like my experience with the British National Corpus was that there's far more word types than you ever think because anything that's sort of unusual generally is a new word type.,\n",
       " Like any typo or any strange thing where they put two words together.,\n",
       " And also any number as a word type of its own.,\n",
       " So you can easily end up with hundred thousands of words when you didn't expect them.,\n",
       " So generally dictionaries can grow bigger,\n",
       " then you think they do.,\n",
       " Well you can probably also you can probably pre-filter like with regular expressions even just say if it consists of only dig digits, then skip it, or even if it consists any special characters, then skip it because it's probably something with a dot in between, which is usually not something you wanna have,\n",
       " and What I did, for my project I just ignored the hundred most frequent words, because they actually end up all being articles and and everything and stuff.,\n",
       " So we need like several of us need a dictionary.,\n",
       " Am I the only one who needs it with frequencies?,\n",
       " Am I the only one who needs it with frequencies?,\n",
       " Or Frequencies.,\n",
       " Yeah.,\n",
       " Well I guess as soon as we have the raw text, we can probably just start with the Java hash map and,\n",
       " like just hash map over it and see how far we get.,\n",
       " I mean we can probably on a machine with a few hundred megabyte RAM,\n",
       " you can go quite far.,\n",
       " You can write it on beefy.,\n",
       " So even if it goes wrong and even if it has a million words be,\n",
       " Oh yeah,\n",
       " , burning it on a like we should be able to burn the whole corpus, just the X_ hmm?,\n",
       " Ah I see,\n",
       " , I asked support about that two days ago.,\n",
       " In the Informatics building there,\n",
       " oh sorry, in in Appleton Tower five the ones closest t two machines closest to the support office.,\n",
       " So I presume,\n",
       " oh wait, I have the exact email.,\n",
       " I think he's talking about sort of the ones that Yeah, if you if you enter the big room, in the right-hand corner, I think.,\n",
       " Um the thing is like you can only burn from the local file-system.,\n",
       " So if it's from s,\n",
       " well actually I think if it's mounted, you can directly burn from there, but the problem is I have my data on beefy,\n",
       " and so I have to get it into the local temp directory and burn it from there.,\n",
       " But you can burn it from there.,\n",
       " Uh we looked that up and I for we looked that up,\n",
       " and I forgot.,\n",
       " Yeah,\n",
       " yeah.,\n",
       " No, you you we should be able to get it at,\n",
       " I don't think it was,\n",
       " I don't think it was a gigabyte.,\n",
       " Hmm.,\n",
       " See I would off,\n",
       " I would offer you to to get it on this one, and then um like copy it.,\n",
       " But you know what I figured out, I'm quicker down-loading over broad-band into my computer than using this hard disk.,\n",
       " There's something strange about the way how they access the hard disk, how they mount it, which is unfortunate.,\n",
       " Hmm.,\n",
       " What operating system do you have?,\n",
       " Okay.,\n",
       " Wh what connection do you have at home?,\n",
       " Yeah.,\n",
       " So if anyone of us gets it, we can then just use an ext hmm?,\n",
       " Yeah, burn it to C_D_ or,,\n",
       " yeah, put it on on hard disk, whatever.,\n",
       " Question is if you're not quicker if you uh because you should get massive compression out of that.,\n",
       " Like fifty percent or something with a good algorithm.,\n",
       " So if you could compress it and just put it into a temp directory.,\n",
       " Like The temp the temps usually have for gigabyte three or two.,\n",
       " The temps,,\n",
       " yeah.,\n",
       " I do like,\n",
       " I mean there's not guarantee that anything stays there,,\n",
       " but overnight it'll stay.,\n",
       " And I think the temps usually have.,\n",
       " Ah yeah,,\n",
       " but that would have to be the temp directory off the machine you can S_S_H_ into directory of S_S_H_.,\n",
       " Yeah, they wou they'd,\n",
       " they'd probably hate you for doing it.,\n",
       " But They'd probably they'd like you more if you,\n",
       " S_S_H,\n",
       " _ uh into another computer, compress it there and then sort of copy it into the into the gateway machine.,\n",
       " They have um if you S_S_,\n",
       " hey, you know, if you if you S_S_H_ and,\n",
       " they have this big warning about doing nothing at all in the gateway machine.,\n",
       " Yeah.,\n",
       " To your home machine.,\n",
       " I haven't I haven't figured out how to tunnel through the gateway into another machine yet.,\n",
       " It's not,\n",
       " it's not easy definitely.,\n",
       " That's why I end up sort of copying stuff into the temp directory at the gateway machine.,\n",
       " Sorry if this is boring everybody else.,\n",
       " This is just details and how to get stuff home from what we can probably just look at that together when we're meeting.,\n",
       " I'm sorry.,\n",
       " Mm-hmm.,\n",
       " Well yeah.,\n",
       " As soon as somebody gives me the raw text of the whole thing, I can probably just implement like a five line Java hash table frequency dictionary builder and see,\n",
       " Oh, did you not say frequencies f of words in the whole sorry,\n",
       " , did uh,\n",
       " So you'd you,\n",
       " Yeah, you'd have to count it yourself,,\n",
       " yeah.,\n",
       " Oh, you don't wanna have different counts for each chunk, but,\n",
       " just like sort of for for something from old chunks.,\n",
       " Oh yeah, no,\n",
       " , that's yeah,,\n",
       " so once I write an ar like w if I write like an algorithm which does a hash um table dictionary with frequency from a raw text, then the raw text can be anything.,\n",
       " So how far are we,\n",
       " g,\n",
       " uh how f how far are you getting raw text out of it,\n",
       " do you think?,\n",
       " Okay, well that's good, because for the dictionary the order doesn't make a difference, does it?,\n",
       " So yeah,,\n",
       " so um I'll get that from you,\n",
       " and I'll write the hash table which goes over that and creates a dictionary file.,\n",
       " So for the dictionary, is it okay if I do, whatever, word blank frequency or something?,\n",
       " Just p could everybody sort of start from that?,\n",
       " I mean I guess we can,\n",
       " Yeah, I I need frequency as well.,\n",
       " Well I think we might have a lot in common what we calculate because I for my latent semantic analysis need like counts of words within a document, uh within a a segment actually, within a topic segment.,\n",
       " Can I convert these probabilities back into frequencies?,\n",
       " Okay.,\n",
       " Oh, so that's what f Rainbow does, because that's what L_S_A_ builds on.,\n",
       " Like it builds a f a document by frequency matrix.,\n",
       " So I could probably get that.,\n",
       " Even though but I already have I already have my code to build it up myself.,\n",
       " No, don't bother.,\n",
       " I have my code already.,\n",
       " Um,\n",
       " Yeah, so Dave, you said you need the frequency counts actually for per document, would you say, not for the whole thing?,\n",
       " It more and more appears to me that if we if we scrap the notion of the meeting as an individual thing and sort of ju see meetings as as topic segments and have sort of like hierarchical topic segmentation instead, then it's b like a more coherent framework.,\n",
       " Wait, are we are we using this um for the for the for the do for the weighting in the end now, this this measure you're calculating?,\n",
       " Because if we're doing Like I think for for the information density we uh we should calculate it on the lowest level, not on the highest.,\n",
       " But like 'cause,\n",
       " Yeah,,\n",
       " but w it don't you have to like go sort of like for in a document versus the whole thing?,\n",
       " Isn't that how it works that you c look look at r,\n",
       " I don't think that's a good idea because isn't it like that we expect th there to change over i b with the different topic segments more?,\n",
       " That they talk about something different in each different topic segment.,\n",
       " 'Cause that's what relative term frequency is about, that like in some context they're talking more about a certain word than in general.,\n",
       " So that would more be the the topic segments then.,\n",
       " I don't know.,\n",
       " Yeah.,\n",
       " Yeah.,\n",
       " Yeah.,\n",
       " So I'm just wondering if there's ways to abandon the whole concept of of meetings and sort of but just not really treating separate meetings as too much of a separate entity.,\n",
       " But But on algorithmic level, whether we actually whether there's some way to just represent meetings as as topics.,\n",
       " Hmm.,\n",
       " That's not really what I meant.,\n",
       " But I think I have to think more about what I meant.,\n",
       " Um g I'm confused about everything.,\n",
       " Yeah.,\n",
       " I'm,\n",
       " I'm not so concerned about the m a meeting plus something else, I'm more talking about like,,\n",
       " yeah, the keeping keeping the same algorithm and the same way of handling it and just saying like just this this topic here,\n",
       " i,\n",
       " uh it happens to be like a whole meeting and it has sort of sub-topics, so,\n",
       " just that sort of topics a hierarchical concept where like a topic where there can be super-topics and topics, and,\n",
       " the super-topics are in the end what the meetings are, but in general at some level super-topics are treated like like topics.,\n",
       " Hmm.,\n",
       " Mm,\n",
       " I'm not really sure what I want.,\n",
       " So sorry, could describe that again, the Mm-hmm.,\n",
       " Mm-hmm.,\n",
       " Mm-hmm.,\n",
       " So that would be the series as a whole.,\n",
       " That would be sort of m meetings,,\n",
       " yeah.,\n",
       " Yeah.,\n",
       " I'm a,\n",
       " I'm a,\n",
       " I'm a bit brain-damaged at the moment, but,\n",
       " I think I'll just sit together with you again and and go through it again.,\n",
       " Hmm.,\n",
       " So so I'll is th it like,\n",
       " is this and this structurally then always identical?,\n",
       " So that we can that we can treat it with the same algorithm or,\n",
       " Yeah, I'm also not sure how we can go from from bottom-up.,\n",
       " I have always thought it's like more that oh, whatever, I'm a can't think of it at the moment.,\n",
       " Probably this is all too complicated worrying about that at that moment anyway.,\n",
       " Now have have we have we decided anything, are we doing anything?,\n",
       " S Wednesday we are meeting and looking at their at their implementation in some more detail to actually understand what's going on.,\n",
       " We had two things from their stuff just to make sure that we are like understand it, we understand it enough to to m modify it.,\n",
       " Yep.,\n",
       " How would we do that?,\n",
       " By just making like it w read write for everyone. ',\n",
       " Kay, who has most free space on their Same here.,\n",
       " Well we alternatively we can probably just make another directory on the beefy scratch space.,\n",
       " I mean that's where I'm having gigabytes and gigabytes of stuff at the moment.,\n",
       " No.,\n",
       " No.,\n",
       " Yeah.,\n",
       " But I think if he sends to the I think if he sends to the port he'd probably be in a better position.,\n",
       " Yeah.,\n",
       " Hmm.,\n",
       " I think he said yes to that.,\n",
       " I think uh that was like in,\n",
       " when we were still in the seminar room, I asked that once or like ask is it possible to get it off and,\n",
       " nobody said like people were discussing about the technical practicalities, but nobody said anything about al being allowed to or not allowed to.,\n",
       " I mean, we have access to it here,\n",
       " and I guess it probably means that we we can't give it to anybody else.,\n",
       " But but if they give us access to it here o sitting on a DICE machine, then there shouldn't be a reason why we shouldn't be able to use it on our laptop.,\n",
       " I personally don't have too many friends who would be too keen on getting it anyway.,\n",
       " I have that really excited pirate copied thing.,\n",
       " It annotated meeting data.,\n",
       " Huh.,\n",
       " Wait, wait, wait.,\n",
       " Um sorry.,\n",
       " Yeah, sorry.,\n",
       " What I just realised, we should really t keep different serieses completely separate for virtually all purposes.,\n",
       " Just let's be careful about that,,\n",
       " because like the the ICSI corpus isn't isn't one meeting series, it's several meeting series with different people meeting for completely different things.,\n",
       " For each meeting.,\n",
       " Alright.,\n",
       " Okay, but like let's just be careful that whatever we sort of we merge together,\n",
       " , that like the highest level of merging, it's not the whole ICSI corpus but individual series..,\n",
       " I think we might,\n",
       " actually I think That's probably be somewhere like well,\n",
       " or something like it.,\n",
       " Um I think we might just get away with for the whole project just like looking at only one series and just doing within one series.,\n",
       " I mean you can do everything you want in one series.,\n",
       " Oh yeah, let's take that.,\n",
       " Is the is the data always clearly split up by different series?,\n",
       " Uh like is it easy to just pick one,\n",
       " Okay.,\n",
       " Okay.,\n",
       " Okay.,\n",
       " Okay.,\n",
       " So at at every level everyone has to be careful to really just take even at the highest level, just take stuff from one series and not merge stuff from different series together because they would probably be just majorly messy.,\n",
       " Yeah,,\n",
       " so so t,\n",
       " so like if even if we make one single text file which has the whole corpus, sort of our corpus, that would still be from one series only.,\n",
       " Wou but it what you're producing at the moment is like individual text files that sort of have the raw text for a whole a meeting as a whole or Mm-hmm.,\n",
       " Yeah. ',\n",
       " Kay.,\n",
       " Um so is is anybody creating an uh a real raw text thing at the moment, like which is just the words?,\n",
       " Yeah, tha,\n",
       " 'cause that's what I'm gonna need as well.,\n",
       " But i but if there uh b aren't like,\n",
       " so it's,\n",
       " it's start and end times just for the file.,\n",
       " Like is it just the first and the last line?,\n",
       " Or is it for every single thing in,\n",
       " So what do you mean by just not print out that?,\n",
       " Okay.,\n",
       " If you're into it, can you make a text file which just like makes just the words? ',\n",
       " Kay.,\n",
       " Do you want it straight flowing, 'cause I would need something that marks the end of uh of uh,\n",
       " is is yours segmented by topics,\n",
       " then that like is there any information that you have to the topic, to the automated topic topic segmentation?,\n",
       " Oh then I need something different later anyway.,\n",
       " Okay, but for now, if you c,\n",
       " Okay.,\n",
       " You're gonna put that as an output of yours, the segmentation.,\n",
       " Okay, so for now can you create like sort of just uh a dump which is pure text, just pure text so that I can get a dictionary,\n",
       " and you can work on that for your topic segmentation.,\n",
       " And Or for for the series.,\n",
       " But I can,\n",
       " but I can also deal with separate files,,\n",
       " I mean I can just write the algorithm that it loads all files in a directory or something.,\n",
       " But I mean if you,\n",
       " But if you can put it in one single mega-file, that would be quite useful for me.,\n",
       " Even though for you, wouldn't it be easier if you had different files because then you sort of know like,\n",
       " Yeah.,\n",
       " So give m give me different files as long as,\n",
       " like it m if you could name them in a way that is easy to enumerate over them, like whatever,,\n",
       " one two three four five or something.,\n",
       " Or just anything that I can,\n",
       " Yeah.,\n",
       " Is is it something that's easily enu like to enumerate over?,\n",
       " Is it some just some ordered pattern?,\n",
       " Okay, cool.,\n",
       " Okay, cool.,\n",
       " Yeah.,\n",
       " In the right order.,\n",
       " It's just a wish list.,\n",
       " Orders.,\n",
       " When do you think you'll have um like a primitive segmentation by some ready-made topic segmentation by some ready-made tool ready?,\n",
       " Okay.,\n",
       " Okay, cool.,\n",
       " 'Cause I'll need that then when it's done.,\n",
       " Okay.,\n",
       " Mm-hmm.,\n",
       " What's what's nine megabyte?,\n",
       " The the That sounds quite reasonable.,\n",
       " That's nine nine characters over,\n",
       " okay.,\n",
       " Okay.,\n",
       " Okay.,\n",
       " That is for are we are we picking one particular series at the moment?,\n",
       " Or Yes.,\n",
       " Okay.,\n",
       " Yeah.,\n",
       " Yeah, I guess we can probably process the data for all different series and then check which series is the best for the presentation.,\n",
       " It sounds quite reasonable, nine megabyte.,\n",
       " I mean if you think if it's r roughly a million words and nine characters per word sounds realisti,\n",
       " Yeah.,\n",
       " Yes, I'm gonna build a dictionary then from that.,\n",
       " Like just a list of the words that maybe a list of the words with the frequencies or a list of the words sorted alphabetically or numerically.,\n",
       " What what does anyone want?,\n",
       " Does this there any wishes for dictionaries?,\n",
       " So I'll create a dictionary.,\n",
       " Add add the structure,,\n",
       " yeah.,\n",
       " And then the actual file we can probably like copy from your home directory or something like it.,\n",
       " Yeah,\n",
       " yeah,,\n",
       " but I'm sa,\n",
       " I'm saying for the whole thing in the end.,\n",
       " Then like the big thing we probably shouldn't do by email.,\n",
       " Yeah.,\n",
       " Oh, from the time I get the file I can do that in an afternoon, the next sort of the next morning.,\n",
       " Oh, you mean how long processing time it takes.,\n",
       " Ah, it's a,\n",
       " it's a bog standard algorithm.,\n",
       " I've,\n",
       " I've sort of I've written it for for DIL just in half an hour or something similar.,\n",
       " It's just you put them in a hash table and and,\n",
       " say well if it exists already in the hash table then you increase the count by one,\n",
       " and I'll probably implement some filter for filtering out numbers or something.,\n",
       " Really?,\n",
       " How do you do that?,\n",
       " Okay, well I don't know any Perl.,\n",
       " I mean if anyone wants to do a Perl script for that that does it does it nicely, I uh I've no problem with that.,\n",
       " I,\n",
       " but I think I have the Java code virtually ready because for DIL I wrote something very similar.,\n",
       " Like for DIL I wrote something that counts the the different occurrences of all the tags,\n",
       " um Sorry?,\n",
       " The hash table?,\n",
       " Uh I've never serialized anything.,\n",
       " Wouldn't that be absolutely massive though?,\n",
       " And then seriali and then write the serialization to a file.,\n",
       " So you want like a se like a file which is the serialization of a hash table.,\n",
       " Okay.,\n",
       " Yeah.,\n",
       " I,\n",
       " I'll,\n",
       " I'll check if I understand how it works.,\n",
       " I mean otherwise I can give you the code for loading a dictionary.,\n",
       " Give you my my,\n",
       " it's just,\n",
       " it's,\n",
       " it's,\n",
       " sort of it's a line break separated file, you know.,\n",
       " Yeah.,\n",
       " Yeah, I'll see if I understand how to serialize.,\n",
       " There's a there's a serialise command,\n",
       " so that gives me one mega mother of a s,\n",
       " Yeah, but do they automatically write to the file,\n",
       " anyway,\n",
       " I'll,\n",
       " I'll figure that out.,\n",
       " We don't have to,\n",
       " Yes, is that pretty much pretty much it?,\n",
       " So Dave and me look at how NITE X_M_L_ works,\n",
       " and we're Hmm.,\n",
       " I'll build a dictionary as soon as I get the text.,\n",
       " And yeah,,\n",
       " so that When do we have to meet again then with this?,\n",
       " How are we gonna do a demonstrator next week?,\n",
       " My God.,\n",
       " No no, not demonstrate, but like didn't you say that uh didn't we sort of agree that it would be useful to have a demonstrator of it, like some primitive thing working next week.,\n",
       " That's gotta be very prototype.,\n",
       " Mm-hmm.,\n",
       " Ah well, let's go.,\n",
       " Sorry.,\n",
       " I feel like like hanging mid-air and not really like finding a point where you can get your teeth into it and start working properly,\n",
       " and so it's all so fuzzy the whole,\n",
       " Yeah,,\n",
       " but it at the moment but at the moment it's also an implementational level.,\n",
       " Like with the data structures, I'm just like over these vague ideas of some trees, I'm f,\n",
       " Yeah.,\n",
       " It's just we are half-way through the project time table.,\n",
       " That's just what freaks me out.,\n",
       " Um,\n",
       " Yeah.,\n",
       " Yeah,,\n",
       " I mean if we just want to have um some data for the user face, could even be random data.,\n",
       " Uh mm mm,\n",
       " Yeah, I'm Hmm.,\n",
       " Yes.,\n",
       " Hmm yes.,\n",
       " Hmm.,\n",
       " I'm not so sure.,\n",
       " I,\n",
       " I thought we would just have like um one big summary um with all the uh different importance levels um displayed on it.,\n",
       " And depending on what our um zoom level is, we just display a part of it.,\n",
       " And we would have one very big thing off-line.,\n",
       " And from that we would just select what we are displaying.,\n",
       " Yes.,\n",
       " So for example you would um give a high value to those um sequences you want to display in the meeting series summary.,\n",
       " And you just cut off.,\n",
       " That was what I sh,\n",
       " I thought,,\n",
       " yeah.,\n",
       " I thought.,\n",
       " But I think the m difference might be,\n",
       " that we want just want to have um the words.,\n",
       " And that's not so much what he meant with not possibly loading everything was that you m um load all the uh annotation stuff, all the sound files,,\n",
       " all In Um,\n",
       " I r,\n",
       " I,\n",
       " I'm getting quite lost um at the moment because um w what's um our difference between the um se um uh the importance measure and the skimming?,\n",
       " I mean, do we do both or is it the same thing?,\n",
       " Okay.,\n",
       " So but when when we talk about summaries you talk about this uh abo about skimming and not about Yeah.,\n",
       " Yeah right, isn't that the skimming?,\n",
       " Isn't that the skimming?,\n",
       " Yeah,,\n",
       " but it use the same data.,\n",
       " Yeah.,\n",
       " A,\n",
       " And, yeah,,\n",
       " I think we also thought about combining that measure with um the measures I get from um s uh hot-spots and so on.,\n",
       " So that would also be on utterance level, I think.,\n",
       " I think.,\n",
       " Yes, sure.,\n",
       " Yes.,\n",
       " Yes, right.,\n",
       " Oops, it does.,\n",
       " So I define baseline and what it loads?,\n",
       " For example it loads all the utterances and so on, but it doesn't load um the discourse acts and for example not the and what's what else there?,\n",
       " Not the summaries.,\n",
       " It only loads those on demand.,\n",
       " Y you mean that you um basically split up th the big thing into um different summaries.,\n",
       " For example that you have a very um top-level um summary and a separate file for for each level.,\n",
       " Mm-hmm.,\n",
       " Yes.,\n",
       " N,\n",
       " Uh no no, it's f for No,\n",
       " , you're right.,\n",
       " Yeah.,\n",
       " It's for Um,\n",
       " No, I I think we would just take the segments that are already that were,\n",
       " Yeah, there's um this segments file.,\n",
       " Um you know, the X_M_L_ segments.,\n",
       " Oh.,\n",
       " That I don't know.,\n",
       " Yeah, that's um Mm-hmm.,\n",
       " There there are time stamps um for, well, segments um and for th um segments is for example when when you look at the data, what is displayed in one line.,\n",
       " What when when you look at it in the hmm?,\n",
       " I think so.,\n",
       " Isn't Um for ex,\n",
       " um I I compared it with what I did for the pause um duration extraction.,\n",
       " Um and basically it's uh words that are uttered in a sequence without pauses.,\n",
       " But sometimes um however there are um short pauses in it,\n",
       " and they're indicated by square brackets pause or something in the data.,\n",
       " Um someti uh but uh the annotators decided what was one segment and what wasn't.,\n",
       " I think so.,\n",
       " Yeah,,\n",
       " but um I think for some annotations um an uttera ca utterance can have several um types.,\n",
       " For example for the dialogue acts and so on.,\n",
       " Okay.,\n",
       " Yeah, that should be for Yeah.,\n",
       " Should be,,\n",
       " yeah.,\n",
       " Yes,,\n",
       " but that's,\n",
       " Yeah, everything that's a word has a sti time stamp.,\n",
       " That's at the end.,\n",
       " That's at the end, I think, her time.,\n",
       " Yeah, maybe.,\n",
       " Didn't have a look at our meetings.,\n",
       " Uh I I think it wouldn't as it occurs,\n",
       " I mean it would be,\n",
       " it occurs in every meeting.,\n",
       " So,\n",
       " And I think it even has uh its own annotation, like digits or something.,\n",
       " So that should be really easy to cut out.,\n",
       " Yeah.,\n",
       " I'm sure.,\n",
       " Ah it's just to test the system, I think.,\n",
       " So Mm they have to read numbers from,\n",
       " Uh I didn't have a look at that.,\n",
       " So They Mm-hmm.,\n",
       " Uh th yeah. ',\n",
       " Kay.,\n",
       " Um I just um wondered, so who's uh then doing um the frequencies on on the words, because I'm,\n",
       " I think I will also um I could also make use of it um for the agreement and disagreement thing.,\n",
       " Because I um I in my outline,\n",
       " I talked about um using the um discourse acts first, and um then in the chunks of text I found looking for word patterns and so on.,\n",
       " So um I would for example need the um most freq um frequent words.,\n",
       " So if you cut off all that, I'd won't be use,\n",
       " or,\n",
       " Yeah, I I,\n",
       " but I need it for my chunks then.,\n",
       " I would You know?,\n",
       " Yeah,,\n",
       " but I'd uh I would like to look at the frequency of words in my um in the regions of text,\n",
       " I found out to be interesting.,\n",
       " So I wouldn't need it.,\n",
       " It it would have to be re-calculated only for my segments.,\n",
       " Huh?,\n",
       " Uh uh mm.,\n",
       " I think it would be, you know, l as as big at as the hot-spot annotation things.,\n",
       " That's quite small,,\n",
       " yeah, that's some utterances.,\n",
       " Yes.,\n",
       " Yeah,,\n",
       " yeah.,\n",
       " So I would probably just concatenate all my um text chunks and then let's say m I will run over it.,\n",
       " Yes.,\n",
       " Yes, definitely.,\n",
       " Yeah, right.,\n",
       " Ye M Um Jasmine, uh um what is um the text you're extracting uh,\n",
       " looking like then at the end?,\n",
       " Because um I I think it's actually very similar to what I did for my um speaker um uh extraction,\n",
       " and I think I would ch perhaps have to change two lines of codes to get you um for each meeting a file that says fr from um this millisecond to this millisecond there was this sequence of words.,\n",
       " And so on.,\n",
       " So that's just changing two lines of code.,\n",
       " And it would give you that.,\n",
       " So Um yeah.,\n",
       " So far I extracted um the dura durations.,\n",
       " But it's from the words file.,\n",
       " So I could just um contatenate concatenate um the words instead of the durations, and,\n",
       " it should I mean Should be very straight-forward.,\n",
       " I can try to do it and send it to you.,\n",
       " Pe and you have a look at it, will it make sense for what you want.,\n",
       " Yeah, uh p,\n",
       " I mean it,\n",
       " I just let it run over all the files.,\n",
       " So Yes.,\n",
       " I just ordered.,\n",
       " ...]"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdQAyAkranVn"
   },
   "outputs": [],
   "source": [
    "sentence_scores = {}\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_freq.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_freq[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_freq[word.text.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyfKaZCFanVn",
    "outputId": "1269f145-e658-4906-f55d-a57e40c5cb8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Is there much more in it than he d: 0.08125, Is there much more in it than he said yesterday?: 0.140625, Yeah, now I'd say if for the prototype if we just like wherever possible p chunk in the stuff that we have um pre-annotated and stuff, and for the stuff that we don't have pre-annotated write like a stupid baseline, then we should probably be able to basically that means we focus on on the interface first sort of, so that we we take the the ready-made parts and just see how we get them work together in the interface the way we want: 2.6531250000000006, and then we have a working prototype.: 0.0625, And then we can go back and replace pieces either by our own components or by more sophisticated compo po components of our own.: 0.16875, So it's probably feasible.: 1.240625, The thing is I'm away this weekend.: 0.35000000000000003, So that's for me: 1.0, Oh yeah,: 0.01875, But also I might like the the similarity thing, like my just my matrix itself for my stuff: 0.44062499999999993, , I c: 0.028125, I think I can do that fairly quickly because I have the algorithms.: 0.3625, Yeah, I think today's meeting is really the one where we where we sort of settle down the data structure and as soon as we have that, uh probably like after today's meeting, we then actually need to well go back first of all and look at NITE X_M_L_ to see in how far that that which we want is compatible with that which NITE X_M_L_ offers us.: 4.571875, And then just sort of everyone make sure everyone understand the interface.: 0.5499999999999999, So I think if today we decide on what data we wanna have now,: 0.5375, and and later, maybe even today, we go and look at NITE X_M_L_ or some of us look at NITE X_M_L_ in a bit more detail, just trying to make some sense of that code and see how does the representation work in their system.: 0.9125000000000002, And then sort of with that knowledge we should be able to then say okay, that type of NITE X_M_L_ data we wanna load into it, and this is how everyone can access it, and then we should be able to go from there.: 0.85625, I've looked looked at the documentation and n like seen enough to make me think that we want to use the NITE X_M_L_ framework because um they have a good a event model that synchronizes sort of the data: 1.3093750000000002, and and every display element.: 0.15625, So that takes a lot of work away from us.: 0.17812499999999998, Sort of that would be a reason for staying within their framework and using their general classes.: 0.7375, But beyond that I haven't looked at it at all, which is something we should really do.: 0.7781250000000001, Who actually like for this whole discussion I mean, who of us is doing stuff that is happening on-line and who of us is doing stuff that's happening off-line?: 2.109375, Like my data is coming c Hmm?: 0.18750000000000003, So basically apart from the display module, the i the display itself, we don't have an extremely high degree of interaction between sort of our modules that create the stuff: 1.2062500000000003, and and the interface, so the interface is mainly while it's running just working on data that's just loaded from a file, I guess.: 2.4656249999999997, There isn't Yeah, I know.: 0.64375, Th: 0.046875, Yeah, the search is: 0.040625, I guess the search is sort of a strange beast anyway because for the search we're leaving the NITE X_M_L_ framework.: 0.6937500000000001, Um but that's still sort of that's good.: 2.365625, That means that at least like we don't have the type of situation where somebody has to do like a billion calculations on on data on-line.: 0.821875, 'Cause that would make it a lot more like that: 0.49374999999999997, would mean that our interface for the data would have to be a lot more careful about how it performs and and everything.: 1.1343750000000001, And nobody is modifying that data at at on-line time at all it seems.: 0.40625000000000006, Nobody's making any changes to the actual data on-line.: 1.3062500000000001, So that's actually making it a lot easier.: 1.1750000000000003, That basically means our browser really is a viewer mostly, which isn't doing much with the data except for sort of selecting a piece piece of it and and displaying it.: 1.2812500000000002, Well some parts relevant for the search, yes.: 0.0625, I'd say so.: 0.253125, Yeah, but nobody of us is doing much of searching from the data in the on-line stage.: 0.39375, And for all together, like the display itself, I think we are easier if we if it's sitting on the X_M_L_ than if it's sitting on the S_Q_L_ stuff, because if it's sitting on the X_M_L_, we have the the NITE X_M_L_ framework with all its functionality for synchronizing through all the different levels whenever there's a change, whenever something's moving forward and stuff.: 6.284375, And we can just more or less look at their code, like how their player moves forward, and how that moving forward is represented in different windows and stuff.: 0.503125, So I think in the actual browser itself: 0.384375, I don't wanna sit on the S_Q_L_ if we can sit on the X_M_L_ because sitting on the X_M_L_ we have all we have so much help.: 0.6218750000000002, And for y for like the p the calculations that we're doing apart from the search, it seems that everyone needs some special representations anyway.: 0.384375, You mean our results?: 0.259375, Yeah, in in the NITE X_M_L_ X_M_L_ format, so with their time stamps and stuff, so that it's easy to to tie together st things.: 1.521875, What I'm like what we have to think about is if we go with this multi-level idea, like this idea that sort of if you start with a whole meeting series as one entity, as one thing that you display, as one whole sort of, that then the individual chunks of the individual meetings, whereas and then you can click on a meeting, and then sort of the meeting is the whole thing and the chunks are the individual segments, that means sort of we have multiple levels of of representation, which we probably If we if we do it this way like we f we have to discuss that if we do it this way, then we should probably find some abstraction model, so that the interface in the sense like deals with it as if it's same so that the interface doesn't really have to worry whether it's a meeting in the whole meeting series or a segment within a meeting: 9.528125000000005, , you know what I mean?: 0.42500000000000004, And that's probably stuff that we have to sort of like process twice then.: 1.6875, Like for example that like the summary of a meeting within the whole meeting corpus or meeting series y is meeting series a good word for that?: 1.6093750000000002, I don't really know what how to call it.: 0.7687499999999999, You know what I mean, like not not the whole corpus, but every meeting that has to do with one topic.: 1.29375, Um so in in the meeting se series so that a summary for a meeting within the meeting series, are sort of compiled off-line by a summary module.: 1.378125, And that is separate from a summary of a segment within a meeting.: 0.371875, 'Cause I don't think we can So are we doing that at all levels?: 0.89375, Are we um And just have different like fine-grainedness levels sort of.: 0.453125, So the only thing that: 0.15625, the only thing that would happen basically if I double-click let's say from the whole meeting series on a single meeting, is that the zoom level changes.: 2.634374999999999, Like the th the start and the end position changes and the zoom level changes.: 0.38125, I thought we couldn't do that.: 0.634375, Like I was under the impression that we couldn't do that because we couldn't load the data for all that.: 1.3687500000000001, But I don't know: 0.64375, , I mean that So I'm s not sure if I got it.: 0.5499999999999999, I wa: 0.00625, I was just worried about the total memory complexity of it.: 0.075, But I I completely admit, I mean,: 0.265625, I just sort of like th took that from some thing that Jonathan once said about not loading everything.: 0.625, But maybe I was just wrong about it.: 0.109375, How many utterances: 0.175, w: 0.05, and I w: 0.05, So what we have is we would have a word.: 0.403125, Like we would have words with some priority levels.: 0.5062500000000001, And they would basically be because even the selection would would the summaries automatically feed from just how prioritized an individual word or how indiv uh prioritized an individual utterance is?: 1.4500000000000002, Or i are the summaries sort of refined from it and made by a machine to make sentences and stuff?: 0.590625, Or are they just sort of taking out the words with the highest priority and: 0.48750000000000004, then the words of the second highest priority?: 0.215625, And the u okay.: 0.003125, Are we doing it on th the whole thing on the utterance level?: 0.659375, Or are we doing it on word level, like the information density calculation?: 0.38125000000000003, I think we have start and end times for words actually, but it's yeah,: 1.765625, it might: 0.05625, but it might sound crazy in the player.: 0.0875, We should really maybe we can do that together at some point today that we check out how the player works.: 0.39062499999999994, But there's maybe some merit in altogether doing it on an utterance level in the end.: 1.4312500000000001, Well but also about the displays, I mean the displays in the in the text body, in the in the latest draft that we had sort of we came up with the idea that it isn't displaying utterance for utterance, but it's also displaying uh a summarised version in you know, like below the below the graph, the part.: 2.784375, Maybe Yeah, r Hmm?: 0.1125, Oh yeah,: 0.01875, f: 0.04375, it's just like: 1.0, there there's like audio skimming: 1.0718750000000001, and there's displayed skimming.: 1.05, maybe there's some merit of going altogether for utterance level and not even bother to calculate: 1.490625, I mean if you have to do it internally, then you can do it.: 0.259375, But maybe like not even store the importance levels for individual words and just sort of rank utterances as a whole.: 1.15625, 'Cause it: 0.05, it might be better skimming and less memory required at the same time.: 0.33125, And I mean if you if you know how to do it for individual words, then you can just in the worst case, if you can't find anything else, just sort of make the mean of the words over the utterance.: 2.184375, You know what I mean?: 0.42500000000000004, W: 0.05, it's: 1.0, it's: 1.0, Well what's the smallest chunk at the moment you're thinking of of assigning an importance measure to, is it a word or is it an utterance?: 1.575, So we're thinking of like maybe just storing it on a per utterance level.: 0.59375, Because it's it's less stuff to store probably for Dave in the in the audio playing.: 2.4843749999999996, And for in the display it's probably better if you have whole utterances than I don't know, like what it's like: 3.346875, if you just take single words out of utterances.: 0.40937500000000004, That probably doesn't make any sense at all, whereas if you just uh show important utterances but the utterance as a whole it makes more sense.: 1.409375, So it doesn't actually make a difference for your algorithm, 'cause it just means that if you're working on a word level, then we just mean it over the utterance.: 1.6218750000000002, Oh so that's good anyway then,: 1.1062500000000002, Because that makes it a lot easier than to t put it on utterance level.: 0.378125, Oh yeah.: 0.01875, but I mean like how how Jasmine does it internally: 0.259375, I don't know,: 0.64375, but it's probably,: 1.2375, yeah, you probably have to work on word levels for importance.: 0.46875, But there should be ways of easily going from a word level to an utterance level.: 0.528125, Yeah, prob Hmm.: 0.003125, Well we do a pre-filtering of sort of the whole thing, sort of like: 0.9437500000000001, but that, like the problem with that is: 0.028125, it's easy to do in the text level.: 1.28125, But that would mean it would still play the uh in your audio, unless we sort of also store what pieces we cut out for the audio.: 1.3968750000000003, I think before we can like answer that specific question how we c deal with that, it's probably good for us to look at what the audio player is capable of doing.: 1.8593750000000002, Yes.: 0.009375, So what do you mean by buffering?: 0.25, Like you think directly feeding: 0.359375, but not but not stored on the hard disk and then loaded in, but loaded in directly from memory.: 0.13125, But it's probably a stream if it exists in Java, it would be probably some binary stream going in of some type.: 1.8468750000000003, Okay, so I mean so that means that there's probably,: 1.51875, even if you go on an per utterance level, there's still some merit on within utterances cutting out stuff which clearly isn't relevant at all, and that maybe also for the audio we'd have to do.: 2.6625, So let's say we play the whole au phrase, but then in addition to that, we have some information that says minus that part of something.: 1.6875, That's okay, that we can do.: 1.0, Yeah, maybe even I mean that's sort of that depends on how how advanced we get.: 1.825, If maybe if we realise that there's massive differences in in gain or in something, you can probably just make some simple simple normalization, but that really depends on how much time we have and and how much is necessary.: 2.1062499999999997, Yeah, if like I d I don't know anything about audio: 0.7312500000000001, and I have never seen the player.: 0.040624999999999994, So if you find that the player accepts some n input from memory, and if it's easy to do, then I guess that's: 2.2281250000000004, that's fairly doable.: 1.015625, So but that means in the general structure we're actually quite lucky, so we we have we load into memory for the whole series of meetings just the utterances and rankings for the utterances and some information probably that says, well, the I guess that goes with the utterance, who's speaking.: 2.821875, Because then we can also do the display about who's speaking.: 1.1781249999999999, But I'm I'm still confused 'cause I thought like that's just what Jonathan said we do c that we can't do, like load a massive document of that size.: 2.2812500000000004, On the other hand The other hand, I mean it shouldn't be like should be like fifty mega-byte in RAM or something: 0.9343750000000001, , it shouldn't be massive, should it?: 0.49375, Actually fifty hundred megabyte is quite big in RAM.: 0.31562500000000004, Just thinking, what's the simp: 1.04375, so We do get an error message with the project if we load everything into the project with all the data they load.: 0.4875, So we know that doesn't work.: 0.70625, So our hope is essentially that we load less into it.: 0.10625, What's this lazy loading thing, somebody explain lazy loading to me.: 1.2656249999999998, So that is that only by type of file.: 0.1625, Like if if if the same thing is in different files, would it then maybe like, you know, if if utterances are split over three or ten or w hundred different files, is then a chance maybe that it doesn't try to load them all into memory at the same time, but just So why does it fail then in the first place?: 2.2750000000000004, Then it shouldn't ever fail,: 0.47812499999999997, because then it should never Yeah,: 0.009375, but um it uh it it failed right when you load it,: 0.140625, right, the NITE X_M_L_ kit, so that's interesting.: 1.0875000000000001, Let's check that out.: 1.046875, Um I'll p: 0.140625, I'll probably ask Jonathan about it.: 0.36874999999999997, So alternatively, if we realise we can't do the whole thing in one go, we can probably just process some sort of meta-data: 1.896875, , you know what I mean, like sort of sort of for the whole series chunks representing the individual meetings or some Like something that represents the whole series in in a v in a structure very similar to the structure in which we represent individual um meetings, but with data sort of always combined from the whole series.: 3.059375, so instead of having an single utterance that we display, it would probably be like that would be representing a whole um topic, a segment in a meeting.: 1.675, And sort of so that wi using the same data st Well, in a sense: 0.521875, Uh I'm I'm thinking of in a sense of like creating a virtual a virtual meeting out of the whole meeting series, sort of.: 1.5093750000000001, Yeah, sort of like off-line create a virtual meeting, which which basically treats the meeting series as if it was a meeting, and treats the individual meetings within the series as if they were segments, and treats the individual segments within meetings as if they were um utterances.: 2.115625, You know, so we just sort of we shift it one level up.: 0.815625, And in that way we could probably use the same algorithm and just like make vir like one or two ifs that say okay, if you are on a whole document uh a whole series level and that was a double-click, then don't just go into that um segment, but load a new file or something like it, but in general use the same algorithm.: 2.9437499999999996, That would be an alternative if we can't actually load the whole thing and 'Cause also: 1.4375, like even if we maybe this whole like maybe I'm worrying too much about the whole series in one thing display, because actually I mean probably users wouldn't view that one too often.: 3.1374999999999997, but I'm: 0.18125, I'm still worried.: 0.23750000000000002, Like for example for the display, if you actually if you want a display uh like for the whole series, the information density levels based on and and the f and the only granularity you have is individual utterances, that means you have to through every single utterance in a series of seventy hours of meetings.: 1.6656250000000001, and if you make that structurally very similar to the the le like one level down, like the way how we uh store individual utterances and stuff, then maybe we can more or less use the same code and just make a few ifs and stuff.: 1.41875, so so but still so in in general we're having we're having utterances and they have a score.: 0.6, And that's as much as we really need.: 1.325, And of cou: 0.003125, and they also have a time a time information of course.: 0.434375, And a and a s and a speaker information,: 0.1, Yeah, so an information which topic they're in: 0.375, And and probably separate to that an information about the different topics like that: 0.51875, So so the skimming can work on that because the skimming just sort of sorts the utterances and puts as many in as it needs: 0.61875, Yeah, it'll it'll play them in some order in which they were set because otherwise it's gonna be more entertaining.: 1.546875, Um but that that's enough data for the skimming and the the searching, so what the searching does is the searching leaves the whole framework, goes to the S_Q_L_ database and gets like basically in the end gets just a time marker for where that is, like that utterance that we are concerned with.: 1.984375, And then we have to find I'm sure there's some way in in NITE X_M_L_: 1.3218750000000001, to just say set position to that time mark.: 0.29062499999999997, And then it shifts the whole frame: 0.221875, and it alerts every single element of the display and the display updates.: 0.303125, ju: 0.00625, but so so if if somethi so: 0.003125, So if in that tree display somebody clicks on something: 0.296875, and then you sort of feed the time stamp to and the NITE X_M_L_ central manager, and that central manager alerts everything that's there: 1.540625, , like alerts the skim like the the audio display, alerts the text display, alerts the visual display and says we have a new time frame: 0.63125, and then they all sort of do their update routines with respect to the current level of zoom.: 0.43437499999999996, So how much do they display, and starting position at where the or maybe the mid-position of it, I don't know, like w if start where the thing was found or if that thing wa was found it's in the middle of the part that we display, that I don't know.: 3.2156250000000006, But that we can decide about, but a general sort of It's the same thing if like whether you play and it moves forward or whether you jump to a position through search, it's essentially for all the window handling: 2.66875, , it's the same event.: 1.009375, It's only that the event gets triggered by the search routine which sort of push that into NITE X_M_L_ and says please go there now.: 1.4749999999999999, Why do we have to do it in memory?: 0.05625, But that stuff's: 1.140625, so I mean like the information is coming from off-line.: 0.43750000000000006, So we probably we don't even have to change the utterance document, right, because the whole way, like the whole beauty of the NITE X_M_L_ is that it ties together lots of different files.: 1.8312500000000003, So we can just create an additional X_M_L_ file which for every utterance like the utterances have I_D_s: 0.484375, I presume, some references.: 0.0125, So we just we tie uh p just a very short X_M_L_ file, which it's the only information it has: 1.26875, that has whatever a number for for the um weight, for the information density, and we just tie that to the existing utterances and tie them to the existing speaker changes.: 0.47187499999999993, Well otherwise we probably have to go over it and like add some integer that we just increment from top to bottom sort of to every utterance as an as an I_D_ some type.: 0.8656249999999999, Or un or try to understand how NITE X_M_L_ I_D_s work: 0.1125, and maybe there's some special route we have to follow when we use these I_D_s.: 1.178125, It's alm hmm?: 1.003125, Yeah, the the girl said the utterances themselves are not numbered at the moment.: 0.278125, So I guess that would be solvable if not.: 0.346875, Sorry?: 0.028125, Is that a board marker pen actually?: 0.096875, Oh.: 0.01875, That's just so like to make a list of all this stuff, or we probably can somebody can do it on paper.: 1.5375, All these fancy pens.: 0.009375000000000001, So what so the stuff we have we have utterances and speakers and weights for utterances.: 0.45625000000000004, So for for every utterance sort of like the utterance has a speaker and a weight which is coming from outside.: 0.61875, Or we just tie it to it.: 0.01875, And there is segments, which hmm?: 0.109375, Oh, so sorry um.: 0.046875, Uh topic s topic segments I meant.: 0.3375, Like they are they are a super-unit.: 0.015625, So so the utterances are tied to topic segments.: 0.371875, And if the time stamps are on a word level, then we b somehow have to extract time stamps for utterances where they start.: 0.8375, W what segments now?: 0.159375, Is the uh is that the same as utterances that is that the same as utterances that Mm-hmm.: 0.3, What so that's Oh.: 1.01875, But that's one o one segment or is that two segments then?: 1.6906249999999998, but but generally utterances is that which we just called uh sorry, segments is that which we just called utterances now.: 0.46562500000000007, Like it's it's the sa: 2.00625, it's sort of like one person's contribution at a time sort of thingy dingy.: 2.9406249999999994, Okay, so yeah, so we have those, and and then we have some f field somewhere else which has topics.: 0.125, and and a topic's basically they are just on the I_D_, probably with a start time or something, and and the utterances referenced to those topics I guess.: 2.0218749999999996, So the topics don't contain any redundant thing of like showing the whole topic again, but they just sort of say a number and where they start and where they finish.: 1.490625, And the utterances then say which topic they belong to.: 0.38125, But I was thinking of the topic segmentation now and and f for that there would only be one, right, because it's sort of like it's just a time window.: 3.23125, So if this lazy loading works, then this should definitely fit into I mean not memory then because it wouldn't all be in memory at the same time.: 1.3312499999999998, So if we just have those sort of that information like a long list of all the utterances slash segments and like short or smaller lists which give weight to them.: 0.775, And even though probably if there's a lot of over-head in having two different files, we can probably merge the weights into it off-line.: 2.0125, You know what I mean, like if if there's a lot of bureaucracy involved with having two different trees and whether one ties to the other because the one has the weight for the other, then it's probably quicker to: 3.4499999999999997, just Yeah, I thought that was the whole beauty that like you can just make a new X_M_L_ file and sort of tie that to the other: 0.828125, tre: 0.003125, Oh yeah.: 0.01875, So no, I didn't I didn't mean tree.: 1.190625, I meant just like handling two different files internally.: 0.296875, Sort of c I was just thinking you know like if if the overhead for having the same amount of data coming from two d files instead of from one file is massive then it would probably be for us easy to just like off-line put the the weight into into the file that has the segments, uh yeah, segments slash utterances already.: 2.565625, But that we can figure out I mean if it's going horrendously wrong.: 1.29375, no, we'd we'd be completely using like the whole infrastructure and: 0.54375, basically just I mean the main difference really between our project and theirs really is that we load a different part of the data.: 0.959375, But otherwise we're doing it the same way that they are doing it.: 0.259375, So we just we're sort of running different types of queries on it.: 0.6312500000000001, We in a sense we: 0.046875, I think we are running queries, it's not just about um what we load and what we don't load, but we're l running queries in the sense that we dynamically select by by weights: 2.2468749999999997, , don't we?: 0.465625, That we have to check how fast that is, like to say give us all the ones that whether that works with their query language, whether that's too many results and whether we shou: 1.43125, You know, if 'cause: 0.22812500000000002, if it i let's say I mean if if their query language is strange and if it would return b ten million results and it can't handle it, then we can just write our individual components in the way that they know which what the threshold is.: 2.6625, So they still get all the data and just they internally say oh no, this is less than three: 0.5125000000000001, and I'm not gonna display it or something.: 0.65625, I'm just thinking for this whole thing of like a different level, sort of cutting out different different pieces, whether we do that through a query where we say give us everything that's ab above this: 2.703125, and this weight, or whether we skip the same infrastructure, but every individual module like the player and the display say like they still get sort of all the different utterances, uh all the different pieces, but: 1.309375, they say oh, this piece I leave out, because it's below the current threshold level.: 1.303125, When do we need the one for the meet: 0.36250000000000004, Yeah, I guess for the so when we have the display, will we display the whole series.: 0.5718749999999999, Then if we have for the individual topic segments within the meetings if we have ready calculated disp um measures, then we don't have to sort of extract that data from the individual utterances.: 1.5812499999999998, Yeah, and that's also fairly easy to store along with our segments, isn't it.: 1.765625, For the segments, are we extracting some type of title for them that we craft with some fancy algorithm or manually or we're just taking the single most highly valued key-word utterance for the segment heading?: 0.75625, It's probably like in in the end: 1.309375, probably it wouldn't be the best thing if it's just the high most highly ranked phrase or key-word because like for example for an introduction that would most definitely not be anything that has any title anywhere similar to introduction or something.: 2.9218749999999996, Also like for this part, maybe if we go over it with named entity in the end, if I mean w if one of the people doing DIL has some named entity code to spare, and just like at least for the for sort of for finding topics, titles for for segments, just take a named entity which has a really high, what's it called,: 2.734375, D_F_I_D_F_, whatever.: 0.053125, 'Cause you'd probably be quite likely if they're talking about a conference or a person, that that would be a named entity which is very highly fr um frequented in that part.: 1.1375000000000004, Yeah, he said they're quite sparse.: 0.35, So that basically was don't bother basing too much of your general calculation on it.: 0.6593750000000002, But like especially if they're sparse, probably individual named entities which describe what a what a segment is about would probably be quite good.: 1.275, Like if there's some name of some conference, they would could probably say that name of the conference quite often, even though he's right that they make indirect references to it.: 3.2124999999999995, Anyway: 0.05, Sorry?: 0.028125, So you're doing that on a on a per word level.: 0.44375000000000003, Okay, cool.: 0.015625, I was just wondering where you had the corpus from at the moment.: 0.125, So it it seems that the data structure isn't a big problem and that basically we don't have to have all these massive discussions of how we exactly interact with the data structure because most of our work isn't done with that data structure in memory in the browser, but it's just done off-line and everyone can ha represent it anyway: 3.5500000000000003, they want as long as they sort of store it in a useful X_M_L_ representation in the end.: 0.609375, So like Yeah, that would mean understanding the NITE: 0.5437500000000001, _ X_M_L_ sort of format in a lot more detail.: 0.353125, We should I think we should just have a long session in the computer room together and like now that we know a bit more what we want, take a closer look at NITE X_M_L_.: 0.9656250000000001, Good.: 0.0375, Yeah, I haven't looked at this stuff much at all.: 0.7125000000000001, Who's who's sort of doing the the the central coordination of of of the browser application now?: 2.3187499999999996, Yeah, or but also like all these elements like like the loading and, yeah, integration and and like handling the data loading and stuff.: 0.45625000000000004, I'm sort of like: 0.459375, I think I'll take over the display, just because I've started with a bit and found it found it doable.: 0.7593749999999999, So somebody should sort of be the one person who's who understands most about what's t centrally going on with with the with the project, like with the with the browser as a whole and where the data comes in and Any volunteers?: 3.003125, It's also a complicated one.: 1.3125, I know: 0.178125, but uh b I guess we can do it like several people together: 0.1875, , it's probably just those people have to work together a lot and very closely and just make sure that they're always f: 1.8625, understand what the other one is doing.: 0.253125, Yeah, or or ready-made versions of them for that matter: 0.06562499999999999, but I think actually like at the moment the integration comes first: 0.5499999999999999, , I mean it's sort of at the moment: 1.5843749999999999, the building the browser comes first, and then only comes the creating new sophisticated data chunks, because that's sort of the whole thing about having a prototype system which is more or less working on on chunk data.: 2.2531250000000003, But it at least we have the framework in which we can then test everything and and look at everything.: 0.24687499999999998, 'Cause before we have that, it's gonna be very difficult for anyone to really see how much the work that they're doing is making sense because you just well I guess you can see something from the data that you have in your individual: 2.4, X_M_L_ s files files that you create, but it would be nice to have some basic system which just displays some stuff.: 0.64375, Or just adapt like their like just sort of go from their system and and adapt that piece for piece and see how we could how we could arran like adapt it to our system.: 0.7875000000000002, Does anyone want to like just sit with me and like play for three hours with NITE X_M_L_ at some point?: 0.240625, Uh I wouldn't like to be 'cause I'd like to go to the gym.: 1.0406250000000001, I'm theoretically free.: 0.19999999999999998, But if there's any time t hmm?: 1.134375, You have nothing no free time on Wednesday.: 0.1625, Nine ': 0.028125, til twelve and then nothi you have or you Hmm?: 0.021875000000000002, Anytime Wednesday afternoon I'd be cool, I think.: 0.509375, Yo, Forrest Hill, whatever one's easier to discuss stuff, I don't know.: 2.096875, I'm not biased.: 0.18437499999999998, What time do you wanna do?: 0.159375, Okay, so I'll just meet you in in eighteen a in the afternoon.: 0.14687499999999998, I guess at the moment nobody critically depends on like the NITE X_M_L_ stuff working right now, right?: 0.48125, Like at the moment you can all do your stuff: 0.2, and I can do my L_S_A_ stuff.: 0.140625, And I can even do the display to a vast degree without actually having their supplying framework working.: 0.346875, So it's not that crucial.: 1.00625, Yeah, actually I need the raw text as well.: 0.34375, I was more thinking of the sort of the the whole browser framework as a running programme now.: 0.6124999999999999, Yeah, I think we all need the raw text in different in different flavours, don't we?: 1.328125, But number within the X_M_L_ context.: 0.1, Are they spoken numbers?: 0.040625, Like do they look like they're utterances numbers?: 0.4625, There's the number task, isn't there.: 1.5062499999999999, That's part of the whole thing.: 1.4, Yeah, we have to probably cut that out anyway for our project, I don't know.: 0.975, It's probably gonna screw up a lot of our data otherwise.: 1.6812500000000004, If Not sure if it what it does to document: 0.140625, It would probably make the yeah,: 0.628125, if if you have segments for that, probably the Okay.: 0.346875, Uh I'm just thinking like it pro: 0.228125, it pro probably like the L_S_A_ would perform quite well on it.: 0.64375, It would probably find another number task quite easily seeing that it's a constrained vocabulary with a high co-occurrence of the same nine words.: 1.9656250000000002, So that wou ten word.: 0.125, I think it's also something that they they said the numbers in order, right?: 1.79375, Yeah, I think it's it: 1.34375, it sounded like they wanted to check out how well they were doing with overlapping and stuff,: 0.178125, because basically it's like they're reading them at different speeds, but you know in which order they are said.: 1.6531250000000002, Anyway.: 0.05, ICSI has some reasons for doing it.: 0.003125, They must have been pissed off saying like numbers at the end of every meeting.: 0.39999999999999997, Um Dave, if you would or actually for well, if you're doing I_D_F_s or you whatever you call your your frequencies, I always mix up the name, uh you need some dictionary for that at some point though, like you need to have some representation of a word as not not that specific occurrence of that word token, but of of of a given word form.: 1.4468750000000001, Because you're making counts for word forms, right?: 0.415625, Yeah, so we should work together on that, because I need a dictionary as well.: 0.321875, Didn't you say that the o: 0.584375, the ord: 0.00625, but for I'm just wondering for the whole thing.: 0.559375, Does somebody wo who was it of you two who said that um there's some programme which spits out a dictionary probably with frequencies?: 1.4968750000000002, Is anyone of you for the for the document frequency over total frequency, you gonna have total frequencies of words then with that, right?: 0.7250000000000001, Like over the whole corpus sort of.: 0.546875, Or W using which tool are you talking about?: 0.12187500000000001, Be careful with that.: 0.015625, Like my experience with the British National Corpus was that there's far more word types than you ever think because anything that's sort of unusual generally is a new word type.: 3.0625, Like any typo or any strange thing where they put two words together.: 0.525, And also any number as a word type of its own.: 0.246875, So you can easily end up with hundred thousands of words when you didn't expect them.: 0.75, So generally dictionaries can grow bigger: 0.021875, then you think they do.: 0.34375, Well you can probably also you can probably pre-filter like with regular expressions even just say if it consists of only dig digits, then skip it, or even if it consists any special characters, then skip it because it's probably something with a dot in between, which is usually not something you wanna have: 2.5156249999999996, and What I did, for my project I just ignored the hundred most frequent words, because they actually end up all being articles and and everything and stuff.: 0.578125, So we need like several of us need a dictionary.: 0.3625, Am I the only one who needs it with frequencies?: 0.28125, Am I the only one who needs it with frequencies?: 0.28125, Or Frequencies.: 0.03125, Well I guess as soon as we have the raw text, we can probably just start with the Java hash map and: 0.5468750000000001, like just hash map over it and see how far we get.: 0.25625000000000003, I mean we can probably on a machine with a few hundred megabyte RAM: 0.553125, you can go quite far.: 0.225, You can write it on beefy.: 0.043750000000000004, So even if it goes wrong and even if it has a million words be: 0.346875, Oh yeah: 0.01875, , burning it on a like we should be able to burn the whole corpus, just the X_ hmm?: 0.321875, Ah I see: 0.071875, , I asked support about that two days ago.: 0.084375, In the Informatics building there: 0.0125, oh sorry, in in Appleton Tower five the ones closest t two machines closest to the support office.: 0.175, So I presume: 0.00625, oh wait, I have the exact email.: 0.04375, I think he's talking about sort of the ones that Yeah, if you if you enter the big room, in the right-hand corner, I think.: 2.2, Um the thing is like you can only burn from the local file-system.: 0.35000000000000003, So if it's from s: 1.0, well actually I think if it's mounted, you can directly burn from there, but the problem is I have my data on beefy: 1.646875, and so I have to get it into the local temp directory and burn it from there.: 0.190625, But you can burn it from there.: 0.01875, Uh we looked that up and I for we looked that up: 0.05, and I forgot.: 0.003125, No, you you we should be able to get it at: 0.14375, I don't think it was: 0.809375, I don't think it was a gigabyte.: 0.8156249999999999, See I would off: 0.365625, I would offer you to to get it on this one, and then um like copy it.: 0.6499999999999999, But you know what I figured out, I'm quicker down-loading over broad-band into my computer than using this hard disk.: 0.496875, There's something strange about the way how they access the hard disk, how they mount it, which is unfortunate.: 1.284375, What operating system do you have?: 0.03125, Wh what connection do you have at home?: 0.021875, So if anyone of us gets it, we can then just use an ext hmm?: 0.159375, Yeah, burn it to C_D_ or,: 0.01875, yeah, put it on on hard disk, whatever.: 0.128125, Question is if you're not quicker if you uh because you should get massive compression out of that.: 0.340625, Like fifty percent or something with a good algorithm.: 0.2625, So if you could compress it and just put it into a temp directory.: 0.2125, Like The temp the temps usually have for gigabyte three or two.: 0.125, The temps,: 0.009375, I mean there's not guarantee that anything stays there,: 1.3062500000000001, but overnight it'll stay.: 0.128125, And I think the temps usually have.: 0.36250000000000004, but that would have to be the temp directory off the machine you can S_S_H_ into directory of S_S_H_.: 0.40625, Yeah, they wou they'd: 0.140625, they'd probably hate you for doing it.: 0.37812499999999993, But They'd probably they'd like you more if you: 0.50625, _ uh into another computer, compress it there and then sort of copy it into the into the gateway machine.: 0.384375, hey, you know, if you if you S_S_H_ and: 0.18125, they have this big warning about doing nothing at all in the gateway machine.: 0.15000000000000002, To your home machine.: 0.053125000000000006, I haven't I haven't figured out how to tunnel through the gateway into another machine yet.: 1.028125, It's not: 1.0, it's not easy definitely.: 1.078125, That's why I end up sort of copying stuff into the temp directory at the gateway machine.: 1.590625, Sorry if this is boring everybody else.: 0.06875, This is just details and how to get stuff home from what we can probably just look at that together when we're meeting.: 1.0687499999999999, I'm sorry.: 0.209375, As soon as somebody gives me the raw text of the whole thing, I can probably just implement like a five line Java hash table frequency dictionary builder and see: 1.1562499999999998, Oh, did you not say frequencies f of words in the whole sorry: 0.621875, So you'd you: 0.134375, Yeah, you'd have to count it yourself,: 0.14375, Oh, you don't wanna have different counts for each chunk, but: 0.6718749999999999, just like sort of for for something from old chunks.: 0.48437499999999994, Oh yeah, no: 0.01875, , that's yeah,: 1.0, so once I write an ar like w if I write like an algorithm which does a hash um table dictionary with frequency from a raw text, then the raw text can be anything.: 0.6656249999999999, So how far are we: 0.028125, g: 0.00625, uh how f how far are you getting raw text out of it: 0.22499999999999998, do you think?: 0.34375, Okay, well that's good, because for the dictionary the order doesn't make a difference, does it?: 1.709375, so um I'll get that from you: 0.23125, and I'll write the hash table which goes over that and creates a dictionary file.: 0.428125, So for the dictionary, is it okay if I do, whatever, word blank frequency or something?: 0.44375, Just p could everybody sort of start from that?: 0.484375, I mean I guess we can: 0.296875, Yeah, I I need frequency as well.: 0.178125, Well I think we might have a lot in common what we calculate because I for my latent semantic analysis need like counts of words within a document, uh within a a segment actually, within a topic segment.: 1.34375, Can I convert these probabilities back into frequencies?: 0.053125000000000006, Oh, so that's what f Rainbow does, because that's what L_S_A_ builds on.: 2.06875, Like it builds a f a document by frequency matrix.: 0.184375, So I could probably get that.: 0.46249999999999997, Even though but I already have I already have my code to build it up myself.: 0.265625, No, don't bother.: 0.47500000000000003, I have my code already.: 0.078125, Yeah, so Dave, you said you need the frequency counts actually for per document, would you say, not for the whole thing?: 1.21875, It more and more appears to me that if we if we scrap the notion of the meeting as an individual thing and sort of ju see meetings as as topic segments and have sort of like hierarchical topic segmentation instead, then it's b like a more coherent framework.: 2.58125, Wait, are we are we using this um for the for the for the do for the weighting in the end now, this this measure you're calculating?: 0.34375, Because if we're doing Like I think for for the information density we uh we should calculate it on the lowest level, not on the highest.: 0.8406250000000001, But like 'cause: 0.05, but w it don't you have to like go sort of like for in a document versus the whole thing?: 1.3343749999999999, Isn't that how it works that you c look look at r: 0.7062499999999998, I don't think that's a good idea because isn't it like that we expect th there to change over i b with the different topic segments more?: 2.7937499999999997, That they talk about something different in each different topic segment.: 0.6, 'Cause that's what relative term frequency is about, that like in some context they're talking more about a certain word than in general.: 1.475, So that would more be the the topic segments then.: 0.509375, I don't know.: 0.64375, So I'm just wondering if there's ways to abandon the whole concept of of meetings and sort of but just not really treating separate meetings as too much of a separate entity.: 2.096875, But But on algorithmic level, whether we actually whether there's some way to just represent meetings as as topics.: 1.4593749999999999, That's not really what I meant.: 1.134375, But I think I have to think more about what I meant.: 0.703125, Um g I'm confused about everything.: 0.246875, I'm: 0.18125, I'm not so concerned about the m a meeting plus something else, I'm more talking about like,: 0.790625, yeah, the keeping keeping the same algorithm and the same way of handling it and just saying like just this this topic here: 0.246875, uh it happens to be like a whole meeting and it has sort of sub-topics, so: 0.7499999999999999, just that sort of topics a hierarchical concept where like a topic where there can be super-topics and topics, and: 0.546875, the super-topics are in the end what the meetings are, but in general at some level super-topics are treated like like topics.: 0.446875, I'm not really sure what I want.: 0.49374999999999997, So sorry, could describe that again, the Mm-hmm.: 0.146875, So that would be the series as a whole.: 0.634375, That would be sort of m meetings,: 0.634375, I'm a: 0.18125, I'm a: 0.18125, I'm a bit brain-damaged at the moment, but: 0.271875, I think I'll just sit together with you again and and go through it again.: 0.646875, So so I'll is th it like: 0.165625, is this and this structurally then always identical?: 0.034375, So that we can that we can treat it with the same algorithm or: 0.053125, Yeah, I'm also not sure how we can go from from bottom-up.: 0.425, I have always thought it's like more that oh, whatever, I'm a can't think of it at the moment.: 2.2375000000000003, Probably this is all too complicated worrying about that at that moment anyway.: 0.359375, Now have have we have we decided anything, are we doing anything?: 0.11249999999999999, S Wednesday we are meeting and looking at their at their implementation in some more detail to actually understand what's going on.: 1.3875, We had two things from their stuff just to make sure that we are like understand it, we understand it enough to to m modify it.: 0.48125, How would we do that?: 0.29375, By just making like it w read write for everyone. ': 0.14375000000000002, Kay, who has most free space on their Same here.: 0.03125, Well we alternatively we can probably just make another directory on the beefy scratch space.: 0.42500000000000004, I mean that's where I'm having gigabytes and gigabytes of stuff at the moment.: 1.640625, But I think if he sends to the I think if he sends to the port he'd probably be in a better position.: 1.10625, I think he said yes to that.: 0.40937500000000004, I think uh that was like in: 0.34375, when we were still in the seminar room, I asked that once or like ask is it possible to get it off and: 0.20625, nobody said like people were discussing about the technical practicalities, but nobody said anything about al being allowed to or not allowed to.: 0.24375, I mean, we have access to it here: 0.259375, and I guess it probably means that we we can't give it to anybody else.: 0.8937499999999999, But but if they give us access to it here o sitting on a DICE machine, then there shouldn't be a reason why we shouldn't be able to use it on our laptop.: 1.175, I personally don't have too many friends who would be too keen on getting it anyway.: 0.8625000000000002, I have that really excited pirate copied thing.: 0.284375, It annotated meeting data.: 0.365625, Huh.: 0.00625, Wait, wait, wait.: 0.037500000000000006, Um sorry.: 0.028125, Yeah, sorry.: 0.028125, What I just realised, we should really t keep different serieses completely separate for virtually all purposes.: 0.30624999999999997, Just let's be careful about that,: 1.04375, because like the the ICSI corpus isn't isn't one meeting series, it's several meeting series with different people meeting for completely different things.: 3.431249999999999, For each meeting.: 0.20625, Okay, but like let's just be careful that whatever we sort of we merge together: 1.4593749999999999, , that like the highest level of merging, it's not the whole ICSI corpus but individual series..: 1.6374999999999997, I think we might: 0.4, actually I think That's probably be somewhere like well: 1.675, or something like it.: 0.165625, Um I think we might just get away with for the whole project just like looking at only one series and just doing within one series.: 1.553125, I mean you can do everything you want in one series.: 0.784375, Oh yeah, let's take that.: 1.1, Is the is the data always clearly split up by different series?: 0.44687499999999997, Uh like is it easy to just pick one: 0.29375, So at at every level everyone has to be careful to really just take even at the highest level, just take stuff from one series and not merge stuff from different series together because they would probably be just majorly messy.: 2.1968749999999995, so like if even if we make one single text file which has the whole corpus, sort of our corpus, that would still be from one series only.: 1.9625, Wou but it what you're producing at the moment is like individual text files that sort of have the raw text for a whole a meeting as a whole or Mm-hmm.: 1.5281249999999997, Um so is is anybody creating an uh a real raw text thing at the moment, like which is just the words?: 0.540625, Yeah, tha: 0.003125, 'cause that's what I'm gonna need as well.: 1.575, But i but if there uh b aren't like: 0.5, so it's: 1.0, it's start and end times just for the file.: 1.3031249999999999, Like is it just the first and the last line?: 0.140625, Or is it for every single thing in: 0.253125, So what do you mean by just not print out that?: 0.253125, If you're into it, can you make a text file which just like makes just the words? ': 0.690625, Do you want it straight flowing, 'cause I would need something that marks the end of uh of uh: 0.85, is is yours segmented by topics: 0.046875, then that like is there any information that you have to the topic, to the automated topic topic segmentation?: 0.428125, Oh then I need something different later anyway.: 0.4937499999999999, Okay, but for now, if you c: 0.028125, You're gonna put that as an output of yours, the segmentation.: 0.475, Okay, so for now can you create like sort of just uh a dump which is pure text, just pure text so that I can get a dictionary: 0.678125, and you can work on that for your topic segmentation.: 0.19062500000000002, And Or for for the series.: 0.128125, but I can also deal with separate files,: 0.17812499999999998, I mean I can just write the algorithm that it loads all files in a directory or something.: 0.6124999999999999, But I mean if you: 0.246875, But if you can put it in one single mega-file, that would be quite useful for me.: 0.890625, Even though for you, wouldn't it be easier if you had different files because then you sort of know like: 1.54375, So give m give me different files as long as: 0.30624999999999997, like it m if you could name them in a way that is easy to enumerate over them, like whatever,: 0.3, one two three four five or something.: 0.49375, Or just anything that I can: 0.053125, Is is it something that's easily enu like to enumerate over?: 1.1875, Is it some just some ordered pattern?: 0.024999999999999998, Okay, cool.: 0.015625, Okay, cool.: 0.015625, In the right order.: 0.1125, It's just a wish list.: 1.0375, When do you think you'll have um like a primitive segmentation by some ready-made topic segmentation by some ready-made tool ready?: 0.7281249999999998, Okay, cool.: 0.015625, 'Cause I'll need that then when it's done.: 1.309375, What's what's nine megabyte?: 2.0406250000000004, The the That sounds quite reasonable.: 0.128125, That's nine nine characters over: 1.0656249999999998, That is for are we are we picking one particular series at the moment?: 0.43124999999999997, Or Yes.: 0.009375, Yeah, I guess we can probably process the data for all different series and then check which series is the best for the presentation.: 0.8781250000000002, It sounds quite reasonable, nine megabyte.: 0.16875, I mean if you think if it's r roughly a million words and nine characters per word sounds realisti: 1.9718749999999998, Yes, I'm gonna build a dictionary then from that.: 0.50625, Like just a list of the words that maybe a list of the words with the frequencies or a list of the words sorted alphabetically or numerically.: 0.7500000000000002, What what does anyone want?: 0.15625, Does this there any wishes for dictionaries?: 0.009375000000000001, So I'll create a dictionary.: 0.2, Add add the structure,: 0.056249999999999994, And then the actual file we can probably like copy from your home directory or something like it.: 0.615625, but I'm sa: 0.1875, I'm saying for the whole thing in the end.: 0.6375000000000001, Then like the big thing we probably shouldn't do by email.: 0.9500000000000001, Oh, from the time I get the file I can do that in an afternoon, the next sort of the next morning.: 0.7593750000000001, Oh, you mean how long processing time it takes.: 0.45312499999999994, Ah, it's a: 1.0, it's a bog standard algorithm.: 1.053125, I've: 0.075, I've sort of I've written it for for DIL just in half an hour or something similar.: 0.640625, It's just you put them in a hash table and and: 1.10625, say well if it exists already in the hash table then you increase the count by one: 0.465625, and I'll probably implement some filter for filtering out numbers or something.: 0.5874999999999999, Really?: 0.11875, Okay, well I don't know any Perl.: 0.64375, I mean if anyone wants to do a Perl script for that that does it does it nicely, I uh I've no problem with that.: 0.39375000000000004, but I think I have the Java code virtually ready because for DIL I wrote something very similar.: 0.60625, Like for DIL I wrote something that counts the the different occurrences of all the tags: 0.33125, um Sorry?: 0.028125, The hash table?: 0.0625, Uh I've never serialized anything.: 0.140625, Wouldn't that be absolutely massive though?: 0.83125, And then seriali and then write the serialization to a file.: 0.178125, So you want like a se like a file which is the serialization of a hash table.: 0.34062499999999996, I'll: 0.11875, I'll check if I understand how it works.: 0.18124999999999997, I mean otherwise I can give you the code for loading a dictionary.: 0.4375, Give you my my: 0.0375, it's just: 1.0, it's: 1.0, it's: 1.0, sort of it's a line break separated file, you know.: 1.690625, Yeah, I'll see if I understand how to serialize.: 0.22499999999999998, There's a there's a serialise command: 2.0062499999999996, so that gives me one mega mother of a s: 0.253125, Yeah, but do they automatically write to the file: 0.178125, anyway: 0.05, I'll: 0.11875, I'll figure that out.: 0.125, We don't have to: 0.465625, Yes, is that pretty much pretty much it?: 0.203125, So Dave and me look at how NITE X_M_L_ works: 0.109375, and we're Hmm.: 0.184375, I'll build a dictionary as soon as I get the text.: 0.434375, so that When do we have to meet again then with this?: 0.009375, How are we gonna do a demonstrator next week?: 0.28125, No no, not demonstrate, but like didn't you say that uh didn't we sort of agree that it would be useful to have a demonstrator of it, like some primitive thing working next week.: 1.940625, That's gotta be very prototype.: 1.078125, Ah well, let's go.: 1.121875, Sorry.: 0.028125, I feel like like hanging mid-air and not really like finding a point where you can get your teeth into it and start working properly: 0.390625, and so it's all so fuzzy the whole: 1.215625, but it at the moment but at the moment it's also an implementational level.: 1.328125, Like with the data structures, I'm just like over these vague ideas of some trees, I'm f: 0.575, It's just we are half-way through the project time table.: 1.2562499999999999, That's just what freaks me out.: 1.003125, I mean if we just want to have um some data for the user face, could even be random data.: 0.8687500000000001, Yeah, I'm Hmm.: 0.18125, Yes.: 0.009375, Hmm yes.: 0.009375, I'm not so sure.: 0.246875, I thought we would just have like um one big summary um with all the uh different importance levels um displayed on it.: 0.8906249999999999, And depending on what our um zoom level is, we just display a part of it.: 0.26875, And we would have one very big thing off-line.: 0.85625, And from that we would just select what we are displaying.: 0.315625, Yes.: 0.009375, So for example you would um give a high value to those um sequences you want to display in the meeting series summary.: 0.9718749999999998, And you just cut off.: 0.01875, That was what I sh: 0.003125, I thought,: 0.05625, I thought.: 0.05625, But I think the m difference might be: 0.415625, that we want just want to have um the words.: 0.425, And that's not so much what he meant with not possibly loading everything was that you m um load all the uh annotation stuff, all the sound files,: 1.4687500000000002, I r: 0.0125, I'm getting quite lost um at the moment because um w what's um our difference between the um se um uh the importance measure and the skimming?: 1.525, I mean, do we do both or is it the same thing?: 0.403125, So but when when we talk about summaries you talk about this uh abo about skimming and not about Yeah.: 0.07500000000000001, Yeah right, isn't that the skimming?: 0.5812499999999999, Isn't that the skimming?: 0.503125, but it use the same data.: 0.209375, I think we also thought about combining that measure with um the measures I get from um s uh hot-spots and so on.: 0.6375000000000001, So that would also be on utterance level, I think.: 0.9593750000000001, I think.: 0.34375, Yes, sure.: 0.075, Yes.: 0.009375, Yes, right.: 0.0875, So I define baseline and what it loads?: 0.034375, For example it loads all the utterances and so on, but it doesn't load um the discourse acts and for example not the and what's what else there?: 1.80625, Not the summaries.: 0.015625, It only loads those on demand.: 0.028124999999999997, Y you mean that you um basically split up th the big thing into um different summaries.: 0.7562500000000001, For example that you have a very um top-level um summary and a separate file for for each level.: 0.4875, Yes.: 0.009375, N: 0.009375, Uh no no, it's f for No: 1.04375, , you're right.: 0.2625, It's for Um: 1.0, No, I I think we would just take the segments that are already that were: 0.8374999999999999, Yeah, there's um this segments file.: 1.24375, Um you know, the X_M_L_ segments.: 0.2875, Oh.: 0.01875, That I don't know.: 0.64375, Yeah, that's um Mm-hmm.: 1.0, There there are time stamps um for, well, segments um and for th um segments is for example when when you look at the data, what is displayed in one line.: 1.0375, What when when you look at it in the hmm?: 0.090625, I think so.: 0.34375, Isn't Um for ex: 0.46875, um I I compared it with what I did for the pause um duration extraction.: 0.018750000000000003, Um and basically it's uh words that are uttered in a sequence without pauses.: 1.2656250000000002, But sometimes um however there are um short pauses in it: 0.028124999999999997, and they're indicated by square brackets pause or something in the data.: 0.5125, Um someti uh but uh the annotators decided what was one segment and what wasn't.: 0.76875, I think so.: 0.34375, but um I think for some annotations um an uttera ca utterance can have several um types.: 0.521875, For example for the dialogue acts and so on.: 0.04687500000000001, Yes,: 0.009375, but that's: 1.0, Yeah, everything that's a word has a sti time stamp.: 1.315625, That's at the end.: 1.071875, That's at the end, I think, her time.: 1.5499999999999998, Yeah, maybe.: 0.1, Didn't have a look at our meetings.: 0.61875, Uh I I think it wouldn't as it occurs: 1.109375, I mean it would be: 0.540625, it occurs in every meeting.: 0.271875, And I think it even has uh its own annotation, like digits or something.: 0.596875, So that should be really easy to cut out.: 0.19999999999999998, I'm sure.: 0.246875, Ah it's just to test the system, I think.: 1.378125, So Mm they have to read numbers from: 0.053125, Uh I didn't have a look at that.: 0.55625, Uh th yeah. ': 0.046875, Um I just um wondered, so who's uh then doing um the frequencies on on the words, because I'm: 1.384375, I think I will also um I could also make use of it um for the agreement and disagreement thing.: 0.9343750000000002, Because I um I in my outline: 0.003125, I talked about um using the um discourse acts first, and um then in the chunks of text I found looking for word patterns and so on.: 0.39062499999999994, So um I would for example need the um most freq um frequent words.: 0.63125, So if you cut off all that, I'd won't be use: 0.696875, but I need it for my chunks then.: 0.1625, I would You know?: 0.47187500000000004, but I'd uh I would like to look at the frequency of words in my um in the regions of text: 0.8343749999999999, I found out to be interesting.: 0.028124999999999997, So I wouldn't need it.: 0.884375, It it would have to be re-calculated only for my segments.: 0.41875, Huh?: 0.00625, I think it would be, you know, l as as big at as the hot-spot annotation things.: 0.96875, That's quite small,: 1.121875, yeah, that's some utterances.: 1.15, Yes.: 0.009375, So I would probably just concatenate all my um text chunks and then let's say m I will run over it.: 1.8249999999999997, Yes.: 0.009375, Yes, definitely.: 0.025, Yeah, right.: 0.078125, Ye M Um Jasmine, uh um what is um the text you're extracting uh: 0.28750000000000003, looking like then at the end?: 0.103125, Because um I I think it's actually very similar to what I did for my um speaker um uh extraction: 1.4718750000000003, and I think I would ch perhaps have to change two lines of codes to get you um for each meeting a file that says fr from um this millisecond to this millisecond there was this sequence of words.: 1.4062500000000004, So that's just changing two lines of code.: 1.11875, And it would give you that.: 0.33125, So far I extracted um the dura durations.: 0.043750000000000004, But it's from the words file.: 1.3031249999999999, So I could just um contatenate concatenate um the words instead of the durations, and: 0.315625, it should I mean Should be very straight-forward.: 0.26875, I can try to do it and send it to you.: 0.03125, Pe and you have a look at it, will it make sense for what you want.: 0.3625, Yeah, uh p: 0.021875, I mean it: 0.246875, I just let it run over all the files.: 0.1, So Yes.: 0.009375, I just ordered.: 0.021875, Uh I ordered according to the um starting times of the utterances.: 0.21562499999999998, What do you mean by diffe: 0.25, I mean t: 0.246875, I have one what I give you: 0.265625, would be one file for each meeting.: 0.8625, Yeah, not for each meeting series.: 0.334375, I didn't do that yet.: 0.478125, Yeah, one group,: 0.2375, Yeah, I mean there's one series that has just one meeting.: 2.0374999999999996, Yes.: 0.009375, Um the you you the data is of the form you have um three identification letter.: 0.1875, So B_E_D_ or B_B_D_ or something, and that's always the same group.: 1.1999999999999997, And then after that there's um a number like O_O_ one, O_O_ two.: 1.321875, So, it's a Yeah, but that's: 2.0, that's really quite easy to see because they're named.: 1.5624999999999998, Yes.: 0.009375, But I I mean as um the start uh start times um start for each meeting at zero, you could just probably just um add the um final second time to the next meeting and so on and just put it all together.: 1.5531249999999996, But then we would have to change um the information about who on which channel it was set, um to by which person it was set.: 0.45000000000000007, And that is actually stored in another X_M_L_ document.: 0.19687500000000002, Yeah, I w would then just not print out the um start and end times.: 0.5187499999999999, No, it's for every single word.: 1.20625, Or for every single utterance.: 0.2125, Yeah, that depends on what you want.: 0.140625, but I do it with Perl, it's just string manipulation.: 1.0093750000000001, So I would I mean I would just Sure.: 0.9000000000000001, No, I didn't do a sea no.: 0.46875, And you would want that all in one file for all the corpus?: 0.8406250000000001, Or For the series.: 0.128125, Yeah, I can directly put it into uh just like: 0.056249999999999994, So uh only words um per meeting series.: 0.5249999999999999, Uh-huh.: 0.00625, Yes.: 0.009375, just I will just take I would uh take over the names they have anyway.: 0.45312499999999994, Yeah, one series has the um same three starting letters.: 0.39374999999999993, So So only words and words and times.: 0.36875, Yeah, you want it ordered.: 0.15, Okay, anybody Um ord base dot times.: 0.05625, Yeah, and do you want: 0.128125, Yeah, sometimes they're contained in one another.: 0.45, So Just after th mm-hmm. ': 0.046875, Ordered.: 0.021875, Only words.: 0.16875, Um and I think um for all the corpus, it's just from: 1.4, I know from other times: 0.209375, , it's um nine megami byte to have: 1.040625, I mean should be should be similar to have the words.: 0.4375, Na um all the words together um for all the meetings.: 0.415625, That's what I'm guessing that's, you know, um: 2.3625000000000003, what I because nine mega-byte is what I got for when I said for every um utterance, this is goes from there to there and takes takes seconds.: 0.38125000000000003, Oh.: 0.01875, Yeah, I mean I'm it doing it for all of it.: 0.428125, Doesn't matter.: 0.4875, Yeah, I mean I hope it will be the same for the words.: 0.421875, It's just what I: 1.0, So so um I will probably send um just one file of the first meeting um to all those who need it so that you can have a look whether that's what you want.: 2.234375, Yeah, I mean if it's just for one meeting, it's really not too big.: 2.884375, What do we have to demonstrate?\n",
      ": 0.009375, The basic word importance is off-line as well.: 0.234375, The combined measure might not be if we want to wait what the user has typed in into the search.: 0.278125, I'm not quite so what it did you want to do it: 0.4125, , i you just wanted to assign: 0.015625, Uh I thought about words.: 0.225, but how about those words which don't carry any meaning at all, the um and uhs and something like that.: 0.8093750000000002, Because if we if we average average over over a whole utterance all the words, and there are quite unimportant words in there, but quite important words as well: 1.06875, , I think we should just disregard the the: 0.346875, But there is no I_D_ for an utterance I think.: 0.459375, It's just for individual words.: 1.24375, We for utterances as well.: 0.15, I think it's just for one word.: 1.68125, Uh I'm not quite sure: 0.35, , I have only seen that the uh the individual words have got an I_D_.: 0.309375, You always could have a look at the time stamps and then take the ones that uh belong together to form an utterance.: 0.6781249999999999, Yeah, if they are already, there's: 1.0375, it's easy: 1.0625, but it would be possible.: 0.30625, uh you said you are currently in uh implementing the idea.: 0.09062500000000001, What exactly are you computing?: 0.0125, Yeah, I w: 0.05, w: 0.05, I would need the raw text pretty soon because I have to find out um how I have to put the segments into bins.: 0.7625, No, that's not necessary.: 1.00625, Yes, I did.: 0.009375, But um I've only just got the notes.: 0.134375, I have to still have uh to order everything by the time: 0.271875, Yeah, I think it's quite easy after the: 1.509375, b: 0.034375, w: 0.05, that's what I was uh thought.: 1.05625, That you just combine them and then order the time stamps accordingly.: 0.20937499999999998, Um what I found out was that there are quite a lot of things without without s time stamps in the beginning.: 0.43125, Yeah, and uh X_M_L_ files.: 0.065625, Yeah, that's just an I_D_ or something.: 1.165625, I don't know.: 0.64375, Just numbers.: 0.0375, Yes, but what are the other things that's uh some kind of number?: 1.0875000000000001, F maybe the file number or something that is in the beginning.: 0.490625, Do you know?: 0.178125, Um I think there are quite a lot of numbers in the beginning where n there is no time stamp for the numbers.: 0.75, It's Think they say um quite a lot of numbers and before that, uh um there's this number.: 2.6875, Yeah, there i are numbers in the um the W_ tag, but there are no time stamps.: 0.25625, Yeah, in the beginning as well sometimes, I think.: 0.36875, At least I saw some.: 0.01875, But what it is it actually that numbers?: 0.12187500000000001, but there are no time stamps annotated to that.: 0.178125, It's it's quite strange.: 2.11875, And also um there are different um combinations of letters.: 0.21562499999999998, B_R_E_ and something like that.: 0.165625, Is it everything ordered are the time stamps global or uh are they local at any point?: 0.27812499999999996, Yeah, it's Rainbow.: 1.0, It's um I think it's just the dictionary in the first place.: 2.45, But Um no, I have to bin it up: 0.00625, and so I will only have counts for each each bin or something.: 0.19374999999999998, It's because um Rainbow is a text classification system.: 1.125, And I think it's not possible to have just one class.: 1.5937499999999998, That's the problem.: 1.028125, Maybe we could: 0.21250000000000002, Yeah sure, you sure, we could do that, but I don't that makes sense.: 0.7718750000000001, If we need just frequencies, maybe we should just calculate them by using Perl or something.: 0.484375, I don't know.: 0.64375, Yeah, it's quite easy to just count and s or sort them by um frequency.: 1.5062499999999999, Just using a Perl script.: 0.05, Is it too big?: 0.084375, I don't know how you how many terms you can handle in Perl.: 0.690625, Uh I can get all the raw text, but it has to be ordered still.: 0.31875, So No, it isn't.: 0.465625, Um it's in what is implemented in Rainbow: 1.003125, is information gain, and I'm not quite sure how they calculate that.: 0.46249999999999997, Uh that's what Rainbow does.: 1.0, I think you j can just get probabilities for a certain words for each document.: 0.7218749999999999, Certain: 0.009375, Um we would have to look at that.: 0.384375, Oh.: 0.01875, Yeah, that's what I thought as well,: 1.05625, that you that probably the the topic segment level is the most um informative for the words.: 0.70625, Yeah, that's the problem.: 1.028125, I don't know.: 0.64375, So shall we sit together tomorrow then as well?: 0.096875, w would it be best?: 0.353125, At the moment it's it's just lines of Mm-hmm.: 2.06875, So um you'd do you extract the words, the raw text, as well?: 0.453125, Print out.: 0.00625, So have we already extracted from all the files?: 0.109375, Did you also order Mm-hmm.: 0.1125, Uh I don't need the times, I just need the words.: 0.9156249999999999, But um Yeah, in the right order.: 0.1125, Yes.: 0.009375, Yeah, that doesn't matter too much, I think.: 0.9125, How long would it take to make the frequency counts with a Java hash table?: 0.6187499999999999, No, how long you would have to program something.: 0.5, Because it's quite easy in Perl as well: 1.165625, , it's just a line of code for counting all the words: 1.30625, , it's it's by hashes.: 2.003125, I dry-read it the last time..: 0.17187499999999997, Next week.: 0.05625, Uh mine's gonna be mostly using the off-line.: 1.36875, But the actual stuff it's doing will be on-line.: 1.25, But it won't be very um processor intensive or memory intensive, I don't think.: 1.3625, Don't think so.: 0.809375, Are we still gonna go for dumping it into a database?: 0.38437499999999997, Are we still gonna dump it into a database?: 0.3, 'Cause: 0.05, if we are, I reckon we should all read our classes out of the database.: 0.053125000000000006, It'll be so much easier.: 0.22187500000000002, Well if we're gonna dump the part of it into a database anyway, we might as well dump all the fields we want into the database, calculate everything from there.: 0.809375, Then we don't even have to worry that much about the underlying X_M_L_ representation.: 0.6531250000000001, We can just query it.: 0.0125, Well if we're gonna do that, we should try and store everything in in an X_M_L_ format as well.: 0.528125, Well we don't even need to do that, 'cause if we got our information density calculated off-line, so all we do is treat the whole lot as one massive document.: 1.615625, I mean they'll: 0.365625, it's not gonna be so big that we can't load in a information density for every utterance.: 2.1718750000000004, And we can just summarise based on that.: 0.009375000000000001, I think you can do it on-line.: 0.4375, I don't think there's really much point in doing like that when it's just gonna feed off in the end the information density measure basically.: 3.55625, And that's all calculated off-line.: 1.109375, So what you're really doing is sorting a list, is the p computationally hard part of it.: 0.4156249999999999, Well like the ideas we're calculating are information density all off-line first for every utterance in the whole corpus, right?: 0.9875, So what you do is you say: 0.11875, if you're looking at a series of meetings, you just say well our whole document comprises of all these stuck together.: 0.89375, And then all you have to do is sort them by j information density.: 0.41875, Like maybe weighted with the search terms, and then extract them.: 0.17500000000000002, I don't think it's too slow to do on-line, to be honest.: 1.909375, Well, on the utterance level I was thinking.: 0.284375, So the utterances with the highest like mean information density.: 0.55625, Well the trouble with doing it on the word level is if you want the audio to synch up, you've got no way of getting in and extracting just that word.: 0.73125, I mean it's impossible.: 1.25, For every single word?: 0.20625, Oh, okay.: 0.01875, I don't think that will do it.: 0.809375, We'll have to buffer it.: 0.125, Well the skimming's gonna use the importance.: 1.34375, But like at first it's just gonna be I_D_F_.: 1.25625, Well mostly skimming,: 0.046875, Well the nice thing about that is: 0.165625, it will automatically be in sentences.: 0.015625, Well more or less.: 0.03125, So it will make more sense, and if you get just extract words.: 0.440625, I see it.: 0.071875, But it'll need to be calculated at word level though because otherwise there won't be enough occurrences of the terms to make any meaningful sense.: 1.2312500000000002, Yeah, I reckon you can just mean it over the sentence.: 0.25625, I think we should filter them.: 0.35625, Maybe we should have like um a cut-off.: 0.11875000000000001, So it a w word only gets a value if it's above a certain threshold.: 1.2093749999999999, So anything that has less than say nought point five importance gets assigned to zero.: 0.3, Yeah, that's the other th: 1.046875, I think we'll have to buffer the audio.: 0.503125, But I don't think it will be very hard.: 0.828125, I think it would be like an hour or two's work.: 1.7687499999999998, Like just build an another f wave file essentially.: 0.2625, Yeah, I mean I bet there would be packages In memory,: 0.60625, So just like unp there's bound to be like a media wave object or something like that.: 1.190625, And just build one in memory.: 0.321875, I don't know.: 0.64375, I have no idea.: 0.025, But it must have like classes for dealing with files.: 0.08750000000000001, And if it has classes for concatenating files, you can do it in memory.: 0.1375, So Well what I think I might try and build is basically a class that you just feed it a linked list of um different wave-forms, and it will just string them all together with maybe, I don't know, tenth of a second silence in between each one or something like that.: 1.96875, Oh yeah,: 0.01875, yeah, we'll need that.: 0.24375, We also really wanna be able to search by who's speaking as well.: 1.3031249999999999, It doesn't matter, 'cause all the calculation's done off-line.: 1.65625, That's easy.: 1.0625, You just like create a new X_M_L_ document in memory.: 0.178125, I don't think it's really that much of a problem because if it's too big, what we can do is just well all the off-line stuff doesn't really matter.: 3.9625000000000004, And all we can do is just process a bit at a time.: 0.1875, Like for summarisation, say we wanted a hundred utterances in the summary, just look at the meeting, take the top one hundred utterances in each other meeting.: 1.3, If it scores higher than the ones already in the summary so far, just replace them.: 0.13125, And then you only have to process one meeting at a time.: 0.5968749999999999, Okay, so maybe we should build a b store a mean measure for the segments and meetings as well?: 0.65, And speaker.: 0.015625, Speaker and um topic segmenting we'll need as well.: 0.37187499999999996, and then it'll f preserve the order when it's displayed: 1.2125, Yeah, I think so.: 0.34375, So we should basically make our own X_M_L_ document in memory that everyone's um module changes that, rather than the underlying data.: 1.5125000000000002, _ document tied to the interface.: 0.109375, Well, you can make it in a file if you want.: 0.359375, They are utterances, aren't they?: 0.615625, The segments are utterances, aren't they?: 0.7250000000000001, Well, that's easy.: 1.0625, Well it's close enough, isn't it?: 1.490625, It may not be exact every time, but it's a so sort of size we're looking for.: 1.7156249999999997, But why don't we just write it as a new X_M_L_ file?: 0.659375, Can NITE handle just loading arbitrary uh new like attributes and stuff?: 0.221875, I mean, I would have thought they'd make it able to.: 0.8593750000000001, So why do we need to have two X_M_L_ trees in memory at once?: 0.253125, The other thing is that would mean we'd be using their parser as well, which means we wouldn't have to parse anything, which be quite nice.: 1.84375, 'Cause their parser is probably much faster than anything we've come up with anyway.: 0.56875, Yeah, I mean we can process it in chunks if it gets too big basically.: 0.4875, We can just process it all in chunks if it gets too big to load it into memory.: 0.290625, I think we probably want to store Sorry.: 0.775, I think we probably want to store um a hierarchical information density as well.: 0.89375, So like an informan mation density score for each meeting and each topic segment.: 0.4375, 'Cause otherwise we'd be recalculating the same thing over and over and over again.: 0.365625, And that will obviously make it much easier to display.: 0.296875, Well it may not for the whole meeting, but like Yeah, exactly.: 0.44062500000000004, Well, we can start off like that.: 0.065625, Well I was gonna start off: 0.284375, I've: 0.075, v got sort of half-way through implementing one that does just I_D_F_.: 0.6437499999999999, And then just I can change that to work on whatever.: 0.140625, And it should be weighted by stuff like the hot spots and um the key-words in the search and stuff like that.: 0.5218750000000001, Did he not say something about named entities?: 0.31249999999999994, So I thought he said there wasn't very many.: 0.603125, It's not T_F_I_D_F_: 1.0, , it's just inverse document frequency.: 1.13125, 'Cause it's really easy to do basically.: 1.296875, There's just like for a baseline really.: 1.1281249999999998, Well, I'm half-way through.: 0.25, It's not working yet, but it will do.: 1.05625, And then averaging it over the utterances.: 0.15312499999999998, But it's not like um related to the corpus at all.: 1.059375, It's just working on an arbitrary text file at the moment.: 1.3406249999999997, It would be useful to know how everyone's gonna store their things though.: 1.875, Well I've got like a few hours free.: 0.15625, It's the most boring task.: 1.0187499999999998, Or at least um simple versions of them.: 0.034375, So maybe we should try doing something really simple, like just displaying a whole meeting.: 0.8531249999999999, And like just being able to scroll through it or something like that.: 0.2, Are you free after this?: 0.015625, 'Cause I'm off all Friday.: 0.23125, Uh Wednesday I've got a nine 'til twelve.: 0.17812500000000003, Yeah, nothing in the afternoon.: 0.028125, I've got nothing in the afternoon.: 0.15937500000000002, So you ha: 0.009375, Uh I'll be in um the Appleton Tower anyway.: 0.16875, Um well I'll be there from twelve.: 0.13125, I've got some other stuff that needs done on Matlab, so if you're not there at twelve, I can just work on that.: 0.56875, Why w: 0.05, I'm just building a dictionary.: 0.253125, Oh, mine's just gonna use the um hash map one in um Java.: 1.5781249999999998, 'Cause I'm only gonna do it on small documents.: 0.475, It's just like bef until the information density is up and running.: 1.1593750000000003, Just something to get give me something to work with.: 0.54375, So it's only gonna use quite small documents, you see, to start with.: 1.546875, Why does it need to be classified into like different segments?: 0.365625, Can we just fill a second class with junk that we don't care about?: 0.496875, Like, I don't know, copies of Shakespeare or something.: 0.8125000000000001, 'Cause if what we're looking for is the um frequency statistics, I don't see how that would be changed by the classification.: 1.1625, Well there maybe another tool available?: 0.140625, Um I can't remember who's got it.: 1.559375, Might be WordNet.: 0.05625, But one of these big corpuses has a list of stop words that you can download and: 0.528125, they're just basically lists of really uninteresting boring words that we could filter out before we do that.: 0.68125, It's like: 1.0, that's one: 1.228125, the papers I read: 0.01875, , that's um one things they did right at the beginning: 1.3624999999999998, is they've got this big s stop-list: 0.25625000000000003, and they just ignore all of those throughout the experiment.: 0.009375000000000001, Yeah, I it would be useful for me as well.: 0.33125, uh I think that'd be useful for me as well.: 0.515625, Well all you really wanna do is look into getting some sub-set of the ICSI corpus off the DICE machines.: 0.33749999999999997, 'Cause I hate working on DICE.: 0.1, It's awful.: 1.003125, Like so I can use my home machine.: 0.115625, ha has a C_D_ burner though.: 0.05625, has a C_D_ burner.: 0.00625, The right-hand corner, far right.: 0.203125, How big is it without um the WAV files and stuff?: 0.30625, 'Cause: 0.05, I could just say at um going over S_C_P_ one night and just leave it going all night: 0.5343749999999999, It's yeah,: 1.0, I mean the wave data are obviously not gonna get off there completely.: 0.759375, Really?: 0.11875, Oh right?: 0.096875, I'll see if I can S_C_P: 0.190625, _ it, I suppose.: 0.00625, I've got a Linux box and a Windows box.: 0.146875, So Broad-band.: 0.009375000000000001, Put it on to C_D_.: 0.04375, I can if I get down I can put to C_D_.: 0.15625, I'm not sure if there's enough space.: 1.284375, Is how much do we get?: 0.19375, Really?: 0.11875, but I can do it from that session, can't I?: 0.5125, You can compress it from a remote session and S_C_P: 0.025, _ it from the same session?: 0.0125, Do you think?: 0.34375, Oh no no, I was thinking of SSHing just into some machine and then just SCPing it from there.: 0.09375, I mean it has to go through the gateway.: 0.35625, Mm, I see.: 0.071875, So you could: 0.1125, just But th first, uh how big are the chunks?: 0.20625000000000002, How big are the chunks you're looking at?: 0.3375, So quite small then.: 0.121875, So you could just um you could use just the same thing we used to build the big dictionary.: 0.6281249999999999, You just do that on-line 'cause that won't take long to build a little dictionary that big, will it.: 0.9031249999999998, I mean just use the same tool that we use.: 0.384375, It doesn't need ordered, no.: 0.6124999999999999, Um well that's the t are you using T_F_I_D_F_ for the information density?: 1.175, Like 'cause frequency would be useful, I think.: 0.778125, But um depending on the context, the size, and what we consider a document in the sense of calculating T_F_I_D_F_ is gonna change.: 0.41875, Which might need thinking about.: 0.221875, I think it would be useful,: 0.6749999999999999, Well you need the raw frequency as well.: 0.22187500000000002, But um you also need how many times things occur within each document.: 0.42812500000000003, And um what we consider a document's gonna depend on our context, I think.: 1.6687500000000002, 'Cause if we're looking at the whole lot of meetings, we'll consider each meeting a document in sort of terms of this algorithm.: 1.340625, And if we're viewing like say just a small topic segment you might look at even each utterance as a small document.: 0.921875, Yeah, but the thing is um It's gonna need some th th thought of how we Actually maybe it doesn't actually matter.: 2.4062500000000004, Maybe if you just do it once at the highest level, it it will be fine.: 0.2625, But I was just thinking it might be difficult to calculate the T_F_I_D_F_ off-line for all the different levels we might want.: 0.571875, 'Cause if we're gonna allow disjoint segments for example, then how are we gonna know what's gonna be in context at any given time?: 2.378125, But I suppose if you just did it globally, treating a meeting as a document, it'd probably still be work out fine, because you'd only be comparing to ones within the context.: 1.01875, Uh I don't know, I thought were you gonna use that in the end?: 1.053125, The information density.: 0.13437500000000002, Oh sorry, that's what I mean.: 1.29375, Like um yeah, for each word or whatever, but across the whole lot is what I mean by highest level.: 0.8343749999999999, Like across the whole corpus.: 0.275, Yeah, but you'd probably look at each meeting as a document.: 0.7437499999999999, Mm possibly.: 0.00625, Are they big enough to get anything meaningful out of?: 0.27812499999999996, it's not an issue.: 1.003125, You just concatenate an X_M_L_ file together.: 0.221875, but we still want to have like a notion of meetings for the user.: 0.25625, Yeah, sure.: 0.065625, Yeah, you just like whatever you want to look at, you just jam together into an X_M_L_ file and that's your meeting, even though bits of it may come from all over the place or whatever.: 1.8906249999999998, I mean I don't see why that's really a big problem.: 2.015625, So basically what you're saying is you can take an arbitrary amount of data and process it with the same algorithm.: 0.5625, It doesn't matter conceptually what that data is.: 0.6375, It could be a meeting.: 0.31875, it could be two utterances.: 0.32499999999999996, it could be a meeting plus half a meeting from somewhere else.: 0.58125, I don't think it's very difficult though.: 1.8624999999999998, I mean what you do is you just build an X_M_L_ file, and if you want it to get down to the utterances, you'd go to the leaves.: 1.053125, And then if you wanted the next level up, you'd go to the parents of those and like just go from like the leaves inwards towards the branch to build up things like um you know,: 0.7781250000000001, when you click on a segment, it's gonna have like words or whatever that are important.: 1.528125, As long as like the algorithms are designed um with it in mind, I don't think it's a very big problem.: 1.971875, Well like say you had um like say for a meeting,: 0.44375, right, you've got like uh say a hierarchy that looks quite big, like this.: 0.521875, And like the utterances come off of here maybe.: 0.259375, Then when whatever your algorithm is doing, as long as when you're working with utterances, you go for all the leaves, like then if you need something next up, so like a topic segment, you'd go to here.: 1.34375, But if you were looking at say this one, so only went like this.: 0.38125, Right, so you: 0.078125, it's same, you'd start with the leaves, and you go: 1.309375, oh, I want a topic segment.: 0.315625, So I go one layer up.: 0.325, See, and then if you're working with just a topic segment in there, it's the only thing you have to worry about.: 1.634375, And like each time you want a higher level, you just need to go up the tree.: 0.6281249999999998, And as long as your algorithm respects that, then we can just process any arbitrary X_M_L_ file with whatever hierarchical structure we want.: 0.49687499999999996, A meeting, say, and that would be a topic segment.: 0.7874999999999999, So I think as long as you build an algorithm that respects whatever structure's in the file, rather than imposing its own structure: 1.7437500000000001, Well no, it doesn't have to be.: 0.465625, But I mean it could be as many nodes as you want.: 0.515625, Like this one could be deeper maybe, say.: 0.5625, So then you'd start with all your utterances here, and when you go up to get topic segments, you go to here here here here here here here.: 0.865625, That might be a bit confusing though 'cause you have things on different levels.: 0.378125, So we'll see if we can get like a mini-browser just displays two things synched together of some kind.: 0.53125, It'd be useful.: 0.171875, I don't know who you see about that though.: 0.7562500000000001, I d have no idea.: 0.025, I've probably got a reasonable amount because um everything on my DICE account can actually be deleted 'cause I store it all at home as well.: 0.6375000000000002, Is that guaranteed to stay, the Maybe you should send a support form.: 0.140625, Just say we want some web space.: 0.265625, 'Cause: 0.05, that'd be really useful: 0.29062499999999997, is if we had a big directory.: 0.115625, Especially for transferring stuff.: 0.146875, Having said that, are we allowed to take a copy of the ICSI corpus?: 0.1875, Something we should probably ask before we do it..: 0.425, No, me neither.: 0.003125, Might be funny to see what is summarised the whole corpus as anyway.: 0.45625, I think it'd be very useful.: 0.515625, But We can just change the code.: 0.065625, That's quite good.: 1.140625, I could just use it with the frequency, I think, until the information density thing's finished.: 1.865625, That would be really useful.: 0.44999999999999996, If you're doing it in Java, could you um serialize the output as well as writing it to a file?: 0.453125, If you're doing it in Java, could you serialize the um dictionary,: 0.36562500000000003, yeah, as well as writing it to a file?: 0.140625, It's really easy.: 1.18125, I don't see why it'd be any more massive than the file.: 0.834375, It just saves you parsing the um file representation of it.: 0.16249999999999998, And now 'cause I would be using it in Java anyway.: 0.434375, So I'd just be building the data structure again.: 0.33125, Yeah, but it seems like a bit silly to be parsing it over and over again kinda thing.: 0.209375, I would've thought that um I think all the collections and things implement serializable already.: 0.8625000000000002, I think they might do.: 0.4, Tonight I'll try and um I'll either work some more on uh the T_F_I_D_F_ summarizer or do the audio thing.: 0.521875, Do we have to demonstrate something next week?: 0.23124999999999998, Yeah, I know.: 0.178125, I think it's 'cause we had to specify it ourselves that it's not as um like focus the specification of most um work we have to do.: 2.4718750000000003, Once we start doing it it will all become more or less obvious: 0.10312500000000001, I think anyway.\n",
      ": 0.39375, Does anyone want to see uh Steve's feedback from the specification?: 1.2375, Right.: 0.078125, Not really, um just what he's talking about, like duplication of effort and Like duplication of effort and stuff, and: 1.3031250000000003, um yeah, he was saying that we should maybe uh think about having a prototype for week six, which is next week.: 0.5625, So we should probably prioritize our packages.: 0.25, Has has anyone actually looked at the Java code for the: 0.178125, , huh? Hmm.: 0.00625, Yeah, I think so.: 0.34375, Yeah, I I don't know about the search functionality, that might be online.: 0.7500000000000001, Depends how it's gonna work.: 1.29375, Yeah, that makes sense.: 0.0625, Yeah, you just concatenate them together.: 0.0875, It just means it loads on demand.: 0.0625, It only loads when it needs a particular type of file.: 0.21875, Like when it's being accessed.: 1.003125, Yeah, I think that's the idea, it just loads the particular ones it needs.: 1.4468750000000001, But if you were doing a search over the whole corpus you'd have to load them all.: 0.5031249999999999, Yeah, we do not want it in to develop a little tree display as well for multiple results.: 0.25937499999999997, Yeah, but that'd be quite easy to do.: 0.3, You just need to find the time stamp.: 0.296875, Yeah, I think I think those segments for each utterance are split up.: 0.9249999999999999, Think so.: 0.34375, Yeah, I'm pretty sure it's already there.: 1.3, Pretty sure that's already there.: 1.1187500000000001, The the utterances are numbered.: 0.159375, Yeah, I think so.: 0.34375, Ye that's the impression I get,: 1.1187500000000001, Oh.: 0.01875, Yeah, uh Right.: 0.078125, Topics,: 0.04375, Yeah, I think that's the right one.: 1.65, Yeah, that'd be much more efficient to do that.: 0.21875, Yeah, you're able to do that in Java,: 0.215625, Huh.: 0.00625, Yeah, I've had a b I've had a look at the the topic segments, how it's stored.: 1.503125, And then yeah, th those are few per meeting, and it um: 0.275, well, it gives a time stamp and inside each one there's uh the actual like utterance segments.: 1.63125, And the list of them that occurred.: 0.037500000000000006, And they're all numbered.: 0.19375, Um so that's where that's stored.: 2.0125, Yeah, so I guess um if I'm gonna be segmenting it with a L_C_ seg: 0.46249999999999997, then that's like same format: 1.0125, I'd want to um put it back out in so it'd be equivalent.: 0.45625, Well, like the integration.: 0.0125, What do you mean, integration?: 0.259375, I don't know.: 0.64375, I don't think anyone's been allocated to do that yet.: 1.853125, Yeah, definitely.: 0.015625, Yeah, it c could be difficult,: 0.153125, Well I guess the important thing is to get the crucial m modules built.: 0.34687499999999993, and then we'll maybe have to prioritize somebody into just integrating it.: 0.253125, Yeah, I think so.: 0.34375, Jasmine, I thought you just said that you'd uh looked at extracting the text.: 0.37500000000000006, So you you said you did it in Python,: 0.05625, Yeah, did you use uh b the X_L_ uh X_M_L_ parser in Python?: 0.10625, Right.: 0.078125, Yeah, sounds pretty good.: 0.06875, So um 'cause, yeah, I was having a look in it a look at it as well: 0.23125, and I noticed the um the speakers are all in that separate file?: 0.16875, So did did you have to combine them all and and then re-order them?: 0.040625, c: 0.028125, Right.: 0.078125, Yeah, so that's approach um: 1.003125, well, I was going to do.: 0.028125, So yeah, we may as well collaborate.: 0.015625, In the word files?: 0.175, I'm not sure I what you mean.: 0.49375, Oh right.: 0.096875, Mm I thought they were local to th a particular meeting.: 0.334375, Mm is there anything else we should discuss?: 0.0875, Yeah, should we not have like a group directory or something where we can put all our code in and that kinda thing?: 0.453125, I've gotten mm hardly any Hmm.: 0.08125, Yeah, we can ask Steve if um we can get space.: 0.140625, Yeah, uh we could do that.: 0.1125, Yeah, I'm sure he had to deal with that last year.: 0.26875000000000004, That sounds good.: 0.053125, Yeah, that's what I'm gonna need.: 1.525, Yes.: 0.009375, Yeah, it's just mo changing it a bit.: 1.034375, but uh that's what M_L_C_ seg does.: 1.00625, it marks the end of each segment.: 0.140625, Oh.: 0.01875, Yeah, for me it's better if they're by meeting.: 1.403125, Then that'll be really easy to do once they've got the raw text.: 0.565625, It's just a case of running the script.: 1.0375, Yeah, I mean hopefully this week.: 0.275, And we could Don't know.: 0.75625, Suppose we're just getting on with all our components.: 0.22187500000000002, So I know.: 0.178125, Wa: 0.00625, Yeah, he suggested that we could have an uh initial prototype.: 0.1375, I know, I'd b: 0.346875, I'd be surprised if we can get anything working by next week.: 0.403125}\n"
     ]
    }
   ],
   "source": [
    "print(sentence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7hxcNtTanVo"
   },
   "outputs": [],
   "source": [
    "select_length = int(len(sentence_tokens) * 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0k63z6vanVo",
    "outputId": "8ddd5c30-7b31-4649-9cb9-72699ec7b85e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[What I'm like what we have to think about is if we go with this multi-level idea, like this idea that sort of if you start with a whole meeting series as one entity, as one thing that you display, as one whole sort of, that then the individual chunks of the individual meetings, whereas and then you can click on a meeting, and then sort of the meeting is the whole thing and the chunks are the individual segments, that means sort of we have multiple levels of of representation, which we probably If we if we do it this way like we f we have to discuss that if we do it this way, then we should probably find some abstraction model, so that the interface in the sense like deals with it as if it's same so that the interface doesn't really have to worry whether it's a meeting in the whole meeting series or a segment within a meeting,\n",
       " And for all together, like the display itself, I think we are easier if we if it's sitting on the X_M_L_ than if it's sitting on the S_Q_L_ stuff, because if it's sitting on the X_M_L_, we have the the NITE X_M_L_ framework with all its functionality for synchronizing through all the different levels whenever there's a change, whenever something's moving forward and stuff.,\n",
       " Yeah, I think today's meeting is really the one where we where we sort of settle down the data structure and as soon as we have that, uh probably like after today's meeting, we then actually need to well go back first of all and look at NITE X_M_L_ to see in how far that that which we want is compatible with that which NITE X_M_L_ offers us.,\n",
       " I don't think it's really that much of a problem because if it's too big, what we can do is just well all the off-line stuff doesn't really matter.,\n",
       " I don't think there's really much point in doing like that when it's just gonna feed off in the end the information density measure basically.,\n",
       " So it it seems that the data structure isn't a big problem and that basically we don't have to have all these massive discussions of how we exactly interact with the data structure because most of our work isn't done with that data structure in memory in the browser, but it's just done off-line and everyone can ha represent it anyway,\n",
       " You know what I mean, like if if there's a lot of bureaucracy involved with having two different trees and whether one ties to the other because the one has the weight for the other, then it's probably quicker to,\n",
       " because like the the ICSI corpus isn't isn't one meeting series, it's several meeting series with different people meeting for completely different things.,\n",
       " And for in the display it's probably better if you have whole utterances than I don't know, like what it's like,\n",
       " But I was thinking of the topic segmentation now and and f for that there would only be one, right, because it's sort of like it's just a time window.,\n",
       " So how much do they display, and starting position at where the or maybe the mid-position of it, I don't know, like w if start where the thing was found or if that thing wa was found it's in the middle of the part that we display, that I don't know.,\n",
       " Like if there's some name of some conference, they would could probably say that name of the conference quite often, even though he's right that they make indirect references to it.,\n",
       " like even if we maybe this whole like maybe I'm worrying too much about the whole series in one thing display, because actually I mean probably users wouldn't view that one too often.,\n",
       " Like my experience with the British National Corpus was that there's far more word types than you ever think because anything that's sort of unusual generally is a new word type.,\n",
       " , you know what I mean, like sort of sort of for the whole series chunks representing the individual meetings or some Like something that represents the whole series in in a v in a structure very similar to the structure in which we represent individual um meetings, but with data sort of always combined from the whole series.,\n",
       " So somebody should sort of be the one person who's who understands most about what's t centrally going on with with the with the project, like with the with the browser as a whole and where the data comes in and Any volunteers?,\n",
       " And in that way we could probably use the same algorithm and just like make vir like one or two ifs that say okay, if you are on a whole document uh a whole series level and that was a double-click, then don't just go into that um segment, but load a new file or something like it, but in general use the same algorithm.,\n",
       " it's sort of like one person's contribution at a time sort of thingy dingy.,\n",
       " probably it wouldn't be the best thing if it's just the high most highly ranked phrase or key-word because like for example for an introduction that would most definitely not be anything that has any title anywhere similar to introduction or something.,\n",
       " Yeah, I mean if it's just for one meeting, it's really not too big.,\n",
       " So but that means in the general structure we're actually quite lucky, so we we have we load into memory for the whole series of meetings just the utterances and rankings for the utterances and some information probably that says, well, the I guess that goes with the utterance, who's speaking.,\n",
       " I don't think that's a good idea because isn't it like that we expect th there to change over i b with the different topic segments more?,\n",
       " Well but also about the displays, I mean the displays in the in the text body, in the in the latest draft that we had sort of we came up with the idea that it isn't displaying utterance for utterance, but it's also displaying uh a summarised version in you know, like below the below the graph, the part.,\n",
       " Also like for this part, maybe if we go over it with named entity in the end, if I mean w if one of the people doing DIL has some named entity code to spare, and just like at least for the for sort of for finding topics, titles for for segments, just take a named entity which has a really high, what's it called,,\n",
       " I'm just thinking for this whole thing of like a different level, sort of cutting out different different pieces, whether we do that through a query where we say give us everything that's ab above this,\n",
       " It's Think they say um quite a lot of numbers and before that, uh um there's this number.,\n",
       " But that we can decide about, but a general sort of It's the same thing if like whether you play and it moves forward or whether you jump to a position through search, it's essentially for all the window handling,\n",
       " even if you go on an per utterance level, there's still some merit on within utterances cutting out stuff which clearly isn't relevant at all, and that maybe also for the audio we'd have to do.,\n",
       " if it i let's say I mean if if their query language is strange and if it would return b ten million results and it can't handle it, then we can just write our individual components in the way that they know which what the threshold is.,\n",
       " Yeah, now I'd say if for the prototype if we just like wherever possible p chunk in the stuff that we have um pre-annotated and stuff, and for the stuff that we don't have pre-annotated write like a stupid baseline, then we should probably be able to basically that means we focus on on the interface first sort of, so that we we take the the ready-made parts and just see how we get them work together in the interface the way we want,\n",
       " the only thing that would happen basically if I double-click let's say from the whole meeting series on a single meeting, is that the zoom level changes.,\n",
       " It more and more appears to me that if we if we scrap the notion of the meeting as an individual thing and sort of ju see meetings as as topic segments and have sort of like hierarchical topic segmentation instead, then it's b like a more coherent framework.,\n",
       " Sort of c I was just thinking you know like if if the overhead for having the same amount of data coming from two d files instead of from one file is massive then it would probably be for us easy to just like off-line put the the weight into into the file that has the segments, uh yeah, segments slash utterances already.,\n",
       " Well you can probably also you can probably pre-filter like with regular expressions even just say if it consists of only dig digits, then skip it, or even if it consists any special characters, then skip it because it's probably something with a dot in between, which is usually not something you wanna have,\n",
       " Because it's it's less stuff to store probably for Dave in the in the audio playing.,\n",
       " I think it's 'cause we had to specify it ourselves that it's not as um like focus the specification of most um work we have to do.,\n",
       " and and the interface, so the interface is mainly while it's running just working on data that's just loaded from a file, I guess.,\n",
       " It's um I think it's just the dictionary in the first place.,\n",
       " Yeah, but the thing is um It's gonna need some th th thought of how we Actually maybe it doesn't actually matter.,\n",
       " 'Cause before we have that, it's gonna be very difficult for anyone to really see how much the work that they're doing is making sense because you just well I guess you can see something from the data that you have in your individual,\n",
       " 'Cause if we're gonna allow disjoint segments for example, then how are we gonna know what's gonna be in context at any given time?,\n",
       " Um but that's still sort of that's good.,\n",
       " That's what I'm guessing that's, you know, um,\n",
       " Who's who's sort of doing the the the central coordination of of of the browser application now?,\n",
       " But I'm I'm still confused 'cause I thought like that's just what Jonathan said we do c that we can't do, like load a massive document of that size.,\n",
       " Like if if if the same thing is in different files, would it then maybe like, you know, if if utterances are split over three or ten or w hundred different files, is then a chance maybe that it doesn't try to load them all into memory at the same time, but just So why does it fail then in the first place?,\n",
       " the building the browser comes first, and then only comes the creating new sophisticated data chunks, because that's sort of the whole thing about having a prototype system which is more or less working on on chunk data.,\n",
       " I think we are running queries, it's not just about um what we load and what we don't load, but we're l running queries in the sense that we dynamically select by by weights,\n",
       " I have always thought it's like more that oh, whatever, I'm a can't think of it at the moment.,\n",
       " So so um I will probably send um just one file of the first meeting um to all those who need it so that you can have a look whether that's what you want.,\n",
       " So if you find that the player accepts some n input from memory, and if it's easy to do, then I guess that's,\n",
       " I think he's talking about sort of the ones that Yeah, if you if you enter the big room, in the right-hand corner, I think.,\n",
       " So at at every level everyone has to be careful to really just take even at the highest level, just take stuff from one series and not merge stuff from different series together because they would probably be just majorly messy.,\n",
       " And I mean if you if you know how to do it for individual words, then you can just in the worst case, if you can't find anything else, just sort of make the mean of the words over the utterance.,\n",
       " it's not gonna be so big that we can't load in a information density for every utterance.,\n",
       " It's it's quite strange.,\n",
       " Yeah, sort of like off-line create a virtual meeting, which which basically treats the meeting series as if it was a meeting, and treats the individual meetings within the series as if they were segments, and treats the individual segments within meetings as if they were um utterances.,\n",
       " Who actually like for this whole discussion I mean, who of us is doing stuff that is happening on-line and who of us is doing stuff that's happening off-line?,\n",
       " If maybe if we realise that there's massive differences in in gain or in something, you can probably just make some simple simple normalization, but that really depends on how much time we have and and how much is necessary.,\n",
       " Yo, Forrest Hill, whatever one's easier to discuss stuff, I don't know.,\n",
       " So I'm just wondering if there's ways to abandon the whole concept of of meetings and sort of but just not really treating separate meetings as too much of a separate entity.,\n",
       " Oh, so that's what f Rainbow does, because that's what L_S_A_ builds on.,\n",
       " At the moment it's it's just lines of Mm-hmm.,\n",
       " What's what's nine megabyte?,\n",
       " Yeah, I mean there's one series that has just one meeting.,\n",
       " and and a topic's basically they are just on the I_D_, probably with a start time or something, and and the utterances referenced to those topics I guess.,\n",
       " I mean I don't see why that's really a big problem.,\n",
       " And even though probably if there's a lot of over-head in having two different files, we can probably merge the weights into it off-line.,\n",
       " Um so that's where that's stored.,\n",
       " Like it's it's the sa,\n",
       " There's a there's a serialise command,\n",
       " , it's it's by hashes.,\n",
       " So, it's a Yeah, but that's,\n",
       " Um but that that's enough data for the skimming and the the searching, so what the searching does is the searching leaves the whole framework, goes to the S_Q_L_ database and gets like basically in the end gets just a time marker for where that is, like that utterance that we are concerned with.,\n",
       " As long as like the algorithms are designed um with it in mind, I don't think it's a very big problem.,\n",
       " I mean if you think if it's r roughly a million words and nine characters per word sounds realisti,\n",
       " So Well what I think I might try and build is basically a class that you just feed it a linked list of um different wave-forms, and it will just string them all together with maybe, I don't know, tenth of a second silence in between each one or something like that.,\n",
       " It would probably find another number task quite easily seeing that it's a constrained vocabulary with a high co-occurrence of the same nine words.,\n",
       " so like if even if we make one single text file which has the whole corpus, sort of our corpus, that would still be from one series only.,\n",
       " No no, not demonstrate, but like didn't you say that uh didn't we sort of agree that it would be useful to have a demonstrator of it, like some primitive thing working next week.,\n",
       " I don't think it's too slow to do on-line, to be honest.,\n",
       " So alternatively, if we realise we can't do the whole thing in one go, we can probably just process some sort of meta-data,\n",
       " Yeah, you just like whatever you want to look at, you just jam together into an X_M_L_ file and that's your meeting, even though bits of it may come from all over the place or whatever.,\n",
       " It would be useful to know how everyone's gonna store their things though.,\n",
       " I could just use it with the frequency, I think, until the information density thing's finished.,\n",
       " , it's probably just those people have to work together a lot and very closely and just make sure that they're always f,\n",
       " I don't think it's very difficult though.,\n",
       " I think before we can like answer that specific question how we c deal with that, it's probably good for us to look at what the audio player is capable of doing.]"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYYE-cn1anVo",
    "outputId": "215859b7-7aaa-4029-de4e-b9eb080b5811"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What I'm like what we have to think about is if we go with this multi-level idea, like this idea that sort of if you start with a whole meeting series as one entity, as one thing that you display, as one whole sort of, that then the individual chunks of the individual meetings, whereas and then you can click on a meeting, and then sort of the meeting is the whole thing and the chunks are the individual segments, that means sort of we have multiple levels of of representation, which we probably If we if we do it this way like we f we have to discuss that if we do it this way, then we should probably find some abstraction model, so that the interface in the sense like deals with it as if it's same so that the interface doesn't really have to worry whether it's a meeting in the whole meeting series or a segment within a meeting And for all together, like the display itself, I think we are easier if we if it's sitting on the X_M_L_ than if it's sitting on the S_Q_L_ stuff, because if it's sitting on the X_M_L_, we have the the NITE X_M_L_ framework with all its functionality for synchronizing through all the different levels whenever there's a change, whenever something's moving forward and stuff. Yeah, I think today's meeting is really the one where we where we sort of settle down the data structure and as soon as we have that, uh probably like after today's meeting, we then actually need to well go back first of all and look at NITE X_M_L_ to see in how far that that which we want is compatible with that which NITE X_M_L_ offers us. I don't think it's really that much of a problem because if it's too big, what we can do is just well all the off-line stuff doesn't really matter. I don't think there's really much point in doing like that when it's just gonna feed off in the end the information density measure basically. So it it seems that the data structure isn't a big problem and that basically we don't have to have all these massive discussions of how we exactly interact with the data structure because most of our work isn't done with that data structure in memory in the browser, but it's just done off-line and everyone can ha represent it anyway You know what I mean, like if if there's a lot of bureaucracy involved with having two different trees and whether one ties to the other because the one has the weight for the other, then it's probably quicker to because like the the ICSI corpus isn't isn't one meeting series, it's several meeting series with different people meeting for completely different things. And for in the display it's probably better if you have whole utterances than I don't know, like what it's like But I was thinking of the topic segmentation now and and f for that there would only be one, right, because it's sort of like it's just a time window. So how much do they display, and starting position at where the or maybe the mid-position of it, I don't know, like w if start where the thing was found or if that thing wa was found it's in the middle of the part that we display, that I don't know. Like if there's some name of some conference, they would could probably say that name of the conference quite often, even though he's right that they make indirect references to it. like even if we maybe this whole like maybe I'm worrying too much about the whole series in one thing display, because actually I mean probably users wouldn't view that one too often. Like my experience with the British National Corpus was that there's far more word types than you ever think because anything that's sort of unusual generally is a new word type. , you know what I mean, like sort of sort of for the whole series chunks representing the individual meetings or some Like something that represents the whole series in in a v in a structure very similar to the structure in which we represent individual um meetings, but with data sort of always combined from the whole series. So somebody should sort of be the one person who's who understands most about what's t centrally going on with with the with the project, like with the with the browser as a whole and where the data comes in and Any volunteers? And in that way we could probably use the same algorithm and just like make vir like one or two ifs that say okay, if you are on a whole document uh a whole series level and that was a double-click, then don't just go into that um segment, but load a new file or something like it, but in general use the same algorithm. it's sort of like one person's contribution at a time sort of thingy dingy. probably it wouldn't be the best thing if it's just the high most highly ranked phrase or key-word because like for example for an introduction that would most definitely not be anything that has any title anywhere similar to introduction or something. Yeah, I mean if it's just for one meeting, it's really not too big. So but that means in the general structure we're actually quite lucky, so we we have we load into memory for the whole series of meetings just the utterances and rankings for the utterances and some information probably that says, well, the I guess that goes with the utterance, who's speaking. I don't think that's a good idea because isn't it like that we expect th there to change over i b with the different topic segments more? Well but also about the displays, I mean the displays in the in the text body, in the in the latest draft that we had sort of we came up with the idea that it isn't displaying utterance for utterance, but it's also displaying uh a summarised version in you know, like below the below the graph, the part. Also like for this part, maybe if we go over it with named entity in the end, if I mean w if one of the people doing DIL has some named entity code to spare, and just like at least for the for sort of for finding topics, titles for for segments, just take a named entity which has a really high, what's it called, I'm just thinking for this whole thing of like a different level, sort of cutting out different different pieces, whether we do that through a query where we say give us everything that's ab above this It's Think they say um quite a lot of numbers and before that, uh um there's this number. But that we can decide about, but a general sort of It's the same thing if like whether you play and it moves forward or whether you jump to a position through search, it's essentially for all the window handling even if you go on an per utterance level, there's still some merit on within utterances cutting out stuff which clearly isn't relevant at all, and that maybe also for the audio we'd have to do. if it i let's say I mean if if their query language is strange and if it would return b ten million results and it can't handle it, then we can just write our individual components in the way that they know which what the threshold is. Yeah, now I'd say if for the prototype if we just like wherever possible p chunk in the stuff that we have um pre-annotated and stuff, and for the stuff that we don't have pre-annotated write like a stupid baseline, then we should probably be able to basically that means we focus on on the interface first sort of, so that we we take the the ready-made parts and just see how we get them work together in the interface the way we want the only thing that would happen basically if I double-click let's say from the whole meeting series on a single meeting, is that the zoom level changes. It more and more appears to me that if we if we scrap the notion of the meeting as an individual thing and sort of ju see meetings as as topic segments and have sort of like hierarchical topic segmentation instead, then it's b like a more coherent framework. Sort of c I was just thinking you know like if if the overhead for having the same amount of data coming from two d files instead of from one file is massive then it would probably be for us easy to just like off-line put the the weight into into the file that has the segments, uh yeah, segments slash utterances already. Well you can probably also you can probably pre-filter like with regular expressions even just say if it consists of only dig digits, then skip it, or even if it consists any special characters, then skip it because it's probably something with a dot in between, which is usually not something you wanna have Because it's it's less stuff to store probably for Dave in the in the audio playing. I think it's 'cause we had to specify it ourselves that it's not as um like focus the specification of most um work we have to do. and and the interface, so the interface is mainly while it's running just working on data that's just loaded from a file, I guess. It's um I think it's just the dictionary in the first place. Yeah, but the thing is um It's gonna need some th th thought of how we Actually maybe it doesn't actually matter. 'Cause before we have that, it's gonna be very difficult for anyone to really see how much the work that they're doing is making sense because you just well I guess you can see something from the data that you have in your individual 'Cause if we're gonna allow disjoint segments for example, then how are we gonna know what's gonna be in context at any given time? Um but that's still sort of that's good. That's what I'm guessing that's, you know, um Who's who's sort of doing the the the central coordination of of of the browser application now? But I'm I'm still confused 'cause I thought like that's just what Jonathan said we do c that we can't do, like load a massive document of that size. Like if if if the same thing is in different files, would it then maybe like, you know, if if utterances are split over three or ten or w hundred different files, is then a chance maybe that it doesn't try to load them all into memory at the same time, but just So why does it fail then in the first place? the building the browser comes first, and then only comes the creating new sophisticated data chunks, because that's sort of the whole thing about having a prototype system which is more or less working on on chunk data. I think we are running queries, it's not just about um what we load and what we don't load, but we're l running queries in the sense that we dynamically select by by weights I have always thought it's like more that oh, whatever, I'm a can't think of it at the moment. So so um I will probably send um just one file of the first meeting um to all those who need it so that you can have a look whether that's what you want. So if you find that the player accepts some n input from memory, and if it's easy to do, then I guess that's I think he's talking about sort of the ones that Yeah, if you if you enter the big room, in the right-hand corner, I think. So at at every level everyone has to be careful to really just take even at the highest level, just take stuff from one series and not merge stuff from different series together because they would probably be just majorly messy. And I mean if you if you know how to do it for individual words, then you can just in the worst case, if you can't find anything else, just sort of make the mean of the words over the utterance. it's not gonna be so big that we can't load in a information density for every utterance. It's it's quite strange. Yeah, sort of like off-line create a virtual meeting, which which basically treats the meeting series as if it was a meeting, and treats the individual meetings within the series as if they were segments, and treats the individual segments within meetings as if they were um utterances. Who actually like for this whole discussion I mean, who of us is doing stuff that is happening on-line and who of us is doing stuff that's happening off-line? If maybe if we realise that there's massive differences in in gain or in something, you can probably just make some simple simple normalization, but that really depends on how much time we have and and how much is necessary. Yo, Forrest Hill, whatever one's easier to discuss stuff, I don't know. So I'm just wondering if there's ways to abandon the whole concept of of meetings and sort of but just not really treating separate meetings as too much of a separate entity. Oh, so that's what f Rainbow does, because that's what L_S_A_ builds on. At the moment it's it's just lines of Mm-hmm. What's what's nine megabyte? Yeah, I mean there's one series that has just one meeting. and and a topic's basically they are just on the I_D_, probably with a start time or something, and and the utterances referenced to those topics I guess. I mean I don't see why that's really a big problem. And even though probably if there's a lot of over-head in having two different files, we can probably merge the weights into it off-line. Um so that's where that's stored. Like it's it's the sa There's a there's a serialise command , it's it's by hashes. So, it's a Yeah, but that's Um but that that's enough data for the skimming and the the searching, so what the searching does is the searching leaves the whole framework, goes to the S_Q_L_ database and gets like basically in the end gets just a time marker for where that is, like that utterance that we are concerned with. As long as like the algorithms are designed um with it in mind, I don't think it's a very big problem. I mean if you think if it's r roughly a million words and nine characters per word sounds realisti So Well what I think I might try and build is basically a class that you just feed it a linked list of um different wave-forms, and it will just string them all together with maybe, I don't know, tenth of a second silence in between each one or something like that. It would probably find another number task quite easily seeing that it's a constrained vocabulary with a high co-occurrence of the same nine words. so like if even if we make one single text file which has the whole corpus, sort of our corpus, that would still be from one series only. No no, not demonstrate, but like didn't you say that uh didn't we sort of agree that it would be useful to have a demonstrator of it, like some primitive thing working next week. I don't think it's too slow to do on-line, to be honest. So alternatively, if we realise we can't do the whole thing in one go, we can probably just process some sort of meta-data Yeah, you just like whatever you want to look at, you just jam together into an X_M_L_ file and that's your meeting, even though bits of it may come from all over the place or whatever. It would be useful to know how everyone's gonna store their things though. I could just use it with the frequency, I think, until the information density thing's finished. , it's probably just those people have to work together a lot and very closely and just make sure that they're always f I don't think it's very difficult though. I think before we can like answer that specific question how we c deal with that, it's probably good for us to look at what the audio player is capable of doing.\""
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_luhn =[]\n",
    "for i in summary:\n",
    "    summary_luhn.append(str(i))\n",
    "final_luhn = ' '.join(summary_luhn)\n",
    "final_luhn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "U05bS9X7bsv-"
   },
   "outputs": [],
   "source": [
    "# соберем все в одну функцию \n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "def summary_luhn(transcript_sum):\n",
    "    stopwords = stopwords_english\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(transcript_sum)\n",
    "    tokens = [token.text for token in doc]\n",
    "    word_freq = {}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in stopwords_english:\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_freq.keys():\n",
    "                    word_freq[word.text] = 1\n",
    "                else:\n",
    "                    word_freq[word.text] += 1\n",
    "    max_freq = max(word_freq.values())\n",
    "    for word in word_freq.keys():\n",
    "        word_freq[word] = word_freq[word]/max_freq\n",
    "    sentence_tokens = [sent for sent in doc.sents]\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_freq.keys():\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = word_freq[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_freq[word.text.lower()]\n",
    "    select_length = int(len(sentence_tokens) * 0.05)\n",
    "    summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)\n",
    "    summary_luhn =[]\n",
    "    for i in summary:\n",
    "        summary_luhn.append(str(i))\n",
    "    final_luhn = ' '.join(summary_luhn)\n",
    "    return final_luhn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "R-gqfZaTcezk",
    "outputId": "fba6f617-cfc0-4ec4-be82-5530dc9487ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>extractive_text</th>\n",
       "      <th>extractive_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Wouldn't wanna be Project Manager. Uh, what we...</td>\n",
       "      <td>Um , once again I'm uh gonna take minutes . Uh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Me too. Okay. Um here's the agenda for our las...</td>\n",
       "      <td>Okay . Um here's the agenda for our last meeti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oops. That's as far as it goes. Do you also do...</td>\n",
       "      <td>uh good morning everybody here . And uh I want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hmm. E excuse me I forgot my copy. No, not min...</td>\n",
       "      <td>Uh oh I've forgotten to mail you the minutes ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Okay, can I have the laptop over here, or? Oka...</td>\n",
       "      <td>Tod uh for this meeting I will take the notes ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                 extractive_summary\n",
       "0           0  ...  Um , once again I'm uh gonna take minutes . Uh...\n",
       "1           1  ...  Okay . Um here's the agenda for our last meeti...\n",
       "2           2  ...  uh good morning everybody here . And uh I want...\n",
       "3           3  ...  Uh oh I've forgotten to mail you the minutes ,...\n",
       "4           4  ...  Tod uh for this meeting I will take the notes ...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extractive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6bLbJ0bbsv-"
   },
   "outputs": [],
   "source": [
    "final_luhn = summary_luhn(df_extractive['extractive_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3135Y5O-bsv-",
    "outputId": "2e63345b-39aa-4c29-f7ff-9b4ee97e4cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luhn scores: [{'rouge-1': {'f': 0.41947565150169724, 'p': 0.7808764940239044, 'r': 0.2867593269934162}, 'rouge-2': {'f': 0.23286937508712185, 'p': 0.4336989032901296, 'r': 0.15916575192096596}, 'rouge-l': {'f': 0.48659383849881027, 'p': 0.6786703601108033, 'r': 0.37925696594427244}}]\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(final_luhn, df_extractive['extractive_summary'][0])\n",
    "print('Luhn scores: {}'.format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ox5lYuYbsv_"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np \n",
    "def preprocess_text_simple(text):\n",
    "    # 0>\n",
    "    text = text.lower()\n",
    "    # 1\n",
    "    tokens = word_tokenize(text)\n",
    "    # 2 и 3 \n",
    "    tokens = [token for token in tokens if token not in stopwords_english\n",
    "              and token.isalpha()\n",
    "              and token.strip() not in punctuation\n",
    "              #and token.strip() not in numbers\n",
    "             ]\n",
    "    # 4\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzLz0EPabsv_",
    "outputId": "34e90baa-341c-4e57-bbe1-9b950936c4d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "df_extractive = df_extractive.head(10)\n",
    "for i in range(len(df_extractive)):\n",
    "    fin_luhn = summary_luhn(df_extractive['extractive_text'][i])\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(fin_luhn, df_extractive['extractive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple(df_extractive['extractive_summary'][i])\n",
    "    candidate = preprocess_text_simple(fin_luhn)\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu(reference, candidate, weights=(0, 0, 1, 0))\n",
    "    bleu3.append(bleu_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khcXBaLGbsv_",
    "outputId": "3db2f6f3-2a25-4aab-e7f4-9b1618c60b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.008318538642514797, bleu: 0.22522189515769978\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qE-ZObxUbswA",
    "outputId": "31646f41-b135-4050-a870-08c8dc0180c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.488610924575542, p: 0.7671100830591521, f:0.37229235252960735\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYO4uIfgbswA",
    "outputId": "dde0ccb3-af16-4990-c488-121a77bc7574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.28006854334783815, p: 0.46054044023998963, f:0.20959993232641735\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WS9BT7agbswA",
    "outputId": "03ff8610-f79c-4648-b403-f283629d77b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.4835266898525979, p: 0.6261392581218478, f:0.3997901483232325\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBUUUDxNanVq"
   },
   "source": [
    "### TextRank <a class=\"anchor\" id=\"ch5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqkHWG9AanVr"
   },
   "outputs": [],
   "source": [
    "# косинусовая сходимость \n",
    "# на вход подается списки слов двух предложений\n",
    "def read(a):\n",
    "    text =[]\n",
    "    split_regex = re.compile(r'[.|!|?|…]')\n",
    "    sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "    for s in sentences:\n",
    "        text.append(s)\n",
    "    res = list(sent_to_words(text))\n",
    "    return res\n",
    "\n",
    "\n",
    "def sentence_similarity(sent1, sent2, stopwords):\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "     \n",
    "    # вектор для первого предложения \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # вектор для второго предложения \n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return (1 - cosine_distance(vector1, vector2))\n",
    "\n",
    "\n",
    "# создаем матрицу косинусовой сходимости \n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def generate_summary_textrank(file_name, top_n):\n",
    "    summarize_text = []\n",
    "    sentences = read(file_name)\n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stopwords_english)\n",
    "\n",
    "    # используем pagerank, чтобы определить веса предложений \n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank_numpy(sentence_similarity_graph)\n",
    "\n",
    "    # отсортируем предложения и выберем веса с большим весом \n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    #print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "\n",
    "    for i in range(top_n - 1):\n",
    "        if len(ranked_sentence[i][1]) > 2 and len(list((Counter(ranked_sentence[i][1]) - Counter(ranked_sentence[i + 1][1])).elements())) > 3:\n",
    "              summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "    return summarize_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UftBoQeXanVs",
    "outputId": "b702a979-7157-49fa-c870-8e937a9e223d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/cluster/util.py:133: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sqrt(numpy.dot(u, u)) * sqrt(numpy.dot(v, v))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text TextRank: \n",
      " what really miss also is uh is is turtle is decision uh decision system like um with the evaluation you have to polls like what do you want one two maybe little application like uh uh give your own number and click one two three four five six seven. well maybe can then do it one two three. thats one of the functionability uh well th think you two uh especially you and uh and uh daniel you you you both had uh the less creative uh roles in the project. think ah you must see it as uh uh according to uh the the other uh remote controls there may uh uh be there in your uh t_v_ room this one will stand out think. uh one two three. thats our remote control. we mean uh one one person maybe said three. think its its it look like this one. it would be best to to appeal to broad public and make the covers exchangeable so the young people will buy an orange and red and blue and purple but when the older people uh go in the shop and they see uh an orange um remote control it would be less appealing than white one. yeah uh but it its one one thing its three euro. so thats wh tha thats one option. exa think that thats what its about. and th the one or two things you have to draw when youre there just use flip board. because think it will oh five minutes from to finish meeting. well maybe thats uh only yeah well its for us because uh yeah. yeah but we we going to yeah yeah thats true. no uh thats true. cause think think jeroen and we had more design we could have more we had more room for creativity than than you two. so there must be some cheap standard cover um maybe white or something thats could comes with it and you can buy so we can make extra money. oh thats cool tim. yeah one or most true. be it it takes lot of time to draw things and to write things and thats the yeah but thats not th the the you when you at foreign audience you dont gonna wr uh write uh small. who because if you want to go to kinetic youre uh youre on thirteen and half and you must go to flat and think now its its more of uh compromise thing. and thats thats mostly the case from the over here with the managements you get two minutes to make your case and if you have to do all this kind youll rather use powerpoint and work it out in advance. okay so uh anybody uh misses something here about uh yeah okay thats thats what im gonna write between now. okay thats thats it from us. oh before you change anything maybe you um save it first. so thats uh thats big so lets uh wait it uh um we have we have must uh we must have uh some time for that uh because it will be uh yeah quite lot of mathematics. yeah but we want to make uh the wood colours uh that uh yeah one. no advanced chip uh thats little bit of problem. all the mo yeah are between one and two. our own people can make that think. one oh okay uh have to expla explain something. no you have to put uh switch channels uh at the top because thats the most used function and teletext at the second oh nay volume changing second. yeah but the most uh easy to use is just with one button on yeah okay but easy not not the most easy to use think. and young people we think are little bit more flexible they think ah ill buy for couple of euros some noi nice hip uh well um think cover is necessary cause als otherwise youll just have the l_c_d_ screen. but wha kay look what is the uh if you make it double curved it costs one euro more. so you have as you saw you have little uh oh you can yeah thank you. and thats pity if you uh if you have uh thirty forty minutes uh for this kind of things and we are now with four people but it well imagine you are here youre with the ten people and everyone uh yeah. follow the master class for the smartboard so think thats the thats the main issue. so um uh but but the single curved is just oh oh okay okay. so think uh it will be better idea to have some uh flashy fruity colours as as standard and for the people who uh really want uh more sophisticated more traditional look theyre willing to pay uh that. not too but little because thats our aim. but then uh think the idea of one person entering it and the rest uh discussing it that uh isnt that bad idea actually. uh um would call uh choose two cause we decided not to make two uh fresh colours as it would not. because uh four is between three and uh uh also between between true and false. if you uh promote kinetic um kinetic remote control mean that would sell better than an normal remote control. because think it will uh it must be uh yeah its three uh with seventy five uh yeah just about. theres one way to uh maybe if if youre not using the eraser something else th yeah arrow. yeah but but but daniel tha thats thats another brand. oh yeah if they under yeah\n"
     ]
    }
   ],
   "source": [
    "a = generate_summary_textrank(df_extractive['extractive_text'][0], top_n=100)\n",
    "print(\"Summarize Text TextRank: \\n\", \". \".join(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPLtp_KJanVs"
   },
   "source": [
    "Применив алгоритм TextRank, можно заметить, что наше краткое содержание не отражает главную суть текста и включает в себя предложения из одного-двух слов, которые почти одни и те же (forrest gump). Давайте попробуем поставить ограничение на то, что предложение должно содержать больше 4 - 5 слов и эти слова должны быть не похожи на лругие слова в нашем саммари, поэтому в конце добавим условия на то, что длина предложения > 2 и слова одного предложения отличаются от слов второго предложения на 3 и больше. \n",
    "Возможные варианты модификации данного алгоритма: \n",
    "1. Мы столкнулись с проблемой, что предложения в саммари одинаковые, поэтому возможно нужно добавить оглраничение на добавление предложения в саммари. Давайте попробуем использовать Maximum marginal relevance из пункта 8 (описание возможных алгоритмов)    \n",
    "MMR = $argmax_{s_i \\in \\mathcal{R-S}} (\\lambda * Sim_1(s_i, Q) - (1-\\lambda) * \\max\\limits_{s_j \\in S}Sim_2(s_i, s_j))$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "occBgw1xanVs"
   },
   "outputs": [],
   "source": [
    "textrank_hypothesis = ''\n",
    "for i in a:\n",
    "    textrank_hypothesis += i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcI3wahmanVt",
    "outputId": "1586a82a-c064-45a3-9254-975f932ed4fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextRank scores: [{'rouge-1': {'f': 0.4478741955069878, 'p': 0.2957692307692308, 'r': 0.9220623501199041}, 'rouge-2': {'f': 0.3927738890977979, 'p': 0.2593305117352828, 'r': 0.8091236494597839}, 'rouge-l': {'f': 0.5626134259831654, 'p': 0.3979460847240051, 'r': 0.9597523219814241}}]\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(textrank_hypothesis, transcript_sum)\n",
    "print('TextRank scores: {}'.format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUQnH0jZbswD"
   },
   "source": [
    "На всем датасете. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-WF83KsbswD",
    "outputId": "e5e713bd-6b9b-4797-a188-3bfcde075db4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/cluster/util.py:133: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sqrt(numpy.dot(u, u)) * sqrt(numpy.dot(v, v))))\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "for i in range(len(df_extractive)):\n",
    "    fin_textrank = generate_summary_textrank(df_extractive['extractive_text'][i], top_n = 20)\n",
    "    textrank_hypothesis = ''\n",
    "    for j in fin_textrank :\n",
    "        textrank_hypothesis += j \n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(textrank_hypothesis, df_extractive['extractive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple(df_extractive['extractive_summary'][i])\n",
    "    candidate = preprocess_text_simple(textrank_hypothesis)\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu(reference, candidate, weights=(0, 0, 1, 0))\n",
    "    bleu3.append(bleu_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tbd0w71TbswE",
    "outputId": "f57a8519-d7af-44d9-811f-34dc5d522459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.0, bleu: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aiVm0wiDbswE",
    "outputId": "b26f2869-a601-46ec-f4ba-d52227f44d55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.2752905593824052, p: 0.7682673464763903, f:0.17618050659279216\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YVvuIXNIbswE",
    "outputId": "93181646-5fa5-41cc-ec97-5af241fd1ea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.1401567773835038, p: 0.38214511471720825, f:0.09030515190635624\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CrR_ddqbswF",
    "outputId": "bf8a8b46-b998-4a65-f5a9-bc09ce1bd550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.3144335234155838, p: 0.6293826796237951, f:0.215987109149876\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLloGUgsanVt"
   },
   "source": [
    "### ClusterRank  <a class=\"anchor\" id=\"ch6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNB1JW_0anVu"
   },
   "outputs": [],
   "source": [
    "def read(a):\n",
    "    text =[]\n",
    "    split_regex = re.compile(r'[.|!|?|…]')\n",
    "    sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "    for s in sentences:\n",
    "        text.append(s)\n",
    "    res = list(sent_to_words(text))\n",
    "    return res\n",
    "\n",
    "# Расстояние левенштайна \n",
    "def lDistance(firstString, secondString):\n",
    "    if len(firstString) > len(secondString):\n",
    "        firstString, secondString = secondString, firstString\n",
    "    distances = range(len(firstString) + 1)\n",
    "    for index2, char2 in enumerate(secondString):\n",
    "        newDistances = [index2 + 1]\n",
    "        for index1, char1 in enumerate(firstString):\n",
    "            if char1 == char2:\n",
    "                newDistances.append(distances[index1])\n",
    "            else:\n",
    "               newDistances.append(1 + min((distances[index1], distances[index1+1], newDistances[-1])))\n",
    "        distances = newDistances\n",
    "    return distances[-1]\n",
    "\n",
    "def build_lev_matrix(sentences, stop_words):\n",
    "    lev_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            lev_matrix[idx1][idx2] = lDistance(sentences[idx1], sentences[idx2])\n",
    "    return lev_matrix\n",
    "\n",
    "\n",
    "def generate_clusterrank_summary(file_name, top_n):\n",
    "    summarize_text = []\n",
    "    sentences = read(file_name)\n",
    "    sentence_lev_martix = build_lev_matrix(sentences, stopwords_english)\n",
    "\n",
    "    # используем pagerank, чтобы определить веса предложений \n",
    "    sentence_lev_graph = nx.from_numpy_array(sentence_lev_martix)\n",
    "    scores = nx.pagerank(sentence_lev_graph)\n",
    "\n",
    "    # отсортируем предложения и выберем веса с большим весом \n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    #print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "\n",
    "    for i in range(top_n):\n",
    "        summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "    return summarize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykbiD0LoanVu",
    "outputId": "60118122-a4c3-4afa-e490-1810371bb0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " it would be best to to appeal to broad public and make the covers exchangeable so the young people will buy an orange and red and blue and purple but when the older people uh go in the shop and they see uh an orange um remote control it would be less appealing than white one. uh we had decided to uh put uh some flashy fruity colours in it uh and uh in the survey from uh milan and paris uh it uh it came out that uh uh the the older people are uh more willing to uh to spend money on extra features. what really miss also is uh is is turtle is decision uh decision system like um with the evaluation you have to polls like what do you want one two maybe little application like uh uh give your own number and click one two three four five six seven. and thats pity if you uh if you have uh thirty forty minutes uh for this kind of things and we are now with four people but it well imagine you are here youre with the ten people and everyone uh yeah. what do you think about uh putting battery in it but also selling like uh the covers docking station just apart from the from the thing so that you can uh put uh rechargeable batteries in it and just yeah yeah okay. and thats thats mostly the case from the over here with the managements you get two minutes to make your case and if you have to do all this kind youll rather use powerpoint and work it out in advance. and young people we think are little bit more flexible they think ah ill buy for couple of euros some noi nice hip uh well um think cover is necessary cause als otherwise youll just have the l_c_d_ screen. um well during the meeting showed you the concept of uh placing the buttons on top usable with your thumb and uh the menu structure uh if necessary with your other hand so its just gonna hold it easily. so think uh it will be better idea to have some uh flashy fruity colours as as standard and for the people who uh really want uh more sophisticated more traditional look theyre willing to pay uh that. be it it takes lot of time to draw things and to write things and thats the yeah but thats not th the the you when you at foreign audience you dont gonna wr uh write uh small\n"
     ]
    }
   ],
   "source": [
    "k = generate_clusterrank_summary(df_extractive['extractive_text'][0], 10)\n",
    "print(\"Summarize Text: \\n\", \". \".join(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dV1XQIVYanVv"
   },
   "outputs": [],
   "source": [
    "clusterrank_hypothesis = ''\n",
    "for i in k:\n",
    "    clusterrank_hypothesis += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_kb7JK2anVv",
    "outputId": "b4464925-13d6-437e-fb32-448e73794e7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'f': 0.4539363441966954,\n",
       "   'p': 0.7527777777777778,\n",
       "   'r': 0.3249400479616307},\n",
       "  'rouge-2': {'f': 0.22651006290472558,\n",
       "   'p': 0.37604456824512533,\n",
       "   'r': 0.16206482593037214},\n",
       "  'rouge-l': {'f': 0.42043221540151543,\n",
       "   'p': 0.5752688172043011,\n",
       "   'r': 0.33126934984520123}}]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(clusterrank_hypothesis, transcript_sum)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLvGoVNEanVv"
   },
   "source": [
    "На всем датасете. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSRDPD67bswH"
   },
   "outputs": [],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu_together = []\n",
    "df_extractive_clusterrank = df_extractive.head(5)\n",
    "for i in range(len(df_extractive_clusterrank)):\n",
    "    fin_clusterrank = generate_clusterrank_summary(df_extractive_clusterrank['extractive_text'][i], top_n = 13)\n",
    "    clusterrank_hypothesis = ''\n",
    "    for j in fin_clusterrank :\n",
    "        clusterrank_hypothesis += j \n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(clusterrank_hypothesis, df_extractive_clusterrank['extractive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple(df_extractive_clusterrank['extractive_summary'][i])\n",
    "    candidate = preprocess_text_simple(clusterrank_hypothesis)\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfn62yMBbswH",
    "outputId": "887853eb-fd4d-4db7-8799-c12598517e3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.0, bleu: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xykYDkn6bswH",
    "outputId": "2f61212d-89ad-4b35-838b-c60854532d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.44656084930842505, p: 0.7501809189199112, f:0.3302438389940815\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8NEXvnabswH",
    "outputId": "f331fef5-f10a-488e-b326-9b7631cdc523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.2353707213979946, p: 0.39898885768783376, f:0.17269982337677467\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1s5nUVObswI",
    "outputId": "37825b4d-c515-47f2-f626-f8bea3cb4ddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.42527543931265355, p: 0.5915725123717029, f:0.3396944529392348\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrw50ZHdanVv"
   },
   "source": [
    "### LSA  <a class=\"anchor\" id=\"ch7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RORkFDr_anVx"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcnGEBILanVx"
   },
   "outputs": [],
   "source": [
    "def calc_sigma(matrix):\n",
    "    (m, n) = matrix.shape   # узнаем размерность матрицы train\n",
    "    sigma = np.zeros((m, n))  # задаем матрицу из нулей для сигмы такой же размерности, как A\n",
    " \n",
    "    matrix_transposed = matrix.transpose()    # транспонируем A\n",
    "    matrix_c = 1/n * matrix.dot(matrix_transposed)   # считаем ковариационную матрицу C\n",
    " \n",
    "    wa, u = np.linalg.eig(matrix_c)   # wa - собственные значения, u - соответствующие собственные векторы\n",
    "    wa.sort()   # сортируем собственные значения\n",
    "    wa = wa[::-1]  # в порядке убывания\n",
    " \n",
    "    sigmas = np.sqrt(wa)   # вычисляем корни от всех собственных чисел\n",
    " \n",
    "    i = 0\n",
    "    if m < n:   # выставляем собственные значения по главной диагонали\n",
    "        while i < m:\n",
    "            sigma[i, i] = sigmas[i]\n",
    "            i += 1\n",
    "    if n < m:\n",
    "        while i < n:\n",
    "            sigma[i, i] = sigmas[i]\n",
    "            i += 1\n",
    " \n",
    "    s = []  # формальность: для удобства меняем тип array на список\n",
    "    for vector in sigma:\n",
    "        s.append([vector[i] for i in range(len(vector))])\n",
    " \n",
    "    return s\n",
    " \n",
    " \n",
    "# Подсчет W_transposed - каждый столбик - собственный вектор матрицы C = A^(T) * A (отсортированы по убыванию)\n",
    " \n",
    "def calc_w(matrix):\n",
    "    va_sorted = []  # отсортируем собственные векторы по убыванию собственных значений\n",
    " \n",
    "    matrix_transposed = matrix.transpose()  # транспонируем A\n",
    "    matrix_c = matrix_transposed.dot(matrix)  # считаем матрицу С\n",
    "    print(\"Матрица C: \")\n",
    "    print(matrix_c)\n",
    "    print()\n",
    " \n",
    "    eigenvalues_c, eigenvectors_c = np.linalg.eig(matrix_c)  # собственные значения и собственные векторы матрицы C (правые)\n",
    "    wa_index_value = []  # создадим массив с элементами вида (индекс собственного значения, собственное значение)\n",
    " \n",
    "    counter = 0\n",
    "    while counter < len(eigenvalues_c):  # заполним такой массив\n",
    "        (m, n) = (counter, eigenvalues_c[counter])\n",
    "        wa_index_value.append((m, n))\n",
    "        counter += 1\n",
    "    wa_index_value_sorted = sorted(wa_index_value, key=lambda index_value: index_value[1])  # сортируем элементы по величине собственного значения\n",
    "    wa_index_value_sorted = wa_index_value_sorted[::-1]  # в порядке убывания\n",
    " \n",
    "    counter = 0  # заполняем поэлементно матрицу сортированных собственных значений\n",
    "    while counter < len(wa_index_value_sorted):  # проходим по очереди по всем () в wa_index_value_sorted\n",
    "        va_sorted.append(eigenvectors_c[:, wa_index_value_sorted[counter][0]])  # берем из списка собств. векторов тот, который с таким же индексом, как индекс в ()\n",
    "        counter += 1\n",
    " \n",
    "    eigenvectors_c_sorted = []  # формальность: для удобства меняем тип array на список\n",
    "    for vector in va_sorted:\n",
    "        eigenvectors_c_sorted.append([vector[i] for i in range(len(va_sorted))])\n",
    " \n",
    "    w = np.array(eigenvectors_c_sorted).transpose()  # транспонируем матрицу W\n",
    " \n",
    "    return w\n",
    " \n",
    " \n",
    "#   Подсчет U\n",
    " \n",
    "def calc_u(matrix):\n",
    "    matrix_transposed = matrix.transpose()  # транспонируем A\n",
    "    matrix_c2 = matrix.dot(matrix_transposed)  # считаем матрицу c2\n",
    "    va_sorted = []  # отсортируем впоследствии собственные векторы по убыванию собственных значений и внесем сюда\n",
    " \n",
    "    eigenvalues_c2, eigenvectors_c2 = np.linalg.eig(matrix_c2)   # левые собственные числа и векторы\n",
    "    wa_index_value = []  # создадим массив с элементами вида (индекс собственного значения, собственное значение)\n",
    " \n",
    "    counter = 0\n",
    "    while counter < len(eigenvalues_c2):  # заполним такой массив\n",
    "        (m, n) = (counter, eigenvalues_c2[counter])\n",
    "        wa_index_value.append((m, n))\n",
    "        counter += 1\n",
    "    wa_index_value_sorted = sorted(wa_index_value, key=lambda index_value: index_value[1])  # сортируем элементы по величине собственного значения\n",
    "    wa_index_value_sorted = wa_index_value_sorted[::-1]  # в порядке убывания\n",
    " \n",
    "    counter = 0  # заполняем поэлементно матрицу сортированных собственных значений\n",
    "    while counter < len(wa_index_value_sorted):  # проходим по очереди по всем () в wa_index_value_sorted\n",
    "        va_sorted.append(eigenvectors_c2[:, wa_index_value_sorted[counter][0]])  # берем из списка собств. векторов тот, который с таким же индексом, как индекс в ()\n",
    "        counter += 1\n",
    " \n",
    "    u = []  # формальность: для удобства меняем тип array на список\n",
    "    for vector in va_sorted:\n",
    "        u.append([vector[i] for i in range(len(va_sorted))])\n",
    "    u = np.array(u)\n",
    " \n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wV9fzwZMbswJ"
   },
   "outputs": [],
   "source": [
    "# как вариант можно делать через truncatedsvd \n",
    "'''\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "components = 30\n",
    "lsa = TruncatedSVD(n_components=components) \n",
    "lsa.fit(dtm)\n",
    "lsa_dtm = lsa.transform(dtm)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmYwvr2-anVx"
   },
   "outputs": [],
   "source": [
    "# входные данные (текст , разбитый на предложения; количество предложений, которое мы хотим видеть в summary)\n",
    "df_extractive_lsa = df_extractive.iloc[1:7]\n",
    "def summary_LSA(transcript, k):\n",
    "    a2 = transcript.replace(\"\\n\", \"\")\n",
    "    a = a2.replace(\"\\ \", \" \")\n",
    "    text =[]\n",
    "    split_regex = re.compile(r'[.|!|?|…]')\n",
    "    sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "    for s in sentences:\n",
    "        text.append(s)\n",
    "    vectorizer = TfidfVectorizer(stop_words = stopwords_english)\n",
    "    X = vectorizer.fit_transform(text)\n",
    "    y = X.toarray()\n",
    "    a = np.matrix(y).T\n",
    "    U_numpy, s_numpy, W_numpy = np.linalg.svd(a) \n",
    "    W_numpy_2 = np.square(W_numpy)\n",
    "    s_numpy_2 = np.square(s_numpy)\n",
    "    weights = np.sqrt(np.dot(W_numpy_2, s_numpy_2))\n",
    "    weights = np.array(weights)[0]\n",
    "    dict_weights = {k: v for k, v in enumerate(list(weights))}\n",
    "    indexes_weights = sorted(dict_weights, key=dict_weights.get, reverse = True)\n",
    "    indexes = indexes_weights[:k]\n",
    "    summary = []\n",
    "    for i in indexes:\n",
    "        summary.append(text[i])\n",
    "    return summary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mwN4Mt7anVy"
   },
   "outputs": [],
   "source": [
    "summary = summary_LSA(df_extractive['extractive_text'][1], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ManQNUMKanVy",
    "outputId": "8171b739-00c1-444f-c0da-706ca46049a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text LSA: \n",
      " Yeah. Well, since our materials aren't exactly what we were going for, I'm just gonna translate what this all means for you. Thumb-shaped. Irritating, yeah. And did you determine um the curvature of the bottom part of it for the hand, is it gonna be a single or a double. And so we n k everybody have that. Um we are really gonna sell this. Wow that's a it's definitely a strong one. Yeah they were fun, even though I'm not really sure what I could do with them, but they are awesome. We're under. Mm. Colours. Yeah, and no internet. You too. Mm-hmm. Yeah. Yeah, 'cause they're pretty and just like Uh yeah. Yeah. And the digital the digital pens were they were pretty cool. Yeah. Are we going to indi I say we individually rate what do you say. Oh. Yeah. And these things whoa. Um then there's the latex cover, which is what you see as red. Oh sorry I'm taking over your job here. Yeah, no, iPods They want all those words for presentation, even the plugs. I think we just discuss it. Ta-da. Alright. Um bright yellow sort of design with the R_R_ which will actually look like our logo. Minus that one fight. Oh yeah, everybody. Yeah, let's let's do a lithium. You or me. Me too. Marketing Director says yeah. We're gonna have the integrated scroll scroll wheel. Fashionable people will buy it. Mm-hmm. If so, we can proceed, if not, we need to go back to the drawing board a little bit. Yeah. Um sure. Um easy to use. And then the last thing is just that it'll be black labelling on top, just which we didn't do. Okay. That is a piece of work. Yeah, it's a two. Yeah. Um and the buttons will be a l much lighter blue, almost see-through\n"
     ]
    }
   ],
   "source": [
    "print(\"Summarize Text LSA: \\n\", \". \".join(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xCx3FiJanVy",
    "outputId": "95418472-a03d-4837-b1a9-1388f8fa3b9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'f': 0.4440789430592647,\n",
       "   'p': 0.7068062827225131,\n",
       "   'r': 0.3237410071942446},\n",
       "  'rouge-2': {'f': 0.2487644108496292,\n",
       "   'p': 0.3963254593175853,\n",
       "   'r': 0.18127250900360145},\n",
       "  'rouge-l': {'f': 0.3724394737907334,\n",
       "   'p': 0.4672897196261682,\n",
       "   'r': 0.30959752321981426}}]"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_hypothesis = ''\n",
    "for i in summary:\n",
    "    lsa_hypothesis += i\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(lsa_hypothesis, transcript_sum)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtSuhnRIbswK"
   },
   "source": [
    "На всем датасете. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UOTF7usbswK",
    "outputId": "c52c71a3-4dca-48a7-f4e2-c2f8a6d2d2de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "for i in range(1, len(df_extractive_lsa)):\n",
    "    fin_LSA = summary_LSA(df_extractive_lsa['extractive_text'][i],20)\n",
    "    LSA_hypothesis = ''\n",
    "    for j in fin_LSA :\n",
    "        LSA_hypothesis += j \n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(LSA_hypothesis, df_extractive_lsa['extractive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple(df_extractive_lsa['extractive_summary'][i])\n",
    "    candidate = preprocess_text_simple(LSA_hypothesis)\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu(reference, candidate, weights=(0, 0, 1, 0))\n",
    "    bleu3.append(bleu_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--JMsqxybswL",
    "outputId": "de18d367-451d-4f6e-9b06-321bcec25c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.008510638297872339, bleu: 0.03487976676161907\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KURWEUnJbswL",
    "outputId": "9a788e71-c38b-48b9-c28f-ba8a409611f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.1415345242015588, p: 0.6963862391409895, f:0.08019001800924401\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFCGedlmbswL",
    "outputId": "93ab1f5b-9079-43a9-d1b5-b4480235cf3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.06870184646138798, p: 0.32287328875446664, f:0.03889482439901886\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GMyyijEgbswL",
    "outputId": "39221762-4ff6-43d7-f369-e7cea2ab13db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.2310095345641363, p: 0.5684390252514553, f:0.1482840764902869\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxM6MCGUanVz"
   },
   "source": [
    "### KLsum   <a class=\"anchor\" id=\"ch8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eR1ZOwjZanV0"
   },
   "outputs": [],
   "source": [
    "# принимает список частот слов в саммари и список частот слов в тексте\n",
    "def sent_to_words_1(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent) \n",
    "\n",
    "def delete_sentecnes_with_stopwords(a):\n",
    "    for i in a:\n",
    "        length_sent = len(i)\n",
    "        for j in i:\n",
    "            if j in stopwords_english:\n",
    "                length_sent -= 1\n",
    "        if length_sent < 3:\n",
    "            a.remove(i)\n",
    "    return a\n",
    "                \n",
    "    \n",
    "def kl_divergence(summary_density, text_density):\n",
    "        sum_val = 0\n",
    "        # для каждого слова из саммари смотрим, есть ли слово из саммари в тексте \n",
    "        for w in summary_density:\n",
    "            # frequency \n",
    "            frequency = text_density.get(w)\n",
    "            # если частота этого слова существует, то мы считаем частоту в тексте и в саммари этого слова и используем формулу kl\n",
    "            if frequency: \n",
    "                sum_val += frequency * math.log(frequency / summary_density[w])\n",
    "        return sum_val\n",
    "\n",
    "\n",
    "def get_all_words(snw):\n",
    "    all_words = []\n",
    "    for i in snw:\n",
    "        for j in i:\n",
    "            if j not in stopwords_english:\n",
    "                all_words.append(j)\n",
    "    return all_words\n",
    "\n",
    "def calculate_freq(array):\n",
    "    word_freq = {}\n",
    "    for w in array:\n",
    "        word_freq[w] = word_freq.get(w, 0) + 1\n",
    "    return word_freq  \n",
    "\n",
    "def get_sentences_list(a):\n",
    "    text =[]\n",
    "    split_regex = re.compile(r'[.|!|?|…]')\n",
    "    sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "    for s in sentences:\n",
    "        if len(s) > 7:\n",
    "            text.append(s)\n",
    "    return text   \n",
    "\n",
    "def find_index_of_best_sentence(kls):\n",
    "    return kls.index(min(kls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WljsKfnnbswQ"
   },
   "outputs": [],
   "source": [
    "import math \n",
    "import re\n",
    "from gensim import models\n",
    "def generate_klsum_summary(transcript, num_sent):\n",
    "    sentences_list = get_sentences_list(transcript)\n",
    "    sentences_as_words_= list(sent_to_words(sentences_list))\n",
    "    sentences_as_words = delete_sentecnes_with_stopwords(sentences_as_words_)\n",
    "    all_w = get_all_words(sentences_as_words)\n",
    "    word_freq = calculate_freq(all_w)\n",
    "    summary = []\n",
    "    while num_sent > 0:\n",
    "        # будет хранить значения kls, чтобы из них выбрать наиментгее\n",
    "        kls = []\n",
    "        # превращает краткое содержание в список слов \n",
    "        summary_as_word_list = get_all_words(sent_to_words(summary))\n",
    "\n",
    "        for s in sentences_as_words:\n",
    "            # если мы добавим предложение, то какое будет распределение\n",
    "            # соединим список слов в предложении и то, что в саммари \n",
    "            new_joint = s + summary_as_word_list\n",
    "            joint_freq = calculate_freq(new_joint)\n",
    "\n",
    "            # считаем kls между распределением саммари и слова в тексте \n",
    "            kls.append(kl_divergence(joint_freq, word_freq))\n",
    "            new_joint = summary_as_word_list\n",
    "\n",
    "        indexToRemove = find_index_of_best_sentence(kls)\n",
    "        best_sentence = sentences_list.pop(indexToRemove)\n",
    "        del sentences_as_words[indexToRemove]\n",
    "        summary.append(best_sentence)\n",
    "        num_sent -= 1 \n",
    "    summary_fin = ''\n",
    "    for i in summary:\n",
    "        summary_fin += '. ' + i\n",
    "    return summary_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "id": "kIV3-_zZbswQ",
    "outputId": "900bb4bb-07d6-49e7-c7ab-7848a4833970"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\". And after that, uh uh an evaluation of uh the process how we uh how we have done it here with the SMARTboard, with the with our laptops, with the all uh all this. Um, you see. Yeah, maybe. I can delete it for you if you want. During the design uh design life-cycle we uh we made lot of requirements and trend analysis and stuff. All the mo yeah, are between one and two. No, tho uh that that can be done. Leads to user face, yeah. I'm uh when I said it, I remember I had it here. The blue blue uh Okay. We have the sub-menus and stu stuff. Now we're done. Oh, okay, but 'kay, look. J_ and J_. Not really, yeah. Uh, button, no. That's an add-on. Yeah, if the costs are under twelve and a half Euro, uh then we uh can uh ra uh move on to the project evaluation, as we have uh experienced it. You can be you can go quicker, 'cause then it it won't notice it. The remote control has m remova removable from Multilux\""
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_klsum_summary(df_extractive['extractive_text'][0], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lOQ2jR_anV0"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# существует библиотека для этого метода \n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.kl import KLSummarizer\n",
    "document = a\n",
    "parser=PlaintextParser.from_string(document,Tokenizer(\"english\"))\n",
    "summarizer = KLSummarizer()\n",
    "summary = summarizer(parser.document,50)\n",
    "summ_klsumm = []\n",
    "for sentence in summary:\n",
    "    summ_klsumm.append(sentence)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luWCpQ8ObswR"
   },
   "source": [
    "На полном датасете: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjABn70YbswR",
    "outputId": "1ff4411a-91e2-4619-87c7-0146709a9539"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "for i in range(len(df_extractive)):\n",
    "    fin_klsum = generate_klsum_summary(df_extractive['extractive_text'][i], 30)\n",
    "    klsum_hypothesis = ''\n",
    "    for j in fin_klsum :\n",
    "        klsum_hypothesis += j \n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(klsum_hypothesis, df_extractive['extractive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple(df_extractive['extractive_summary'][i])\n",
    "    candidate = preprocess_text_simple(klsum_hypothesis)\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu(reference, candidate, weights=(0, 0, 1, 0))\n",
    "    bleu3.append(bleu_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJrhgRqiqzHn",
    "outputId": "aa36e65e-e5d1-4074-cb48-1bb5fc855026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.01159354346014289, bleu: 0.20833329258339495\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4BZeh4Bq349",
    "outputId": "6ad0ffd0-f672-4e5f-bed3-55ae5ddb6923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.29031370197713297, p: 0.7801536103408768, f:0.18650998198840268\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwR1qRS8q7DK",
    "outputId": "c9c0b389-a97a-4449-9124-7c592181b1f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.15824751254645825, p: 0.4378632344124955, f:0.1007183555013194\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjWoBUAYq7PY",
    "outputId": "44caec88-d4b1-4523-c696-8d9a4c0e3a80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.3892319176600572, p: 0.6659284825541392, f:0.28462192187826574\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-OXnyqianV1"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "namNjickanV1"
   },
   "source": [
    "### Mead <a class=\"anchor\" id=\"ch9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6rEAgAdanV2"
   },
   "outputs": [],
   "source": [
    "# функция, которая объединяет все выше сделанные действия \n",
    "def text_to_sentences(a):\n",
    "    text =[]\n",
    "    split_regex = re.compile(r'[.|!|?|…]')\n",
    "    sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "    for s in sentences:\n",
    "        text.append(s)\n",
    "    return text\n",
    "    \n",
    "def preprocess(a):\n",
    "    text =[]\n",
    "    split_regex = re.compile(r'[.|!|?|…]')\n",
    "    sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "    for s in sentences:\n",
    "        text.append(s)\n",
    "    res = list(sent_to_words(text))\n",
    "    res_ = []\n",
    "    s_ =[]\n",
    "    for s in res:\n",
    "        for word in s:\n",
    "            if word not in stopwords_english:\n",
    "                s_.append(word)\n",
    "        res_.append(s_)\n",
    "        s_ = []\n",
    "    res_fin = []\n",
    "    s_fin = []\n",
    "    for s in res_:\n",
    "        for word in s:\n",
    "            s_fin.append(lemmatizer.lemmatize(word))\n",
    "        res_fin.append(s_fin)\n",
    "        s_fin = []\n",
    "    return res_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "4KgWdobRatUt",
    "outputId": "31877494-84c1-4ce0-873b-55c5a6588a45"
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn-extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igE-I5W8anV3"
   },
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "def summary_mead(file):\n",
    "    text = text_to_sentences(file)\n",
    "    words = []\n",
    "    f = preprocess(file)\n",
    "    new_f = []\n",
    "    for i in f:\n",
    "        if len(i) > 6:\n",
    "            new_f.append(i)\n",
    "            for j in i:\n",
    "                words.append(j)\n",
    "    all_words = list(set(words))\n",
    "    matrix = []\n",
    "    vector = [0] * len(all_words)\n",
    "    for sent in new_f:\n",
    "        for w in sent:\n",
    "            if w in all_words:\n",
    "                vector[all_words.index(w)] += 1\n",
    "        matrix.append(vector)\n",
    "        vector = [0] * len(all_words)\n",
    "    kmedoids = KMedoids(n_clusters=len(matrix) - 5, random_state=42).fit(matrix)\n",
    "    kmedoids_centers = kmedoids.cluster_centers_\n",
    "    kmedoids_centers = list(kmedoids_centers)\n",
    "    for i in range(len(kmedoids_centers)):\n",
    "        kmedoids_centers[i] = list(kmedoids_centers[i])\n",
    "    indexes_sum = []\n",
    "    for i in kmedoids_centers:\n",
    "        indexes_sum.append(matrix.index(i))\n",
    "    final_summary = []\n",
    "    for i in indexes_sum:\n",
    "        final_summary.append(' '.join(new_f[i]))\n",
    "    full_summary = '. '.join(final_summary)\n",
    "    return full_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihjnesEeanV3"
   },
   "outputs": [],
   "source": [
    "mead_hypothesis = summary_mead(df_extractive['extractive_text'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "UNDQUvIUbswT",
    "outputId": "3a556984-1def-43a1-c7cc-05b44ba67642"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'website went look announcement introduction sort seven inch monitor understood project goal. immediate next step start determining functional design. im glad didnt work ahead time clearly didnt understand project goal. please please copy mail discussion need submit management. would th think depends much money give u. know make different choice different financial model. request keep ed loop meeting christine meeting know whats happening. basically need interact christine user acceptability testing yes. got lot project im right ill wait see go. enough time think two week close enough. would mind conclusion meeting could could send u copy slide. think see throughout day going put together marketing market product. define exactly product mind supposed marketing coffee right. design core marketing need sell youre responsible money finance tomorrow. yes prefer maybe need interact christine know going know sell. ed whats think project remote control already planned something marketing strategy sale strategy. think give kind design functional design technical design. design already product youre still working design. whether work first say design gotta simple use. oh think im wrong making remote control. sure name agnes im user usability user interface designer. goal project think maybe ill hand ed explain project he sale accounting. think give kind project plan discussion next meeting great. want introduce name shrida daseri im project manager new project going discus. think three group need interact quite bit. guess build plan based think need take factor account. anything need anytime please either call send email come knock door im available. thats talk finance idea sell product project market much going benefit company course individual also. begun working design actually didnt know designing remote control thought designing new monitor. ill copy le let u keep email copy share know everybody whats happening. know kind think general something thats fashionable thats attractive people see recognize goal immediately wanna one. design long take whole project much going cost u much going benefit company. thanks coming meeting first long time twenty five minute discus project project initiation. yet research taking remote control looking company theyre building design idea also pinpoint market gonna go. also feed marketing depending user want depends sell tag line attach try make attractive user. mean job understood look usability requirement make sure product usable acceptable people gonna use look best way. youll leading team design team many member working team design. come functional design discus ed going work first user acceptance look going work market discus thing. see starting new project together going four member team composed people thats thats read different step relative step. already cost limit th idea much want market much gonna sell thats thats u decide eh. would really would need something ipod would good seems caught fairly know dont care look cool. something visual something draw people buy product think everybodys experienced remote control remote control worth throwing window. need coordination compared maybe technical vendor commercial vendor depends want marketing plan technical plan let know. think maybe give kind sale plan including technical shes going talk within team help discus management put proper project plan. people need marketing technical side administration point view add documentation technical point view let know coordinate team. think ill interact christine discus shes designing something study show right bat going work sort loop feed dont think necessarily im coordinating position. fairly large market number people competition th agree something something new something draw people saying eh. th ar dont know come new idea make lot easier use cause lot time spend half day instruction book trying figure use'"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mead_hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24OKMSSNbswU",
    "outputId": "54ff22b2-dd5b-416a-f122-2b0453f97c22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "for i in range(len(df_extractive)):\n",
    "    fin_mead= summary_mead(df_extractive['extractive_text'][i])\n",
    "    mead_hypothesis = ''\n",
    "    for j in fin_mead:\n",
    "        mead_hypothesis += j \n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(mead_hypothesis, df_extractive['extractive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple(df_extractive['extractive_summary'][i])\n",
    "    candidate = preprocess_text_simple(mead_hypothesis)\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu(reference, candidate, weights=(0, 0, 1, 0))\n",
    "    bleu3.append(bleu_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQQ-FFLYuXDI",
    "outputId": "e1232f8a-b3b6-4985-e4ea-f2c1c6701759"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.0015992527765157731, bleu: 0.16493003816252755\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4FMlvm0uXRF",
    "outputId": "9726e3b6-f4ec-40a9-9687-0b2253e70de4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.32504767292556996, p: 0.4661053839606678, f:0.2613586623721295\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Psr8yZUuXbc",
    "outputId": "fec48ea2-3211-4e71-b269-1137774635f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.06483390330861646, p: 0.09193227772074546, f:0.052268572513609515\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzDBlHlyuXlX",
    "outputId": "883b9201-cc43-44e1-8bef-de6251dde2f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.5062470211025011, p: 0.5432611173755149, f:0.48166070780670617\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahE81epdanV3"
   },
   "source": [
    "## Abstractive methods <a class=\"anchor\" id=\"ch10\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bNBSt-TanV3"
   },
   "source": [
    "### Bidirectional Encoder Representations from Transformers (BERT) - 2018 <a class=\"anchor\" id=\"ch11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlkJk59TanV4",
    "outputId": "aca312f8-5acd-4da0-aa53-7f7fda064c5a"
   },
   "outputs": [],
   "source": [
    "# !pip install sentencepiece\n",
    "# !pip install bert-extractive-summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIPboZ8fanV4"
   },
   "outputs": [],
   "source": [
    "# работает на tpu\n",
    "from summarizer import TransformerSummarizer\n",
    "from summarizer import Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cn7MKbnyw1Lr"
   },
   "outputs": [],
   "source": [
    "df_abstractive = pd.read_csv('/content/abstractive_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvyJmvHNanV4",
    "outputId": "783beb79-8c43-4a7e-c08c-390ce10defb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Um, I'm going to be responsible for the functional design phase. Well there are loads of different types of dogs, so I'm sure it'll represent one kind of dog. But this part was all brown and then it has these big blue dots like this. This is the first meeting uh for developing our, our new product. If everyone could go around and explain their role and um, and their name. Um, we want this to be a marketable product that can be trendy, um, a completely new style, so that, um, can really appeal to a, to a generation that doesn't want a simple plain kind of, uh, channel-changer. And, um, it needs to be user-friendly for, um, maybe, for an example, for people that, um, can't see the numbers as well, or, um, perhaps an ergonomic design. I mean, you're the designers, you c, you can um decide what kind of, um, direction you wanna go in, but at this point in the, in the first meeting it can be any ideas that we just throw out there. Um, that does not necessarily mean it needs to be outrageous. Um, like you can go over your ideas, of course, in your own personal times. Um, maybe how this can be achieved, and, um, we need the user requirements from the manag Marketing Expert. Um, you will get specific instructions, um, of what to do in the next half an hour.\n"
     ]
    }
   ],
   "source": [
    "bert_model = Summarizer()\n",
    "bert_summary = ''.join(bert_model(df_abstractive['abstractive_text'][0], min_length=60))\n",
    "print(bert_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "id": "JXXYR1EJw_0X",
    "outputId": "e4b12d34-fb48-4192-ec2b-88c92970a5f6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'The project manager opens the meeting by introducing herself and asking everyone to say their name and role in the group. She then states the agenda of the meeting and tells them that they will be designing and creating a new remote control that should be trendy and user-friendly. The meetings will focus on functional, conceptual, and detailed design. Next, each group member draws their favorite animal on the whiteboard and explains the characteristics of that animal. After that the project manager covers the project budget, and then they begin discussing their personal experiences with remote controls and how they want their remote to look. Then the project manager closes the meeting by telling each group member what to do in preparation for the next meeting. '"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abstractive['abstarctive_summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTxeHU4uwN0p",
    "outputId": "24e3e99e-58b7-4bab-d502-4f6d27ba8e76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "df_abstractive = df_abstractive.head(10)\n",
    "for i in range(len(df_abstractive)):\n",
    "    bert_summary = ''.join(bert_model(df_abstractive['abstractive_text'][i], min_length=60))\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(bert_summary, df_abstractive['abstarctive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple( df_abstractive['abstarctive_summary'][i])\n",
    "    candidate = preprocess_text_simple(bert_summary )\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qy3BclWrwN-U",
    "outputId": "ee3fb7d7-5f5a-4080-a115-9bbc06c04219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.009429617015806153, bleu: 0.2254619800841125\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1Hiuwrlx-aW",
    "outputId": "1b682566-23fa-46ba-9057-25afcb7ec801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.17886214677584958, p: 0.12396242591199387, f:0.41062445436683764\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUrcRhAmx-jo",
    "outputId": "28db3270-b25f-4a81-9f54-1ddcde61a0b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.026312991193576617, p: 0.01803723380123618, f:0.06077928317614902\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDy62wodx-ta",
    "outputId": "92ff463b-18fe-4d16-a567-6661958c1d0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.16225746333306398, p: 0.11625716262041248, f:0.3105863049439002\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRy305iXanV5"
   },
   "source": [
    "### GPT2 <a class=\"anchor\" id=\"ch12\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "891d1f193b1e4e19bd8a659c8afa9f2b",
      "c8d3dba8950647f78e42a0c6cfc16bde",
      "3d099d24ff2b45698e534449749b1848",
      "1ea0ab94c1dd4a739de7c2d6d47d80ad",
      "85f9ab0a563249d3a93809befdcf0a1a",
      "32f237d7af1a475cbce8cf894c62d709",
      "59ba018eec7c497f8a1c49bd28dfab60",
      "81c5e0ec7358422b84b3438f9eac6d64",
      "bcb274a7b3934d6faf868c6c87045e54",
      "c71c0054b8994abfa6fcace945fcf5cf",
      "f819d6152cfe44bca8d8fbcfd4fe5198",
      "c4652d164ada49ad882f4e7a15ec3be0",
      "922f3ecc616144708f1179de850b9004",
      "1ab3ee790a56498e800681ddd172ba5c",
      "a5ccefeb6404490fb4c1f3c65c1d04af",
      "69438792226a472095d2cd18c15e0c0e",
      "b9649c01a1d846c4a5f0975ef6e236c2",
      "c7749ca11e9d496cb33f04dfc2f7a7b3",
      "e29e881d804d4703a828cc40e88cda67",
      "98d407c4f98d446f91649abb973e7e70",
      "6c23b18bea4841d0a6a61631ab238c95",
      "62bbb122f57c4d0a9222e07ec075c245",
      "a145b6236efa46cf8b2b3fbf3f4a9a43",
      "be0cc8bf2946474092c2faa4e521866f",
      "4babc5cc0ef24f9686833cab4e113962",
      "6fb9d897c22d470db9e5951df85cf8ab",
      "9dfdaa37cdb54bfc9cafa79319704fe9",
      "c897f7abf39f49e7824bb0c9f45ad7c1",
      "0ae3520789264d9fa3da4f9a4d255a5a",
      "7559d35bc0384edea390bfdc74eb9b1f",
      "db2b377166ed47739d21eaf982b901d7",
      "00107b9bd80a4708ab7603561c696296",
      "c605c3af29c04a23873ebe773ebc6838",
      "8035d2d9c4ba4934adb5bcd02a4ca1d1",
      "f1c60283aec64252b995af76e1a0d403",
      "1841f119895c473786ff4adf68a0bb49",
      "e32c623da4124d95b5d2d7db13bc516a",
      "62a772f051ae4210bb019c0ca598c2cc",
      "c82809532ead4f138911dd25b2d69f1f",
      "10a5245500bc4f95817b00ebc0af4d70"
     ]
    },
    "id": "iBrVQ0bPanV5",
    "outputId": "f17a4cf2-d3d1-41fa-dcc5-711c3ed4a106"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891d1f193b1e4e19bd8a659c8afa9f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=718.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb274a7b3934d6faf868c6c87045e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1520013706.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.5.attn.masked_bias', 'h.19.attn.masked_bias', 'h.2.attn.masked_bias', 'h.4.attn.masked_bias', 'h.21.attn.masked_bias', 'h.23.attn.masked_bias', 'h.9.attn.masked_bias', 'h.3.attn.masked_bias', 'h.8.attn.masked_bias', 'h.10.attn.masked_bias', 'h.15.attn.masked_bias', 'h.14.attn.masked_bias', 'h.7.attn.masked_bias', 'h.6.attn.masked_bias', 'h.1.attn.masked_bias', 'h.18.attn.masked_bias', 'h.0.attn.masked_bias', 'h.17.attn.masked_bias', 'h.16.attn.masked_bias', 'h.12.attn.masked_bias', 'h.22.attn.masked_bias', 'h.20.attn.masked_bias', 'h.11.attn.masked_bias', 'h.13.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9649c01a1d846c4a5f0975ef6e236c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4babc5cc0ef24f9686833cab4e113962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c605c3af29c04a23873ebe773ebc6838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Um, I'm going to be responsible for the functional design phase. So maybe if you could have some kind of tracking device for the remote control or some signal that you could find out where it was. You can press a button on your wall, signal, 'cause it always gets lost. I'm going to draw a butterfly, because I saw a butterfly yesterday, that seemed to be like the symbol of Spring arriving. And then it kinda there was a green, I think it was a green ring, and there was like red going out like this. I will also be responsible for the functional design phase, the conceptual design phase and the detailed design phase of the user interface design. It's a dog.. Um, I like dogs because, um, they're so good to humans, like they can be trained to be police dogs and seeing-eye dogs, and they're just such friendly animals. Um, we want this to be a marketable product that can be trendy, um, a completely new style, so that, um, can really appeal to a, to a generation that doesn't want a simple plain kind of, uh, channel-changer. And, um, as a sort of team-building moment, um, I, I'd like us to, um, try out the whiteboard by expressing our favourite animal and the charac characteristics of that animal. And so we have to, um, come up with a way to, to create a, a uh remote control, where um we can like the price to create it will be significantly less. Um, that does not necessarily mean it needs to be outrageous. Um, maybe how this can be achieved, and, um, we need the user requirements from the manag Marketing Expert.\n"
     ]
    }
   ],
   "source": [
    "GPT2_model = TransformerSummarizer(transformer_type=\"GPT2\",transformer_model_key=\"gpt2-medium\")\n",
    "full = ''.join(GPT2_model(df_abstractive['abstractive_text'][0], min_length=60))\n",
    "print(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIElnJQL1I3t",
    "outputId": "1b6ae428-eb94-4644-f34d-77f0ffea515c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "for i in range(len(df_abstractive)):\n",
    "    gpt2_summary = ''.join(GPT2_model(df_abstractive['abstractive_text'][i], min_length=60))\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(gpt2_summary, df_abstractive['abstarctive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple( df_abstractive['abstarctive_summary'][i])\n",
    "    candidate = preprocess_text_simple(gpt2_summary )\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CjOMLVj1bs-",
    "outputId": "cc6cd2c3-d98e-4712-ef63-46676f8c2f54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.009874406105362226, bleu: 0.2278826075075439\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJWaZSbY3lVo",
    "outputId": "8005834b-94d6-41e1-de00-9c1c362524ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.1702615738460246, p: 0.11479004053164751, f:0.4186480246040213\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OFkwFZD3lgf",
    "outputId": "7e0af8ca-cdde-4413-bd4f-c67a6d5d8e48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.029194837926160407, p: 0.019625734983963798, f:0.07275841919916458\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQcpA8533lsD",
    "outputId": "58e37047-2a2c-44f8-8f1a-9341315d812c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.15234277183338343, p: 0.10677330851926703, f:0.3088545223669531\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhmoBjAoanV5"
   },
   "source": [
    "### XLNet <a class=\"anchor\" id=\"ch13\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "34217d3e5fef458f8926401f4b20f387",
      "931d193ae0214e758efd29e41626f90b",
      "b34585c5368d4abbb5fecb945c36ed99",
      "b4c543b0eb464266a49282e9e4e78418",
      "ee133ace14ed40509ba1a02fcbadd8f4",
      "a3d94fb508004f209b8c111f9d3d06f0",
      "bd70ec3d30444aed84eff7566adaf47f",
      "19624aa597a44bb2a5046a3b596ef9ff",
      "50261ef7495e4945a3872e0763d2e2f4",
      "86c08d5c47234b17af4f5d4aa2c6851a",
      "6de0683e6879443990f9bc6c72701d93",
      "2660203eb45241259a2f54fb4dae1287",
      "ef9c691337e94ff9aed14caf9dc2a853",
      "6bb846902712490586a40e2a06da019c",
      "071b8f612462401d9a970b0abd19d80e",
      "b369cd644e2e426081def3d61da7599a",
      "4c15223e676742de9ef4ffee93a79d50",
      "2e84676350724a8b95fd44a677739790",
      "8ca4ba425c2442ddb408f8f129d3ff83",
      "b2528515b58c437c8bde2f394beab879",
      "ec2ccccdb118404b8a440dd52051c86e",
      "9c98fc626a6c4b6ca24fef5d49cd1c3d",
      "81fb4ea6cf1246d096c9ffa883fee037",
      "2772502f70f545439ac4aa4b35231213",
      "d43f5e8d725f4aa2a90f3f90c8a111ab",
      "6de8d5ac9f6a4bcf974b4e59fe0f27b0",
      "ea67009a4c03433aa209ba0aa6da41d0",
      "14fd9c1a574b48e0a1780230ddc8b8ee",
      "c9a64a646ed8450a9480f046bfa61d65",
      "b9991e2d045a4601adde589d8266bd9a",
      "147e46798936490a917ce5cf2b2c9b62",
      "4016c4f8b7344ba5b17413815eb61977"
     ]
    },
    "id": "1V_3iIQoanV6",
    "outputId": "dea23c46-a5d5-4424-8e90-3fda4e4d8546"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34217d3e5fef458f8926401f4b20f387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50261ef7495e4945a3872e0763d2e2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467042463.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c15223e676742de9ef4ffee93a79d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43f5e8d725f4aa2a90f3f90c8a111ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1382015.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Um, I'm going to be responsible for the functional design phase. Also the conceptual design and the detailed design for the final product. But I like cats because they're so independent, and they always seem to be doing what they want to be doing. You can press a button on your wall, signal, 'cause it always gets lost. Um, I'll be doing some trend-watching in the conceptual design, and product evaluation for the design phase. But this part was all brown and then it has these big blue dots like this. There's some remote controls where there's kind of a hidden panel, so all those buttons that you don't really use unless you're programming or something. I'm tempted to draw a snail 'cause I draw them sometimes and they're really easy to draw. And uh tool training is one thing that we're going to be doing today, um um as well as planning the project, how we're going to, uh, create this product, and, um, discuss, um, our aims and objects of this, uh Which brings us to our next subject, is, um, um, as a team we're going to be designing and creating a new kind of remote control. This is a team-building time where, um,, okay cool, um My favourite animal, which changes all the time, okay, right now it is an elk. Um, one thing we'd have to think about internationally is in the design of, um, like different kinds of, uh, V_C_R_s. Um, that does not necessarily mean it needs to be outrageous.\n"
     ]
    }
   ],
   "source": [
    "model_xlnet = TransformerSummarizer(transformer_type=\"XLNet\",transformer_model_key=\"xlnet-base-cased\")\n",
    "full = ''.join(model_xlnet(df_abstractive['abstractive_text'][0], min_length=60))\n",
    "print(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LH1o5Er_4WAd",
    "outputId": "d36ad071-9844-4775-ff98-8c29cd7d0199"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "for i in range(len(df_abstractive)):\n",
    "    xlnet_summary = ''.join(model_xlnet(df_abstractive['abstractive_text'][i], min_length=60))\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(xlnet_summary, df_abstractive['abstarctive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple( df_abstractive['abstarctive_summary'][i])\n",
    "    candidate = preprocess_text_simple(xlnet_summary)\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_LWc-l64WOU",
    "outputId": "9bf26ae6-4fed-4819-867f-d5be45722676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.009995255436174608, bleu: 0.25507821449390133\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dphYhq6D4WbK",
    "outputId": "067e13ac-75c4-46c2-89ac-cefde69dfe12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.18453680726612712, p: 0.12595571221544882, f:0.4199341022849861\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQfN7dvc4WmI",
    "outputId": "ff683523-f096-45f8-9ba4-17167f66c90b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.026544523097869033, p: 0.01768701814423483, f:0.061826963691579875\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G47G6f284Wxf",
    "outputId": "7205764a-7a2a-4269-ffca-823965c46eea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.16406639476946955, p: 0.11676655123284632, f:0.3146559009338134\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjQoP1vWzeZd"
   },
   "source": [
    "### T5 with fine-tuning <a class=\"anchor\" id=\"ch14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJPxrg9K0AtB",
    "outputId": "b7c2513f-0d76-4b08-eb2e-217485639c2b"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers==2.9.0 \n",
    "#!pip install pytorch_lightning==0.7.5\n",
    "#!pip install transformers -q\n",
    "#!pip install wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqNdHLhg0EKP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import wandb\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Ncv_8MK0P2z",
    "outputId": "fc537b1f-8287-4fa4-af0c-92e41ec7a6be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "# для ускорения моделей будем использовать сервис wandb\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qFdaKbHDTdn"
   },
   "outputs": [],
   "source": [
    "df_abstractive.columns = ['id', 'ctext', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YKN-rf3pMK3"
   },
   "outputs": [],
   "source": [
    "df_abstractive = df_abstractive.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6foIeqqzisR"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = summ_len\n",
    "        self.text = self.data.text\n",
    "        self.ctext = self.data.ctext\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ctext = str(self.ctext[index])\n",
    "        ctext = ' '.join(ctext.split())\n",
    "\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n",
    "        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n",
    "\n",
    "        source_ids = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'source_ids': source_ids.to(dtype=torch.long), \n",
    "            'source_mask': source_mask.to(dtype=torch.long), \n",
    "            'target_ids': target_ids.to(dtype=torch.long),\n",
    "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0Lc_-QSzw3e"
   },
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "    model.train()\n",
    "    for _,data in enumerate(loader, 0):\n",
    "        y = data['target_ids'].to(device, dtype = torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0-C3g7Ez1jp"
   },
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            y = data['target_ids'].to(device, dtype = torch.long)\n",
    "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "            generated_ids = model.generate(\n",
    "                input_ids = ids,\n",
    "                attention_mask = mask, \n",
    "                max_length=150, \n",
    "                num_beams=2,\n",
    "                repetition_penalty=2.5, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True\n",
    "                )\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "            if _%100==0:\n",
    "                print(f'Completed {_}')\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "    return predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632,
     "referenced_widgets": [
      "b0ef92e111da49b7975f2cfbc1b215db",
      "3cee2c70c2c54552b08173da2b43bbec",
      "1c1eb4aa3c9744c694a70a63f9d520e0",
      "555a8a1bb11b49559e4dd19a6afc56d8",
      "960a0b2f008d4ecf92971b45870bce31",
      "141de01b4881492382a9800600622cd9",
      "5798a95b255343d9a8fb8d2759346b18",
      "9a4bae3695754a0bad15cab7da5f7379"
     ]
    },
    "id": "Ke5RD-gjz5BU",
    "outputId": "9fbee34c-9b23-4e7e-bb86-173a99d269ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2em3kh8h) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 915<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ef92e111da49b7975f2cfbc1b215db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/content/wandb/run-20210522_195647-2em3kh8h/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/content/wandb/run-20210522_195647-2em3kh8h/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">floral-gorge-36</strong>: <a href=\"https://wandb.ai/spakt26/transformers_tutorials_summarization/runs/2em3kh8h\" target=\"_blank\">https://wandb.ai/spakt26/transformers_tutorials_summarization/runs/2em3kh8h</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2em3kh8h). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">quiet-sun-37</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/spakt26/transformers_tutorials_summarization\" target=\"_blank\">https://wandb.ai/spakt26/transformers_tutorials_summarization</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/spakt26/transformers_tutorials_summarization/runs/34gmiwbm\" target=\"_blank\">https://wandb.ai/spakt26/transformers_tutorials_summarization/runs/34gmiwbm</a><br/>\n",
       "                Run data is saved locally in <code>/content/wandb/run-20210522_195712-34gmiwbm</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  ...                                               text\n",
      "0   0  ...  The project manager opens the meeting by intro...\n",
      "1   1  ...  The project manager acquainted the team with t...\n",
      "2   2  ...  The project manager recapped the decisions mad...\n",
      "3   3  ...  The project manager opens the meeting by welco...\n",
      "4   4  ...  The Project Manager reviewed the decisions fro...\n",
      "\n",
      "[5 rows x 3 columns]\n",
      "Initiating Fine-Tuning for the model on our dataset\n",
      "Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe\n",
      "Completed 0\n",
      "Output Files generated for review\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    wandb.init(project=\"transformers_tutorials_summarization\")\n",
    "\n",
    "    config = wandb.config          \n",
    "    config.TRAIN_BATCH_SIZE = 2    \n",
    "    config.VALID_BATCH_SIZE = 2    \n",
    "    config.TRAIN_EPOCHS = 2        \n",
    "    config.VAL_EPOCHS = 1 \n",
    "    config.LEARNING_RATE = 1e-4    \n",
    "    config.SEED = 42               \n",
    "    config.MAX_LEN = 500\n",
    "    config.SUMMARY_LEN = 50 \n",
    "\n",
    "    torch.manual_seed(config.SEED) \n",
    "    np.random.seed(config.SEED) \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "    df_abstractive.ctext = 'summarize: ' + df_abstractive.ctext\n",
    "    print(df_abstractive.head())\n",
    "    train_size = 0.8\n",
    "    train_dataset=df_abstractive.sample(frac=train_size,random_state = config.SEED)\n",
    "    val_dataset=df_abstractive.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "    training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
    "    val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
    "\n",
    "    train_params = {\n",
    "        'batch_size': config.TRAIN_BATCH_SIZE,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 0\n",
    "        }\n",
    "\n",
    "    val_params = {\n",
    "        'batch_size': config.VALID_BATCH_SIZE,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 0\n",
    "        }\n",
    "\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
    "\n",
    "    wandb.watch(model, log=\"all\")\n",
    "\n",
    "    print('Initiating Fine-Tuning for the model on our dataset')\n",
    "\n",
    "    for epoch in range(config.TRAIN_EPOCHS):\n",
    "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "    print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
    "    for epoch in range(config.VAL_EPOCHS):\n",
    "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "        final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "        final_df.to_csv('predictions.csv')\n",
    "        print('Output Files generated for review')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1xpgrddDA4q"
   },
   "outputs": [],
   "source": [
    "predictions = pd.read_csv('/content/predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0R-Bqj5pAE8",
    "outputId": "9f356133-293f-42b0-815e-015eef0b293d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Generated Text', 'Actual Text'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BBfZ8LYd8xwM",
    "outputId": "8414679c-319e-43b6-f741-9929a0eadb2d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ctext</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>summarize: Okay okay Okay. Hello. Okay. My nam...</td>\n",
       "      <td>The project manager opens the meeting by intro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>summarize: Good morning. Sorry? Yeah, busy job...</td>\n",
       "      <td>The project manager acquainted the team with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>summarize: Alright, yeah. crack on. Okay so we...</td>\n",
       "      <td>The project manager recapped the decisions mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>summarize: Right w welcome to the the first me...</td>\n",
       "      <td>The project manager opens the meeting by welco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>summarize: Oops. Mm. After lunch. Yeah. Mm-hmm...</td>\n",
       "      <td>The Project Manager reviewed the decisions fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>summarize: Okay. Everybody ready? Welcome at t...</td>\n",
       "      <td>The project manager opened the meeting. The in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>summarize: Bless you. Yeah. Um, can I do next?...</td>\n",
       "      <td>The Project Manager reviewed the minutes from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>summarize: Is that alright? or Okay. Keeps com...</td>\n",
       "      <td>The project manager introduced the upcoming pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>summarize: Yep. Okay. Oh. Well we will try. Wh...</td>\n",
       "      <td>For the first meeting, the task of designing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>summarize: Okay. Right. Okay. Alright. Is ever...</td>\n",
       "      <td>The project manager reviewed the minutes of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>summarize: Hello. Yes, I made it. English from...</td>\n",
       "      <td>The marketing expert talked about trendwatchin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>summarize: Yes. Yeah, Martin. Mar Ah. Yeah, ho...</td>\n",
       "      <td>One team member presented her proposal regardi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>summarize: Hello. Yeah. Yep. Um I've got a Pow...</td>\n",
       "      <td>The project manager opened the meeting and sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>summarize: I'm proud of it. Uh-huh. How how mu...</td>\n",
       "      <td>The project manager opens this detailed design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>summarize: So I hope you're ready for this uh ...</td>\n",
       "      <td>The project manager opened the meeting and sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>summarize: Okay. Could could I see the scroll ...</td>\n",
       "      <td>The UI and ID presented a prototype drawing of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>summarize: Hello. Make a start yeah. So. Cable...</td>\n",
       "      <td>The User Interface Designer presented the majo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>summarize: Wow, good expression. Well after us...</td>\n",
       "      <td>The Industrial Designer gave her components co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>summarize: So is Why not save that. Do you wan...</td>\n",
       "      <td>The first prototype for the remote control was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>summarize: It's not saved yet. So Our beautifu...</td>\n",
       "      <td>The project manager presented the agenda and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>summarize: I keep forgetting whether I've done...</td>\n",
       "      <td>The project manager opened the meeting and wen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>summarize: Good afternoon. So Hello. No proble...</td>\n",
       "      <td>In the detailed design meeting the team create...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>summarize: Hello. Um, Project Manager, I have ...</td>\n",
       "      <td>The project manager went over the agenda. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>summarize: Good morning, Flores. Marketing Exp...</td>\n",
       "      <td>The project manager opened the meeting and int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>summarize: Why are you looking at me? Do I hav...</td>\n",
       "      <td>The project manager opens the meeting by going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>summarize: Just trying to move mine right now....</td>\n",
       "      <td>The Marketing Expert presented more informatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>summarize: No. We should make a big sponge lem...</td>\n",
       "      <td>The Marketing Expert presented the results of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>summarize: Morning. Yep. My name's Frank. Than...</td>\n",
       "      <td>The project manager introduced himself to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>summarize: Uh yeah. Fine now. Oh, it's not lik...</td>\n",
       "      <td>The project manager opened the meeting by stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>summarize: Yeah. Yeah, sure. It kinda does mak...</td>\n",
       "      <td>The project manager recapped the decisions mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>summarize: Hello. Hello. You have to put it ex...</td>\n",
       "      <td>The Project Manager introduced himself and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>summarize: Hello. So, are you d what were j yo...</td>\n",
       "      <td>For the conceptual design, the ID suggested to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>summarize: Mm-hmm. Yeah. I'm Robin. I'm the Ma...</td>\n",
       "      <td>The group introduced themselves and their role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>summarize: Well I'll uh start just with anothe...</td>\n",
       "      <td>There are some new requirements for the projec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>summarize: Hi. Mm-hmm. Interface designer. Yes...</td>\n",
       "      <td>The project manager opens the meeting by going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>summarize: Could have one for your stereo, one...</td>\n",
       "      <td>The project manager opens the meeting by stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>summarize: That's new one? Yep. Yep. Big micro...</td>\n",
       "      <td>The project manager opened the meeting and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>summarize: Okay. Here we go. Alright, the agen...</td>\n",
       "      <td>The project manager opens the meeting by stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>summarize: Okay. Okay. Next.. What do you mean...</td>\n",
       "      <td>The project manager opens the meeting and pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>summarize: Okay. So, now um, last time. Can yo...</td>\n",
       "      <td>The industrial designer and user interface des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>summarize: Play-Doh's edible. Did you know tha...</td>\n",
       "      <td>The interface specialist and industrial design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>summarize: So we come again for the the second...</td>\n",
       "      <td>The Project Manager presented the goals of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>summarize: Hold that. Okay. Okay. Mm. Mm-hmm. ...</td>\n",
       "      <td>The meeting begins with the group trying to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>summarize: Good morning. Well, I think we shou...</td>\n",
       "      <td>The Project Manager introduced the project to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>summarize: Mm-hmm. Uh, they have another group...</td>\n",
       "      <td>The project manager opened the meeting and des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>summarize: Okay? Good afternoon. Hope you have...</td>\n",
       "      <td>The project manager opens the meeting, stating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>summarize: Mm-hmm. Mm. A nice one. Yeah. Yeah....</td>\n",
       "      <td>The User Interface Designer presented three di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>summarize: Okay, welcome to the detailed desig...</td>\n",
       "      <td>The project manager opened the meeting. The us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>summarize: Yep. Uh-huh. Don't think so. Jess. ...</td>\n",
       "      <td>The project manager recapped the decisions mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>summarize: Mm-hmm. Maybe you should try to wri...</td>\n",
       "      <td>After introducing the remote control objective...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  ...                                               text\n",
       "0    0  ...  The project manager opens the meeting by intro...\n",
       "1    1  ...  The project manager acquainted the team with t...\n",
       "2    2  ...  The project manager recapped the decisions mad...\n",
       "3    3  ...  The project manager opens the meeting by welco...\n",
       "4    4  ...  The Project Manager reviewed the decisions fro...\n",
       "5    5  ...  The project manager opened the meeting. The in...\n",
       "6    6  ...  The Project Manager reviewed the minutes from ...\n",
       "7    7  ...  The project manager introduced the upcoming pr...\n",
       "8    8  ...  For the first meeting, the task of designing a...\n",
       "9    9  ...  The project manager reviewed the minutes of th...\n",
       "10  10  ...  The marketing expert talked about trendwatchin...\n",
       "11  11  ...  One team member presented her proposal regardi...\n",
       "12  12  ...  The project manager opened the meeting and sta...\n",
       "13  13  ...  The project manager opens this detailed design...\n",
       "14  14  ...  The project manager opened the meeting and sta...\n",
       "15  15  ...  The UI and ID presented a prototype drawing of...\n",
       "16  16  ...  The User Interface Designer presented the majo...\n",
       "17  17  ...  The Industrial Designer gave her components co...\n",
       "18  18  ...  The first prototype for the remote control was...\n",
       "19  19  ...  The project manager presented the agenda and t...\n",
       "20  20  ...  The project manager opened the meeting and wen...\n",
       "21  21  ...  In the detailed design meeting the team create...\n",
       "22  22  ...  The project manager went over the agenda. The ...\n",
       "23  23  ...  The project manager opened the meeting and int...\n",
       "24  24  ...  The project manager opens the meeting by going...\n",
       "25  25  ...  The Marketing Expert presented more informatio...\n",
       "26  26  ...  The Marketing Expert presented the results of ...\n",
       "27  27  ...  The project manager introduced himself to the ...\n",
       "28  28  ...  The project manager opened the meeting by stat...\n",
       "29  29  ...  The project manager recapped the decisions mad...\n",
       "30  30  ...  The Project Manager introduced himself and the...\n",
       "31  31  ...  For the conceptual design, the ID suggested to...\n",
       "32  32  ...  The group introduced themselves and their role...\n",
       "33  33  ...  There are some new requirements for the projec...\n",
       "34  34  ...  The project manager opens the meeting by going...\n",
       "35  35  ...  The project manager opens the meeting by stati...\n",
       "36  36  ...  The project manager opened the meeting and the...\n",
       "37  37  ...  The project manager opens the meeting by stati...\n",
       "38  38  ...  The project manager opens the meeting and pres...\n",
       "39  39  ...  The industrial designer and user interface des...\n",
       "40  40  ...  The interface specialist and industrial design...\n",
       "41  41  ...  The Project Manager presented the goals of the...\n",
       "42  42  ...  The meeting begins with the group trying to re...\n",
       "43  43  ...  The Project Manager introduced the project to ...\n",
       "44  44  ...  The project manager opened the meeting and des...\n",
       "45  45  ...  The project manager opens the meeting, stating...\n",
       "46  46  ...  The User Interface Designer presented three di...\n",
       "47  47  ...  The project manager opened the meeting. The us...\n",
       "48  48  ...  The project manager recapped the decisions mad...\n",
       "49  49  ...  After introducing the remote control objective...\n",
       "\n",
       "[50 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abstractive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yyx0f5479SSr"
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_abstractive.assign(column1=df_abstractive ['text'].str.lower()),\n",
    "                     predictions.assign(column1=predictions['Actual Text'].str.lower()),\n",
    "                     on='column1', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "HvNadjPF9tBZ",
    "outputId": "529b3494-0850-4eb5-c5be-775a23c3fda4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ctext</th>\n",
       "      <th>text</th>\n",
       "      <th>column1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Generated Text</th>\n",
       "      <th>Actual Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the project manager introduced the upcoming pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>'I have no idea what my favourite animal is. O...</td>\n",
       "      <td>The project manager introduced the upcoming pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the marketing expert talked about trendwatchin...</td>\n",
       "      <td>1</td>\n",
       "      <td>the presentation is about trendwatching and tr...</td>\n",
       "      <td>The marketing expert talked about trendwatchin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the project manager opened the meeting and sta...</td>\n",
       "      <td>2</td>\n",
       "      <td>a functional design meeting will be held to di...</td>\n",
       "      <td>The project manager opened the meeting and sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the first prototype for the remote control was...</td>\n",
       "      <td>3</td>\n",
       "      <td>the only thing that has really changed is the ...</td>\n",
       "      <td>The first prototype for the remote control was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the project manager opened the meeting and wen...</td>\n",
       "      <td>4</td>\n",
       "      <td>the prototype is a simple, clean design. It's ...</td>\n",
       "      <td>The project manager opened the meeting and wen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the project manager went over the agenda. the ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Project Manager, I have a little problem with ...</td>\n",
       "      <td>The project manager went over the agenda. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the project manager opened the meeting by stat...</td>\n",
       "      <td>6</td>\n",
       "      <td>the group is going to create a new remote cont...</td>\n",
       "      <td>The project manager opened the meeting by stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the project manager opens the meeting and pres...</td>\n",
       "      <td>7</td>\n",
       "      <td>the user can select a channel and then switch ...</td>\n",
       "      <td>The project manager opens the meeting and pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the meeting begins with the group trying to re...</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;extra_id_0&gt; We'll be recording what we write ...</td>\n",
       "      <td>The meeting begins with the group trying to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after introducing the remote control objective...</td>\n",
       "      <td>9</td>\n",
       "      <td>I'm the Industrial Designer. Chief, he is the ...</td>\n",
       "      <td>After introducing the remote control objective...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ...                                        Actual Text\n",
       "0 NaN  ...  The project manager introduced the upcoming pr...\n",
       "1 NaN  ...  The marketing expert talked about trendwatchin...\n",
       "2 NaN  ...  The project manager opened the meeting and sta...\n",
       "3 NaN  ...  The first prototype for the remote control was...\n",
       "4 NaN  ...  The project manager opened the meeting and wen...\n",
       "5 NaN  ...  The project manager went over the agenda. The ...\n",
       "6 NaN  ...  The project manager opened the meeting by stat...\n",
       "7 NaN  ...  The project manager opens the meeting and pres...\n",
       "8 NaN  ...  The meeting begins with the group trying to re...\n",
       "9 NaN  ...  After introducing the remote control objective...\n",
       "\n",
       "[10 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Ax1Mrjyo7hG",
    "outputId": "798e37fd-e239-4341-84bb-459b672c4dd2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "for i in range(len(merged_df)):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(merged_df['Generated Text'][i], merged_df['column1'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple(merged_df['column1'][i])\n",
    "    candidate = preprocess_text_simple(merged_df['Generated Text'][i])\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu(reference, candidate, weights=(0, 0, 1, 0))\n",
    "    bleu3.append(bleu_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3A42Go--NTk",
    "outputId": "0febb053-bbe0-4653-e756-70cc5beb4b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.002439024390243902, bleu: 0.03951882613244048\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaVt8OCH-Ngc",
    "outputId": "a3e8b11b-1497-4f61-c72f-b7560ea91b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.1875125551650351, p: 0.13913032521201818, f:0.29041155553569176\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63nv9JnC-Ntm",
    "outputId": "da144eb9-a822-4664-b9d3-bb570a477ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.010258759419941702, p: 0.007282964329023525, f:0.01740757304710793\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mCeLDXLD-N6W",
    "outputId": "bfdd9387-fbd1-4477-bb91-27b67f76a6ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.15257445393796518, p: 0.11039666726405226, f:0.2508889497694052\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkRXLfNLanV8"
   },
   "source": [
    "# Speech Recognition <a class=\"anchor\" id=\"ch15\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sW50a1X1FAr_"
   },
   "outputs": [],
   "source": [
    "speech_trans = open('ES2006d.transcript.txt', \"r\", errors = 'ignore')\n",
    "transcript_speech = speech_trans.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_idJJyz0xQY"
   },
   "source": [
    "## Обработка звука <a class=\"anchor\" id=\"ch16\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KVide0snQkcU",
    "outputId": "952dc35d-84c3-42e9-a4a2-d1f686aa09a4"
   },
   "outputs": [],
   "source": [
    " # !pip3 install timit-utils==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mio9ZLpxQmzv",
    "outputId": "73cacc16-1f74-46aa-ba94-7f4fc089a05b"
   },
   "outputs": [],
   "source": [
    "# !pip3 install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owWZJS4eQsrv"
   },
   "outputs": [],
   "source": [
    "import timit_utils as tu\n",
    "import os\n",
    "import IPython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5ltAxDp00HD"
   },
   "outputs": [],
   "source": [
    "data, sr = librosa.load('ES2006d.Array1-01.wav', 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "gOARsDr0QWo1",
    "outputId": "949b8a43-2d6b-4760-80b4-4202fb3edd26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8258268c90>]"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylabel('Амплитуда')\n",
    "plt.xlabel('t')\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xsit0zc9mgsa"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def entropy(labels):\n",
    "  entropies = []\n",
    "  final = []\n",
    "  vc = pd.Series(labels).value_counts(normalize=True, sort=False)\n",
    "  for i in vc:\n",
    "    entropies.append(i * np.log(i)/np.log(2))\n",
    "  threshold = (max(entropy(data)) - min(entropy(data))) * 0.5\n",
    "  for i in entropies: \n",
    "    if i < threshold:\n",
    "      final.append(i)\n",
    "  return final\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FL500QkGrpk9",
    "outputId": "40860a75-0c27-4932-8d87-9d931d641afc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00119019, -0.0022583 , -0.00219727, ...,  0.00418091,\n",
       "        0.00311279,  0.00125122], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3w0DHBPrtsj",
    "outputId": "37e450e4-ea22-438d-f1b2-19326a7c4845"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31479126,)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tzuQHphr65G"
   },
   "outputs": [],
   "source": [
    "# !apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFKvZ46Mrw4Z"
   },
   "outputs": [],
   "source": [
    "# hop length==number audio of frames between STFT columns. If unspecified, defaults win_length / 4.\n",
    "\n",
    "def slice_into_frames(amplitudes, window_length, hop_length):\n",
    "    return librosa.core.spectrum.util.frame(\n",
    "        np.pad(amplitudes, int(window_length // 2), mode='reflect'),\n",
    "        frame_length=window_length, hop_length=hop_length)\n",
    "    # выход: [window_length, num_windows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzyQznnhrxEs"
   },
   "outputs": [],
   "source": [
    "def get_STFT(amplitudes, window_length, hop_length):\n",
    "    \"\"\" Compute short-time Fourier Transform \"\"\"\n",
    "    # разбиваем амплитуды на пересекающиеся фреймы [window_length, num_frames]\n",
    "    frames = slice_into_frames(amplitudes, window_length, hop_length)\n",
    "\n",
    "    # получаем веса для Фурье, float[window_length]\n",
    "    fft_weights = librosa.core.spectrum.get_window('hann', window_length, fftbins=True)\n",
    "    \n",
    "    # применяем преобразование Фурье\n",
    "    stft = np.fft.rfft(frames * fft_weights[:, None], axis=0)\n",
    "    return stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LBDsQmIQrxQR"
   },
   "outputs": [],
   "source": [
    "# fmin == lowest frequency\n",
    "def get_melspectrogram(amplitudes, sample_rate=22050, n_mels=128,\n",
    "                       window_length=2048, hop_length=512, fmin=1, fmax=10002):\n",
    "\n",
    "   # оконное преобразование фурье \n",
    "    stft = get_STFT(amplitudes, window_length, hop_length)\n",
    "    # возводим в квадрат mel частоты и лоагрифмируем \n",
    "    spectrogram = np.log(stft ** 2)\n",
    "    # получаем из них спектральные коэффициенты с помощью косинусного дискретного преобразования \n",
    "    mel_basis = librosa.filters.mel(sample_rate, n_fft=window_length,\n",
    "                                    n_mels=n_mels, fmin=fmin, fmax=fmax)\n",
    "    \n",
    "    mel_spectrogram = np.dot(mel_basis, spectrogram)\n",
    "    return mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZRWxMQIMtfMR",
    "outputId": "a8a5057d-5e8d-44e2-c87c-8f9741d30d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41184431 points, 1867.774648526077 sec, sr 22050\n"
     ]
    }
   ],
   "source": [
    "amplitudes, sample_rate = librosa.load('ES2006d.Array1-01.wav')\n",
    "print(f\"{len(amplitudes)} points, {len(amplitudes) / sample_rate} sec, sr {sample_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "benVujlmM3vO"
   },
   "outputs": [],
   "source": [
    "# проверим на готовом методе получения спектограммы из библиотеке librosa\n",
    "spect_library = librosa.feature.melspectrogram(amplitudes, sr=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "1xq543nitOQd",
    "outputId": "b2434392-d07d-44dd-e91c-15c39d1d8a2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f824ea1e5d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10, 10])\n",
    "plt.imshow(spect_library.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9WpWMEEbp6Z",
    "outputId": "2f86b79e-a06b-4304-8d45-c8fa71e64e36"
   },
   "outputs": [],
   "source": [
    "# !pip3 install --upgrade speechrecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8yppp1Tc6-D",
    "outputId": "144fc411-eceb-4d70-d9ad-9f217121eab2"
   },
   "outputs": [],
   "source": [
    "# !pip install ibm_watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Arql3hbkcEwd",
    "outputId": "aca4c0f8-19cb-4c86-d679-e230ff551a96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess \n",
    "import os\n",
    "command = 'ffmpeg -i ES2006d.Array1-01.wav -vn -ar 44100 -ac 2 -b:a 192k audio.mp3'\n",
    "subprocess.call(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zZPINklcYsB",
    "outputId": "19c64cae-0018-4f21-9ef1-851566259dc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = 'ffmpeg -i audio.mp3 -f segment -segment_time 360 -c copy %03d.mp3'\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Waw5U6--dFoG"
   },
   "source": [
    "## Google speech to text <a class=\"anchor\" id=\"ch17\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djzg1pl7vps7",
    "outputId": "7bdbcf72-c58d-4d09-b587-1028e18eacec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/e1/7f5678cd94ec1234269d23756dbdaa4c8cfaed973412f88ae8adf7893a50/SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8MB)\n",
      "\u001b[K     |████████████████████████████████| 32.8MB 111kB/s \n",
      "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHAlFtPEvLJJ",
    "outputId": "1f9443f2-21c6-45ee-d157-1b2319bdfba0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not request results from Google Speech Recognition service; recognition connection failed: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()\n",
    "audio = sr.AudioFile('/content/ES2006d.Array1-01.wav')\n",
    "text_google = []\n",
    "with audio as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    audio = r.record(source)\n",
    "try:\n",
    "    print(\"Google Speech Recognition thinks you said \" + r.recognize_google(audio))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mgi0NneKvDtC",
    "outputId": "ad2cea3b-d405-4c62-ae36-32297f787b99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vY2IBOil8vF1",
    "outputId": "633ffeff-a9d6-4b3f-a743-fccdc06707ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not request results from Wit.ai service; recognition request failed: Bad Request\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "AUDIO_FILE = \"/content/ES2006d.Array1-01.wav\"\n",
    "WIT_AI_KEY = \"SVPUW2NGGISTKVCCZMUKH3LEJVJY5Q7I\" \n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "    audio = r.record(source) # Wit.ai keys are 32-character uppercase alphanumeric strings\n",
    "try:\n",
    "    print(\"Wit.ai thinks you said \" + r.recognize_wit(audio, key=WIT_AI_KEY))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Wit.ai could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Wit.ai service; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKUYtn_0y1oi"
   },
   "source": [
    "## wav2vec <a class=\"anchor\" id=\"ch18\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QphVP5PF_S44",
    "outputId": "7d0aaedd-2c6e-4e6d-9257-62162dd50a77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess \n",
    "import os\n",
    "command = 'ffmpeg -i /content/ES2009c.Array1-01.wav -vn -ar 44100 -ac 2 -b:a 192k audio.mp3'\n",
    "subprocess.call(command, shell=True)\n",
    "command = 'ffmpeg -i audio.mp3 -f segment -segment_time 10 -c copy %03d.mp3'\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "br6ePnE6_ZIF"
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "for filename in os.listdir('.'):\n",
    "    if filename.endswith(\".mp3\") and filename !='audio.mp3':\n",
    "        files.append(filename)\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gW0QOCsL1JpZ"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0KJR-mE41NWT"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "#Importing Pytorch\n",
    "import torch\n",
    "\n",
    "#Importing Wav2Vec\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StoX73JMy0rT",
    "outputId": "2acb3863-770f-4757-fc1d-4003e674ddd9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    }
   ],
   "source": [
    "audio, rate = librosa.load('/content/000.mp3', sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UHrzyS-1Xbl",
    "outputId": "66a0d725-fe39-4b8f-8251-3e940ad8b24a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:419: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  FutureWarning,\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POWQeiTW1bU5"
   },
   "outputs": [],
   "source": [
    "input_values = tokenizer(audio, return_tensors = \"pt\").input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShSekqwf7xDz",
    "outputId": "8ec16d3e-8d55-4fa4-8336-1bfa23f07bff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159887"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBujdaIs1fXu"
   },
   "outputs": [],
   "source": [
    "# Storing logits (non-normalized prediction values)\n",
    "\n",
    "logits = model(input_values).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKMaOA-t1kx-"
   },
   "outputs": [],
   "source": [
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = tokenizer.batch_decode(prediction)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYiZDZxINbBl",
    "outputId": "1ab14c3d-e7fd-4322-e94d-8c07d62c45d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000.mp3',\n",
       " '001.mp3',\n",
       " '002.mp3',\n",
       " '003.mp3',\n",
       " '004.mp3',\n",
       " '005.mp3',\n",
       " '006.mp3',\n",
       " '007.mp3',\n",
       " '008.mp3',\n",
       " '009.mp3',\n",
       " '010.mp3',\n",
       " '011.mp3',\n",
       " '012.mp3',\n",
       " '013.mp3',\n",
       " '014.mp3',\n",
       " '015.mp3',\n",
       " '016.mp3',\n",
       " '017.mp3',\n",
       " '018.mp3',\n",
       " '019.mp3',\n",
       " '020.mp3',\n",
       " '021.mp3',\n",
       " '022.mp3',\n",
       " '023.mp3',\n",
       " '024.mp3',\n",
       " '025.mp3',\n",
       " '026.mp3',\n",
       " '027.mp3',\n",
       " '028.mp3',\n",
       " '029.mp3',\n",
       " '030.mp3',\n",
       " '031.mp3',\n",
       " '032.mp3',\n",
       " '033.mp3',\n",
       " '034.mp3',\n",
       " '035.mp3',\n",
       " '036.mp3',\n",
       " '037.mp3',\n",
       " '038.mp3',\n",
       " '039.mp3',\n",
       " '040.mp3',\n",
       " '041.mp3',\n",
       " '042.mp3',\n",
       " '043.mp3',\n",
       " '044.mp3',\n",
       " '045.mp3',\n",
       " '046.mp3',\n",
       " '047.mp3',\n",
       " '048.mp3',\n",
       " '049.mp3',\n",
       " '050.mp3',\n",
       " '051.mp3',\n",
       " '052.mp3',\n",
       " '053.mp3',\n",
       " '054.mp3',\n",
       " '055.mp3',\n",
       " '056.mp3',\n",
       " '057.mp3',\n",
       " '058.mp3',\n",
       " '059.mp3',\n",
       " '060.mp3',\n",
       " '061.mp3',\n",
       " '062.mp3',\n",
       " '063.mp3',\n",
       " '064.mp3',\n",
       " '065.mp3',\n",
       " '066.mp3',\n",
       " '067.mp3',\n",
       " '068.mp3',\n",
       " '069.mp3',\n",
       " '070.mp3',\n",
       " '071.mp3',\n",
       " '072.mp3',\n",
       " '073.mp3',\n",
       " '074.mp3',\n",
       " '075.mp3',\n",
       " '076.mp3',\n",
       " '077.mp3',\n",
       " '078.mp3',\n",
       " '079.mp3',\n",
       " '080.mp3',\n",
       " '081.mp3',\n",
       " '082.mp3',\n",
       " '083.mp3',\n",
       " '084.mp3',\n",
       " '085.mp3',\n",
       " '086.mp3',\n",
       " '087.mp3',\n",
       " '088.mp3',\n",
       " '089.mp3',\n",
       " '090.mp3',\n",
       " '091.mp3',\n",
       " '092.mp3',\n",
       " '093.mp3',\n",
       " '094.mp3',\n",
       " '095.mp3',\n",
       " '096.mp3',\n",
       " '097.mp3',\n",
       " '098.mp3',\n",
       " '099.mp3',\n",
       " '100.mp3',\n",
       " '101.mp3',\n",
       " '102.mp3',\n",
       " '103.mp3',\n",
       " '104.mp3',\n",
       " '105.mp3',\n",
       " '106.mp3',\n",
       " '107.mp3',\n",
       " '108.mp3',\n",
       " '109.mp3',\n",
       " '110.mp3',\n",
       " '111.mp3',\n",
       " '112.mp3',\n",
       " '113.mp3',\n",
       " '114.mp3',\n",
       " '115.mp3',\n",
       " '116.mp3',\n",
       " '117.mp3',\n",
       " '118.mp3',\n",
       " '119.mp3',\n",
       " '120.mp3',\n",
       " '121.mp3',\n",
       " '122.mp3',\n",
       " '123.mp3',\n",
       " '124.mp3',\n",
       " '125.mp3',\n",
       " '126.mp3',\n",
       " '127.mp3',\n",
       " '128.mp3',\n",
       " '129.mp3',\n",
       " '130.mp3',\n",
       " '131.mp3',\n",
       " '132.mp3',\n",
       " '133.mp3',\n",
       " '134.mp3',\n",
       " '135.mp3',\n",
       " '136.mp3',\n",
       " '137.mp3',\n",
       " '138.mp3',\n",
       " '139.mp3',\n",
       " '140.mp3',\n",
       " '141.mp3',\n",
       " '142.mp3',\n",
       " '143.mp3',\n",
       " '144.mp3',\n",
       " '145.mp3',\n",
       " '146.mp3',\n",
       " '147.mp3',\n",
       " '148.mp3',\n",
       " '149.mp3',\n",
       " '150.mp3',\n",
       " '151.mp3',\n",
       " '152.mp3',\n",
       " '153.mp3',\n",
       " '154.mp3',\n",
       " '155.mp3',\n",
       " '156.mp3',\n",
       " '157.mp3',\n",
       " '158.mp3',\n",
       " '159.mp3',\n",
       " '160.mp3',\n",
       " '161.mp3',\n",
       " '162.mp3',\n",
       " '163.mp3',\n",
       " '164.mp3',\n",
       " '165.mp3',\n",
       " '166.mp3',\n",
       " '167.mp3',\n",
       " '168.mp3',\n",
       " '169.mp3',\n",
       " '170.mp3',\n",
       " '171.mp3',\n",
       " '172.mp3',\n",
       " '173.mp3',\n",
       " '174.mp3',\n",
       " '175.mp3',\n",
       " '176.mp3',\n",
       " '177.mp3',\n",
       " '178.mp3',\n",
       " '179.mp3',\n",
       " '180.mp3',\n",
       " '181.mp3',\n",
       " '182.mp3',\n",
       " '183.mp3',\n",
       " '184.mp3',\n",
       " '185.mp3',\n",
       " '186.mp3',\n",
       " '187.mp3',\n",
       " '188.mp3',\n",
       " '189.mp3',\n",
       " '190.mp3',\n",
       " '191.mp3',\n",
       " '192.mp3',\n",
       " '193.mp3',\n",
       " '194.mp3',\n",
       " '195.mp3']"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTP9YoqI2U0x",
    "outputId": "53e55243-9d90-4ed1-a2b3-9344a372de31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    }
   ],
   "source": [
    "results_facebook = []\n",
    "for filename in files:\n",
    "        audio, rate = librosa.load(filename, sr = 16000)\n",
    "        input_values = tokenizer(audio, return_tensors = \"pt\").input_values\n",
    "        logits = model(input_values).logits\n",
    "        prediction = torch.argmax(logits, dim = -1)\n",
    "        transcription = tokenizer.batch_decode(prediction)[0]\n",
    "        results_facebook.append(transcription.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUniVfKEKzpI"
   },
   "outputs": [],
   "source": [
    "results_facebook_ = []\n",
    "for i in results_facebook:\n",
    "  results_facebook_.append(i.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugNTMBK1LY6n"
   },
   "outputs": [],
   "source": [
    "text_str_facebook = ' '.join(results_facebook_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "h7gioU8eNL5D",
    "outputId": "29bb2630-7a21-4503-f726-4284476de3cc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"o o  angr me yo art selt an  rainas you o go all right mejuss howr parosir fool h right so on this meaning will be about the conceptual design tot as ma precisell conceptual design is sa just something important at we not do im ti scanava turningly abstract into slighting more concretein is meaning ideal we will come to some final decisions aover than it is for the prototat im right so an apoligise for the last meeting it was brought to my hension that i did not make the rules clear enough and so i will attempt to do so more accurately in paricular medi am there enough exulin watars good am so bsi ga worging to do is hassome presentat to get much at glast time im gaga throughyo i werotska firsis find mi ma i many old kolat what we know about im o iscussing lasting any possible directions and then we'll make some more decisions on a basinfirm up our idea how we want this romoo t look and work se perfect so without the further adea where alt go first to spikin ot o er sciding togoet it is eithera a going the row away erins good said the nathin ar partisipant to she mister berchasmen tyo let is nase a k mis a beastly woman has talkty about to day is am component design and it's bedn brouhts my attention now may be somewhat limited as welk you do because of would our manufacture offers so you baseley what are gon be doing tarue alike that a prits of rm control ca we've already kind of butteer this bot ranteand tip worty tellind proa have to reach some conclusions sometimes soon energy source on our manufacture offers of riety of energy sources you standard battery sor selvs our manufacture didn't say anything about lythium so we might have to l if we do go that room we may have to look elsewhere ah and also there's a cnetic energy possibility baselaed sigkay own the idea mov think that remote would create have energy to keep it running satrel huspry i don't know whether that would be powerful enough to illuminate a touchy soll have to look into that a the case we have a few options plastic rubber or wood ah and then as far as ways shaked we can do standard born flat wich repuled dun to curve dor very sexy duble curved tickles erry looking ot ah i imagine that we could specify ah i don't see you reason to go outside f that convention if three or four millianrs  m the buttons there are moltil scope buttons ail bfore manufacturer pla to use those who would have to use more chips now acostume and if we do go with rubber double curt case ah whap do ye use rubber bushbands bcause yeether buttons out could have hu with them ah and just e one out there ti screet iguas mn cheps which equas mi earop an one think that i neris is that most remods uperat on a and freenly ofred part of spectro so you notice when you push a byly mot you can't see anything coming out of it but in fac there's light coming out of youremot and ando the telligent condecti and if you what's a record you'red nake of ary bernie could ac jus sea li ah one thing tha i thought my interestingas to use part yu'se visible like commanded mil just kind as a fun ginick das he could actually see something coming out nnt pushed it course a happyer parlespection that would it damage to humano  io i is yore nox er we cold have to offer ons o prisicud select like yea i an trure that wu could do im me horse sai yo at's good to do yea just as a fon ginick just says parlaba ah then on to the circuit he wo down the euwse all soons the chip ah we're good to hony wear round te te a one one eih three five o findings o k we are very limited by what our cre manufactores can offer o and my question to all of you is she we looked ot the manufactories snak to what we have belll you dress yo sto champed wish i say shap aroun bu it with our tinecin traites that really if he's mocket an right that's my consent too  if we do go thel it the embarrer explained 'l hav to go asight kr my personal prefinces i'll ustrow ma carts on the table i think we shall figer the sourt o battery roo just can keep with ye environmentaly friendly thame that we have going on i like edyo the visible light signaling something te says apart and i was thinking about but's thinking at ways that we could produce the remote and of rie a different casin chails a suit different taste sonat so can fined by one style onsaysintly now say er the one ef re scote one and is a goobe wall en renne that situation n  call you mark it an pile in to try to see what kint before we lunch can me so one received aits and alshan ive actually there's i've got some mer sorjury and like what we're looking and trans in casey moree now aprojectiony madine goon play beforehand in orders decipher now great thet verymu in smerchers so i ge si makes as read y a kin i guess e because i fancy interesting things ene fassing did you knowii know what i's you earn it and right so hernt lookat trends scrat um he sas hooking at what's goming on ther in woll control market right now and what's going on other design fields to seese her whats whits trendy what's new what's happening um mokento all right now basically everybody says they want knewer fancier or more siting their sick itness boring norma old function all am that we need innovative design auctions and e neese to be an easy user in her face a the challenge is that current trensray now across the board in fashion in furniture in technology is a very organic for vegetable anthing nowi'm not saying we should have you know to made o shave remote controls anything but i think it is possible maybe to use i natural colors like if wood is an option that hole organicsly clean it vine thing it maybe so we can look into different ski aptions or if we can't afford this touch plaything er touched faced screane in her face am maybe having the images b specific lhy you could choose your mano bullets to be it's differes she he another name no egey haven't you you know what i mean tipto and apparently the feel of the next coup of years is spongy i not something ha at a i wut him deaf t is rundo if we can get around getting piling i thought may be a casing oction like at not like a skin but like a colder almost if he could do like in naither option or bod oction or something i should have mentioned is so as far as the rubber that we can use we k'se a ruber as parle case t has a consistency of those stress boyspeope might be notetoay togo querk um yat so something to set on frenounce so over all i think we should stick with what we're finding every's looking for easy euse technologic invative and this fancy knew i think praft the double curting and maybe dis rom roption is our best way to gope ma now um intervens olyto phis gratic for ya un well i don't spet dan if the touched screen thing isn't  nwork out for us that's really non iss you i like ced to of rever s you becaus it's tense thi say so t being durable somethingthat he can drop does he  her so many you go to so many houses is tis  sepret on not controls ain't you yo hint with dat te very much then would have the fault as you did we should haven't a doctor kiss ah i could think at goes against the whole fancy something do you mind bu w shalk in goin the thig gernala crowd a e and the at that's what i know sgrap fixbat said or compuners a just one olttis so itor interpase concept by your faithful user intervece egia so you don't use in er pace guises vascaly aspects of a comperisins that we can see or here or otherwise a perceive a commands to mechanisms that basically your usus to control the operate operate system  here's an series of different ral controls that areout on theamerica to day i think we're deckly trying to get away from this kind of look e a so the following are a bunch of different i interpase aa consepts a vace recognition we if we am actually have some new a information from our research designed tim but a get t that moment am so rboyce recognition stars up to about eighty speech sampems am anbasically record your own verbal labels can connect them to the real control now or design team research team has been all to you ah set up a system in which ah you can teach the rirma control whisk recognitioned system to prspan chi a with standard responses like you can say good morning a ruma control will say in h a female voice good morning joe am in fact we already have this for a copymaker line glass single people yehave a e marpange ro cho said gami wa am another concept is what to that apple has come up with the spinning wheel with a elsie to play likeon theaeyepods which a ture must be no ond  then we have the scroll bottle with intecated bush bot mon like a modern mos a bit bulky a bit crazy and don't think that's what we're necessarily going for and a some special component sa ideas like gob locking having they villated a block channels from for your children hem and a dedicated buttons for for commonly used achannels and even nat ideas like secure or hidden progamming but and again if we go with atsce nothin that's a big issue am and athis is canadea the big daddyar jloga athe jumble you ar sort of o control is almost impossib the misplace en as yet onseh again probably not what we're going for s mean my ideas here in the kind of where i think we're heading as something slightly lik to the i regular ey upon with a hard classic cat classic casing well i think some of the suggestions would come up with her definitely o very good ideas a changeable ca sincs  our designe team was possibly talking about including one extra face fight with the package akit of set the idea that you can change him you can tri changing a kindo get used to thinking of what may be buying another one which can ad value to our bottom wine a touchd ine fa i possibly having go two buttons being a stuck into the system so those don't move away from the screen the important ones like power volume and jump between channels um and of course our woys command system which ave talked a little bit about already and i the use of recognizable colors in shavesae recogniti of the feature san tittround so read for power whi airows wer different volume up downs and channels up and downs ane what not and a perhaps you an adding in some stupe lottl jokes with the boie recognition idea rnfrens it's my toasty maker that i got from my bank as jokes when it's ready yes the great and a bad sa botter pral for a o a good ideas good facts in o eh at to then neas a little doggl and just six up the sprrows you don to stand at and begins an a cateno right so go didn't all that sathi as im now can act come tos in decision sam tig we jus go while i'm not through the cnaba chab bau i'll me base on what natin presented as far as he athere is cossin benefits an i think i don't know what he guessin about the touch grait at this point i think it's a most markable feature just because it's so new and is something that is show nough in other places a can we really afordi cause it looks like thing be that would be a really main cost sorce of an right my estimate is that simeratu incorporate toh creen technologies an covses upwards aid seventeen fifty yero throu e mant and that shous nes weeness you guess were always the damper is on te en you industrial design lie now it's iin an our goal was to be under twelve fifth year we have to be in atweverty well i thouht there was so fux bility with um there is it's just it is a questionto jestii and how much o doesady gret the increase surprise to make money a from twelve si dif ye want to get at fift at hundredsof profet mergint a that would me  salin for twenty five she was by seventeen fifty about yue that's thirty five only so youhath come up with these mumbers a suf top ma head it is penting further hemounts  h ai funable  for him oh dogh i think that's aurd people would pay for if you're gen a paper an expensive high class remote you can't expect to do something that's true i isn't it w being aclassa john en and that's to be veiry young the puset of the market we're not going for mass an  mansails anyway we're going to make and e won wat ar talking about selling eight zillin  of these things we just couldn't no for twenty at your ows so we can cronly me shak the profit wers an rather th sether for twenty five sellin for thirty but that's endiit again ad stillwet no i say that we provisionally go at the taxscrare youreworry what was your bout manr or i'm thinking that ser definitely good idea inaow to thing that we can probably come up wi some sertva cheabera means to to go about this kin is tat you get my corners my cheav in the yell on the third floor ojustwhi we can't look at this other manufacturing out jennean get a o reas he per  it's true we can initially go i what we hav were you can find jusdin win any night thut we can have as very simple touch screen heu know is always the opportatit to daby about the size of the ey tought o whatever you o'o yere iguess we can play around a fit of bit ilands one say that theu case of the testian will be our a our main selly point here wuy i think t atwe really have two man salin one e jas ina cletter tais nan anned the voi strickin mein weally dicious and pretty thousand whistles cansr low the voice rak thing i mean iif were looking at bottom wine now were looking up in cossa savanteen to get tettian i think mater drop the wesser i can gase to sat between our deafinitely nou to be on us we have the cape we have the design in house i mean we've we've come of with us with just newwix we're using it burk off here machines already i can pass you on that yeu mail from my a guy and now guy down the hall sounds good act po waysint on otherwors back i think if wee we did b both the i see prassian cospin togotehead but just put it intoo it become the rolls riser for mo contrantents or tanks mean we we have to reflect back on what our markeet reserch jatson i and they said they ont voice recognition crsimet and thought of this little touch scream option but deat linkwe know the work at us there for rhich recognition so to say we had a techknology and we're not any use it even though we know it'll sall it's a calin think i can do that said langrily i can't go in to say now ere goin to stick no arm it you we now ye does have him both really a perhops i can't see how oodn i mean there's yeto the old affriswom you can have a fast you can have a cheap when you can have a qu pick two of thirty ye very can't cant can hav olf rar caus e iyes i be number of chepsley need to deal with each o function well if were it a pipati i so we have to pick two one or two aotherwise eamogisted just becane cossperhanded awhat which which do you suspect we should old who should alone to well we already have researched back ingwy sercoition you know hiskily solded but a i i i personally would tend to othe direction but if that was miss sall i think as we need to go at ten mame we can teale this touch screen for our next monel i would have to sid with that i think the voice recognitionis simply were to have the all this acknolegy and house it's ready to gets package ts what is a costuk like word is a cheaper who the yard to re the a touch screet nethin wel my pa itho is just off top my head keeping on bet i think the voice recognishouted they're both it they're both going to push the cross up replied tom since we already have the techknology had asked for the boy's recognition rogen had to do as much design work and sometimes design work as what pushed the osso where fewit aman daff way after yo with a lot and we're still not then youre to da with his barry is you knew is wuh either then begin to stick before yebore e guy he'll not always did and so all getting or  tod more or less yes think other two of  the boy's recognition wl be betteed an any tangleo rescoption wit yo ot right now we can have it on the market schooner riches all in all our best aption look i sortiy we wonl amit the custry in favor of wisrecognition noti noso and when are we can have beesick protentives coming up next that's youris a next tatrigt ye are alwors sigol tor out what what what else for ge to talk about men orittapayelater n extantan pigo are we going to talk now bot done temittya's arranged foanis a case wudis run thoug yahakana hum you discuss it in ther a lithia more a solar power would the solar power be enough to febl a goistr mitsha was chenestetic one with that be enough to fuel avoice recognition ruma oo the sole power dephlin wouldn be but i think just keep peoble from inanoyicus sometimes saw ow our fellows to snowround that we should install a small backat ary hu e just tecover those moments when whatever is the mud has a loks of bo such as even ther basement minlingwit the wouldnt we can't get an tea somethit at a race o having a shingerry sources probably it worse about the san is a so o coard calculator and you know how does this arealy require that much lihe cheered augustly little more like than calculatod but were not tacking ow a while it is at to be ou tacking some last er try staini cat way they got i'm going to do agree with everything that's been so i have to say though that another ideas come upon my head if we're really not a handling that promod control to a great extent we could poss i get away from the idea of having and held win control and maybe kind of half her round her in control the cantlis like caperwaers kin of a sweep little ot anything that sits undour table or semetingetor sak nmaspa thought why don't you away from hentill why its pen well if you don't mean to pick it up if you kind he is coming els trecking to shaking me technically anyway in your room and still do is job you think people are people at byrin moter they always get one use the worse ritinsionsis something they do sometimes ature any probably i think were bang on telling to more in just we sirk me should people like e want to work one mentally y i is lite earnt too wa rank but that's done that's so bother me if you look at the cowalogue from tices out a sharp remager whenever now they might have all like a who has an apple makes these really pretentious speakers wot the sablipher not clear and glad isn't now ny got th i turmiddle type of o stanier something why not have a little roundy cutathing it could still have the basif buttons on it om cause we're goin for basif function ality ci rarilias we it ba ye and maybe i ma new biton n so forth in yor arm use a jannel biton to skull for the mania if they want to recort corencial what every mett ats sonl i think you're on to something yes we to escape the traditionain shape of remote maybe something h looked slice on the tables would be good even though ann had held us in time figo thall about following applesly on beyind thinking of the airport no do you knon a nes it all podlookin thing esie yemeeted is although we do ev az eer calling she mention we need get away from the surgical wi kind of brusha an wen om thinking in tact rabet he could have a very tasteful on wood colore or all the time it of om connaborge still i main't yet i will always lince yet i like that i like that ideal lot am but see we can do as far as it goes and the athe material like a plassic and so forth we were discussing that being a uon make a rubber kind of softer feel yu ameal i like to filla tip on his pet is a bit givs just a bit youn't know something wore it's a aa more bis from a plassin passing cao tacked out wats to it we just cind of the swish you do yeh which is the next big thing so it after her if e i we ha yes if you can do it sqishy non remote control looking in remote control but di be feiry avin you just just put it glittre ta put it on that the night the cocker table mex an italian say bow him up ani don't like i ike gat im isga ah  ser dis guss ka don i guess well all that's going to be up i think if the run a bit over budger than might yo kay ha sorry banthia lack hem fromisi jn kassashs havnt been provided fish by my advinturs oon more anger to get us to and more  one more itin wy aha ha ron't a stami goffre meric an so we've re visited the touch screen and more or less you'll bat out an ithink so or more or less can w what were more less in agreement than we want to have a m a simple kind of function you know not twokomblax gray well when the majority people are only using the most primary funtiontle in e day besis although i'm not saying we she completely rule out major functionply should be secondary at least if not functionalyg and visually like those it shouldn't be right at maybe have made yor tings if n if we're nt go in the touch screen roote then we ken in am just in corporate may be something that folds out like way off to see a these country notes is the most basic functions of gair nissinting am swides down into violia th more coplicaates wonl do on to consider like an ipod screan which isn't a touch screan but you're still squirling through many ochins in think then we're hiddin our costa si o chairs we sa bos  dons and men the thing i  fore i have a none remote looking remill  you have awe te but none who can do sly at her compartment you know like i can sasiore a little vaguely avoidable type thing and ease to have a compartment in there or ino bu up a series of mel threeorful buttons with a many batton and then at science up and down ake a thing like onne lik got at he ne clare yet ais't mard mebbe plaer sll just have i a madian button on a side and then the ant foll luttons around the mas kind of he annever throe made like lat so rigin are we talking music ye are worcon bitons with oine teas rgoine teas score bitons reber bitons what seems i er it seems to me a we could justubi sick with the robert is for probaga to be used in some kind of a rober for the outside case an mellas mistake with that or think to a certain extent we have to stick with the tin of et a little be traditional on terms of the buttons and then and then make our uni e jurkis  ander gris well in those rays it just like four directions that ar that can use as many or channel in volumer hov e one do it our really birst at all end everysoere he got them tisn't he said on mose there yo own some stot like we're dealing with everydy realer in vabscase it's ot so manybays can one it what i agar om the very has cover this is well at sas be selli i o o morais good i y or to cart targas youth market oh especially now as eighteen thirty fivals being so as quatity of population perticularly intechological field sam to daco ratit acoun u ye right wont moral is covered moundid coverthink fo indyin for thoughts before we chank about doreparted or movenont ert well what are we actually doing what right i was just get step on to em ah how i wasn't in i wasn't alk my bed i'm sorry no no n bea yalwkawska besin tasks him h nextionner if an adny o fiva thout boo we go him go so have we said that we are going to go with different style cases for different people are we skungof warning it's very it's very part thing to predict because we have different cases and then my open remarket will bat ae sleep but he have son case and it doesn't go to on yewich waguste having mork asassa cosswas well then a gain colors wouldn't be so hardy dar you get out ar sinta i et em i a a capanateral wood collar like a skinin wod and now all in green or something idean that woldn't be so much mprompt and corporating in the colour of the rever out think and again c upping eymax kind of fer eye pod mackt apples o collar sceme yet tolly ye i think that's probably getter ill ga so it's work arde amultiboy case colors baasic wot the same matter ye adte same masic an on remote kind of remote design col i to oll the next meeding about half an hour im ho want thee id like nithin likey work on just a basic look and feel what can we accomplish given these grammars o sir sir gat this kind of a non remote remote brown what are abroad constrain it's before we'd design of pos ie and i'm long if you can so youre how how we best to lay out this idea of h simple design with the voice recognition ot den and also this kind of drop down or omiside can of manu octions simple somehow e work out how we can get this alks in the same place eh and if you can ject product of gaation tsumed pilots a stuff i did you gess to work together and making a put as ide im imusing protatihe guilding material aman rowmd it allso wot mispecific instructions will be seid you menhe coach as a tox so that's t start with renax tat all right mes the sin skad bobulis all right a yisit dirst is a go\""
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_str_facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zbpUa2-XLhkX",
    "outputId": "417b6bdc-57d8-47ac-c36d-c9a48adb77bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER facebook: 131.48404993065188\n"
     ]
    }
   ],
   "source": [
    "wer_facebook = wer(text_str_facebook, transcript_speech)\n",
    "print('WER facebook: {}'.format(wer_facebook))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_G9yw8Rqbswe"
   },
   "source": [
    "## IBM Watson <a class=\"anchor\" id=\"ch19\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RvyIGOrv2fye",
    "outputId": "4703feeb-f521-49f2-99b2-1d09e702c866"
   },
   "outputs": [],
   "source": [
    "# !pip install ibm_watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCOuwIUvbswf"
   },
   "outputs": [],
   "source": [
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ub1BruG5bswf"
   },
   "outputs": [],
   "source": [
    "apikey = 'wx9rd4_OMeYZpzOHBcfhDNXW5X6ECrfaU0u54fhwiY0M'\n",
    "url = 'https://api.eu-gb.speech-to-text.watson.cloud.ibm.com/instances/5019271f-5147-4778-835d-8c1fac38fee6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jo9L8o4Mbswf"
   },
   "outputs": [],
   "source": [
    "authenticator = IAMAuthenticator(apikey)\n",
    "stt = SpeechToTextV1(authenticator = authenticator)\n",
    "stt.set_service_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTvz9tpfbswg"
   },
   "outputs": [],
   "source": [
    "results_ibm = []\n",
    "for filename in files:\n",
    "    with open(filename, 'rb') as f:\n",
    "        res = stt.recognize(audio=f, content_type='audio/mp3', model='en-AU_NarrowbandModel', continuous=True, \\\n",
    "                           inactivity_timeout=360).get_result()\n",
    "        results_ibm.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLDO8NGzbswg"
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "for file in results_ibm:\n",
    "    for result in file['results']:\n",
    "        text.append(result['alternatives'][0]['transcript'].rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJkl7Mh8EhYr"
   },
   "outputs": [],
   "source": [
    "text_str = ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ljapv2e0DaTe",
    "outputId": "e4152651-230e-4a3e-dfa2-3cd46c67e4d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER IBM: 752.6385224274406\n"
     ]
    }
   ],
   "source": [
    "wer_ibm = wer(text_str, transcript_speech)\n",
    "print('WER IBM: {}'.format(wer_ibm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awTYlCCAbswg"
   },
   "source": [
    "## Метрики для распознавания речи <a class=\"anchor\" id=\"ch20\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGGXtWyzbswh",
    "outputId": "db0a8311-2131-4a2d-f891-aaa2e6e4aa24"
   },
   "outputs": [],
   "source": [
    "# !pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9Jyd8cjbswh"
   },
   "outputs": [],
   "source": [
    "import Levenshtein as Lev\n",
    "def wer(s1, s2): \n",
    "    b = set(s1.split() + s2.split()) \n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "    w1 = [chr(word2char[w]) for w in s1.split()]\n",
    "    w2 = [chr(word2char[w]) for w in s2.split()]\n",
    "    wer_lev = Lev.distance(''.join(w1), ''.join(w2)) \n",
    "    wer_inst = float(wer_lev)/len(s1.split()) * 100\n",
    "    return wer_inst\n",
    "def cer(s1, s2):\n",
    "    s1, s2, = s1.replace(' ', ''), s2.replace(' ', '')\n",
    "    cer_inst = float(Lev.distance(s1, s2)) / len(s1) * 100 \n",
    "    return cer_inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuP5zb9-ShUm"
   },
   "source": [
    "# Комбинация алгоритма распознавания речи и суммаризации <a class=\"anchor\" id=\"ch21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Stt_HdLXY4Fr"
   },
   "outputs": [],
   "source": [
    "test_ext = open('/content/ES2009c.extsumm.txt', \"r\", errors = 'ignore')\n",
    "human_ext = test_ext.read()\n",
    "test_abs = open('/content/ES2009c.abssumm.txt', \"r\", errors = 'ignore')\n",
    "human_abs = test_abs.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OmC6Q7bdLWuZ",
    "outputId": "ee118b3f-6c21-4a5d-d353-87375e8065da"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_str_facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTHvNS74SgoN"
   },
   "outputs": [],
   "source": [
    "# частотный подход и wav2vec\n",
    "final_sum_2_freq = summary_luhn(text_str_facebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJnExYXhYMFf",
    "outputId": "b8644c71-547a-428a-bc97-22ad74688f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luhn scores: [{'rouge-1': {'f': 0.28158457933283115, 'p': 0.7315716272600834, 'r': 0.17434537620152468}, 'rouge-2': {'f': 0.12533475854345016, 'p': 0.32590529247910865, 'r': 0.07758620689655173}, 'rouge-l': {'f': 0.33093524735212015, 'p': 0.49595687331536387, 'r': 0.2483130904183536}}]\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(final_sum_2_freq, human_ext)\n",
    "print('Luhn scores: {}'.format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ab8pe8yT35_X",
    "outputId": "6f714874-3f7b-4e27-f741-10035256ef96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwCkv7sbYrPZ",
    "outputId": "6b8e3766-cb96-4d1a-af5f-ca37dc1cfcda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2726342139657395\n",
      "0.005524861878453037\n"
     ]
    }
   ],
   "source": [
    "reference = preprocess_text_simple(human_ext)\n",
    "candidate = preprocess_text_simple(final_sum_2_freq)\n",
    "score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "print(score_together)\n",
    "print(bleu_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "Xd8TdCkDjEh8",
    "outputId": "c29d2672-3104-45ba-a0d4-20dd4e68531e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"shdie oiicious visant witli  ma here are repli gis o o oweryo soyo o yes think us  befort managincin ah so and then no wewere close is meeting aand oft if meetet weal o  lat a lech god oo ma a why a anna can you a door a pristalta you don have for olliver i a one at tay gain agan again my l iwork e tas ou bet go an  walo an able to n to wa i can dell tha abat mer a it my be may be cenente candyof thork bad or it may be con you to wid what if necessary am but i disdaine an present withsom by set a da ad a small bagof scrapes i honpy people disasking atat there remark a trall yeu seigh havits and what they want to know my control um it's haw igatyon asked he ive just got a white page tisnt at on it im bis clit saying that use is jerally disli it at a beal of yot to say ma oe sai an e may ogantis comoka asaays open it or fees wic teaf there my controls i'm seventy five yo senta cap set of uses fine mustwrite te tross eyway nam i hip said afbusist would spend more money when i are aout to trall little patsy  ta mat con crharls did not match while the uprit ing behavior of the usis seventy five cent of es e said as aperlot said eesirmy catrol quite frequently while i ought to tell me i thif you pe cent of yes i side that there any ye s ten cent of the battins 's ither bot fo rakentros    yes youe off me so we a for yo jus out all e te some men  tear the ou aac sha so lov o rtonality but the arylisis time that i need small part of that in un wo do you have the assir information on the reapon hond it e wet as yes ters mank maybe you can can set any mil to me layer or  yet j about yi  sa descay and there's a b dat paliti te different cuction or rit control an power and body selection areused a few times within this a prow ow chiles like he  r disis i is it dayaties an a and the same black channel settings oryer setting an used very afrequently an kelitex is used a fourteen times an the our so dis but not merely as much as the chances lectionsis on don't you think that this rebort is brought up is a annd ti ti fifty bsead at eas as youretought that the ragatar gets lost aball the time in the wayn yes i dont my har hat   tho they are a to come i av like itim in a re control what be very useful to bout of eases an thirty four per cent said i tight tilong the lantesar muc control the with things easy to ge stright away aro to pats iise it's easy to know an you turn you stady bob said said it to t o much time to land au guros nerestoni to moroonor and and thirty twenty six percent cents remork contrals a bab arsi i don't know ly it's got that fo coma at wonded me for asac hesasy o a brodis here fish short me  e was the gain of te dis mating te i will ah we shan toer attende with with ot wich lie sight to ah as i to er e joo first the i was tet for bet ti ty injury ie that i fingta are gly doctors doctor says tut is is the opinion of ter you to yeo es a abotote am and then it's tha denographic bright down may beyou cannave put this wepage on lion onte ah i should be abetact if i connot see you now your culness correcte ton loocan may be just o your tat ye aga into whipage and see yesified ain how though i sou yet many con connected you just to mention i o bag notes aof his meeting and i'll try to work him out and get himto yuk also make notes of the breeter's meeting and ah i was about to send him you wut then h i hat go to o sand meeting so you will get a to wor am shere your the secretary anser ye benny indeed am then i can connect is one  a por dea so these are important numbers that mathew and iny to take into account for oh arasnol it's por easier peope are yours nosday nowty mis is lebi he help yool haf a worked out tetergus ma u fo for presedations about teh about all yo de ditosk if to in a previous meaning ah we will ah in a minute we will a stark wits dem ah youill feen which order the landl tem off a then i will a bringinfom fom fm you qe yeris numbers us as to be astibut i cenning to account  fote both and hesenta face and the out froson desiing wone dak is anto talk about intstay is he because there are many numbers and we need to select to constraint ah our design bezon one is more important andyet and monday ther sday is tokhe that poor requirements i gote fonde acantenser i try to work amout to work quite abtract and o can av ma a n description about it sir about funcus and well just meeting we should be try to recha decision about t cru and pefutiality you mean the soshur tagedru yes i means well iga yes who are we going to it well to sali us al geycosf rigtin indeed i'm sa you conmistion in i mi contrall specher omissionin and he would pay himore for that and by tha pid with my easfol do you ho ande yes a sos ther wou don't do woudn't need any bitten an thou i w os go ther oben or beson speech rinkien i even for dressing adia most yer i think nowane not wet si while you and hav by thoughcants ii yes thingus as befort madasencan ah so and tenwewele close his meeting aand of if meeting weal a lav luk i o  may a why a anna can you a do yoa pris genalsa you don't have for tolisan e one a day fell it wont be a solution for on your remust av foldid lost i mean when as peterecommissioned thand ah it doesn't matter where it is my wallets who should be enranked  who maybe it can rech waltan produce sounds o fay where it is but did this are al quite fancy future i am not sure whether we will we can make this for fortwellof yeur of yer ifty hands nay can wed able to to right ack and tot bat abat mer hiase mybe maybe endento candeas tork body tor it may be cen you doide what if necessary am ti is and am presented with someberysetue gone and a small bagof scrape si hundy people disasking about there remark atrall useage habits and what they want know o control um it's ibic no in ase yo i've just got a whie page tisnt out on it um islit sighing that he is as gen dislike and of a deal i do't know where the state of the other spicual conmission is maybe you know pah but i de badly don't like taries there it's a very smallolcovlery very on gie dan ic on lie noing fot al why but i's quite noisy nhow there is the me y yenowin anyting not going to be does it so easy but shma es youly ispose you more for icolator do you have o waysborin sect  there miconjrolis i'm seventy five head sen gab sad abuses fine mustert markd te tross hadway non a hap sand of uses would spend more money when a remarkd to troll would look fancy cant ama contrals do not match while the uprit in behavior of the usic seventy five cent of ese sendays apalot said he e sermot cantrol quite breakently while i watch you tell me i think you be said of yos o say that theren years ten cent of the battens so iv got te racontol am oi no threnty to ye ed lateday to some morise may leg this is snatch of he mad a'm he would pipe e state your cognition in our riht control he'll pay mall for it and najig sant of the fifteen twenty five year old market said that they would pay more it goes down from their seventy six per cent for twenty five thirty five thirty ipcept e that he got to boy by am plenty two percent all forty fiv tomisi five an ten i seve rer maser my he required fo forgetwis word yet it really depends where work and be or in love of factionality tut really writs i tin that i news a small part of that  um do you have this  information on the weapon o  o weatonos es as man maybe can can send any mill to me layer i yet juaabout is si besqly an thee's a rectaf pality the different functions or rigt control and power and body in selection are unused a few times within this that afper out i'm charles lectin sivating wis brought out i'm troby toamet letter i think yes i e ye er er a as ein dellen that aishe is i is its gayatimes n and then ha in blak chalnels etdings o yer seading an  used very afrequently and kelidex is used a fourteen times and ow so disease but not nearly as much as the chales lactions is po ot king that this repo is brorn up is et a did t di to pesed o eases youre touht that the markgataw gets lost of all the time in tewn yes i gol my he obsertis the piggelog topping out there the difantern that is merthy as stopping tout there is the elsie des fraine that there's no they tidid a anean ungi o eh maybe yoas mildacai you givfer a fogeve your presentation a  mby ga i stay ot o comi av le etim in a re contral what be various fortl bat of he is and thirty four per sent tha tyces too long to tantesar  muc control tha wats likes easy to ge strie away orga to perhats is it's easy to know you terstenty bob said said it took too much time to land au guris jorston to oraga an and thirty twenty six percent sent from our control a bab asi i don'niw how we had got at from tomatt in hat won you me for i saw you an moretanyo you can hold e an your sfo e beg te cur chir ah yes ar you can you can take take my chair a so i think as everybody knows e am being industryor designer ana in this presentation a how is that for bet to fain oe othat i fing that are gle doctonsdoctor sas but its is the opinion of te yer do youisna that's a repis iser and then it sa a denographic bright down may meeyou cannot put this workidge on lion on te ah i shauld be able to if i not see now you cen disconnected a lok may be just o yor set yen yo an into whipige and see yasified a it how though i sou ye may yo think anhy pismut this quick presentation am is gonaffookers on in the working design althoug he we want contror an i'd like first togivagki ar simply intradiction how daes it work so that everybody knows even if you don't have ave an taking e backgrond a what is a pride i thing in the protectice ind porting so masically ah the bisic function of whom contries to send a message is to another system tat his fixed and  is ordinaras ye can connect this one howade so these are important numbers that matheu and i she took hi to a com for howavosoneaal its not easier  he pan yars n isdayd oty missus ledling bisaucefids an interated sicret the cip that penham bas messages uslia tuta inford bits in an ah to usin to face on for the chief acodinly the the messages i so my method for ah designing the athe work yesai ah yet first tthe main point is that i would wish to to make a ready function our product k ye is numbers us as to be as to be takening to account too for the both and yusenta face and ter fashan tine one day goes on to talk about but his interesting is the because there are many numbers and we need to select to constraint ah our design is on waton is more important yet and monday the day to he that i would prefer to have very functionar ah capabrility is weather than fancies ta that in fact is a deusanasn so for that yer as hesupuden to taking toof the usur requirements from the macketing aspeta ana and now to to you should ae re what are they confunction  place contror and i show you the ther working design so a i'm sag a conitionan in tat contral speech or phoenision and heli i am often at and by te people y yoself do do yo h on dat yes an soys ther we don't do we not need annew bitton on the re go aheade bei or bason speech rinkin i even call dressing idea at least ye i tan no one not let si while you and i thought you arge oh besicly ah here is relagu of what we want is a weont a un offbutton he can be a simple but is i important and so a iny willing ther tobors caners as well as other buttons that come after wigt so the cumpananzai quickly draw hele is that in this part you have the controled va lecender and another bout alligod it will be salution for from your remustav foldet loft i mean whe a pek recognition that ah then it doesn't matter where it is my walletz who should be enranged wo may be at cenry walton produce tons o fay where it is but id this are all quite fancy futrit i am not sure whether we will we can make this for for twelve years of year if yo had ny can we the receiver so that's my methodies aah would be to on my am would be to a gizander and choose the chips ande infered acompanante to bit the oncomfortabe in so of course we inadusources an a the receiver a receiver this is rely quikier is a i used up mia integmita yors bean tat o no way the state of the ots phich rur commision is maybe you kno al i bat pik it badly dont like veris there it's a very small covry very one giv e i sho blake no theye all i all why but it's quite noisy new there is the wa ye h yeo in anything going to be just it so easy but easuly itscose you mor as isalao it does will have some ways but in fact a am so what i had found an after aloth of working stree i had robethis i'd rother for you ithe sias ke ma la can be maybe too technical for you but he's very important for me yyou know  yoa lot tina e afama fofa wolf and  t's it so i won't gointo details about that but a these are my propences to use a anof conpinance eboram but i donoot know  tenty so ga a dos to some morise ma leatle this is snatch ofme mad im who had pie hi state recognition in i li oh good pay more for it an nijug sait of the fifteen twenty five year old market said that they would pay more it goes down from ther seventy six sent four twenty five thirty five thirty five cet thirty five forty five an twenty two pecent four forty five fifty five n ten i e xempary sere fi reclank edet wos wart yet everylthiyg depends where work enty and why do you want this concompany i mean ote cheap or are yey a reliable or your so the the macompenancio see here ah the cheapest i found an y you ave always are compromise with arida biti ana ati expensiv but ah del as not these one also rii r gabrel a so ye that's it for the working desire tha te nameis by that lam sule do tat at athank yes idid you get er er o o a ileli neine age aah i hope you gettng cure of you onawhat what a room would contror hes and ont o ani dignet to i contenance but maybe yer smorke and artinodded madivit o a cag my one market lak again o you ande nno no we wu la this is a preference but we can always change ah wat well thinking about a the dedisceemer about and says the thick at is  stopping that there th decanpan thatits merty has stopping that dar the elsiede esfrained that there's no fiti of mani o tat munin oi uh maybe a mildan you givfer er give your presentation wy gai stay no yeceneran receivee can you  pear ebectly at a the receiver if fort already indit elevation and we are not a able to change it or thoser yeu wisth the dapt to your toshe right i suppose there is a fenthat a way of communicating into le fisin sir yeru u za in for it fot a corp ah using  in for it anh antin quietly you can muva anmoe as faro the bek the cure cheer ah yes ow you can you can sake take my chair stands ino or so is you a erybody knows a i'm the industryor designer ana in this prison dition a and of course we g drive ap to that potopo that already exists an bet we what we can doir a ad ting the the chieps inside a twis the best a chips anna ioard boat of on o great take a wo ot yo don ye et yet ye i tiitis the dregonces yr of course youre ain't the chup yon mat o should be cat of his quick presetitionr am his genougfookis on the working design altho the in what contror and i'd like first to give a  a simple intradiction how does it work so that everybody knows even if you don't h a ve ticnic am background ah what is a pretty lathing inthe parectice and porte so basicly a the big function of homert cuntres to send ah messages to another system that is fixed and sonnigi o people lautatin hegan oo ma agai hat lifily defaint a remot a geman oicutes itself in the other t er sobitically dor through argood things so magy should think of ow cso we should hav hav at in jo vey jusn't i ave thet oaltedi in the next time a through the last or you can destei out o the an then so up irwins ta mat and in cini some worcockicyou dont better be near the yair yoar dao  another i te on mama i think ti source its anintibuted sicket the chip that hanom buz messages usually awoa infrod bits an the usunt it face monfor the chief an acodinmi the the messages why so my method for ah o designing the in the rokisi ah yet first the main point is that i would wish to to ma ready function or product my will will consider is fatet erdiernangress may men may we we can go to to your presentag as tait why i sum were yyust a foas is myo  i would prefer to have very functionar a capabrility is weather than fancies tas that in fact hes adusant as a work so for that yer as hes aculdnt to taking to other usa requirements from the tin aspet aai and now to to  wshould a re what ill d inconfunction  place fom mcomtor and i assow you tha the working design so a i now where the is olete sco i i ge de wont be mutbut oi went toe pope the giv without lost te thicknic i an so  what tankiats of all what i the user bo to do wi a mii en  i what i a i say owhat the user he is going to ti aban mesically ah here is relagur what we want is ah woon a on of butan can be ait simper but itsinsimportant and so a any wiling th toboschaners as well as other butsom that come after why so the cumpananzi quickly draw here is that in this part you have the comtrol a lesender an go the palas halt say that ma contiuly so by that port in that day bettegin thy dars i had he mettic o thetin he said anin my tet out e tan e col ma be corde that me and a gisin me it is fer eo a fele what is tilige te baa a a a  a dinning of wat ate visic e ibtane the message whith is exent et the dvi and and the recuer so that my method is ah would be to wor my anguld be to a design the and chuse the chicks on the iferit ahcompanante to beat the mon confor wine so of course we inad yosources and ara a the receiver or a receiver this is ri quikhe isan a you stup meo intrk me foryors be ont that aha i that ei ateca because at ee becas so as sound an la has said that his e beglady a jed ben things which are weoly te at at eve bego and have  eecame at  tosad questunetoe we have to sakelater but in the burnatenario it that it has at an ga ane tae t ea for and etend and massetiate ana so what iad found and after lot of working tree i hide robetis i d rother for you the si eskima ma kan be may be too technical for you but he's very important for me you know ge of my life apapa fo walkineand  it's it so i won't gointo detais aboe that but a these ar h my profeence is to use a the con of compliments an man dam so denderly i don't aw so fe go sor y but dam so there two kands up fe more offe at me in the household acted his own ears and i te e more fready hav ta say arn off but a ma oning change and kee for nopl  an mor than one be edoptiand and coseee for tampee ia tak no iven the one  or one e one din hi doction ins bartonidit and wit is ti cand and and why do you want mis goncoa i mean oti ke or argi a reliable what or your so the the maincomperencio see here ah the cipi i found an is yoov always a compromise with aridebiti an a aeighty sixpensiv but a t ill has not this one also ridi riebo ah so yet that's it for the roking desig to morrows you may tell contuc to cennas andbos oyocennas bs ooby fast tat and then said this a standard ondon without any magiting in e like it would a a a ded offi a him without anyits a day simplething and its me ite most and then the however a wat there redow bil tedilet usually it has almost atheqi go there and figting ten y has a opul nightme ai hope your getting ceer of you on awhat what even would contror he sa uo and as a dignata somtinance but maybe yes smorin an arking madivit a cantin teat byt on the market and lak agino you wante noo no  wu la this is a preference but we cant always cha h a what what e was thinking about it de de deskima about stal a and then you mad a mo o foupasfa the moi of drumping lake that so it had thus oiether standard a common befond democa rose and there a mocket and then it we did dendally used by the people and then a buzllet wen as i good avitically thing of hiving ther an a man for the ma se me sen thing rather e degeneraly i hebern i  pier anvectl at a the receiver is fort already in the televation and we are not erable to change it or thoser we mist adept to o to sheet wright i suppose there is a tentat ar way of communicating look a in ther yet who you za in forit pot e corp ah using ye inforid anah wektey te have on the at hat tevian that in molt bede o anro begos sir touthe geven that he dos mufandor and the pivy e goo bin ta a a to lether so that ther he good tan ame bo the make in te comin ti ter a y book bo o coasion tow that wlaxi gox ide many avesianity to separate say al my wone im i've got a basy our might w stantiges the challen asia and on didenita te of course we ged drad up to thet foot abo that already exists but we what we can do eser a adep ti the the cheip's inside a twis the best a chips ana intord boat yoo  o great i o bor o yo go be get et yi i i i i this wekon sus yen of course you ait the chut yooe mik you shu beka yet i isan't amy like a stitch on their might that says things te galles asty hours at night wich my youdeas a actaly am yeu could feel could think of fa having tab have a kive its worth ten if be cose of the meeu\""
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_str_facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "015ab8b34530459a98c99931cd80db4d",
      "4c2ce3ec146343ec9a3cc7ef53b7f3e6",
      "093d4050365445859bd40c1130b8082c",
      "c41e0e43ccee4b88a7ac0a98ee178d83",
      "e9f47c13f90146c39e024f9388a35a9b",
      "18beffb555ce4b23a4c6676fdec3d6ff",
      "52456dee26424db48bf99a445db0b7ea",
      "6fbbf84837004bd69cd12cdb9b4be13e",
      "373f2d0b9304407b890684e37f1da2b1",
      "14db0c66a5cd47f8883dbe52d5dd016e",
      "0d2987ff9c564f8a8e88fd838af52f91",
      "22e3601861bf47b885960505733ae04e",
      "de2e0d6d084b4a5aa70ca4db1ceaeb0f",
      "9d5fdb3902e3424983da832259acd90b",
      "d69b792a4d424ee3a14a05da4bc8f0c5",
      "961c70b366954778aa64521e207d5838",
      "142a925c00ea48b6b507fb505b1cb3fa",
      "4e7caa93377a4ac0b6f9aa0f732d846e",
      "1e0b5df63ad146ffab7f0561aa44fe55",
      "7be613290f4d4339802b59bcd09a5cbc",
      "2d87a2582d4d4fb0abe0a673c30b9726",
      "f44fdd752e5c49c281d59e94438e42ed",
      "3bc9f5351a894dd48d7fbbed369f04a7",
      "8423141979ef47d9857dfd9b0b3e07f1",
      "8e438f65b564472bb8df00b327f6a6b9",
      "836e4b9ac9b94e87bd88f91a98debe3f",
      "e42c9e30a0484374b7462d69617dc656",
      "7de905f600cf4fe0bf13425a1e3b3ea0",
      "011e96cab98b4dda925d5adf653f7b78",
      "88d9a3e4d6424913ac37e9d806134c19",
      "c902e075bcd7418bb113e4b0781934cf",
      "968804ae026c4b2eb9aa0ad17b405b83"
     ]
    },
    "id": "38AbVxsHVcUw",
    "outputId": "f48e6fdc-4125-4b44-c7e6-9b1887e984e4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015ab8b34530459a98c99931cd80db4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373f2d0b9304407b890684e37f1da2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467042463.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142a925c00ea48b6b507fb505b1cb3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e438f65b564472bb8df00b327f6a6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1382015.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XLNet\n",
    "model_xlnet = TransformerSummarizer(transformer_type=\"XLNet\",transformer_model_key=\"xlnet-base-cased\")\n",
    "full_abs_fin = ''.join(model_xlnet(text_str_facebook))\n",
    "print(full_abs_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "gu5XRxqDiHnb",
    "outputId": "20d4956d-df4b-4c4f-bec6-f510ae5fd157"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-b2d85d5ae7b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrouge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRouge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_abs_fin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman_abs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xlnet + wav2vec scores: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rouge/rouge.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_avg_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m_get_scores\u001b[0;34m(self, hyps, refs)\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mraw_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                     exclusive=self.exclusive)\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0msen_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(hyp, ref, **k)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mDEFAULT_METRICS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"rouge-1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rouge-2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rouge-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     AVAILABLE_METRICS = {\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;34m\"rouge-1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;34m\"rouge-2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;34m\"rouge-l\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rouge/rouge_score.py\u001b[0m in \u001b[0;36mrouge_n\u001b[0;34m(evaluated_sentences, reference_sentences, n, raw_results, exclusive)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \"\"\"\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluated_sentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hypothesis is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_sentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reference is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Hypothesis is empty."
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(full_abs_fin, human_abs)\n",
    "print('xlnet + wav2vec scores: {}'.format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSCJE944iK3E",
    "outputId": "559e0ae0-dce3-4011-98d4-41644db40e09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "reference = preprocess_text_simple(human_abs)\n",
    "candidate = preprocess_text_simple(full_abs_fin)\n",
    "score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "print(score_together)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Summarization_methods_for_me_sr (2).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00107b9bd80a4708ab7603561c696296": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "011e96cab98b4dda925d5adf653f7b78": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "015ab8b34530459a98c99931cd80db4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_093d4050365445859bd40c1130b8082c",
       "IPY_MODEL_c41e0e43ccee4b88a7ac0a98ee178d83"
      ],
      "layout": "IPY_MODEL_4c2ce3ec146343ec9a3cc7ef53b7f3e6"
     }
    },
    "071b8f612462401d9a970b0abd19d80e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "093d4050365445859bd40c1130b8082c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18beffb555ce4b23a4c6676fdec3d6ff",
      "max": 760,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e9f47c13f90146c39e024f9388a35a9b",
      "value": 760
     }
    },
    "0ae3520789264d9fa3da4f9a4d255a5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0d2987ff9c564f8a8e88fd838af52f91": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d5fdb3902e3424983da832259acd90b",
      "max": 467042463,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de2e0d6d084b4a5aa70ca4db1ceaeb0f",
      "value": 467042463
     }
    },
    "10a5245500bc4f95817b00ebc0af4d70": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "141de01b4881492382a9800600622cd9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "142a925c00ea48b6b507fb505b1cb3fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e0b5df63ad146ffab7f0561aa44fe55",
       "IPY_MODEL_7be613290f4d4339802b59bcd09a5cbc"
      ],
      "layout": "IPY_MODEL_4e7caa93377a4ac0b6f9aa0f732d846e"
     }
    },
    "147e46798936490a917ce5cf2b2c9b62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14db0c66a5cd47f8883dbe52d5dd016e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14fd9c1a574b48e0a1780230ddc8b8ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4016c4f8b7344ba5b17413815eb61977",
      "placeholder": "​",
      "style": "IPY_MODEL_147e46798936490a917ce5cf2b2c9b62",
      "value": " 1.38M/1.38M [00:14&lt;00:00, 97.8kB/s]"
     }
    },
    "1841f119895c473786ff4adf68a0bb49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10a5245500bc4f95817b00ebc0af4d70",
      "placeholder": "​",
      "style": "IPY_MODEL_c82809532ead4f138911dd25b2d69f1f",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 1.95MB/s]"
     }
    },
    "18beffb555ce4b23a4c6676fdec3d6ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19624aa597a44bb2a5046a3b596ef9ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ab3ee790a56498e800681ddd172ba5c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c1eb4aa3c9744c694a70a63f9d520e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_141de01b4881492382a9800600622cd9",
      "placeholder": "​",
      "style": "IPY_MODEL_960a0b2f008d4ecf92971b45870bce31",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "1e0b5df63ad146ffab7f0561aa44fe55": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f44fdd752e5c49c281d59e94438e42ed",
      "max": 798011,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d87a2582d4d4fb0abe0a673c30b9726",
      "value": 798011
     }
    },
    "1ea0ab94c1dd4a739de7c2d6d47d80ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81c5e0ec7358422b84b3438f9eac6d64",
      "placeholder": "​",
      "style": "IPY_MODEL_59ba018eec7c497f8a1c49bd28dfab60",
      "value": " 718/718 [01:04&lt;00:00, 11.1B/s]"
     }
    },
    "22e3601861bf47b885960505733ae04e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_961c70b366954778aa64521e207d5838",
      "placeholder": "​",
      "style": "IPY_MODEL_d69b792a4d424ee3a14a05da4bc8f0c5",
      "value": " 467M/467M [01:03&lt;00:00, 7.41MB/s]"
     }
    },
    "2660203eb45241259a2f54fb4dae1287": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b369cd644e2e426081def3d61da7599a",
      "placeholder": "​",
      "style": "IPY_MODEL_071b8f612462401d9a970b0abd19d80e",
      "value": " 467M/467M [00:17&lt;00:00, 27.1MB/s]"
     }
    },
    "2772502f70f545439ac4aa4b35231213": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d87a2582d4d4fb0abe0a673c30b9726": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2e84676350724a8b95fd44a677739790": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32f237d7af1a475cbce8cf894c62d709": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34217d3e5fef458f8926401f4b20f387": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b34585c5368d4abbb5fecb945c36ed99",
       "IPY_MODEL_b4c543b0eb464266a49282e9e4e78418"
      ],
      "layout": "IPY_MODEL_931d193ae0214e758efd29e41626f90b"
     }
    },
    "373f2d0b9304407b890684e37f1da2b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d2987ff9c564f8a8e88fd838af52f91",
       "IPY_MODEL_22e3601861bf47b885960505733ae04e"
      ],
      "layout": "IPY_MODEL_14db0c66a5cd47f8883dbe52d5dd016e"
     }
    },
    "3bc9f5351a894dd48d7fbbed369f04a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3cee2c70c2c54552b08173da2b43bbec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d099d24ff2b45698e534449749b1848": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32f237d7af1a475cbce8cf894c62d709",
      "max": 718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_85f9ab0a563249d3a93809befdcf0a1a",
      "value": 718
     }
    },
    "4016c4f8b7344ba5b17413815eb61977": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4babc5cc0ef24f9686833cab4e113962": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9dfdaa37cdb54bfc9cafa79319704fe9",
       "IPY_MODEL_c897f7abf39f49e7824bb0c9f45ad7c1"
      ],
      "layout": "IPY_MODEL_6fb9d897c22d470db9e5951df85cf8ab"
     }
    },
    "4c15223e676742de9ef4ffee93a79d50": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8ca4ba425c2442ddb408f8f129d3ff83",
       "IPY_MODEL_b2528515b58c437c8bde2f394beab879"
      ],
      "layout": "IPY_MODEL_2e84676350724a8b95fd44a677739790"
     }
    },
    "4c2ce3ec146343ec9a3cc7ef53b7f3e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e7caa93377a4ac0b6f9aa0f732d846e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50261ef7495e4945a3872e0763d2e2f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6de0683e6879443990f9bc6c72701d93",
       "IPY_MODEL_2660203eb45241259a2f54fb4dae1287"
      ],
      "layout": "IPY_MODEL_86c08d5c47234b17af4f5d4aa2c6851a"
     }
    },
    "52456dee26424db48bf99a445db0b7ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "555a8a1bb11b49559e4dd19a6afc56d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a4bae3695754a0bad15cab7da5f7379",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5798a95b255343d9a8fb8d2759346b18",
      "value": 1
     }
    },
    "5798a95b255343d9a8fb8d2759346b18": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "59ba018eec7c497f8a1c49bd28dfab60": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62a772f051ae4210bb019c0ca598c2cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62bbb122f57c4d0a9222e07ec075c245": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69438792226a472095d2cd18c15e0c0e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bb846902712490586a40e2a06da019c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c23b18bea4841d0a6a61631ab238c95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6de0683e6879443990f9bc6c72701d93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6bb846902712490586a40e2a06da019c",
      "max": 467042463,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef9c691337e94ff9aed14caf9dc2a853",
      "value": 467042463
     }
    },
    "6de8d5ac9f6a4bcf974b4e59fe0f27b0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fb9d897c22d470db9e5951df85cf8ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fbbf84837004bd69cd12cdb9b4be13e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7559d35bc0384edea390bfdc74eb9b1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7be613290f4d4339802b59bcd09a5cbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8423141979ef47d9857dfd9b0b3e07f1",
      "placeholder": "​",
      "style": "IPY_MODEL_3bc9f5351a894dd48d7fbbed369f04a7",
      "value": " 798k/798k [00:46&lt;00:00, 17.1kB/s]"
     }
    },
    "7de905f600cf4fe0bf13425a1e3b3ea0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_968804ae026c4b2eb9aa0ad17b405b83",
      "placeholder": "​",
      "style": "IPY_MODEL_c902e075bcd7418bb113e4b0781934cf",
      "value": " 1.38M/1.38M [00:45&lt;00:00, 30.1kB/s]"
     }
    },
    "8035d2d9c4ba4934adb5bcd02a4ca1d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81c5e0ec7358422b84b3438f9eac6d64": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81fb4ea6cf1246d096c9ffa883fee037": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "836e4b9ac9b94e87bd88f91a98debe3f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8423141979ef47d9857dfd9b0b3e07f1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85f9ab0a563249d3a93809befdcf0a1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "86c08d5c47234b17af4f5d4aa2c6851a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88d9a3e4d6424913ac37e9d806134c19": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "891d1f193b1e4e19bd8a659c8afa9f2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3d099d24ff2b45698e534449749b1848",
       "IPY_MODEL_1ea0ab94c1dd4a739de7c2d6d47d80ad"
      ],
      "layout": "IPY_MODEL_c8d3dba8950647f78e42a0c6cfc16bde"
     }
    },
    "8ca4ba425c2442ddb408f8f129d3ff83": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c98fc626a6c4b6ca24fef5d49cd1c3d",
      "max": 798011,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec2ccccdb118404b8a440dd52051c86e",
      "value": 798011
     }
    },
    "8e438f65b564472bb8df00b327f6a6b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e42c9e30a0484374b7462d69617dc656",
       "IPY_MODEL_7de905f600cf4fe0bf13425a1e3b3ea0"
      ],
      "layout": "IPY_MODEL_836e4b9ac9b94e87bd88f91a98debe3f"
     }
    },
    "922f3ecc616144708f1179de850b9004": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "931d193ae0214e758efd29e41626f90b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "960a0b2f008d4ecf92971b45870bce31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "961c70b366954778aa64521e207d5838": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "968804ae026c4b2eb9aa0ad17b405b83": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98d407c4f98d446f91649abb973e7e70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be0cc8bf2946474092c2faa4e521866f",
      "placeholder": "​",
      "style": "IPY_MODEL_a145b6236efa46cf8b2b3fbf3f4a9a43",
      "value": " 1.04M/1.04M [00:01&lt;00:00, 876kB/s]"
     }
    },
    "9a4bae3695754a0bad15cab7da5f7379": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c98fc626a6c4b6ca24fef5d49cd1c3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d5fdb3902e3424983da832259acd90b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dfdaa37cdb54bfc9cafa79319704fe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7559d35bc0384edea390bfdc74eb9b1f",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ae3520789264d9fa3da4f9a4d255a5a",
      "value": 456318
     }
    },
    "a145b6236efa46cf8b2b3fbf3f4a9a43": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3d94fb508004f209b8c111f9d3d06f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5ccefeb6404490fb4c1f3c65c1d04af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0ef92e111da49b7975f2cfbc1b215db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c1eb4aa3c9744c694a70a63f9d520e0",
       "IPY_MODEL_555a8a1bb11b49559e4dd19a6afc56d8"
      ],
      "layout": "IPY_MODEL_3cee2c70c2c54552b08173da2b43bbec"
     }
    },
    "b2528515b58c437c8bde2f394beab879": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2772502f70f545439ac4aa4b35231213",
      "placeholder": "​",
      "style": "IPY_MODEL_81fb4ea6cf1246d096c9ffa883fee037",
      "value": " 798k/798k [00:14&lt;00:00, 53.6kB/s]"
     }
    },
    "b34585c5368d4abbb5fecb945c36ed99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3d94fb508004f209b8c111f9d3d06f0",
      "max": 760,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ee133ace14ed40509ba1a02fcbadd8f4",
      "value": 760
     }
    },
    "b369cd644e2e426081def3d61da7599a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4c543b0eb464266a49282e9e4e78418": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19624aa597a44bb2a5046a3b596ef9ff",
      "placeholder": "​",
      "style": "IPY_MODEL_bd70ec3d30444aed84eff7566adaf47f",
      "value": " 760/760 [02:49&lt;00:00, 4.48B/s]"
     }
    },
    "b9649c01a1d846c4a5f0975ef6e236c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e29e881d804d4703a828cc40e88cda67",
       "IPY_MODEL_98d407c4f98d446f91649abb973e7e70"
      ],
      "layout": "IPY_MODEL_c7749ca11e9d496cb33f04dfc2f7a7b3"
     }
    },
    "b9991e2d045a4601adde589d8266bd9a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcb274a7b3934d6faf868c6c87045e54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f819d6152cfe44bca8d8fbcfd4fe5198",
       "IPY_MODEL_c4652d164ada49ad882f4e7a15ec3be0"
      ],
      "layout": "IPY_MODEL_c71c0054b8994abfa6fcace945fcf5cf"
     }
    },
    "bd70ec3d30444aed84eff7566adaf47f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be0cc8bf2946474092c2faa4e521866f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c41e0e43ccee4b88a7ac0a98ee178d83": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fbbf84837004bd69cd12cdb9b4be13e",
      "placeholder": "​",
      "style": "IPY_MODEL_52456dee26424db48bf99a445db0b7ea",
      "value": " 760/760 [00:03&lt;00:00, 248B/s]"
     }
    },
    "c4652d164ada49ad882f4e7a15ec3be0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69438792226a472095d2cd18c15e0c0e",
      "placeholder": "​",
      "style": "IPY_MODEL_a5ccefeb6404490fb4c1f3c65c1d04af",
      "value": " 1.52G/1.52G [00:55&lt;00:00, 27.4MB/s]"
     }
    },
    "c605c3af29c04a23873ebe773ebc6838": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1c60283aec64252b995af76e1a0d403",
       "IPY_MODEL_1841f119895c473786ff4adf68a0bb49"
      ],
      "layout": "IPY_MODEL_8035d2d9c4ba4934adb5bcd02a4ca1d1"
     }
    },
    "c71c0054b8994abfa6fcace945fcf5cf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7749ca11e9d496cb33f04dfc2f7a7b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c82809532ead4f138911dd25b2d69f1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c897f7abf39f49e7824bb0c9f45ad7c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00107b9bd80a4708ab7603561c696296",
      "placeholder": "​",
      "style": "IPY_MODEL_db2b377166ed47739d21eaf982b901d7",
      "value": " 456k/456k [00:00&lt;00:00, 624kB/s]"
     }
    },
    "c8d3dba8950647f78e42a0c6cfc16bde": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c902e075bcd7418bb113e4b0781934cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9a64a646ed8450a9480f046bfa61d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d43f5e8d725f4aa2a90f3f90c8a111ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ea67009a4c03433aa209ba0aa6da41d0",
       "IPY_MODEL_14fd9c1a574b48e0a1780230ddc8b8ee"
      ],
      "layout": "IPY_MODEL_6de8d5ac9f6a4bcf974b4e59fe0f27b0"
     }
    },
    "d69b792a4d424ee3a14a05da4bc8f0c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db2b377166ed47739d21eaf982b901d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de2e0d6d084b4a5aa70ca4db1ceaeb0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e29e881d804d4703a828cc40e88cda67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62bbb122f57c4d0a9222e07ec075c245",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c23b18bea4841d0a6a61631ab238c95",
      "value": 1042301
     }
    },
    "e32c623da4124d95b5d2d7db13bc516a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e42c9e30a0484374b7462d69617dc656": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88d9a3e4d6424913ac37e9d806134c19",
      "max": 1382015,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_011e96cab98b4dda925d5adf653f7b78",
      "value": 1382015
     }
    },
    "e9f47c13f90146c39e024f9388a35a9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ea67009a4c03433aa209ba0aa6da41d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9991e2d045a4601adde589d8266bd9a",
      "max": 1382015,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c9a64a646ed8450a9480f046bfa61d65",
      "value": 1382015
     }
    },
    "ec2ccccdb118404b8a440dd52051c86e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ee133ace14ed40509ba1a02fcbadd8f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ef9c691337e94ff9aed14caf9dc2a853": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f1c60283aec64252b995af76e1a0d403": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62a772f051ae4210bb019c0ca598c2cc",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e32c623da4124d95b5d2d7db13bc516a",
      "value": 1355256
     }
    },
    "f44fdd752e5c49c281d59e94438e42ed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f819d6152cfe44bca8d8fbcfd4fe5198": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ab3ee790a56498e800681ddd172ba5c",
      "max": 1520013706,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_922f3ecc616144708f1179de850b9004",
      "value": 1520013706
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
