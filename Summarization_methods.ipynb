{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sONpqynRanVD"
   },
   "source": [
    "# Содержание "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Text summarization](#ch1)\n",
    "    - [Описание набора данных](#ch2)\n",
    "    - [Extractive methods](#ch3)\n",
    "        - [Word frequency method](#ch4)\n",
    "        - [TextRank](#ch5)\n",
    "        - [ClusterRank](#ch6)\n",
    "        - [LSA](#ch7)\n",
    "        - [KLSum](#ch8)\n",
    "        - [MEAD](#ch9)\n",
    "    - [Abstractive methods](#ch10)\n",
    "        - [BERT](#ch11)\n",
    "        - [GPT-2](#ch12)\n",
    "        - [XLNet](#ch13)\n",
    "        - [T5 with fine-tuning](#ch14)\n",
    "- [Speech Recognition](#ch15)\n",
    "    - [Обработка звука](#ch16)\n",
    "    - [Google speech to text](#ch17)\n",
    "    - [wav2vec](#ch18)\n",
    "    - [IBM Watson](#ch19)\n",
    "    - [Метрики распознавания речи](#ch20)\n",
    "- [Комбинация алгоритма распознавания речи и суммаризации](#ch21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Суммаризация текста  <a class=\"anchor\" id=\"ch1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_cX_NY5anVT"
   },
   "source": [
    "## Описание набора данных  + сохранение файлов в отдельные csv <a class=\"anchor\" id=\"ch2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве данных для верификации моделей возьмем AMI Meeting Corpus, содержащий 100 часов звукозаписей, транскрипты, разделенные по говорящим и рефераты к ним - экстрактивный и абстрактивный. Примерно треть данных состоит из искусственно составленных сценариев совещаний от команды дизайнеров, а остальная часть - реально проходящие в деловом центре переговоры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WN-hBqL0bsvt"
   },
   "source": [
    "Пример текстового файла: ES2002a.transcript.txt, первые две буквы это страна, в котором записывалось данное совещание, одно совещание состоит из 4 частей: a, b, c и d.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXUWW70yanVU"
   },
   "outputs": [],
   "source": [
    "test = open('ami-transcripts/ES2002a.transcript.txt', \"r\", errors = 'ignore')\n",
    "transcript = test.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "anBpVjQWanVV",
    "outputId": "4b00d33e-3cc0-4d60-9cea-7fff9ca3b3e0"
   },
   "outputs": [],
   "source": [
    "# transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6mLS2IpanVV"
   },
   "outputs": [],
   "source": [
    "test2 = open('extractive/ES2002a.extsumm.txt', \"r\", errors = 'ignore')\n",
    "transcript_sum = test2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "QHWkb4TGanVW",
    "outputId": "ee099615-03f7-420f-fb7e-1505e0316ebc"
   },
   "outputs": [],
   "source": [
    "# transcript_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLiUMackanVW",
    "outputId": "9d56c071-f953-4a7c-eca8-7b231feba5fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transription: 13676\n",
      "The length of the summary of the transcription: 4318\n"
     ]
    }
   ],
   "source": [
    "print('The length of the transription: {}'.format(len(transcript)))\n",
    "print('The length of the summary of the transcription: {}'.format(len(transcript_sum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhqMJFT5bsvv"
   },
   "source": [
    "Создадим 2 отдельных датасета для extractive методов и abstarctive методов с соотвественными им аудиофайлами. В датасете будет содержаться название файлов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "dYDAxGJlbsvw",
    "outputId": "99fcfcbf-95b6-4364-b6b1-37a00086555c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "folder_ext = 'extractive'\n",
    "ext = [x[2] for x in os.walk(folder_ext)][0]\n",
    "ext_summaries_files = []\n",
    "for i in ext:\n",
    "     ext_summaries_files.append('extractive/' + i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "xirtyngKbsvw",
    "outputId": "43c93205-9680-48b0-d933-ec159ccbed87"
   },
   "outputs": [],
   "source": [
    "folder_transc = 'ami-transcripts'\n",
    "fol_trans = [x[2] for x in os.walk(folder_transc)]\n",
    "ext_sum_trans = []\n",
    "for i in ext:\n",
    "    ext_sum_trans.append('ami-transcripts/' + i[ : i.find(\".\")] + '.transcript.txt' )\n",
    "#ext_sum_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "CGDmyrlJbsvx",
    "outputId": "230eea71-f13b-4a9e-d64a-918c416cebe8"
   },
   "outputs": [],
   "source": [
    "folder_abs = 'abstractive'\n",
    "abs_ = [x[2] for x in os.walk(folder_abs)]\n",
    "abs_summaries_files = []\n",
    "for i in abs_[0]:\n",
    "    abs_summaries_files.append('abstractive/' + i)\n",
    "#abs_summaries_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "LsUQXqXcbsvx",
    "outputId": "5cc8f699-68ef-434f-c4ac-a680f4486648"
   },
   "outputs": [],
   "source": [
    "folder_transc = 'ami-transcripts'\n",
    "fol_trans = [x[2] for x in os.walk(folder_transc)]\n",
    "abs_sum_trans = []\n",
    "for i in abs_[0]:\n",
    "    abs_sum_trans.append('ami-transcripts/' + i[ : i.find(\".\")] + '.transcript.txt' )\n",
    "#abs_sum_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAYhSnk1bsvy"
   },
   "source": [
    "Составим датафрейм с 2 столбцами: текст и реферат к нему "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "uBUnM7Enbsvy",
    "outputId": "6f76fbd4-5cce-48fd-9b8c-bd58f0e74c75"
   },
   "outputs": [],
   "source": [
    "# extractive\n",
    "# summaries\n",
    "import pandas as pd\n",
    "summaries_extractive = []\n",
    "for i in ext_summaries_files:\n",
    "    test1 = open(i, \"r\", errors = 'ignore')\n",
    "    transcript1 = test1.read()\n",
    "    summaries_extractive.append(transcript1)\n",
    "# texts\n",
    "text_extractive = []\n",
    "for j in ext_sum_trans:\n",
    "    test2 = open(j, \"r\", errors = 'ignore')\n",
    "    transcript2 = test2.read()\n",
    "    text_extractive.append(transcript2)\n",
    "df_extractive = pd.DataFrame({'extractive_text': text_extractive, 'extractive_summary': summaries_extractive})\n",
    "df_extractive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISMwHWS4bsvz"
   },
   "outputs": [],
   "source": [
    "df_extractive.to_csv('extractive_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aFyQN5zbsvz",
    "outputId": "fdfbba73-5061-4779-fac1-6f76377fa529"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstractive_text</th>\n",
       "      <th>abstarctive_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Okay okay Okay. Hello. Okay. My name's Poppy. ...</td>\n",
       "      <td>The project manager opens the meeting by intro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning. Sorry? Yeah, busy job. Good morn...</td>\n",
       "      <td>The project manager acquainted the team with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alright, yeah. crack on. Okay so we'll start o...</td>\n",
       "      <td>The project manager recapped the decisions mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right w welcome to the the first meeting of uh...</td>\n",
       "      <td>The project manager opens the meeting by welco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oops. Mm. After lunch. Yeah. Mm-hmm. Mm-hmm. '...</td>\n",
       "      <td>The Project Manager reviewed the decisions fro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    abstractive_text  \\\n",
       "0  Okay okay Okay. Hello. Okay. My name's Poppy. ...   \n",
       "1  Good morning. Sorry? Yeah, busy job. Good morn...   \n",
       "2  Alright, yeah. crack on. Okay so we'll start o...   \n",
       "3  Right w welcome to the the first meeting of uh...   \n",
       "4  Oops. Mm. After lunch. Yeah. Mm-hmm. Mm-hmm. '...   \n",
       "\n",
       "                                 abstarctive_summary  \n",
       "0  The project manager opens the meeting by intro...  \n",
       "1  The project manager acquainted the team with t...  \n",
       "2  The project manager recapped the decisions mad...  \n",
       "3  The project manager opens the meeting by welco...  \n",
       "4  The Project Manager reviewed the decisions fro...  "
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extractive\n",
    "# summaries\n",
    "import pandas as pd\n",
    "summaries_extractive = []\n",
    "for i in abs_summaries_files:\n",
    "    test1 = open(i, \"r\", errors = 'ignore')\n",
    "    transcript1 = test1.read()\n",
    "    summaries_extractive.append(transcript1)\n",
    "# texts\n",
    "text_extractive = []\n",
    "for j in abs_sum_trans:\n",
    "    test2 = open(j, \"r\", errors = 'ignore')\n",
    "    transcript2 = test2.read()\n",
    "    text_extractive.append(transcript2)\n",
    "df_abstractive = pd.DataFrame({'abstractive_text': text_extractive, 'abstarctive_summary': summaries_extractive})\n",
    "df_abstractive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHRZFlzJbsvz"
   },
   "outputs": [],
   "source": [
    "df_abstractive.to_csv('abstractive_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkYa8xboanVX"
   },
   "source": [
    "## Обработка текста "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLn4PZRKanVX",
    "outputId": "6d501be3-dc51-4d3a-bab5-2948d4380eee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import re, numpy as np, pandas as pd\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "stopwords_english = stopwords.words('english')\n",
    "stopwords_english.append('um')\n",
    "stopwords_english.append('Hmm')\n",
    "stopwords_english.append('Um')\n",
    "stopwords_english.append('okay')\n",
    "stopwords_english.append('uh')\n",
    "stopwords_english.append('Yeah')\n",
    "stopwords_english.append('yeah')\n",
    "stopwords_english.append('Mm')\n",
    "stopwords_english.append('well')\n",
    "stopwords_english.append('Well')\n",
    "stopwords_english.append('hmm')\n",
    "stopwords_english.append('weve')\n",
    "stopwords_english.append('ive')\n",
    "stopwords_english.append('yep')\n",
    "stopwords_english.append('alright')\n",
    "stopwords_english.append('Alright')\n",
    "stopwords_english.append('mm')\n",
    "stopwords_english.append('kay')\n",
    "stopwords_english.append('gosh')\n",
    "stopwords_english.append('like')\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "wXutK62BanVY",
    "outputId": "cd6a3191-8b50-4028-c74c-fb866913ff9e"
   },
   "outputs": [],
   "source": [
    "# убираем знак новой строки \n",
    "a2 = transcript.replace(\"\\n\", \"\")\n",
    "a = a2.replace(\"\\ \", \" \")\n",
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fer3xj7EanVY"
   },
   "outputs": [],
   "source": [
    "# убираем знаки препинания из текста \n",
    "text =[]\n",
    "split_regex = re.compile(r'[.|!|?|…]')\n",
    "sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "for s in sentences:\n",
    "    text.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "yV8B7eLxanVZ",
    "outputId": "7ef102c5-d5ce-4232-a454-9ed98e515bfd"
   },
   "outputs": [],
   "source": [
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8ARByqRHanVZ"
   },
   "outputs": [],
   "source": [
    "# убираем ненужные символы и делим предложение на слова\n",
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "kxH5y-y_anVa",
    "outputId": "3db882a0-0f9a-4c51-da5a-be53f2736320"
   },
   "outputs": [],
   "source": [
    "res = list(sent_to_words(text))\n",
    "#res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDqAWR2kanVg"
   },
   "outputs": [],
   "source": [
    "# убираем стоп-слова\n",
    "res_ = []\n",
    "s_ =[]\n",
    "for s in res:\n",
    "    for word in s:\n",
    "        if word not in stopwords_english:\n",
    "            s_.append(word)\n",
    "    res_.append(s_)\n",
    "    s_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "K30Fm0kfanVg",
    "outputId": "6d0fce77-0f8f-427f-de2b-ebc4d08384a9"
   },
   "outputs": [],
   "source": [
    "#res_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jfHSbmyKbsv3",
    "outputId": "a4ddddf1-6849-496a-bb3b-d41a8c2f0d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "# лемматизация \n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijIrYs3YanVh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_fin = []\n",
    "s_fin = []\n",
    "for s in res_:\n",
    "    for word in s:\n",
    "        s_fin.append(lemmatizer.lemmatize(word))\n",
    "    # проверка на пустой список \n",
    "    if s_fin != []:\n",
    "        res_fin.append(s_fin)\n",
    "    s_fin = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "MP77s8pTanVi",
    "outputId": "56da2c64-baac-4197-e29a-5d11b4bf94c3"
   },
   "outputs": [],
   "source": [
    "res_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_Q82dbOanVi"
   },
   "outputs": [],
   "source": [
    "# функция, которая объединяет все выше сделанные действия  \n",
    "def preprocess(filename):\n",
    "    f = open(filename, \"r\") \n",
    "    a = f.read()\n",
    "    text =[]\n",
    "    split_regex = re.compile(r'[.|!|?|…]')\n",
    "    sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "    for s in sentences:\n",
    "        text.append(s)\n",
    "    res = list(sent_to_words(text))\n",
    "    res_ = []\n",
    "    s_ =[]\n",
    "    for s in res:\n",
    "        for word in s:\n",
    "            if word not in stopwords_english:\n",
    "                s_.append(word)\n",
    "        res_.append(s_)\n",
    "        s_ = []\n",
    "    res_fin = []\n",
    "    s_fin = []\n",
    "    for s in res_:\n",
    "        for word in s:\n",
    "            s_fin.append(lemmatizer.lemmatize(word))\n",
    "        if s_fin != []:\n",
    "            res_fin.append(s_fin)\n",
    "        s_fin = []\n",
    "    return res_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j9yl56FMbN6W",
    "outputId": "5763db22-81f1-448f-92d5-a574f572f79b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wod-V3vAanVj"
   },
   "outputs": [],
   "source": [
    "# загружаем нужные нам библиотеки \n",
    "import spacy \n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "punctuation += '\\n'\n",
    "from heapq import nlargest\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import networkx as nx\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B5loPiWanVj"
   },
   "source": [
    "## Extractive methods <a class=\"anchor\" id=\"ch3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyFrkFIQanVk"
   },
   "source": [
    "### Word frequency method  <a class=\"anchor\" id=\"ch4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3fqnq6zanVk"
   },
   "source": [
    "Рассмотрим алгоритм на примере одного файла. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "jHsPv9-qcSXH",
    "outputId": "8ed69032-a741-4a72-e6ac-88e9b9e7bbb8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>extractive_text</th>\n",
       "      <th>extractive_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Wouldn't wanna be Project Manager. Uh, what we...</td>\n",
       "      <td>Um , once again I'm uh gonna take minutes . Uh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Me too. Okay. Um here's the agenda for our las...</td>\n",
       "      <td>Okay . Um here's the agenda for our last meeti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oops. That's as far as it goes. Do you also do...</td>\n",
       "      <td>uh good morning everybody here . And uh I want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hmm. E excuse me I forgot my copy. No, not min...</td>\n",
       "      <td>Uh oh I've forgotten to mail you the minutes ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Okay, can I have the laptop over here, or? Oka...</td>\n",
       "      <td>Tod uh for this meeting I will take the notes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>Morning. Yep. My name's Frank. Thank you. Hmm,...</td>\n",
       "      <td>First I will introduce myself . I'm Bart , My ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>No. We should make a big sponge lemon, and the...</td>\n",
       "      <td>mailed you the minutes of the last meeting uh ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>Mm-hmm. Yeah. I'm Robin. I'm the Marketing Man...</td>\n",
       "      <td>Right Where we uh We have twenty five minutes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>Hello. Hello. You have to put it exactly on th...</td>\n",
       "      <td>Hello you all read what we are going to do or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "      <td>Yeah. Yeah, sure. It kinda does make sense, do...</td>\n",
       "      <td>I'll just just recap on the minutes from the l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  ...                                 extractive_summary\n",
       "0             0  ...  Um , once again I'm uh gonna take minutes . Uh...\n",
       "1             1  ...  Okay . Um here's the agenda for our last meeti...\n",
       "2             2  ...  uh good morning everybody here . And uh I want...\n",
       "3             3  ...  Uh oh I've forgotten to mail you the minutes ,...\n",
       "4             4  ...  Tod uh for this meeting I will take the notes ...\n",
       "..          ...  ...                                                ...\n",
       "132         132  ...  First I will introduce myself . I'm Bart , My ...\n",
       "133         133  ...  mailed you the minutes of the last meeting uh ...\n",
       "134         134  ...  Right Where we uh We have twenty five minutes ...\n",
       "135         135  ...  Hello you all read what we are going to do or ...\n",
       "136         136  ...  I'll just just recap on the minutes from the l...\n",
       "\n",
       "[137 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_extractive = pd.read_csv('/content/extractive_dataset.csv')\n",
    "df_extractive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIw7qdWWanVk"
   },
   "outputs": [],
   "source": [
    "a = open('ami-transcripts/EN2001a.transcript.txt', \"r\", errors = 'ignore')\n",
    "transcript_sum = a.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "0gCG_-OeanVl",
    "outputId": "8b61622f-8899-4b16-aa8b-fc468eb90088"
   },
   "outputs": [],
   "source": [
    "#transcript_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "P3U0_21manVl",
    "outputId": "9698c588-b3ca-4c88-9967-b4c8547a2bdb"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(transcript_sum)\n",
    "tokens = [token.text for token in doc]\n",
    "#tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m45VrwneanVm"
   },
   "outputs": [],
   "source": [
    "word_freq = {}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords_english:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_freq.keys():\n",
    "                word_freq[word.text] = 1\n",
    "            else:\n",
    "                word_freq[word.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "6RUwfDzLanVm",
    "outputId": "bb6d7c41-09f2-4b46-ea7c-fb0369824a7b"
   },
   "outputs": [],
   "source": [
    "print(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "io23c0hganVm"
   },
   "outputs": [],
   "source": [
    "max_freq = max(word_freq.values())\n",
    "for word in word_freq.keys():\n",
    "    word_freq[word] = word_freq[word]/max_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Z3UHHZianVm"
   },
   "outputs": [],
   "source": [
    "sentence_tokens = [sent for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "GFAbkqNSanVn",
    "outputId": "f2cf6ec1-b385-41a8-c294-17f6ae57ff28"
   },
   "outputs": [],
   "source": [
    "#sentence_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdQAyAkranVn"
   },
   "outputs": [],
   "source": [
    "sentence_scores = {}\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_freq.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_freq[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_freq[word.text.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "cyfKaZCFanVn",
    "outputId": "1269f145-e658-4906-f55d-a57e40c5cb8a"
   },
   "outputs": [],
   "source": [
    "#print(sentence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7hxcNtTanVo"
   },
   "outputs": [],
   "source": [
    "select_length = int(len(sentence_tokens) * 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "o0k63z6vanVo",
    "outputId": "8ddd5c30-7b31-4649-9cb9-72699ec7b85e"
   },
   "outputs": [],
   "source": [
    "summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)\n",
    "#summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "jYYE-cn1anVo",
    "outputId": "215859b7-7aaa-4029-de4e-b9eb080b5811"
   },
   "outputs": [],
   "source": [
    "summary_luhn =[]\n",
    "for i in summary:\n",
    "    summary_luhn.append(str(i))\n",
    "final_luhn = ' '.join(summary_luhn)\n",
    "#final_luhn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "U05bS9X7bsv-"
   },
   "outputs": [],
   "source": [
    "# соберем все в одну функцию \n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "def summary_luhn(transcript_sum):\n",
    "    stopwords = stopwords_english\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(transcript_sum)\n",
    "    tokens = [token.text for token in doc]\n",
    "    word_freq = {}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in stopwords_english:\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_freq.keys():\n",
    "                    word_freq[word.text] = 1\n",
    "                else:\n",
    "                    word_freq[word.text] += 1\n",
    "    max_freq = max(word_freq.values())\n",
    "    for word in word_freq.keys():\n",
    "        word_freq[word] = word_freq[word]/max_freq\n",
    "    sentence_tokens = [sent for sent in doc.sents]\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_freq.keys():\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = word_freq[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_freq[word.text.lower()]\n",
    "    select_length = int(len(sentence_tokens) * 0.05)\n",
    "    summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)\n",
    "    summary_luhn =[]\n",
    "    for i in summary:\n",
    "        summary_luhn.append(str(i))\n",
    "    final_luhn = ' '.join(summary_luhn)\n",
    "    return final_luhn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "R-gqfZaTcezk",
    "outputId": "fba6f617-cfc0-4ec4-be82-5530dc9487ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>extractive_text</th>\n",
       "      <th>extractive_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Wouldn't wanna be Project Manager. Uh, what we...</td>\n",
       "      <td>Um , once again I'm uh gonna take minutes . Uh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Me too. Okay. Um here's the agenda for our las...</td>\n",
       "      <td>Okay . Um here's the agenda for our last meeti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oops. That's as far as it goes. Do you also do...</td>\n",
       "      <td>uh good morning everybody here . And uh I want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hmm. E excuse me I forgot my copy. No, not min...</td>\n",
       "      <td>Uh oh I've forgotten to mail you the minutes ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Okay, can I have the laptop over here, or? Oka...</td>\n",
       "      <td>Tod uh for this meeting I will take the notes ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                 extractive_summary\n",
       "0           0  ...  Um , once again I'm uh gonna take minutes . Uh...\n",
       "1           1  ...  Okay . Um here's the agenda for our last meeti...\n",
       "2           2  ...  uh good morning everybody here . And uh I want...\n",
       "3           3  ...  Uh oh I've forgotten to mail you the minutes ,...\n",
       "4           4  ...  Tod uh for this meeting I will take the notes ...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extractive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6bLbJ0bbsv-"
   },
   "outputs": [],
   "source": [
    "final_luhn = summary_luhn(df_extractive['extractive_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3135Y5O-bsv-",
    "outputId": "2e63345b-39aa-4c29-f7ff-9b4ee97e4cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luhn scores: [{'rouge-1': {'f': 0.41947565150169724, 'p': 0.7808764940239044, 'r': 0.2867593269934162}, 'rouge-2': {'f': 0.23286937508712185, 'p': 0.4336989032901296, 'r': 0.15916575192096596}, 'rouge-l': {'f': 0.48659383849881027, 'p': 0.6786703601108033, 'r': 0.37925696594427244}}]\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(final_luhn, df_extractive['extractive_summary'][0])\n",
    "print('Luhn scores: {}'.format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ox5lYuYbsv_"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np \n",
    "def preprocess_text_simple(text):\n",
    "    # 0>\n",
    "    text = text.lower()\n",
    "    # 1\n",
    "    tokens = word_tokenize(text)\n",
    "    # 2 и 3 \n",
    "    tokens = [token for token in tokens if token not in stopwords_english\n",
    "              and token.isalpha()\n",
    "              and token.strip() not in punctuation\n",
    "              #and token.strip() not in numbers\n",
    "             ]\n",
    "    # 4\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzLz0EPabsv_",
    "outputId": "34e90baa-341c-4e57-bbe1-9b950936c4d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "df_extractive = df_extractive.head(10)\n",
    "for i in range(len(df_extractive)):\n",
    "    fin_luhn = summary_luhn(df_extractive['extractive_text'][i])\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(fin_luhn, df_extractive['extractive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple(df_extractive['extractive_summary'][i])\n",
    "    candidate = preprocess_text_simple(fin_luhn)\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu(reference, candidate, weights=(0, 0, 1, 0))\n",
    "    bleu3.append(bleu_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khcXBaLGbsv_",
    "outputId": "3db2f6f3-2a25-4aab-e7f4-9b1618c60b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.008318538642514797, bleu: 0.22522189515769978\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qE-ZObxUbswA",
    "outputId": "31646f41-b135-4050-a870-08c8dc0180c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.488610924575542, p: 0.7671100830591521, f:0.37229235252960735\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYO4uIfgbswA",
    "outputId": "dde0ccb3-af16-4990-c488-121a77bc7574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.28006854334783815, p: 0.46054044023998963, f:0.20959993232641735\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WS9BT7agbswA",
    "outputId": "03ff8610-f79c-4648-b403-f283629d77b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.4835266898525979, p: 0.6261392581218478, f:0.3997901483232325\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBUUUDxNanVq"
   },
   "source": [
    "### TextRank <a class=\"anchor\" id=\"ch5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqkHWG9AanVr"
   },
   "outputs": [],
   "source": [
    "# косинусовая сходимость \n",
    "# на вход подается списки слов двух предложений\n",
    "def read(a):\n",
    "    text =[]\n",
    "    split_regex = re.compile(r'[.|!|?|…]')\n",
    "    sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "    for s in sentences:\n",
    "        text.append(s)\n",
    "    res = list(sent_to_words(text))\n",
    "    return res\n",
    "\n",
    "\n",
    "def sentence_similarity(sent1, sent2, stopwords):\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "     \n",
    "    # вектор для первого предложения \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # вектор для второго предложения \n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return (1 - cosine_distance(vector1, vector2))\n",
    "\n",
    "\n",
    "# создаем матрицу косинусовой сходимости \n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def generate_summary_textrank(file_name, top_n):\n",
    "    summarize_text = []\n",
    "    sentences = read(file_name)\n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stopwords_english)\n",
    "\n",
    "    # используем pagerank, чтобы определить веса предложений \n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank_numpy(sentence_similarity_graph)\n",
    "\n",
    "    # отсортируем предложения и выберем веса с большим весом \n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    #print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "\n",
    "    for i in range(top_n - 1):\n",
    "        if len(ranked_sentence[i][1]) > 2 and len(list((Counter(ranked_sentence[i][1]) - Counter(ranked_sentence[i + 1][1])).elements())) > 3:\n",
    "              summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "    return summarize_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UftBoQeXanVs",
    "outputId": "b702a979-7157-49fa-c870-8e937a9e223d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/cluster/util.py:133: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sqrt(numpy.dot(u, u)) * sqrt(numpy.dot(v, v))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text TextRank: \n",
      " what really miss also is uh is is turtle is decision uh decision system like um with the evaluation you have to polls like what do you want one two maybe little application like uh uh give your own number and click one two three four five six seven. well maybe can then do it one two three. thats one of the functionability uh well th think you two uh especially you and uh and uh daniel you you you both had uh the less creative uh roles in the project. think ah you must see it as uh uh according to uh the the other uh remote controls there may uh uh be there in your uh t_v_ room this one will stand out think. uh one two three. thats our remote control. we mean uh one one person maybe said three. think its its it look like this one. it would be best to to appeal to broad public and make the covers exchangeable so the young people will buy an orange and red and blue and purple but when the older people uh go in the shop and they see uh an orange um remote control it would be less appealing than white one. yeah uh but it its one one thing its three euro. so thats wh tha thats one option. exa think that thats what its about. and th the one or two things you have to draw when youre there just use flip board. because think it will oh five minutes from to finish meeting. well maybe thats uh only yeah well its for us because uh yeah. yeah but we we going to yeah yeah thats true. no uh thats true. cause think think jeroen and we had more design we could have more we had more room for creativity than than you two. so there must be some cheap standard cover um maybe white or something thats could comes with it and you can buy so we can make extra money. oh thats cool tim. yeah one or most true. be it it takes lot of time to draw things and to write things and thats the yeah but thats not th the the you when you at foreign audience you dont gonna wr uh write uh small. who because if you want to go to kinetic youre uh youre on thirteen and half and you must go to flat and think now its its more of uh compromise thing. and thats thats mostly the case from the over here with the managements you get two minutes to make your case and if you have to do all this kind youll rather use powerpoint and work it out in advance. okay so uh anybody uh misses something here about uh yeah okay thats thats what im gonna write between now. okay thats thats it from us. oh before you change anything maybe you um save it first. so thats uh thats big so lets uh wait it uh um we have we have must uh we must have uh some time for that uh because it will be uh yeah quite lot of mathematics. yeah but we want to make uh the wood colours uh that uh yeah one. no advanced chip uh thats little bit of problem. all the mo yeah are between one and two. our own people can make that think. one oh okay uh have to expla explain something. no you have to put uh switch channels uh at the top because thats the most used function and teletext at the second oh nay volume changing second. yeah but the most uh easy to use is just with one button on yeah okay but easy not not the most easy to use think. and young people we think are little bit more flexible they think ah ill buy for couple of euros some noi nice hip uh well um think cover is necessary cause als otherwise youll just have the l_c_d_ screen. but wha kay look what is the uh if you make it double curved it costs one euro more. so you have as you saw you have little uh oh you can yeah thank you. and thats pity if you uh if you have uh thirty forty minutes uh for this kind of things and we are now with four people but it well imagine you are here youre with the ten people and everyone uh yeah. follow the master class for the smartboard so think thats the thats the main issue. so um uh but but the single curved is just oh oh okay okay. so think uh it will be better idea to have some uh flashy fruity colours as as standard and for the people who uh really want uh more sophisticated more traditional look theyre willing to pay uh that. not too but little because thats our aim. but then uh think the idea of one person entering it and the rest uh discussing it that uh isnt that bad idea actually. uh um would call uh choose two cause we decided not to make two uh fresh colours as it would not. because uh four is between three and uh uh also between between true and false. if you uh promote kinetic um kinetic remote control mean that would sell better than an normal remote control. because think it will uh it must be uh yeah its three uh with seventy five uh yeah just about. theres one way to uh maybe if if youre not using the eraser something else th yeah arrow. yeah but but but daniel tha thats thats another brand. oh yeah if they under yeah\n"
     ]
    }
   ],
   "source": [
    "a = generate_summary_textrank(df_extractive['extractive_text'][0], top_n=100)\n",
    "print(\"Summarize Text TextRank: \\n\", \". \".join(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPLtp_KJanVs"
   },
   "source": [
    "Применив алгоритм TextRank, можно заметить, что наше краткое содержание не отражает главную суть текста и включает в себя предложения из одного-двух слов, которые почти одни и те же (forrest gump). Давайте попробуем поставить ограничение на то, что предложение должно содержать больше 4 - 5 слов и эти слова должны быть не похожи на лругие слова в нашем саммари, поэтому в конце добавим условия на то, что длина предложения > 2 и слова одного предложения отличаются от слов второго предложения на 3 и больше. \n",
    "Возможные варианты модификации данного алгоритма: \n",
    "1. Мы столкнулись с проблемой, что предложения в саммари одинаковые, поэтому возможно нужно добавить оглраничение на добавление предложения в саммари. Давайте попробуем использовать Maximum marginal relevance из пункта 8 (описание возможных алгоритмов)    \n",
    "MMR = $argmax_{s_i \\in \\mathcal{R-S}} (\\lambda * Sim_1(s_i, Q) - (1-\\lambda) * \\max\\limits_{s_j \\in S}Sim_2(s_i, s_j))$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "occBgw1xanVs"
   },
   "outputs": [],
   "source": [
    "textrank_hypothesis = ''\n",
    "for i in a:\n",
    "    textrank_hypothesis += i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcI3wahmanVt",
    "outputId": "1586a82a-c064-45a3-9254-975f932ed4fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextRank scores: [{'rouge-1': {'f': 0.4478741955069878, 'p': 0.2957692307692308, 'r': 0.9220623501199041}, 'rouge-2': {'f': 0.3927738890977979, 'p': 0.2593305117352828, 'r': 0.8091236494597839}, 'rouge-l': {'f': 0.5626134259831654, 'p': 0.3979460847240051, 'r': 0.9597523219814241}}]\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(textrank_hypothesis, transcript_sum)\n",
    "print('TextRank scores: {}'.format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUQnH0jZbswD"
   },
   "source": [
    "На всем датасете. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-WF83KsbswD",
    "outputId": "e5e713bd-6b9b-4797-a188-3bfcde075db4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/cluster/util.py:133: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sqrt(numpy.dot(u, u)) * sqrt(numpy.dot(v, v))))\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "for i in range(len(df_extractive)):\n",
    "    fin_textrank = generate_summary_textrank(df_extractive['extractive_text'][i], top_n = 20)\n",
    "    textrank_hypothesis = ''\n",
    "    for j in fin_textrank :\n",
    "        textrank_hypothesis += j \n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(textrank_hypothesis, df_extractive['extractive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple(df_extractive['extractive_summary'][i])\n",
    "    candidate = preprocess_text_simple(textrank_hypothesis)\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu(reference, candidate, weights=(0, 0, 1, 0))\n",
    "    bleu3.append(bleu_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tbd0w71TbswE",
    "outputId": "f57a8519-d7af-44d9-811f-34dc5d522459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.0, bleu: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aiVm0wiDbswE",
    "outputId": "b26f2869-a601-46ec-f4ba-d52227f44d55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.2752905593824052, p: 0.7682673464763903, f:0.17618050659279216\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YVvuIXNIbswE",
    "outputId": "93181646-5fa5-41cc-ec97-5af241fd1ea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.1401567773835038, p: 0.38214511471720825, f:0.09030515190635624\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CrR_ddqbswF",
    "outputId": "bf8a8b46-b998-4a65-f5a9-bc09ce1bd550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.3144335234155838, p: 0.6293826796237951, f:0.215987109149876\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLloGUgsanVt"
   },
   "source": [
    "### ClusterRank  <a class=\"anchor\" id=\"ch6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNB1JW_0anVu"
   },
   "outputs": [],
   "source": [
    "def read(a):\n",
    "    text =[]\n",
    "    split_regex = re.compile(r'[.|!|?|…]')\n",
    "    sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "    for s in sentences:\n",
    "        text.append(s)\n",
    "    res = list(sent_to_words(text))\n",
    "    return res\n",
    "\n",
    "# Расстояние левенштайна \n",
    "def lDistance(firstString, secondString):\n",
    "    if len(firstString) > len(secondString):\n",
    "        firstString, secondString = secondString, firstString\n",
    "    distances = range(len(firstString) + 1)\n",
    "    for index2, char2 in enumerate(secondString):\n",
    "        newDistances = [index2 + 1]\n",
    "        for index1, char1 in enumerate(firstString):\n",
    "            if char1 == char2:\n",
    "                newDistances.append(distances[index1])\n",
    "            else:\n",
    "               newDistances.append(1 + min((distances[index1], distances[index1+1], newDistances[-1])))\n",
    "        distances = newDistances\n",
    "    return distances[-1]\n",
    "\n",
    "def build_lev_matrix(sentences, stop_words):\n",
    "    lev_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            lev_matrix[idx1][idx2] = lDistance(sentences[idx1], sentences[idx2])\n",
    "    return lev_matrix\n",
    "\n",
    "\n",
    "def generate_clusterrank_summary(file_name, top_n):\n",
    "    summarize_text = []\n",
    "    sentences = read(file_name)\n",
    "    sentence_lev_martix = build_lev_matrix(sentences, stopwords_english)\n",
    "\n",
    "    # используем pagerank, чтобы определить веса предложений \n",
    "    sentence_lev_graph = nx.from_numpy_array(sentence_lev_martix)\n",
    "    scores = nx.pagerank(sentence_lev_graph)\n",
    "\n",
    "    # отсортируем предложения и выберем веса с большим весом \n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    #print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "\n",
    "    for i in range(top_n):\n",
    "        summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "    return summarize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykbiD0LoanVu",
    "outputId": "60118122-a4c3-4afa-e490-1810371bb0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " it would be best to to appeal to broad public and make the covers exchangeable so the young people will buy an orange and red and blue and purple but when the older people uh go in the shop and they see uh an orange um remote control it would be less appealing than white one. uh we had decided to uh put uh some flashy fruity colours in it uh and uh in the survey from uh milan and paris uh it uh it came out that uh uh the the older people are uh more willing to uh to spend money on extra features. what really miss also is uh is is turtle is decision uh decision system like um with the evaluation you have to polls like what do you want one two maybe little application like uh uh give your own number and click one two three four five six seven. and thats pity if you uh if you have uh thirty forty minutes uh for this kind of things and we are now with four people but it well imagine you are here youre with the ten people and everyone uh yeah. what do you think about uh putting battery in it but also selling like uh the covers docking station just apart from the from the thing so that you can uh put uh rechargeable batteries in it and just yeah yeah okay. and thats thats mostly the case from the over here with the managements you get two minutes to make your case and if you have to do all this kind youll rather use powerpoint and work it out in advance. and young people we think are little bit more flexible they think ah ill buy for couple of euros some noi nice hip uh well um think cover is necessary cause als otherwise youll just have the l_c_d_ screen. um well during the meeting showed you the concept of uh placing the buttons on top usable with your thumb and uh the menu structure uh if necessary with your other hand so its just gonna hold it easily. so think uh it will be better idea to have some uh flashy fruity colours as as standard and for the people who uh really want uh more sophisticated more traditional look theyre willing to pay uh that. be it it takes lot of time to draw things and to write things and thats the yeah but thats not th the the you when you at foreign audience you dont gonna wr uh write uh small\n"
     ]
    }
   ],
   "source": [
    "k = generate_clusterrank_summary(df_extractive['extractive_text'][0], 10)\n",
    "print(\"Summarize Text: \\n\", \". \".join(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dV1XQIVYanVv"
   },
   "outputs": [],
   "source": [
    "clusterrank_hypothesis = ''\n",
    "for i in k:\n",
    "    clusterrank_hypothesis += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_kb7JK2anVv",
    "outputId": "b4464925-13d6-437e-fb32-448e73794e7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'f': 0.4539363441966954,\n",
       "   'p': 0.7527777777777778,\n",
       "   'r': 0.3249400479616307},\n",
       "  'rouge-2': {'f': 0.22651006290472558,\n",
       "   'p': 0.37604456824512533,\n",
       "   'r': 0.16206482593037214},\n",
       "  'rouge-l': {'f': 0.42043221540151543,\n",
       "   'p': 0.5752688172043011,\n",
       "   'r': 0.33126934984520123}}]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(clusterrank_hypothesis, transcript_sum)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLvGoVNEanVv"
   },
   "source": [
    "На всем датасете. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSRDPD67bswH"
   },
   "outputs": [],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu_together = []\n",
    "df_extractive_clusterrank = df_extractive.head(5)\n",
    "for i in range(len(df_extractive_clusterrank)):\n",
    "    fin_clusterrank = generate_clusterrank_summary(df_extractive_clusterrank['extractive_text'][i], top_n = 13)\n",
    "    clusterrank_hypothesis = ''\n",
    "    for j in fin_clusterrank :\n",
    "        clusterrank_hypothesis += j \n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(clusterrank_hypothesis, df_extractive_clusterrank['extractive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple(df_extractive_clusterrank['extractive_summary'][i])\n",
    "    candidate = preprocess_text_simple(clusterrank_hypothesis)\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfn62yMBbswH",
    "outputId": "887853eb-fd4d-4db7-8799-c12598517e3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.0, bleu: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xykYDkn6bswH",
    "outputId": "2f61212d-89ad-4b35-838b-c60854532d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.44656084930842505, p: 0.7501809189199112, f:0.3302438389940815\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8NEXvnabswH",
    "outputId": "f331fef5-f10a-488e-b326-9b7631cdc523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.2353707213979946, p: 0.39898885768783376, f:0.17269982337677467\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1s5nUVObswI",
    "outputId": "37825b4d-c515-47f2-f626-f8bea3cb4ddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.42527543931265355, p: 0.5915725123717029, f:0.3396944529392348\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrw50ZHdanVv"
   },
   "source": [
    "### LSA  <a class=\"anchor\" id=\"ch7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RORkFDr_anVx"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcnGEBILanVx"
   },
   "outputs": [],
   "source": [
    "def calc_sigma(matrix):\n",
    "    (m, n) = matrix.shape   # узнаем размерность матрицы train\n",
    "    sigma = np.zeros((m, n))  # задаем матрицу из нулей для сигмы такой же размерности, как A\n",
    " \n",
    "    matrix_transposed = matrix.transpose()    # транспонируем A\n",
    "    matrix_c = 1/n * matrix.dot(matrix_transposed)   # считаем ковариационную матрицу C\n",
    " \n",
    "    wa, u = np.linalg.eig(matrix_c)   # wa - собственные значения, u - соответствующие собственные векторы\n",
    "    wa.sort()   # сортируем собственные значения\n",
    "    wa = wa[::-1]  # в порядке убывания\n",
    " \n",
    "    sigmas = np.sqrt(wa)   # вычисляем корни от всех собственных чисел\n",
    " \n",
    "    i = 0\n",
    "    if m < n:   # выставляем собственные значения по главной диагонали\n",
    "        while i < m:\n",
    "            sigma[i, i] = sigmas[i]\n",
    "            i += 1\n",
    "    if n < m:\n",
    "        while i < n:\n",
    "            sigma[i, i] = sigmas[i]\n",
    "            i += 1\n",
    " \n",
    "    s = []  # формальность: для удобства меняем тип array на список\n",
    "    for vector in sigma:\n",
    "        s.append([vector[i] for i in range(len(vector))])\n",
    " \n",
    "    return s\n",
    " \n",
    " \n",
    "# Подсчет W_transposed - каждый столбик - собственный вектор матрицы C = A^(T) * A (отсортированы по убыванию)\n",
    " \n",
    "def calc_w(matrix):\n",
    "    va_sorted = []  # отсортируем собственные векторы по убыванию собственных значений\n",
    " \n",
    "    matrix_transposed = matrix.transpose()  # транспонируем A\n",
    "    matrix_c = matrix_transposed.dot(matrix)  # считаем матрицу С\n",
    "    print(\"Матрица C: \")\n",
    "    print(matrix_c)\n",
    "    print()\n",
    " \n",
    "    eigenvalues_c, eigenvectors_c = np.linalg.eig(matrix_c)  # собственные значения и собственные векторы матрицы C (правые)\n",
    "    wa_index_value = []  # создадим массив с элементами вида (индекс собственного значения, собственное значение)\n",
    " \n",
    "    counter = 0\n",
    "    while counter < len(eigenvalues_c):  # заполним такой массив\n",
    "        (m, n) = (counter, eigenvalues_c[counter])\n",
    "        wa_index_value.append((m, n))\n",
    "        counter += 1\n",
    "    wa_index_value_sorted = sorted(wa_index_value, key=lambda index_value: index_value[1])  # сортируем элементы по величине собственного значения\n",
    "    wa_index_value_sorted = wa_index_value_sorted[::-1]  # в порядке убывания\n",
    " \n",
    "    counter = 0  # заполняем поэлементно матрицу сортированных собственных значений\n",
    "    while counter < len(wa_index_value_sorted):  # проходим по очереди по всем () в wa_index_value_sorted\n",
    "        va_sorted.append(eigenvectors_c[:, wa_index_value_sorted[counter][0]])  # берем из списка собств. векторов тот, который с таким же индексом, как индекс в ()\n",
    "        counter += 1\n",
    " \n",
    "    eigenvectors_c_sorted = []  # формальность: для удобства меняем тип array на список\n",
    "    for vector in va_sorted:\n",
    "        eigenvectors_c_sorted.append([vector[i] for i in range(len(va_sorted))])\n",
    " \n",
    "    w = np.array(eigenvectors_c_sorted).transpose()  # транспонируем матрицу W\n",
    " \n",
    "    return w\n",
    " \n",
    " \n",
    "#   Подсчет U\n",
    " \n",
    "def calc_u(matrix):\n",
    "    matrix_transposed = matrix.transpose()  # транспонируем A\n",
    "    matrix_c2 = matrix.dot(matrix_transposed)  # считаем матрицу c2\n",
    "    va_sorted = []  # отсортируем впоследствии собственные векторы по убыванию собственных значений и внесем сюда\n",
    " \n",
    "    eigenvalues_c2, eigenvectors_c2 = np.linalg.eig(matrix_c2)   # левые собственные числа и векторы\n",
    "    wa_index_value = []  # создадим массив с элементами вида (индекс собственного значения, собственное значение)\n",
    " \n",
    "    counter = 0\n",
    "    while counter < len(eigenvalues_c2):  # заполним такой массив\n",
    "        (m, n) = (counter, eigenvalues_c2[counter])\n",
    "        wa_index_value.append((m, n))\n",
    "        counter += 1\n",
    "    wa_index_value_sorted = sorted(wa_index_value, key=lambda index_value: index_value[1])  # сортируем элементы по величине собственного значения\n",
    "    wa_index_value_sorted = wa_index_value_sorted[::-1]  # в порядке убывания\n",
    " \n",
    "    counter = 0  # заполняем поэлементно матрицу сортированных собственных значений\n",
    "    while counter < len(wa_index_value_sorted):  # проходим по очереди по всем () в wa_index_value_sorted\n",
    "        va_sorted.append(eigenvectors_c2[:, wa_index_value_sorted[counter][0]])  # берем из списка собств. векторов тот, который с таким же индексом, как индекс в ()\n",
    "        counter += 1\n",
    " \n",
    "    u = []  # формальность: для удобства меняем тип array на список\n",
    "    for vector in va_sorted:\n",
    "        u.append([vector[i] for i in range(len(va_sorted))])\n",
    "    u = np.array(u)\n",
    " \n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wV9fzwZMbswJ"
   },
   "outputs": [],
   "source": [
    "# как вариант можно делать через truncatedsvd \n",
    "'''\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "components = 30\n",
    "lsa = TruncatedSVD(n_components=components) \n",
    "lsa.fit(dtm)\n",
    "lsa_dtm = lsa.transform(dtm)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmYwvr2-anVx"
   },
   "outputs": [],
   "source": [
    "# входные данные (текст , разбитый на предложения; количество предложений, которое мы хотим видеть в summary)\n",
    "df_extractive_lsa = df_extractive.iloc[1:7]\n",
    "def summary_LSA(transcript, k):\n",
    "    a2 = transcript.replace(\"\\n\", \"\")\n",
    "    a = a2.replace(\"\\ \", \" \")\n",
    "    text =[]\n",
    "    split_regex = re.compile(r'[.|!|?|…]')\n",
    "    sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "    for s in sentences:\n",
    "        text.append(s)\n",
    "    vectorizer = TfidfVectorizer(stop_words = stopwords_english)\n",
    "    X = vectorizer.fit_transform(text)\n",
    "    y = X.toarray()\n",
    "    a = np.matrix(y).T\n",
    "    U_numpy, s_numpy, W_numpy = np.linalg.svd(a) \n",
    "    W_numpy_2 = np.square(W_numpy)\n",
    "    s_numpy_2 = np.square(s_numpy)\n",
    "    weights = np.sqrt(np.dot(W_numpy_2, s_numpy_2))\n",
    "    weights = np.array(weights)[0]\n",
    "    dict_weights = {k: v for k, v in enumerate(list(weights))}\n",
    "    indexes_weights = sorted(dict_weights, key=dict_weights.get, reverse = True)\n",
    "    indexes = indexes_weights[:k]\n",
    "    summary = []\n",
    "    for i in indexes:\n",
    "        summary.append(text[i])\n",
    "    return summary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mwN4Mt7anVy"
   },
   "outputs": [],
   "source": [
    "summary = summary_LSA(df_extractive['extractive_text'][1], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ManQNUMKanVy",
    "outputId": "8171b739-00c1-444f-c0da-706ca46049a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text LSA: \n",
      " Yeah. Well, since our materials aren't exactly what we were going for, I'm just gonna translate what this all means for you. Thumb-shaped. Irritating, yeah. And did you determine um the curvature of the bottom part of it for the hand, is it gonna be a single or a double. And so we n k everybody have that. Um we are really gonna sell this. Wow that's a it's definitely a strong one. Yeah they were fun, even though I'm not really sure what I could do with them, but they are awesome. We're under. Mm. Colours. Yeah, and no internet. You too. Mm-hmm. Yeah. Yeah, 'cause they're pretty and just like Uh yeah. Yeah. And the digital the digital pens were they were pretty cool. Yeah. Are we going to indi I say we individually rate what do you say. Oh. Yeah. And these things whoa. Um then there's the latex cover, which is what you see as red. Oh sorry I'm taking over your job here. Yeah, no, iPods They want all those words for presentation, even the plugs. I think we just discuss it. Ta-da. Alright. Um bright yellow sort of design with the R_R_ which will actually look like our logo. Minus that one fight. Oh yeah, everybody. Yeah, let's let's do a lithium. You or me. Me too. Marketing Director says yeah. We're gonna have the integrated scroll scroll wheel. Fashionable people will buy it. Mm-hmm. If so, we can proceed, if not, we need to go back to the drawing board a little bit. Yeah. Um sure. Um easy to use. And then the last thing is just that it'll be black labelling on top, just which we didn't do. Okay. That is a piece of work. Yeah, it's a two. Yeah. Um and the buttons will be a l much lighter blue, almost see-through\n"
     ]
    }
   ],
   "source": [
    "print(\"Summarize Text LSA: \\n\", \". \".join(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xCx3FiJanVy",
    "outputId": "95418472-a03d-4837-b1a9-1388f8fa3b9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'f': 0.4440789430592647,\n",
       "   'p': 0.7068062827225131,\n",
       "   'r': 0.3237410071942446},\n",
       "  'rouge-2': {'f': 0.2487644108496292,\n",
       "   'p': 0.3963254593175853,\n",
       "   'r': 0.18127250900360145},\n",
       "  'rouge-l': {'f': 0.3724394737907334,\n",
       "   'p': 0.4672897196261682,\n",
       "   'r': 0.30959752321981426}}]"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_hypothesis = ''\n",
    "for i in summary:\n",
    "    lsa_hypothesis += i\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(lsa_hypothesis, transcript_sum)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtSuhnRIbswK"
   },
   "source": [
    "На всем датасете. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UOTF7usbswK",
    "outputId": "c52c71a3-4dca-48a7-f4e2-c2f8a6d2d2de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "for i in range(1, len(df_extractive_lsa)):\n",
    "    fin_LSA = summary_LSA(df_extractive_lsa['extractive_text'][i],20)\n",
    "    LSA_hypothesis = ''\n",
    "    for j in fin_LSA :\n",
    "        LSA_hypothesis += j \n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(LSA_hypothesis, df_extractive_lsa['extractive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple(df_extractive_lsa['extractive_summary'][i])\n",
    "    candidate = preprocess_text_simple(LSA_hypothesis)\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu(reference, candidate, weights=(0, 0, 1, 0))\n",
    "    bleu3.append(bleu_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--JMsqxybswL",
    "outputId": "de18d367-451d-4f6e-9b06-321bcec25c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.008510638297872339, bleu: 0.03487976676161907\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KURWEUnJbswL",
    "outputId": "9a788e71-c38b-48b9-c28f-ba8a409611f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.1415345242015588, p: 0.6963862391409895, f:0.08019001800924401\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFCGedlmbswL",
    "outputId": "93ab1f5b-9079-43a9-d1b5-b4480235cf3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.06870184646138798, p: 0.32287328875446664, f:0.03889482439901886\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GMyyijEgbswL",
    "outputId": "39221762-4ff6-43d7-f369-e7cea2ab13db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.2310095345641363, p: 0.5684390252514553, f:0.1482840764902869\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxM6MCGUanVz"
   },
   "source": [
    "### KLsum   <a class=\"anchor\" id=\"ch8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eR1ZOwjZanV0"
   },
   "outputs": [],
   "source": [
    "# принимает список частот слов в саммари и список частот слов в тексте\n",
    "def sent_to_words_1(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent) \n",
    "\n",
    "def delete_sentecnes_with_stopwords(a):\n",
    "    for i in a:\n",
    "        length_sent = len(i)\n",
    "        for j in i:\n",
    "            if j in stopwords_english:\n",
    "                length_sent -= 1\n",
    "        if length_sent < 3:\n",
    "            a.remove(i)\n",
    "    return a\n",
    "                \n",
    "    \n",
    "def kl_divergence(summary_density, text_density):\n",
    "        sum_val = 0\n",
    "        # для каждого слова из саммари смотрим, есть ли слово из саммари в тексте \n",
    "        for w in summary_density:\n",
    "            # frequency \n",
    "            frequency = text_density.get(w)\n",
    "            # если частота этого слова существует, то мы считаем частоту в тексте и в саммари этого слова и используем формулу kl\n",
    "            if frequency: \n",
    "                sum_val += frequency * math.log(frequency / summary_density[w])\n",
    "        return sum_val\n",
    "\n",
    "\n",
    "def get_all_words(snw):\n",
    "    all_words = []\n",
    "    for i in snw:\n",
    "        for j in i:\n",
    "            if j not in stopwords_english:\n",
    "                all_words.append(j)\n",
    "    return all_words\n",
    "\n",
    "def calculate_freq(array):\n",
    "    word_freq = {}\n",
    "    for w in array:\n",
    "        word_freq[w] = word_freq.get(w, 0) + 1\n",
    "    return word_freq  \n",
    "\n",
    "def get_sentences_list(a):\n",
    "    text =[]\n",
    "    split_regex = re.compile(r'[.|!|?|…]')\n",
    "    sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "    for s in sentences:\n",
    "        if len(s) > 7:\n",
    "            text.append(s)\n",
    "    return text   \n",
    "\n",
    "def find_index_of_best_sentence(kls):\n",
    "    return kls.index(min(kls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WljsKfnnbswQ"
   },
   "outputs": [],
   "source": [
    "import math \n",
    "import re\n",
    "from gensim import models\n",
    "def generate_klsum_summary(transcript, num_sent):\n",
    "    sentences_list = get_sentences_list(transcript)\n",
    "    sentences_as_words_= list(sent_to_words(sentences_list))\n",
    "    sentences_as_words = delete_sentecnes_with_stopwords(sentences_as_words_)\n",
    "    all_w = get_all_words(sentences_as_words)\n",
    "    word_freq = calculate_freq(all_w)\n",
    "    summary = []\n",
    "    while num_sent > 0:\n",
    "        # будет хранить значения kls, чтобы из них выбрать наиментгее\n",
    "        kls = []\n",
    "        # превращает краткое содержание в список слов \n",
    "        summary_as_word_list = get_all_words(sent_to_words(summary))\n",
    "\n",
    "        for s in sentences_as_words:\n",
    "            # если мы добавим предложение, то какое будет распределение\n",
    "            # соединим список слов в предложении и то, что в саммари \n",
    "            new_joint = s + summary_as_word_list\n",
    "            joint_freq = calculate_freq(new_joint)\n",
    "\n",
    "            # считаем kls между распределением саммари и слова в тексте \n",
    "            kls.append(kl_divergence(joint_freq, word_freq))\n",
    "            new_joint = summary_as_word_list\n",
    "\n",
    "        indexToRemove = find_index_of_best_sentence(kls)\n",
    "        best_sentence = sentences_list.pop(indexToRemove)\n",
    "        del sentences_as_words[indexToRemove]\n",
    "        summary.append(best_sentence)\n",
    "        num_sent -= 1 \n",
    "    summary_fin = ''\n",
    "    for i in summary:\n",
    "        summary_fin += '. ' + i\n",
    "    return summary_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "id": "kIV3-_zZbswQ",
    "outputId": "900bb4bb-07d6-49e7-c7ab-7848a4833970"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\". And after that, uh uh an evaluation of uh the process how we uh how we have done it here with the SMARTboard, with the with our laptops, with the all uh all this. Um, you see. Yeah, maybe. I can delete it for you if you want. During the design uh design life-cycle we uh we made lot of requirements and trend analysis and stuff. All the mo yeah, are between one and two. No, tho uh that that can be done. Leads to user face, yeah. I'm uh when I said it, I remember I had it here. The blue blue uh Okay. We have the sub-menus and stu stuff. Now we're done. Oh, okay, but 'kay, look. J_ and J_. Not really, yeah. Uh, button, no. That's an add-on. Yeah, if the costs are under twelve and a half Euro, uh then we uh can uh ra uh move on to the project evaluation, as we have uh experienced it. You can be you can go quicker, 'cause then it it won't notice it. The remote control has m remova removable from Multilux\""
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_klsum_summary(df_extractive['extractive_text'][0], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lOQ2jR_anV0"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# существует библиотека для этого метода \n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.kl import KLSummarizer\n",
    "document = a\n",
    "parser=PlaintextParser.from_string(document,Tokenizer(\"english\"))\n",
    "summarizer = KLSummarizer()\n",
    "summary = summarizer(parser.document,50)\n",
    "summ_klsumm = []\n",
    "for sentence in summary:\n",
    "    summ_klsumm.append(sentence)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luWCpQ8ObswR"
   },
   "source": [
    "На полном датасете: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjABn70YbswR",
    "outputId": "1ff4411a-91e2-4619-87c7-0146709a9539"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "for i in range(len(df_extractive)):\n",
    "    fin_klsum = generate_klsum_summary(df_extractive['extractive_text'][i], 30)\n",
    "    klsum_hypothesis = ''\n",
    "    for j in fin_klsum :\n",
    "        klsum_hypothesis += j \n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(klsum_hypothesis, df_extractive['extractive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple(df_extractive['extractive_summary'][i])\n",
    "    candidate = preprocess_text_simple(klsum_hypothesis)\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu(reference, candidate, weights=(0, 0, 1, 0))\n",
    "    bleu3.append(bleu_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJrhgRqiqzHn",
    "outputId": "aa36e65e-e5d1-4074-cb48-1bb5fc855026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.01159354346014289, bleu: 0.20833329258339495\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4BZeh4Bq349",
    "outputId": "6ad0ffd0-f672-4e5f-bed3-55ae5ddb6923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.29031370197713297, p: 0.7801536103408768, f:0.18650998198840268\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwR1qRS8q7DK",
    "outputId": "c9c0b389-a97a-4449-9124-7c592181b1f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.15824751254645825, p: 0.4378632344124955, f:0.1007183555013194\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjWoBUAYq7PY",
    "outputId": "44caec88-d4b1-4523-c696-8d9a4c0e3a80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.3892319176600572, p: 0.6659284825541392, f:0.28462192187826574\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-OXnyqianV1"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "namNjickanV1"
   },
   "source": [
    "### Mead <a class=\"anchor\" id=\"ch9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6rEAgAdanV2"
   },
   "outputs": [],
   "source": [
    "# функция, которая объединяет все выше сделанные действия \n",
    "def text_to_sentences(a):\n",
    "    text =[]\n",
    "    split_regex = re.compile(r'[.|!|?|…]')\n",
    "    sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "    for s in sentences:\n",
    "        text.append(s)\n",
    "    return text\n",
    "    \n",
    "def preprocess(a):\n",
    "    text =[]\n",
    "    split_regex = re.compile(r'[.|!|?|…]')\n",
    "    sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(a)])\n",
    "    for s in sentences:\n",
    "        text.append(s)\n",
    "    res = list(sent_to_words(text))\n",
    "    res_ = []\n",
    "    s_ =[]\n",
    "    for s in res:\n",
    "        for word in s:\n",
    "            if word not in stopwords_english:\n",
    "                s_.append(word)\n",
    "        res_.append(s_)\n",
    "        s_ = []\n",
    "    res_fin = []\n",
    "    s_fin = []\n",
    "    for s in res_:\n",
    "        for word in s:\n",
    "            s_fin.append(lemmatizer.lemmatize(word))\n",
    "        res_fin.append(s_fin)\n",
    "        s_fin = []\n",
    "    return res_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "4KgWdobRatUt",
    "outputId": "31877494-84c1-4ce0-873b-55c5a6588a45"
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn-extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igE-I5W8anV3"
   },
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "def summary_mead(file):\n",
    "    text = text_to_sentences(file)\n",
    "    words = []\n",
    "    f = preprocess(file)\n",
    "    new_f = []\n",
    "    for i in f:\n",
    "        if len(i) > 6:\n",
    "            new_f.append(i)\n",
    "            for j in i:\n",
    "                words.append(j)\n",
    "    all_words = list(set(words))\n",
    "    matrix = []\n",
    "    vector = [0] * len(all_words)\n",
    "    for sent in new_f:\n",
    "        for w in sent:\n",
    "            if w in all_words:\n",
    "                vector[all_words.index(w)] += 1\n",
    "        matrix.append(vector)\n",
    "        vector = [0] * len(all_words)\n",
    "    kmedoids = KMedoids(n_clusters=len(matrix) - 5, random_state=42).fit(matrix)\n",
    "    kmedoids_centers = kmedoids.cluster_centers_\n",
    "    kmedoids_centers = list(kmedoids_centers)\n",
    "    for i in range(len(kmedoids_centers)):\n",
    "        kmedoids_centers[i] = list(kmedoids_centers[i])\n",
    "    indexes_sum = []\n",
    "    for i in kmedoids_centers:\n",
    "        indexes_sum.append(matrix.index(i))\n",
    "    final_summary = []\n",
    "    for i in indexes_sum:\n",
    "        final_summary.append(' '.join(new_f[i]))\n",
    "    full_summary = '. '.join(final_summary)\n",
    "    return full_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihjnesEeanV3"
   },
   "outputs": [],
   "source": [
    "mead_hypothesis = summary_mead(df_extractive['extractive_text'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "UNDQUvIUbswT",
    "outputId": "3a556984-1def-43a1-c7cc-05b44ba67642"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'website went look announcement introduction sort seven inch monitor understood project goal. immediate next step start determining functional design. im glad didnt work ahead time clearly didnt understand project goal. please please copy mail discussion need submit management. would th think depends much money give u. know make different choice different financial model. request keep ed loop meeting christine meeting know whats happening. basically need interact christine user acceptability testing yes. got lot project im right ill wait see go. enough time think two week close enough. would mind conclusion meeting could could send u copy slide. think see throughout day going put together marketing market product. define exactly product mind supposed marketing coffee right. design core marketing need sell youre responsible money finance tomorrow. yes prefer maybe need interact christine know going know sell. ed whats think project remote control already planned something marketing strategy sale strategy. think give kind design functional design technical design. design already product youre still working design. whether work first say design gotta simple use. oh think im wrong making remote control. sure name agnes im user usability user interface designer. goal project think maybe ill hand ed explain project he sale accounting. think give kind project plan discussion next meeting great. want introduce name shrida daseri im project manager new project going discus. think three group need interact quite bit. guess build plan based think need take factor account. anything need anytime please either call send email come knock door im available. thats talk finance idea sell product project market much going benefit company course individual also. begun working design actually didnt know designing remote control thought designing new monitor. ill copy le let u keep email copy share know everybody whats happening. know kind think general something thats fashionable thats attractive people see recognize goal immediately wanna one. design long take whole project much going cost u much going benefit company. thanks coming meeting first long time twenty five minute discus project project initiation. yet research taking remote control looking company theyre building design idea also pinpoint market gonna go. also feed marketing depending user want depends sell tag line attach try make attractive user. mean job understood look usability requirement make sure product usable acceptable people gonna use look best way. youll leading team design team many member working team design. come functional design discus ed going work first user acceptance look going work market discus thing. see starting new project together going four member team composed people thats thats read different step relative step. already cost limit th idea much want market much gonna sell thats thats u decide eh. would really would need something ipod would good seems caught fairly know dont care look cool. something visual something draw people buy product think everybodys experienced remote control remote control worth throwing window. need coordination compared maybe technical vendor commercial vendor depends want marketing plan technical plan let know. think maybe give kind sale plan including technical shes going talk within team help discus management put proper project plan. people need marketing technical side administration point view add documentation technical point view let know coordinate team. think ill interact christine discus shes designing something study show right bat going work sort loop feed dont think necessarily im coordinating position. fairly large market number people competition th agree something something new something draw people saying eh. th ar dont know come new idea make lot easier use cause lot time spend half day instruction book trying figure use'"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mead_hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24OKMSSNbswU",
    "outputId": "54ff22b2-dd5b-416a-f122-2b0453f97c22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "for i in range(len(df_extractive)):\n",
    "    fin_mead= summary_mead(df_extractive['extractive_text'][i])\n",
    "    mead_hypothesis = ''\n",
    "    for j in fin_mead:\n",
    "        mead_hypothesis += j \n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(mead_hypothesis, df_extractive['extractive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple(df_extractive['extractive_summary'][i])\n",
    "    candidate = preprocess_text_simple(mead_hypothesis)\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu(reference, candidate, weights=(0, 0, 1, 0))\n",
    "    bleu3.append(bleu_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQQ-FFLYuXDI",
    "outputId": "e1232f8a-b3b6-4985-e4ea-f2c1c6701759"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.0015992527765157731, bleu: 0.16493003816252755\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4FMlvm0uXRF",
    "outputId": "9726e3b6-f4ec-40a9-9687-0b2253e70de4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.32504767292556996, p: 0.4661053839606678, f:0.2613586623721295\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Psr8yZUuXbc",
    "outputId": "fec48ea2-3211-4e71-b269-1137774635f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.06483390330861646, p: 0.09193227772074546, f:0.052268572513609515\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzDBlHlyuXlX",
    "outputId": "883b9201-cc43-44e1-8bef-de6251dde2f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.5062470211025011, p: 0.5432611173755149, f:0.48166070780670617\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahE81epdanV3"
   },
   "source": [
    "## Abstractive methods <a class=\"anchor\" id=\"ch10\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bNBSt-TanV3"
   },
   "source": [
    "### Bidirectional Encoder Representations from Transformers (BERT) - 2018 <a class=\"anchor\" id=\"ch11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlkJk59TanV4",
    "outputId": "aca312f8-5acd-4da0-aa53-7f7fda064c5a"
   },
   "outputs": [],
   "source": [
    "# !pip install sentencepiece\n",
    "# !pip install bert-extractive-summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIPboZ8fanV4"
   },
   "outputs": [],
   "source": [
    "# работает на tpu\n",
    "from summarizer import TransformerSummarizer\n",
    "from summarizer import Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cn7MKbnyw1Lr"
   },
   "outputs": [],
   "source": [
    "df_abstractive = pd.read_csv('/content/abstractive_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvyJmvHNanV4",
    "outputId": "783beb79-8c43-4a7e-c08c-390ce10defb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Um, I'm going to be responsible for the functional design phase. Well there are loads of different types of dogs, so I'm sure it'll represent one kind of dog. But this part was all brown and then it has these big blue dots like this. This is the first meeting uh for developing our, our new product. If everyone could go around and explain their role and um, and their name. Um, we want this to be a marketable product that can be trendy, um, a completely new style, so that, um, can really appeal to a, to a generation that doesn't want a simple plain kind of, uh, channel-changer. And, um, it needs to be user-friendly for, um, maybe, for an example, for people that, um, can't see the numbers as well, or, um, perhaps an ergonomic design. I mean, you're the designers, you c, you can um decide what kind of, um, direction you wanna go in, but at this point in the, in the first meeting it can be any ideas that we just throw out there. Um, that does not necessarily mean it needs to be outrageous. Um, like you can go over your ideas, of course, in your own personal times. Um, maybe how this can be achieved, and, um, we need the user requirements from the manag Marketing Expert. Um, you will get specific instructions, um, of what to do in the next half an hour.\n"
     ]
    }
   ],
   "source": [
    "bert_model = Summarizer()\n",
    "bert_summary = ''.join(bert_model(df_abstractive['abstractive_text'][0], min_length=60))\n",
    "print(bert_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "id": "JXXYR1EJw_0X",
    "outputId": "e4b12d34-fb48-4192-ec2b-88c92970a5f6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'The project manager opens the meeting by introducing herself and asking everyone to say their name and role in the group. She then states the agenda of the meeting and tells them that they will be designing and creating a new remote control that should be trendy and user-friendly. The meetings will focus on functional, conceptual, and detailed design. Next, each group member draws their favorite animal on the whiteboard and explains the characteristics of that animal. After that the project manager covers the project budget, and then they begin discussing their personal experiences with remote controls and how they want their remote to look. Then the project manager closes the meeting by telling each group member what to do in preparation for the next meeting. '"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abstractive['abstarctive_summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTxeHU4uwN0p",
    "outputId": "24e3e99e-58b7-4bab-d502-4f6d27ba8e76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "df_abstractive = df_abstractive.head(10)\n",
    "for i in range(len(df_abstractive)):\n",
    "    bert_summary = ''.join(bert_model(df_abstractive['abstractive_text'][i], min_length=60))\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(bert_summary, df_abstractive['abstarctive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple( df_abstractive['abstarctive_summary'][i])\n",
    "    candidate = preprocess_text_simple(bert_summary )\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qy3BclWrwN-U",
    "outputId": "ee3fb7d7-5f5a-4080-a115-9bbc06c04219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.009429617015806153, bleu: 0.2254619800841125\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1Hiuwrlx-aW",
    "outputId": "1b682566-23fa-46ba-9057-25afcb7ec801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.17886214677584958, p: 0.12396242591199387, f:0.41062445436683764\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUrcRhAmx-jo",
    "outputId": "28db3270-b25f-4a81-9f54-1ddcde61a0b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.026312991193576617, p: 0.01803723380123618, f:0.06077928317614902\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDy62wodx-ta",
    "outputId": "92ff463b-18fe-4d16-a567-6661958c1d0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.16225746333306398, p: 0.11625716262041248, f:0.3105863049439002\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRy305iXanV5"
   },
   "source": [
    "### GPT2 <a class=\"anchor\" id=\"ch12\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "891d1f193b1e4e19bd8a659c8afa9f2b",
      "c8d3dba8950647f78e42a0c6cfc16bde",
      "3d099d24ff2b45698e534449749b1848",
      "1ea0ab94c1dd4a739de7c2d6d47d80ad",
      "85f9ab0a563249d3a93809befdcf0a1a",
      "32f237d7af1a475cbce8cf894c62d709",
      "59ba018eec7c497f8a1c49bd28dfab60",
      "81c5e0ec7358422b84b3438f9eac6d64",
      "bcb274a7b3934d6faf868c6c87045e54",
      "c71c0054b8994abfa6fcace945fcf5cf",
      "f819d6152cfe44bca8d8fbcfd4fe5198",
      "c4652d164ada49ad882f4e7a15ec3be0",
      "922f3ecc616144708f1179de850b9004",
      "1ab3ee790a56498e800681ddd172ba5c",
      "a5ccefeb6404490fb4c1f3c65c1d04af",
      "69438792226a472095d2cd18c15e0c0e",
      "b9649c01a1d846c4a5f0975ef6e236c2",
      "c7749ca11e9d496cb33f04dfc2f7a7b3",
      "e29e881d804d4703a828cc40e88cda67",
      "98d407c4f98d446f91649abb973e7e70",
      "6c23b18bea4841d0a6a61631ab238c95",
      "62bbb122f57c4d0a9222e07ec075c245",
      "a145b6236efa46cf8b2b3fbf3f4a9a43",
      "be0cc8bf2946474092c2faa4e521866f",
      "4babc5cc0ef24f9686833cab4e113962",
      "6fb9d897c22d470db9e5951df85cf8ab",
      "9dfdaa37cdb54bfc9cafa79319704fe9",
      "c897f7abf39f49e7824bb0c9f45ad7c1",
      "0ae3520789264d9fa3da4f9a4d255a5a",
      "7559d35bc0384edea390bfdc74eb9b1f",
      "db2b377166ed47739d21eaf982b901d7",
      "00107b9bd80a4708ab7603561c696296",
      "c605c3af29c04a23873ebe773ebc6838",
      "8035d2d9c4ba4934adb5bcd02a4ca1d1",
      "f1c60283aec64252b995af76e1a0d403",
      "1841f119895c473786ff4adf68a0bb49",
      "e32c623da4124d95b5d2d7db13bc516a",
      "62a772f051ae4210bb019c0ca598c2cc",
      "c82809532ead4f138911dd25b2d69f1f",
      "10a5245500bc4f95817b00ebc0af4d70"
     ]
    },
    "id": "iBrVQ0bPanV5",
    "outputId": "f17a4cf2-d3d1-41fa-dcc5-711c3ed4a106"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891d1f193b1e4e19bd8a659c8afa9f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=718.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb274a7b3934d6faf868c6c87045e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1520013706.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.5.attn.masked_bias', 'h.19.attn.masked_bias', 'h.2.attn.masked_bias', 'h.4.attn.masked_bias', 'h.21.attn.masked_bias', 'h.23.attn.masked_bias', 'h.9.attn.masked_bias', 'h.3.attn.masked_bias', 'h.8.attn.masked_bias', 'h.10.attn.masked_bias', 'h.15.attn.masked_bias', 'h.14.attn.masked_bias', 'h.7.attn.masked_bias', 'h.6.attn.masked_bias', 'h.1.attn.masked_bias', 'h.18.attn.masked_bias', 'h.0.attn.masked_bias', 'h.17.attn.masked_bias', 'h.16.attn.masked_bias', 'h.12.attn.masked_bias', 'h.22.attn.masked_bias', 'h.20.attn.masked_bias', 'h.11.attn.masked_bias', 'h.13.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9649c01a1d846c4a5f0975ef6e236c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4babc5cc0ef24f9686833cab4e113962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c605c3af29c04a23873ebe773ebc6838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Um, I'm going to be responsible for the functional design phase. So maybe if you could have some kind of tracking device for the remote control or some signal that you could find out where it was. You can press a button on your wall, signal, 'cause it always gets lost. I'm going to draw a butterfly, because I saw a butterfly yesterday, that seemed to be like the symbol of Spring arriving. And then it kinda there was a green, I think it was a green ring, and there was like red going out like this. I will also be responsible for the functional design phase, the conceptual design phase and the detailed design phase of the user interface design. It's a dog.. Um, I like dogs because, um, they're so good to humans, like they can be trained to be police dogs and seeing-eye dogs, and they're just such friendly animals. Um, we want this to be a marketable product that can be trendy, um, a completely new style, so that, um, can really appeal to a, to a generation that doesn't want a simple plain kind of, uh, channel-changer. And, um, as a sort of team-building moment, um, I, I'd like us to, um, try out the whiteboard by expressing our favourite animal and the charac characteristics of that animal. And so we have to, um, come up with a way to, to create a, a uh remote control, where um we can like the price to create it will be significantly less. Um, that does not necessarily mean it needs to be outrageous. Um, maybe how this can be achieved, and, um, we need the user requirements from the manag Marketing Expert.\n"
     ]
    }
   ],
   "source": [
    "GPT2_model = TransformerSummarizer(transformer_type=\"GPT2\",transformer_model_key=\"gpt2-medium\")\n",
    "full = ''.join(GPT2_model(df_abstractive['abstractive_text'][0], min_length=60))\n",
    "print(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIElnJQL1I3t",
    "outputId": "1b6ae428-eb94-4644-f34d-77f0ffea515c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "for i in range(len(df_abstractive)):\n",
    "    gpt2_summary = ''.join(GPT2_model(df_abstractive['abstractive_text'][i], min_length=60))\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(gpt2_summary, df_abstractive['abstarctive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple( df_abstractive['abstarctive_summary'][i])\n",
    "    candidate = preprocess_text_simple(gpt2_summary )\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CjOMLVj1bs-",
    "outputId": "cc6cd2c3-d98e-4712-ef63-46676f8c2f54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.009874406105362226, bleu: 0.2278826075075439\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJWaZSbY3lVo",
    "outputId": "8005834b-94d6-41e1-de00-9c1c362524ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.1702615738460246, p: 0.11479004053164751, f:0.4186480246040213\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OFkwFZD3lgf",
    "outputId": "7e0af8ca-cdde-4413-bd4f-c67a6d5d8e48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.029194837926160407, p: 0.019625734983963798, f:0.07275841919916458\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQcpA8533lsD",
    "outputId": "58e37047-2a2c-44f8-8f1a-9341315d812c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.15234277183338343, p: 0.10677330851926703, f:0.3088545223669531\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhmoBjAoanV5"
   },
   "source": [
    "### XLNet <a class=\"anchor\" id=\"ch13\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "34217d3e5fef458f8926401f4b20f387",
      "931d193ae0214e758efd29e41626f90b",
      "b34585c5368d4abbb5fecb945c36ed99",
      "b4c543b0eb464266a49282e9e4e78418",
      "ee133ace14ed40509ba1a02fcbadd8f4",
      "a3d94fb508004f209b8c111f9d3d06f0",
      "bd70ec3d30444aed84eff7566adaf47f",
      "19624aa597a44bb2a5046a3b596ef9ff",
      "50261ef7495e4945a3872e0763d2e2f4",
      "86c08d5c47234b17af4f5d4aa2c6851a",
      "6de0683e6879443990f9bc6c72701d93",
      "2660203eb45241259a2f54fb4dae1287",
      "ef9c691337e94ff9aed14caf9dc2a853",
      "6bb846902712490586a40e2a06da019c",
      "071b8f612462401d9a970b0abd19d80e",
      "b369cd644e2e426081def3d61da7599a",
      "4c15223e676742de9ef4ffee93a79d50",
      "2e84676350724a8b95fd44a677739790",
      "8ca4ba425c2442ddb408f8f129d3ff83",
      "b2528515b58c437c8bde2f394beab879",
      "ec2ccccdb118404b8a440dd52051c86e",
      "9c98fc626a6c4b6ca24fef5d49cd1c3d",
      "81fb4ea6cf1246d096c9ffa883fee037",
      "2772502f70f545439ac4aa4b35231213",
      "d43f5e8d725f4aa2a90f3f90c8a111ab",
      "6de8d5ac9f6a4bcf974b4e59fe0f27b0",
      "ea67009a4c03433aa209ba0aa6da41d0",
      "14fd9c1a574b48e0a1780230ddc8b8ee",
      "c9a64a646ed8450a9480f046bfa61d65",
      "b9991e2d045a4601adde589d8266bd9a",
      "147e46798936490a917ce5cf2b2c9b62",
      "4016c4f8b7344ba5b17413815eb61977"
     ]
    },
    "id": "1V_3iIQoanV6",
    "outputId": "dea23c46-a5d5-4424-8e90-3fda4e4d8546"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34217d3e5fef458f8926401f4b20f387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50261ef7495e4945a3872e0763d2e2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467042463.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c15223e676742de9ef4ffee93a79d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43f5e8d725f4aa2a90f3f90c8a111ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1382015.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Um, I'm going to be responsible for the functional design phase. Also the conceptual design and the detailed design for the final product. But I like cats because they're so independent, and they always seem to be doing what they want to be doing. You can press a button on your wall, signal, 'cause it always gets lost. Um, I'll be doing some trend-watching in the conceptual design, and product evaluation for the design phase. But this part was all brown and then it has these big blue dots like this. There's some remote controls where there's kind of a hidden panel, so all those buttons that you don't really use unless you're programming or something. I'm tempted to draw a snail 'cause I draw them sometimes and they're really easy to draw. And uh tool training is one thing that we're going to be doing today, um um as well as planning the project, how we're going to, uh, create this product, and, um, discuss, um, our aims and objects of this, uh Which brings us to our next subject, is, um, um, as a team we're going to be designing and creating a new kind of remote control. This is a team-building time where, um,, okay cool, um My favourite animal, which changes all the time, okay, right now it is an elk. Um, one thing we'd have to think about internationally is in the design of, um, like different kinds of, uh, V_C_R_s. Um, that does not necessarily mean it needs to be outrageous.\n"
     ]
    }
   ],
   "source": [
    "model_xlnet = TransformerSummarizer(transformer_type=\"XLNet\",transformer_model_key=\"xlnet-base-cased\")\n",
    "full = ''.join(model_xlnet(df_abstractive['abstractive_text'][0], min_length=60))\n",
    "print(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LH1o5Er_4WAd",
    "outputId": "d36ad071-9844-4775-ff98-8c29cd7d0199"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "for i in range(len(df_abstractive)):\n",
    "    xlnet_summary = ''.join(model_xlnet(df_abstractive['abstractive_text'][i], min_length=60))\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(xlnet_summary, df_abstractive['abstarctive_summary'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple( df_abstractive['abstarctive_summary'][i])\n",
    "    candidate = preprocess_text_simple(xlnet_summary)\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_LWc-l64WOU",
    "outputId": "9bf26ae6-4fed-4819-867f-d5be45722676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.009995255436174608, bleu: 0.25507821449390133\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dphYhq6D4WbK",
    "outputId": "067e13ac-75c4-46c2-89ac-cefde69dfe12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.18453680726612712, p: 0.12595571221544882, f:0.4199341022849861\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQfN7dvc4WmI",
    "outputId": "ff683523-f096-45f8-9ba4-17167f66c90b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.026544523097869033, p: 0.01768701814423483, f:0.061826963691579875\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G47G6f284Wxf",
    "outputId": "7205764a-7a2a-4269-ffca-823965c46eea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.16406639476946955, p: 0.11676655123284632, f:0.3146559009338134\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjQoP1vWzeZd"
   },
   "source": [
    "### T5 with fine-tuning <a class=\"anchor\" id=\"ch14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJPxrg9K0AtB",
    "outputId": "b7c2513f-0d76-4b08-eb2e-217485639c2b"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers==2.9.0 \n",
    "#!pip install pytorch_lightning==0.7.5\n",
    "#!pip install transformers -q\n",
    "#!pip install wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqNdHLhg0EKP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import wandb\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Ncv_8MK0P2z",
    "outputId": "fc537b1f-8287-4fa4-af0c-92e41ec7a6be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "# для ускорения моделей будем использовать сервис wandb\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qFdaKbHDTdn"
   },
   "outputs": [],
   "source": [
    "df_abstractive.columns = ['id', 'ctext', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YKN-rf3pMK3"
   },
   "outputs": [],
   "source": [
    "df_abstractive = df_abstractive.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6foIeqqzisR"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = summ_len\n",
    "        self.text = self.data.text\n",
    "        self.ctext = self.data.ctext\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ctext = str(self.ctext[index])\n",
    "        ctext = ' '.join(ctext.split())\n",
    "\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n",
    "        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n",
    "\n",
    "        source_ids = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'source_ids': source_ids.to(dtype=torch.long), \n",
    "            'source_mask': source_mask.to(dtype=torch.long), \n",
    "            'target_ids': target_ids.to(dtype=torch.long),\n",
    "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0Lc_-QSzw3e"
   },
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "    model.train()\n",
    "    for _,data in enumerate(loader, 0):\n",
    "        y = data['target_ids'].to(device, dtype = torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0-C3g7Ez1jp"
   },
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            y = data['target_ids'].to(device, dtype = torch.long)\n",
    "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "            generated_ids = model.generate(\n",
    "                input_ids = ids,\n",
    "                attention_mask = mask, \n",
    "                max_length=150, \n",
    "                num_beams=2,\n",
    "                repetition_penalty=2.5, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True\n",
    "                )\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "            if _%100==0:\n",
    "                print(f'Completed {_}')\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "    return predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632,
     "referenced_widgets": [
      "b0ef92e111da49b7975f2cfbc1b215db",
      "3cee2c70c2c54552b08173da2b43bbec",
      "1c1eb4aa3c9744c694a70a63f9d520e0",
      "555a8a1bb11b49559e4dd19a6afc56d8",
      "960a0b2f008d4ecf92971b45870bce31",
      "141de01b4881492382a9800600622cd9",
      "5798a95b255343d9a8fb8d2759346b18",
      "9a4bae3695754a0bad15cab7da5f7379"
     ]
    },
    "id": "Ke5RD-gjz5BU",
    "outputId": "9fbee34c-9b23-4e7e-bb86-173a99d269ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2em3kh8h) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 915<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ef92e111da49b7975f2cfbc1b215db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/content/wandb/run-20210522_195647-2em3kh8h/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/content/wandb/run-20210522_195647-2em3kh8h/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">floral-gorge-36</strong>: <a href=\"https://wandb.ai/spakt26/transformers_tutorials_summarization/runs/2em3kh8h\" target=\"_blank\">https://wandb.ai/spakt26/transformers_tutorials_summarization/runs/2em3kh8h</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2em3kh8h). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">quiet-sun-37</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/spakt26/transformers_tutorials_summarization\" target=\"_blank\">https://wandb.ai/spakt26/transformers_tutorials_summarization</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/spakt26/transformers_tutorials_summarization/runs/34gmiwbm\" target=\"_blank\">https://wandb.ai/spakt26/transformers_tutorials_summarization/runs/34gmiwbm</a><br/>\n",
       "                Run data is saved locally in <code>/content/wandb/run-20210522_195712-34gmiwbm</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  ...                                               text\n",
      "0   0  ...  The project manager opens the meeting by intro...\n",
      "1   1  ...  The project manager acquainted the team with t...\n",
      "2   2  ...  The project manager recapped the decisions mad...\n",
      "3   3  ...  The project manager opens the meeting by welco...\n",
      "4   4  ...  The Project Manager reviewed the decisions fro...\n",
      "\n",
      "[5 rows x 3 columns]\n",
      "Initiating Fine-Tuning for the model on our dataset\n",
      "Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe\n",
      "Completed 0\n",
      "Output Files generated for review\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    wandb.init(project=\"transformers_tutorials_summarization\")\n",
    "\n",
    "    config = wandb.config          \n",
    "    config.TRAIN_BATCH_SIZE = 2    \n",
    "    config.VALID_BATCH_SIZE = 2    \n",
    "    config.TRAIN_EPOCHS = 2        \n",
    "    config.VAL_EPOCHS = 1 \n",
    "    config.LEARNING_RATE = 1e-4    \n",
    "    config.SEED = 42               \n",
    "    config.MAX_LEN = 500\n",
    "    config.SUMMARY_LEN = 50 \n",
    "\n",
    "    torch.manual_seed(config.SEED) \n",
    "    np.random.seed(config.SEED) \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "    df_abstractive.ctext = 'summarize: ' + df_abstractive.ctext\n",
    "    print(df_abstractive.head())\n",
    "    train_size = 0.8\n",
    "    train_dataset=df_abstractive.sample(frac=train_size,random_state = config.SEED)\n",
    "    val_dataset=df_abstractive.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "    training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
    "    val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
    "\n",
    "    train_params = {\n",
    "        'batch_size': config.TRAIN_BATCH_SIZE,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 0\n",
    "        }\n",
    "\n",
    "    val_params = {\n",
    "        'batch_size': config.VALID_BATCH_SIZE,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 0\n",
    "        }\n",
    "\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
    "\n",
    "    wandb.watch(model, log=\"all\")\n",
    "\n",
    "    print('Initiating Fine-Tuning for the model on our dataset')\n",
    "\n",
    "    for epoch in range(config.TRAIN_EPOCHS):\n",
    "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "    print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
    "    for epoch in range(config.VAL_EPOCHS):\n",
    "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "        final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "        final_df.to_csv('predictions.csv')\n",
    "        print('Output Files generated for review')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1xpgrddDA4q"
   },
   "outputs": [],
   "source": [
    "predictions = pd.read_csv('/content/predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0R-Bqj5pAE8",
    "outputId": "9f356133-293f-42b0-815e-015eef0b293d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Generated Text', 'Actual Text'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BBfZ8LYd8xwM",
    "outputId": "8414679c-319e-43b6-f741-9929a0eadb2d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ctext</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>summarize: Okay okay Okay. Hello. Okay. My nam...</td>\n",
       "      <td>The project manager opens the meeting by intro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>summarize: Good morning. Sorry? Yeah, busy job...</td>\n",
       "      <td>The project manager acquainted the team with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>summarize: Alright, yeah. crack on. Okay so we...</td>\n",
       "      <td>The project manager recapped the decisions mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>summarize: Right w welcome to the the first me...</td>\n",
       "      <td>The project manager opens the meeting by welco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>summarize: Oops. Mm. After lunch. Yeah. Mm-hmm...</td>\n",
       "      <td>The Project Manager reviewed the decisions fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>summarize: Okay. Everybody ready? Welcome at t...</td>\n",
       "      <td>The project manager opened the meeting. The in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>summarize: Bless you. Yeah. Um, can I do next?...</td>\n",
       "      <td>The Project Manager reviewed the minutes from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>summarize: Is that alright? or Okay. Keeps com...</td>\n",
       "      <td>The project manager introduced the upcoming pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>summarize: Yep. Okay. Oh. Well we will try. Wh...</td>\n",
       "      <td>For the first meeting, the task of designing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>summarize: Okay. Right. Okay. Alright. Is ever...</td>\n",
       "      <td>The project manager reviewed the minutes of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>summarize: Hello. Yes, I made it. English from...</td>\n",
       "      <td>The marketing expert talked about trendwatchin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>summarize: Yes. Yeah, Martin. Mar Ah. Yeah, ho...</td>\n",
       "      <td>One team member presented her proposal regardi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>summarize: Hello. Yeah. Yep. Um I've got a Pow...</td>\n",
       "      <td>The project manager opened the meeting and sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>summarize: I'm proud of it. Uh-huh. How how mu...</td>\n",
       "      <td>The project manager opens this detailed design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>summarize: So I hope you're ready for this uh ...</td>\n",
       "      <td>The project manager opened the meeting and sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>summarize: Okay. Could could I see the scroll ...</td>\n",
       "      <td>The UI and ID presented a prototype drawing of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>summarize: Hello. Make a start yeah. So. Cable...</td>\n",
       "      <td>The User Interface Designer presented the majo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>summarize: Wow, good expression. Well after us...</td>\n",
       "      <td>The Industrial Designer gave her components co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>summarize: So is Why not save that. Do you wan...</td>\n",
       "      <td>The first prototype for the remote control was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>summarize: It's not saved yet. So Our beautifu...</td>\n",
       "      <td>The project manager presented the agenda and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>summarize: I keep forgetting whether I've done...</td>\n",
       "      <td>The project manager opened the meeting and wen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>summarize: Good afternoon. So Hello. No proble...</td>\n",
       "      <td>In the detailed design meeting the team create...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>summarize: Hello. Um, Project Manager, I have ...</td>\n",
       "      <td>The project manager went over the agenda. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>summarize: Good morning, Flores. Marketing Exp...</td>\n",
       "      <td>The project manager opened the meeting and int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>summarize: Why are you looking at me? Do I hav...</td>\n",
       "      <td>The project manager opens the meeting by going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>summarize: Just trying to move mine right now....</td>\n",
       "      <td>The Marketing Expert presented more informatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>summarize: No. We should make a big sponge lem...</td>\n",
       "      <td>The Marketing Expert presented the results of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>summarize: Morning. Yep. My name's Frank. Than...</td>\n",
       "      <td>The project manager introduced himself to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>summarize: Uh yeah. Fine now. Oh, it's not lik...</td>\n",
       "      <td>The project manager opened the meeting by stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>summarize: Yeah. Yeah, sure. It kinda does mak...</td>\n",
       "      <td>The project manager recapped the decisions mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>summarize: Hello. Hello. You have to put it ex...</td>\n",
       "      <td>The Project Manager introduced himself and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>summarize: Hello. So, are you d what were j yo...</td>\n",
       "      <td>For the conceptual design, the ID suggested to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>summarize: Mm-hmm. Yeah. I'm Robin. I'm the Ma...</td>\n",
       "      <td>The group introduced themselves and their role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>summarize: Well I'll uh start just with anothe...</td>\n",
       "      <td>There are some new requirements for the projec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>summarize: Hi. Mm-hmm. Interface designer. Yes...</td>\n",
       "      <td>The project manager opens the meeting by going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>summarize: Could have one for your stereo, one...</td>\n",
       "      <td>The project manager opens the meeting by stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>summarize: That's new one? Yep. Yep. Big micro...</td>\n",
       "      <td>The project manager opened the meeting and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>summarize: Okay. Here we go. Alright, the agen...</td>\n",
       "      <td>The project manager opens the meeting by stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>summarize: Okay. Okay. Next.. What do you mean...</td>\n",
       "      <td>The project manager opens the meeting and pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>summarize: Okay. So, now um, last time. Can yo...</td>\n",
       "      <td>The industrial designer and user interface des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>summarize: Play-Doh's edible. Did you know tha...</td>\n",
       "      <td>The interface specialist and industrial design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>summarize: So we come again for the the second...</td>\n",
       "      <td>The Project Manager presented the goals of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>summarize: Hold that. Okay. Okay. Mm. Mm-hmm. ...</td>\n",
       "      <td>The meeting begins with the group trying to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>summarize: Good morning. Well, I think we shou...</td>\n",
       "      <td>The Project Manager introduced the project to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>summarize: Mm-hmm. Uh, they have another group...</td>\n",
       "      <td>The project manager opened the meeting and des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>summarize: Okay? Good afternoon. Hope you have...</td>\n",
       "      <td>The project manager opens the meeting, stating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>summarize: Mm-hmm. Mm. A nice one. Yeah. Yeah....</td>\n",
       "      <td>The User Interface Designer presented three di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>summarize: Okay, welcome to the detailed desig...</td>\n",
       "      <td>The project manager opened the meeting. The us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>summarize: Yep. Uh-huh. Don't think so. Jess. ...</td>\n",
       "      <td>The project manager recapped the decisions mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>summarize: Mm-hmm. Maybe you should try to wri...</td>\n",
       "      <td>After introducing the remote control objective...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  ...                                               text\n",
       "0    0  ...  The project manager opens the meeting by intro...\n",
       "1    1  ...  The project manager acquainted the team with t...\n",
       "2    2  ...  The project manager recapped the decisions mad...\n",
       "3    3  ...  The project manager opens the meeting by welco...\n",
       "4    4  ...  The Project Manager reviewed the decisions fro...\n",
       "5    5  ...  The project manager opened the meeting. The in...\n",
       "6    6  ...  The Project Manager reviewed the minutes from ...\n",
       "7    7  ...  The project manager introduced the upcoming pr...\n",
       "8    8  ...  For the first meeting, the task of designing a...\n",
       "9    9  ...  The project manager reviewed the minutes of th...\n",
       "10  10  ...  The marketing expert talked about trendwatchin...\n",
       "11  11  ...  One team member presented her proposal regardi...\n",
       "12  12  ...  The project manager opened the meeting and sta...\n",
       "13  13  ...  The project manager opens this detailed design...\n",
       "14  14  ...  The project manager opened the meeting and sta...\n",
       "15  15  ...  The UI and ID presented a prototype drawing of...\n",
       "16  16  ...  The User Interface Designer presented the majo...\n",
       "17  17  ...  The Industrial Designer gave her components co...\n",
       "18  18  ...  The first prototype for the remote control was...\n",
       "19  19  ...  The project manager presented the agenda and t...\n",
       "20  20  ...  The project manager opened the meeting and wen...\n",
       "21  21  ...  In the detailed design meeting the team create...\n",
       "22  22  ...  The project manager went over the agenda. The ...\n",
       "23  23  ...  The project manager opened the meeting and int...\n",
       "24  24  ...  The project manager opens the meeting by going...\n",
       "25  25  ...  The Marketing Expert presented more informatio...\n",
       "26  26  ...  The Marketing Expert presented the results of ...\n",
       "27  27  ...  The project manager introduced himself to the ...\n",
       "28  28  ...  The project manager opened the meeting by stat...\n",
       "29  29  ...  The project manager recapped the decisions mad...\n",
       "30  30  ...  The Project Manager introduced himself and the...\n",
       "31  31  ...  For the conceptual design, the ID suggested to...\n",
       "32  32  ...  The group introduced themselves and their role...\n",
       "33  33  ...  There are some new requirements for the projec...\n",
       "34  34  ...  The project manager opens the meeting by going...\n",
       "35  35  ...  The project manager opens the meeting by stati...\n",
       "36  36  ...  The project manager opened the meeting and the...\n",
       "37  37  ...  The project manager opens the meeting by stati...\n",
       "38  38  ...  The project manager opens the meeting and pres...\n",
       "39  39  ...  The industrial designer and user interface des...\n",
       "40  40  ...  The interface specialist and industrial design...\n",
       "41  41  ...  The Project Manager presented the goals of the...\n",
       "42  42  ...  The meeting begins with the group trying to re...\n",
       "43  43  ...  The Project Manager introduced the project to ...\n",
       "44  44  ...  The project manager opened the meeting and des...\n",
       "45  45  ...  The project manager opens the meeting, stating...\n",
       "46  46  ...  The User Interface Designer presented three di...\n",
       "47  47  ...  The project manager opened the meeting. The us...\n",
       "48  48  ...  The project manager recapped the decisions mad...\n",
       "49  49  ...  After introducing the remote control objective...\n",
       "\n",
       "[50 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abstractive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yyx0f5479SSr"
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_abstractive.assign(column1=df_abstractive ['text'].str.lower()),\n",
    "                     predictions.assign(column1=predictions['Actual Text'].str.lower()),\n",
    "                     on='column1', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "HvNadjPF9tBZ",
    "outputId": "529b3494-0850-4eb5-c5be-775a23c3fda4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ctext</th>\n",
       "      <th>text</th>\n",
       "      <th>column1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Generated Text</th>\n",
       "      <th>Actual Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the project manager introduced the upcoming pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>'I have no idea what my favourite animal is. O...</td>\n",
       "      <td>The project manager introduced the upcoming pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the marketing expert talked about trendwatchin...</td>\n",
       "      <td>1</td>\n",
       "      <td>the presentation is about trendwatching and tr...</td>\n",
       "      <td>The marketing expert talked about trendwatchin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the project manager opened the meeting and sta...</td>\n",
       "      <td>2</td>\n",
       "      <td>a functional design meeting will be held to di...</td>\n",
       "      <td>The project manager opened the meeting and sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the first prototype for the remote control was...</td>\n",
       "      <td>3</td>\n",
       "      <td>the only thing that has really changed is the ...</td>\n",
       "      <td>The first prototype for the remote control was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the project manager opened the meeting and wen...</td>\n",
       "      <td>4</td>\n",
       "      <td>the prototype is a simple, clean design. It's ...</td>\n",
       "      <td>The project manager opened the meeting and wen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the project manager went over the agenda. the ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Project Manager, I have a little problem with ...</td>\n",
       "      <td>The project manager went over the agenda. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the project manager opened the meeting by stat...</td>\n",
       "      <td>6</td>\n",
       "      <td>the group is going to create a new remote cont...</td>\n",
       "      <td>The project manager opened the meeting by stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the project manager opens the meeting and pres...</td>\n",
       "      <td>7</td>\n",
       "      <td>the user can select a channel and then switch ...</td>\n",
       "      <td>The project manager opens the meeting and pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the meeting begins with the group trying to re...</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;extra_id_0&gt; We'll be recording what we write ...</td>\n",
       "      <td>The meeting begins with the group trying to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after introducing the remote control objective...</td>\n",
       "      <td>9</td>\n",
       "      <td>I'm the Industrial Designer. Chief, he is the ...</td>\n",
       "      <td>After introducing the remote control objective...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ...                                        Actual Text\n",
       "0 NaN  ...  The project manager introduced the upcoming pr...\n",
       "1 NaN  ...  The marketing expert talked about trendwatchin...\n",
       "2 NaN  ...  The project manager opened the meeting and sta...\n",
       "3 NaN  ...  The first prototype for the remote control was...\n",
       "4 NaN  ...  The project manager opened the meeting and wen...\n",
       "5 NaN  ...  The project manager went over the agenda. The ...\n",
       "6 NaN  ...  The project manager opened the meeting by stat...\n",
       "7 NaN  ...  The project manager opens the meeting and pres...\n",
       "8 NaN  ...  The meeting begins with the group trying to re...\n",
       "9 NaN  ...  After introducing the remote control objective...\n",
       "\n",
       "[10 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Ax1Mrjyo7hG",
    "outputId": "798e37fd-e239-4341-84bb-459b672c4dd2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores1f = []\n",
    "scores1p = []\n",
    "scores1r = []\n",
    "scores2f = []\n",
    "scores2p = []\n",
    "scores2r = []\n",
    "scoresllf = []\n",
    "scoresllp = []\n",
    "scoresllr = []\n",
    "bleu1 = []\n",
    "bleu2 = []\n",
    "bleu3 = []\n",
    "bleu_together = []\n",
    "for i in range(len(merged_df)):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(merged_df['Generated Text'][i], merged_df['column1'][i])\n",
    "    scores1f.append(scores[0]['rouge-1']['f'])\n",
    "    scores1p.append(scores[0]['rouge-1']['p'])\n",
    "    scores1r.append(scores[0]['rouge-1']['r'])\n",
    "    scores2f.append(scores[0]['rouge-2']['f'])\n",
    "    scores2p.append(scores[0]['rouge-2']['p'])\n",
    "    scores2r.append(scores[0]['rouge-2']['r'])\n",
    "    scoresllf.append(scores[0]['rouge-l']['f'])\n",
    "    scoresllp.append(scores[0]['rouge-l']['p'])\n",
    "    scoresllr.append(scores[0]['rouge-l']['r'])  \n",
    "    # bleu \n",
    "    reference = preprocess_text_simple(merged_df['column1'][i])\n",
    "    candidate = preprocess_text_simple(merged_df['Generated Text'][i])\n",
    "    score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_together.append(score_together)\n",
    "    bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu1.append(bleu_1)\n",
    "    bleu_2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    bleu2.append(bleu_2)\n",
    "    bleu_3 = sentence_bleu(reference, candidate, weights=(0, 0, 1, 0))\n",
    "    bleu3.append(bleu_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3A42Go--NTk",
    "outputId": "0febb053-bbe0-4653-e756-70cc5beb4b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu-1 : 0.002439024390243902, bleu: 0.03951882613244048\n"
     ]
    }
   ],
   "source": [
    "print('bleu-1 : {}, bleu: {}'.format(np.mean(np.array(bleu1)), np.mean(np.array(bleu_together))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaVt8OCH-Ngc",
    "outputId": "a3e8b11b-1497-4f61-c72f-b7560ea91b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 : r: 0.1875125551650351, p: 0.13913032521201818, f:0.29041155553569176\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-1 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores1f)), np.mean(np.array(scores1p)), np.mean(np.array(scores1r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63nv9JnC-Ntm",
    "outputId": "da144eb9-a822-4664-b9d3-bb570a477ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 : r: 0.010258759419941702, p: 0.007282964329023525, f:0.01740757304710793\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-2 : r: {}, p: {}, f:{}'.format(np.mean(np.array(scores2f)), np.mean(np.array(scores2p)), np.mean(np.array(scores2r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mCeLDXLD-N6W",
    "outputId": "bfdd9387-fbd1-4477-bb91-27b67f76a6ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-l : r: 0.15257445393796518, p: 0.11039666726405226, f:0.2508889497694052\n"
     ]
    }
   ],
   "source": [
    "print('Rouge-l : r: {}, p: {}, f:{}'.format(np.mean(np.array(scoresllf)), np.mean(np.array(scoresllp)), np.mean(np.array(scoresllr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkRXLfNLanV8"
   },
   "source": [
    "# Speech Recognition <a class=\"anchor\" id=\"ch15\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sW50a1X1FAr_"
   },
   "outputs": [],
   "source": [
    "speech_trans = open('ES2006d.transcript.txt', \"r\", errors = 'ignore')\n",
    "transcript_speech = speech_trans.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_idJJyz0xQY"
   },
   "source": [
    "## Обработка звука <a class=\"anchor\" id=\"ch16\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KVide0snQkcU",
    "outputId": "952dc35d-84c3-42e9-a4a2-d1f686aa09a4"
   },
   "outputs": [],
   "source": [
    " # !pip3 install timit-utils==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mio9ZLpxQmzv",
    "outputId": "73cacc16-1f74-46aa-ba94-7f4fc089a05b"
   },
   "outputs": [],
   "source": [
    "# !pip3 install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owWZJS4eQsrv"
   },
   "outputs": [],
   "source": [
    "import timit_utils as tu\n",
    "import os\n",
    "import IPython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5ltAxDp00HD"
   },
   "outputs": [],
   "source": [
    "data, sr = librosa.load('ES2006d.Array1-01.wav', 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "gOARsDr0QWo1",
    "outputId": "949b8a43-2d6b-4760-80b4-4202fb3edd26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8258268c90>]"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5wTdfoH8M+znV6XXpYmRUDABVQEaQqIit6hh3qKiof+xLtTT08UxbOd2FBPPREVxcKBXTwQj14UgaWDFFdYpLO0ZWkLyz6/PzLZnUxmkslkJjPJPu/Xa1+bTCaTbzLJPN/+JWaGEEIIEakktxMghBAiPkkAEUIIYYkEECGEEJZIABFCCGGJBBAhhBCWpLidgFiqXbs2Z2VluZ0MIYSIKytXrjzIzJna7eUqgGRlZSEnJ8ftZAghRFwhoh1626UKSwghhCUSQIQQQlgiAUQIIYQlEkCEEEJYIgFECCGEJRJAhBBCWCIBRAghhCUSQIQQYeXkHcbmfcfcTobwGFcDCBENJKItRJRLRKN1Hu9FRKuIqJiIhmoeO0dEa5S/6bFLtRDlz9AJSzHw1cVuJ0N4jGsj0YkoGcCbAC4HsAvACiKazsw/q3b7DcBtAB7UOcQpZu7keEKFEELocnMqk24Acpl5GwAQ0VQAQwCUBhBmzlMeK3EjgUIIIYy5WYXVEMBO1f1dyjazMogoh4h+IqJrjXYiopHKfjn5+flW0yqEEEIjnhvRmzJzNoCbALxKRC30dmLmicyczczZmZlBk0kKIYSwyM0AshtAY9X9Rso2U5h5t/J/G4AFADrbmTghhBChuRlAVgBoRUTNiCgNwDAApnpTEVENIkpXbtcG0AOqthMhhBDOcy2AMHMxgHsBfA9gE4BPmXkjET1FRNcAABF1JaJdAK4H8DYRbVSe3hZADhGtBTAfwDhN7y0hhBAOc3VBKWaeCWCmZttY1e0V8FVtaZ/3I4AOjidQCCGEoXhuRBdCCOEiCSBCCCEskQAihBDCEgkgQgghLJEAIoQQwhIJIELEgY9/2oE9R0+5nQwhAkgAEcLjjpw4g8e+3oBbJy13OylCBJAAIoTHnWMG4AskQniJBBAhhBCWSAARQghhiQQQIeIEu50AITQkgAjhceR2AoQwIAFECCGEJRJAXHD67DkUFZ9zOxlCCBEVCSAuaPP4LGQ/M8ftZIg4wyytIMJbJIC4pPB0sdtJEHGCSFpBhDdJABFCCGGJBBAhhBCWSAARIk5IC4jwGgkgcWpvwSl8smyH28kQMSAtIO7YsLsAhafPup0MT5MAEqdum7QCY77agIPHi9xOihAJh5lx1etLcNv7K6I+1ox1e1FwMjEDkasBhIgGEtEWIsolotE6j/ciolVEVExEQzWPDSeiX5S/4bFLtTccPumbmbWkRCo2hLCbv8f0qt+ORHWcnYdPYtSUVbj3P6tsSJX3uBZAiCgZwJsABgFoB+BGImqn2e03ALcBmKJ5bk0ATwDoDqAbgCeIqIbTafYSGRJQ/sg5jz/+AcOJuhiYmyWQbgBymXkbM58BMBXAEPUOzJzHzOsAlGieOwDAbGY+zMxHAMwGMDAWifYcqSBPeDIMJPYkVpvjZgBpCGCn6v4uZZutzyWikUSUQ0Q5+fn5lhIqhCifJHaHlvCN6Mw8kZmzmTk7MzPT7eTYSPJIQiSy5dsPI/dAodvJCMnNALIbQGPV/UbKNqefm1BI8kjlhsyFVb7c8PZS9B+/yO1khORmAFkBoBURNSOiNADDAEw3+dzvAVxBRDWUxvMrlG3lxsHjvl5Yo6YkZu8OUUYyCbFnV7D+19xcAEBRsbYZNzG4FkCYuRjAvfBd+DcB+JSZNxLRU0R0DQAQUVci2gXgegBvE9FG5bmHATwNXxBaAeApZVu5s3x7uXzbQsREtBNZTl+7BwBw8kxiLt+Q4uaLM/NMADM128aqbq+Ar3pK77mTAExyNIFCCOGyoyfPoHrFNLeToSvhG9GFEMJt0ZRjOj0127Z02E0CiEeUlDCOnDjjdjKEh0kTeuzY/Vkn6lgeCSAe8dbCX9H56dkJO2JVRCFBLj7b8o9jyz5vd0vVSpCP3jESQDxizqb9AIC9BaddTokQzuj78kIMeNXb3VKdk5ihSAKIEEJo+HvxJmrVk10kgAgRL6QRJGZY+bBlDE5oEkA8QgYZCyOSC45/iXoOJYB4TKJ+0YSIpfW7CvCP6Rtl+heHSQAREdtz9BRy8mQEvPCuG95eig9+zMOps9ZGgNsddxI1XygBpJwbNWUV/vjusoie0/vFBRg6YalDKbLfd+v3Imv0jLgfZyN56dg7c86eOawStWZBAogJBafOYvKPeQlZHJ6xbi+W5B6M6Dl2/ahi5b0l2wEAufnHXU6JNQl67REJwNW5sOLFo1+ux4z1e9GuQVV0zarpyGskXmhKLFv2FSKJgFZ1q7idFBGHErU3lwQQE46c9FV9nInBlMyJ+TXzhmgKkP4BcHnjBtuUGiHin1RhuajDE9/jytcWu50Myz5cmhcXjemJUv+ciFWowueV2VvxyJfr3E5GxCSAuKiwqBg/7z3mdjLCmrDwVyzaGrye/NhvNsZVY3q8inZNCq2cPO8vlZpoOEwl9Wtzf8F/lu+MUWrsIwFEhDXuu824ddJyR1/jp22H8NXqXY6+huTgfYZO8P5SqW6z+6uy/1iRvQf0CGkDEZ4wbOJPAIDrOuuuHxYVuxswdx4+icwq6chITbb1uGpFxeeQmpSEpKQEqX8TCUlKIKLcMJOpvO7fP+DLVcYlobPnStDzhfn4y39W25cwHa0fm4UHP1sbsI0BPDdzE7JGz3D0tROB1QGEIjISQERCOnryDHb711YxkYmfvnYPxny1Hqt/O4oHPl1ruN+5El8YWqDTJqS2+rcjmLFur+n06vly9W4Agcl/e9G2qI4phJ2kCkskpEvGzcPJM+dMd7uNuEQRpjhz3b9/BAAM7ijdfuNRuEZv4eNqCYSIBhLRFiLKJaLROo+nE9E05fFlRJSlbM8iolNEtEb5mxDrtNtOGnhtdfJMcBWGHR+xm12C1e/p2Omz7iWkHJCfozmuBRAiSgbwJoBBANoBuJGI2ml2GwHgCDO3BPAKgOdVj/3KzJ2Uv7tjkugYsLvLpnBmcKbbOVS2eUzraWkziNi5EsY/pm/E3oLyuwy1myWQbgBymXkbM58BMBXAEM0+QwBMVm5/DqAfxckVdvvBE57vNvr41xtKb5eU6Kd1UxyMU4nWT9sOmd7X36MrlqdW7xtvZwCbtWEv2jw+Cxv3FNh2zHhn5tNdtv0QPvgxDw995r0BgPmFRY53iwfcDSANAahHzuxStunuw8zFAAoA1FIea0ZEq4loIRH1dDqxkViRdxh9XlqAKct/M/2ctbv0f7zvLNqGQQ6NVv/opx1h93lh1mZHXjuWlm33jZY3mgTS34XYjPjIvkRm/mZfh4B1Bt9BYUCJMucMMl9u+tOHObh/2locOHba0deJ115YewE0YebOAB4AMIWIqurtSEQjiSiHiHLy80P3nInE87M2o83j3+k+tk2Z9XXtzqNRv86zMzdFVQooOHkWB48n5iCmDbsL8Nuhk6b3P6TzOVgtJcbyknH6rLNzsCViUIwlJ6ozo61S3K8EjmKHg5ubAWQ3gMaq+42Ubbr7EFEKgGoADjFzETMfAgBmXgngVwDn6b0IM09k5mxmzs7MzLQt8W8t+NXwhx1N9YaV33LflxYYPtb56f8h+5k5YY+Rs+OI7nbv5a3KXPX6EvR6cT5+2V+IWRvCd5nVu1BGOpWM/xCxzHV2eXp2TF7H4zWu3qN8GZz43LxYqtHjZgBZAaAVETUjojQAwwBM1+wzHcBw5fZQAPOYmYkoU2mEBxE1B9AKgGc6yPtPfaymcN528IThY2a/hze8rT+n1YIt9pXanHL5K4tw98erwu6ndz5KIszcb93vjTVF7Lxo+QOr2x0DvMRMyTRRp2iPhGsBRGnTuBfA9wA2AfiUmTcS0VNEdI2y23sAahFRLnxVVf6uvr0ArCOiNfA1rt/NzJ6bFtZK1UCsfsKrf9MvcYjQDp2wrzrw1/zjutVqsRf7jgGJxI2P7eOfduD8sbNc76jj6kBCZp4JYKZm21jV7dMArtd53hcAvnA8gRa5dU6Lis/h2KliZFZJD7uvf6BbIjp6Un/pWiJf+9SAVxdh9v2X4cjJM4afw96CU6hfrYKTyUS/lxeiUloyNj410LZjfpazEwu25uPNm7qYfo60gVjj5OcW7thjv9mAEvbVMCS7eP7itRHd0/xVAWa/YBt229P7ZdQnq9H12fDtHYlqwCuLMPLDHBw9aTzI7qvVu3H2HGP62j14/4c8w/1GfrjSgRQGO6Ez4NGs6Wv34Oc9gW04D32+TncKlWOnz+LZGT+HXBQtEQsga3YetdQgHdFn4cIH56+afuzr9bF/cRUJICZsy/e1MUTeo8FcBLnq9SURPkPfnE37o3h2sHgbXLZlfyH+9/N+JJmM3IUhRnOfOFOsu91L1Tx/+c9qXPkvc128X5m9Fe8s3o7PVwaPDSj9tLz05mxy0zvLMPabDSg4eRYHCu3t0ur/3PIOncCT324MGEuVd/AEjhfpf4fsZLSGSKxOpQQQE/YpXeK0uT0jbv8OT589Z8tUFyM/ik0u3O56XHX8mL/5gGp72QOHT5zB4RAlFa/X6mjHtCzamo9Pc4wXJDqr7F+s02ugrBE9dnIPHA84N34/7zmGN+b9YutrbdxzDN3+OQfdnp1buq2khA0Hz0bqQGER3v8hD5v3lS3S1fulBbj5HfPji5zidPWkBBAHlPbCsvHk+S+y32/chwKdC5+6amLQa4vR8R//i/g1Tp89h+/Wl1V/6K1C6AS7A+6uI2VTS2i76foHy33wY17IcTqxnPBg4KuLSvvtm7VQ0zvu1knL8ffPjUdEhxpB70Zvov7jF+L2D1YEbR/y5hK89L+ttr4WEVCkqbq7ZNw8XPBU5L+RwOMGfm7aXmxGg4NNHdvzWRgfCSAOUn8Fcg8U4uZ3f8KpMHXe6q+gOmf+ac5O7D92Gnd9tBL3TAkuGTyvGjG+Xadb71mDUdhq/5y5Cf/3ySos3x7bDm0lmqva2p1H0fflBUFVAL/mH0f2M3NCVj0B+u8f8J2PhVEGRXVKs0bPwCfLduDF7zdjzs/G1YfvLdmOrNEzDKsEN+8rxLQVES5nqvpymepyquz/xPSNhvu4XXIGgLPnYpOIfcdOo/C0cRWT+rPIGj3D1LgMJz8/o44hbgsbQIgog4hGEdG/iWiS/y8WifMa0/3klW9SserH8OS3P+OH3ENYnhf64rz9YNk4gxmq0sBvh0+iSBm4uENn9PV7S7YHbdt5uGy//MLw3UV3Kzn3Y6f0L9BZo2fYPrXJqCmrgi7qz8/ajG35J4JKCP1eXoiDx4vw5Lc/W3qtNRHMDGA2//fmvFy8Of9X3PlhjuFFZuKiXwEgZOP++NlbI5q5QJ0+Mxe3UO+ntArLCxFEoQ22B46dxsod1jI2lnLzmo9iz9HgCRO1n1f+8SLHBgAWni725OBCMyWQjwDUAzAAwEL4RowXhnxGOeevNpmmUyd90MSF3O83VQDYsq9Q9UM393z15Hh2ffXe1QlU0Zixbi9GTM4J2OZ/fze/u0z3OZv3hW6L+nbtHt3t6oAajv+zPl5UjPGzzVWptHh0Jv41N7D+vuDUWdPn65kZP+P+aWtMdV74Zk3Ze9Q7vLZ+X69Kzl8V6n/EyctTpA3Y/tLB9oMnMG/zfgx6bTF+/5b+YNdwQtVGRtNWeOeHgd/b299fgfGzt1g+XijLtx9Gi0dnxrx2IBwzAaQlMz8O4AQzTwYwGEB3Z5MVP44XFSNr9Aw8O6MsV3z4RHBx018v/7fPjFe7A4yL8HM2HcBEZTW63Tq5oXDM5C5NXUAMdtq875huo6jfvoLTpqrRzNiwO3QAWaqaXbdIdTG20qzR/onvg4JCKNpg882a3bptYnpVaSvyjuCr1bvxhWpJXaML3JLcg6W39U7tf9eHn9rls5U7lXQ5W9++49CJgAZsPcdOnw1Yqtf/fe3z0gLc8UEODun8pqzQth/eN3VN6e25m/bjkufmokCnBK73EelVgfknpoyW9vV++NV3vn9QnXcjuQcKSzv+OM1MAPF/mkeJqD1881HVcS5J8WWzUtp4Z3FZzlyvyGxUL68VqiHUzOy5aj9tK8ut/OHtn0wvsXouRLAxqsYb+OrigEbRNTuPImv0DOQdPIETRcW46Lm5GPOVuT7rdk6pMWFh2Qw3kVRlGO0bahyFEf/HqT7i8EnLTT2338sLwx9f5/M6froYOarqUjMxws4arBnr9pZOJ36Xpjef+iL+4dI8rPrtCFZq5mJjAF/odDkuKWEUR5gRUc8y3G/8goAS6r6CsgvtiMk52FNwGj/mHgz6TM0G2SQXWpVPnz2H/uMXovkjvgDcf/yi0scOFjrbdmLm7U4kohoAHodvbqqfAbzgaKo8Su8HtsyBIuW+gtMoKj4XdU+MD37MK729++gpjJqyCvdNXY2Bry7S3d/fwH/XRysDcoNqZi8yN0zwVTcMeHVRaZXMnE3GJRQrr2GG0RTu4WzZr19L+ydNtUU4ZHjHHDNtV2/Myw3a9uhX6zF0wlJ8rGQ69L5L2vEykX7sZ4pLUFSsX902asoq3D/NV9r+TVN12Pnpst5PY7/ZiN/pzAZQwqxbWh/50Uq0HFM2C/b8zQfwaQQdEA4eP4M/q5Yv1nvPn+bsDBrz5f9tjJqyyvC3AQCb9tpTu29Uy6CX3se/3oDcA8dRwsCwiYHVfFe/sUS3/cYuYacyYeZ3lZsLATR3LCVxJFwuNNoagYuem4uLmtcMKEHY5es1+u0DQGDVjxGzgyn9F+6i4hKcVj6vEmbsKziNc8xoWN3ZaUL0ODFZ4J6C0FUFvmVoI3vdMV9tCL+Tyus6AcRv0dZ8/PGiprqP+b+nVhvRLxk3DwePF5led95P7yuUkhT4ozFq//IPll24NR9HT57BX5UqqBu6Ntbd34r5W/Lx4dLA0v5901aHrToFfB0ajD7HkhJGUlLwxeHr1dpJyIGVeYElslVKCe3N+bl44PLAicc/U5XU9K4ZewtOo4FDvzczvbC66PzNJaJPiehiR1LlUf6V66atML9QFGC82l/o1/JWY5lZD+tUwfUYNw+ArxfSRc/NRY9x8/Dh0jzDY+iV6szkxL3oue824+BxXzWCG337i4pLkF9YhEk/BHd+8JdArKbLzDozZ8+VmDq6tgeaf/YHI8MnLS8NHoD1HmRGa+1o2720waPnC/MMj/nS//Qb0s+qBnEeOl7kax9jxn3T1gTtq83s5Ck9L8+VMF763pmGeivMTKa4EL6p19XfgwuZWXcBp0S2+BdfA5Z6UJLeF1dbArljcvCAqUQ1LWcnnh/aMex+Y7/ZqDsgUs/6XQW4+o0lAdsufd74B2yXBVvMVblpGWUYfvz1IIZ00i666ayFW/MN50ezq+18875jaFOv7HJw39SyKqJWY/QXXdOKZk4wwNc+eOvFWZafH8nCZACw87BxtdCb83/V3X7qzDmkpyQDAC5U1ujxX1PUTp4pLg0Yet6Yb1zi1Odc/zozbSC5zNyXmfv4/+BbwKncUscM9e1dR05izc6jATm6PUdPxcWaGtGwWjp42UT32NaPfafbNVI92tysSM/Dbe9bC/yvGfTa+uvUNZ5aHdL/LfUHkmdmbAo7OZ/eWISBry4ufez1ub+ErCY1EkkXaz1jv9kY1dQkvV6cH9Xrm6H3ndWbm+yOD1bgrQX2XWJt6vyoy0wAqUlENxPRlUTUQdnmvREtMTJv8/6AEdLbD5UVtS99fj6uffOHgP3X7Yp+WVuvs3MG4HHfBQ5ULCouwXybArB2OgunGAUQALh3SviFr2LF37NIPTD1459CV8/++T/66S8pYVzxykJTmQI9/zXZQzAUqx0mYuXkmXM4UVSMq143ngDznk9W2l59bfckq2pmqrCmA+gBoDKAZkRUH0BNx1LkcXd8ENgL58tVwQ1g6hHkHhw86mkTFiZ24Tb3gLnu3LHgL3nsO2a+NDdz/T7838cr8dYfLwzY3vzRmQbPiB1m3wzF0w0GkhoJ1avKTkarfqrNXL/P9teduGgbHr2yre3HBcz1wvqz+j4RNQWwgojmAXiKmRc4krIEoZ3nqTzw4pQLXnHweBEeDDOYNJbOFJcEVXFs2F2A9g2rGT7nuw32X+Ts0HbsLLeT4FlnikuQlmL/IJWwAYSIajFzaf9OZt4BGUho2rI47U0VDb1xCaKMXr23G8Z8tUG3y/BVry/Bk9ecj35t6+DS5/XbBuxaBE3ExtFTZ1CnSobtx6Vw3d+I6BcAawC8D+A79tKMaxHKzs7mnJzIBoIBsSviCiGEE27vkYUnrj7f8vOJaCUzZ2u3mynTnAdgIoBbAPxCRP8kovPCPEcIIYRHhFq+ORphAwj7zGbmGwH8CcBwAMuJaGF5G0gohBDxKtws1laYGYlei4j+SkQ5AB4E8GcAtQH8DcCUaF6ciAYS0RYiyiWi0TqPpxPRNOXxZUSUpXrsEWX7FiIaEE06hBAi0TnRw8tMN96l8K0Jci0zq1v/cohogtUXJqJkAG8CuBzALvh6dk1nZvVqQSMAHGHmlkQ0DMDzAP5ARO0ADANwPoAGAOYQ0XnMHN1wViGESFBV0s1c7iNjpg3kb8z8tCZ4AACY+fkoXrsbfKPctzHzGQBTAQzR7DMEwGTl9ucA+pFv9NMQAFOZuYiZtwPIVY4nhBBCR7LORI7RMhNAnrT9VX0aAlDPw7xL2aa7DzMXAygAUMvkcwEARDSSiHKIKCc/P7GnFBFCCCNOBBAzZZqKRNQZmtUMmNk7czKEwMwT4etFhuzs7LjtgiyEENFwZSAhfDn7lxEYQBhA3yhfezcA9ST+jZRtevvsIqIU+FZDPGTyuUIIIRTahb3sYCaA5DJztMFCzwoArYioGXwX/2EAbtLsMx2+bsNLAQwFMI+ZmYimA5hCROPha0RvBcDcGqFCCFEOVUxNtv2YZgLIkfC7RI6Zi4noXgDfA0gGMImZNxLRUwBymHk6gPcAfEREuQAOwxdkoOz3KXzL6xYDGCU9sIQQwtgV59ez/ZhmJlN0ovThP/ZMADM128aqbp8GcL3Bc58F8KxTaRNCiETRvHYltK5XxfbjmhlIuE7zt56IgtctFULx5T2XuJ0EYYNGNWK/br1wxkUtajlyXDPN8usAnAMwBsDVAK5S/gsTXr+xs9tJiLkuTWq4nQRPe+Mmb3wn0kP0yrn+wkZY8nBf9G9bB2Ovahf0eN64wU4mTdisakaqI8c1MxfWH+GbSHEEgGcAJClTugsDLTIrld6u7MDoTxHfrurYwO0kAAB6tsrU3f787zvgmevaAwDeHd4Vd1zaLODx5qrvt4gPLRw6Z2aqsGoC2APgDgCfAviMiN5wJDVx4rLz9H94fh1Ui/Fw+V391xa5zw5yOwm2urCpd0pnl7erg4uaBy8u+oeuTZCeYtxj5/nfd3QyWVGpWSnN7SR40tALGzlyXDNVWCsB5Ch//4JvJPiVjqQmDqx94gr0a2u8nlaDaoGLtsTv6inekJKchFZ1KrudjIhQiAG/XlpOhxmYOvJi/L5L2cXlveFBSz4EuOy8THTN8uaK1nnjBmPV45e7nYyQruusO2GG4yjUlzIKZqqwmjFzc+Wvmf++I6mJA9UqpAYEhRTV9ABf/N/F+PGRfo6drPLgkzu7B21r16CqCymx7oJG1Q0f8074CE7Li0M7ol/buiGf826YAGNVZpV0246l9x0K5c2buoTdp27V6NP31s1dPF16s8JMFdYDen+xSJxXqXOR9/Rpibxxg5E3bjAubBqcM/NQhtMx25+zViCtpVPd0KNl7aBtT1x9Pm7Ijr4I7lQxXuvVP3QyfOzpIe1jkgYzrHw3U5ODLxl54wYjNTm6TNOA80MHrkjofYdCGdyxflBHgfE3XBBwP8OGQXgNqldAWkoS5jzQy3CfOQ9choUP9UZGqn3TjnRsZLy+fbTMpPIhAFV0/sot9e9Ob4pk9U+pYloyumZFVu/94tD4yqWoS1yf3e1bY+yL/wvflXfxw31MHb9mpTT887oOAdt+HB358KTqFSLrifLfP18a8WsAQFbtwAbLhtV93WFn3dcT7Rs692OOVImNuZsfRvfFnAd6YcIfu+B/9xtfIL3qouaB3Vw7a3oS1qsa/XrildJ9QahlnbLLpzZQtKxTGU1rVcL9/Y0XfX1scNuIXtdMCcsqMwFkLzM/qf1zLEVxQP27C5fzurhFLXxy50URHf/67MaYdV9PK0lzXLhGSn/9+IVNa2De3y5D79aZSNPJtVZMSwZB/7Pr2So4B5miOUaD6pGPUYi0ZtGui72/xGq2R95rw4xLMHays3Bcp0oGWtapgoHt6+O8us7lL6+5QL8H2+09sqI6bhvNILs6miq1G7J9U+91alwdd/QI7JVmVqMaFYO2PTJIPxhcHGLcxp09zbcgzL6/FxrXDH5du5gJIM2J6GsimkpE44no946lJk6of3jXdQldLUJElmbBbFOvKqpFmGM2q3fr0L3I7NI8szI+uL0btj47CC8O7YifHumHX54dhDVjL8fyMf0NL+hOVfvZ0TZ1SYQDshpWr1D6fTH7+na2oV3ZwXj6Cm2DfqxqW7UX65u7h+71pfYvzbgqf+luWNcmltJyvtK+lqRqy0xLSUKKJmPonwqdmfH3ga1D1hK8f1tX3e161X+3XtwUyx7tF7Q9khJP+4bGbYRON8eaubINga/31UcANgG4k4heczRVHtelSVkjabR1v6FE29slxWD+fzfGIVyf3Rj1qmUgNTkJ1SumhcyNh+v6XL+ateoEO35Mt12SFdH+w7qWTRpt9uW1PfmsaKn0XKtTJQM/jO6r233YHz+cvsiEaiDPGzcYz17XIeiCbVaFNF/gCfcefqfq/eSvZgWAQe2DA+zWZwYFlY79x2f42kOuz24c9Dy/Pm30e2nqrcdBRKirFyw0u/ozAnrteP7z2EG3xOzsyTXTC2shM89j5hnM/A58I9Eja6VKEDd39+VytPWjTrkgysavJ645X+HFRDQAABfvSURBVHd7NF+p7s3s68Jp9KNPCnM1qGOxPvpscfR57HRNY2pWrdDVAyMvax5xicpM1Vm483ClcmFkZjSsXgF/0qn2iLYN5I4ezcJ2S13+aL+gEe/+EtZXEUx5Uymt7HN/8Iqy9gF/ZiIjTAnmeVWJoWtWTVzbyZeJMlsV2qZeVVzQuDr+ofpN3djNWqnHDG0A87ebNAyRXm07YSxEXLfCzOeY+WYnEuN1Vc1WKdkU9NXX0V7nZWLEpebqXv31t+oMj7pnkNH1Wa+tQm3OA73wSogeRpEyChQvhOlEUCGCHirqC8/hE0Wmn2dEm2IGsOThPlj0UB88NKB10EUxPSW59LzVqGhukJv6YzHT+6xKRnBpTttWNbB9vaDSU7RVhWOvbhf2+1CnagYGaGaB/ffNXXBT9yboGKK7s9ZPj/bDggd7AwDu7duqdPvrN3bGa8M6oUmYQK6tPvIHMfVn8NCA1pg2Ur+9Mj0lCd+M6hEwTc+lqt5eH97h7IraHZVMhT9zUVH1vX79xs64qXsT3e7urldhEVExER1T/RUS0TFnk+VNtSsHF8Ur6HTv848DaKJqvPL36Pkhgt5D6rrwRVvzdS8Ufuoc6VKlrUGtbf2qaFi9AlpkVjLMxfyha2M8emWbgCK+Wss6VWzpzuhn9N2uX00/ff4cX5/WxgM5AaBxzbLnq6sNIik5+p8XbhAjs69xtEmtihjVp6Xua/ypV3PkjRtcWt2iFaq++4WhFxg+5heqx46a9gJj59gLrWWP9ivtKaetumlWuxL+eV2HkEuszvvbZVj89z6lsz5UyUgN6t0GANUrpmFIp9CloLb1fe97cMf6pdtuUmoTuqtG4o/q0xLdm+u3celdiNUX8VC/TSu0r9e/XV0sebgPLm/n6+6sDnzNMyuXfp7anoNOj0gzk5Vbz8xVVX9VmDm+RnZFyX/S9Oqm9Ro8/V+sbFX33fYNqyFv3OCQRVAt7fw1d1/WwnBf9cUpOYmQmpyEulXK0lutQip+GN0Xc//W2/BHcmfPZhjZqwW6ZtXEz08NMJ1Oq/wlELMjzf2fa7i1nf+iyqEOU1UzNK5ZwXSXan8pbvSgNgHbtZl2O6aq0R7DqHeaEe1cVSFeKPB1HLy61K2aUVo9dFev5qW/ISPa91yvWgYa16yISbd1xeanB9qSpjdv6lI6CWTXrJrIGzdYt2dUpC5sWgPnN6iGnq1q49t7zXX9/v6+XnjlD8aZA71TYyat2upPpwc1mwkg5WAoXGhW16KP9EKgNbB9/YD7GanJuuNOAP3qiEgHVDWtVRawKqaloGmYaoFoJSURPr/7Ynw4Irj4P/6GCzBFM6LYbJ29+kejrn9nNt+V1l+y7Ne2bsiZZ61WA6l73lzXObCaysxvvnlm6KB7mVJKu1bVRmHnuI9I1KqcjnduDT2C3ajbanISRV3qteMSGuq3XDk9BWkpSfhoRHd0MNlu2bpelaDzHvB6UVz41Zk/L5RAKhJRZyLqov5zOF2e5OYMJf7668sMuuDqXRqMqkzM+vxu59f1yM6qqdtd+XddGuESTQD0X//CNbKrqfdkBv4+sE1p1007WL0mq3vePDSgteH4BiN9wnTFbla7EvLGDQ6oUvNyTjDVai7NTQ4mOdyhQ9VGVExLCag+d5KZALIPwHgAL6v+XnIyUV4T6UUimh+qdgCTnz8n/fINF2DRQ8EjuMNN01GjUuRjSpysI1cz+/n6xy2Eu9YEPKwKNgxfffiMv4QfpBmumsxOyUmEv/RrWXrfzCtrc6grxvQP+5xrOzXE77qEaC9wMcJUq+jMmCertNWKlUO0cRh9bD1aWl/EKVwe6a/9W4V83J9+pzO9Zpa07e1sEuJJZGfDyskz/A0rx0pPSdbtcXLNBQ3QpGZFzN98QPfpZgdqucHsdevKDvUxeemOiKvmSl8ngpyAUZWL+hi9W2fi3j4tdfeLlL+94PUbO1uqvtCbV0yrQloyxt/QCV+u2h2w3Qt5//MbVMPkO7qh4NRZTFz0a9huuV+P6oHfDp80dWw7LqJ6MzCEOuzyMf1QNSMVbR6fFf2LW1A6xsfhsxs2gBDRWL3tzPyU/cnxplhmzK7UGdgUjr+RsVPj6ujU2HzXSDulpSThTHGJpeeavbB3b17L1Ep46gtGQBVWBGnS6/GjPcYHt9vXdbNiWkrpeztXEvk3Tv2eYzUVit38Pa7MVOe5+V3X0vv+1qkS3WBQsxd+vWl/fGlSjuN2CQTAaABrAEwHcNbZ5Hib6ZMR4e//iavb4clvfwYANDRYhzrUF8rOrrVW/fBwXxScsvb1sDNA16+WgWzVrMjqc6b+nVdOT8HxomIbX9k+pqqwtPdVbzRct9byRt19106O9nAycegfRvc1VfJ0kpkA0gDAzfCtg74ZwCRmXhfNiyqrHE4DkAUgD8ANzHxEZ7/hAB5T7j7DzJOV7QsA1AdwSnnsCmbWr7uxgdWGUrNfr9t7NCsNIIbHsvhdfeOmzrrd/5IIsJDRNZRZJT1mbSZa3957KbYfOoHerTORmpSEE2fKAgMZlEFWPt4fu4+cwh0frEDeIXNVIQBQKc35JYq15/qD27vitvdXmHpuyDaOcmjOA73QIkyPNS8y83uPZEiAU8xMZXKUmd8EcCOAigDeteF1RwOYy8ytAMxV7gdQgswTALoD6AbgCSJSd+K/mZk7KX+OBQ8fpUFKtaVilD2cDF/J4KJ+y0VNLR3vqo4NdIv66/8xIKBv/gOXmxuM5gSrAXpIpwZ44PLz0KFRNVxzQQNUzUgN2fNM/TrpKclonlkZs+6LbOpxJ9dWiITeBWbDkwPwoomBh+VJxbSUuFzgLdoU+6vVvDAS/Qoi+hjARADfAehhw+sOATBZuT0ZwLU6+wwAMJuZDyulk9kA7BlRZJH6izjngcuCxinYoY7BymdWpi8PpVJ6SkBDsVFjsN0jbO302rDO+Eu/4N4o6m7B6m7PenHKaMLJcLTzO9nJ6gWvcnpKTHuPJTJ1ZsOoTcnJTzraoOcfQ2Z6+iWLzPwKZgFoAyADwB0AviCib6J83brMvFe5vQ+A3jDVhgB2qu7vUrb5vU9Ea4jocQrxaRPRSCLKIaKc/Px8S4nVyyE3qF4haJyCX1dlWpFrLax/XDk98ISP+10Hw4YyOxkVAqyufRAJuy/G6nmPwjW0piQnYeszg0Lu40V1qmTghaEdbZ2DyY5R9YkoXJuSF1cdHTO4LVY9fjmqZjgbQMxkL/ui7PpCAHoCGBbuSUQ0B4Bel6Ix6jvMzEQU6Sm4mZl3E1EVAF8AuAXAh3o7MvNE+EpPyM7OjupUm80T+Adx2WFYtyYB03E4xVfkDX6Hf+3XCq/N/cXR145VJwCjH3ok67X4sypZtfR7afmN6tMCK3cENesFMTPaXy8X2aFRNdOjnsOJwxoeT3C5DT2k5CQKu/ibHcyMA1lARJ0B3ATgegDbAUww8TzDkU1EtJ+I6jPzXiKqD0CvDWM3gN6q+40ALFCOvVv5X0hEU+BrI9ENIHaIRQajf9s6mLPJ4aYcC5ISqErEjhx2ekoy3hueHXYm2YcGtAn5OADkPNZfdzJOLf9kizUqpuLIyXLdETJi8Roc4yXdhlkvIjqPiJ4gos0AXgfwGwBi5j7M/HqUrzsdwHDl9nAAelVi3wO4gohqKI3nVwD4nohSiKi2ksZU+NYn2RBlekxx8qS6XQyOx4bGSNn1GfdrW9eWHme1K6ejksm5uQBvdNeOF3UN2hKd4ETVX0qSc21sdgr17d0MYDGAq5g5FwCI6H6bXnccgE+JaASAHQBuUI6fDeBuZr6TmQ8T0dMA/P0Xn1K2VYIvkKQCSAYwB8A7NqVLVyQjmKPl1mW8PDS+erCqWjjMyZHYdh57+Zh+AQNxrSyD7YZQAeR38LV1zCeiWQCmwqbrGzMfAhC0EDAz5wC4U3V/EoBJmn1OALjQjnREqhxk0hOaF/rNi9iINs8XyfPtyF9GO3LdLYZhjpm/ZuZh8PXAmg/gPgB1iOgtIroiVgn0Asm5xrfP7r4Y3ZrV9MzUFyJ2HG3olgylqYGEJ5h5CjNfDV9D9moADzueMg9yemIyQIKVE7pm1cSnd11suppOvea21xitByPsFUm7htvtl26K6NuoDOgr7RZbXsTiCyK5GXe1qVcFm/cV2tb92gnMwMy/9sTaXUdtPe7wS7Iwfe0e9A6zVHA8ifYna+Y3Lz/ZCANIeVX6XUrgXljl3Vf39AiYQ8tL1JmLxjUrorHNiwWd36AaNj8df4MpzZCLvLPio6nfI2LxZYyHL/zA8yOfct7rKqQlo3ZldyaDjLWPR3RH7crpuNTiuirxoFcr3xQ2GRbnrDOTn+vStAYual4TY69uZ+k1EoGUQEyIZTdeL7qndwtcoGqAfuuPXcAMNH90poupir1Ydq2sXy0Dd/Zs7sixL21VGzmPhV/BMJ4997sOuK9/K0en8shITcbUkRc7dvx4IAEkAuVhsJ2evw8MHFVNROWuzca/aFesLH0kqJe7iEBaSpLtVX0imAQQEZXeqtluE5mMAi9f7K51qJygvecS8105xMlMdzxWkm19ZpBtI9gn3nKh6TWuhYg3iVpglwBiQiybQOKpasjONoErbG6YH9WnBZLi6cMUIg5JAIlAIl6PmtSsiMMnzridDNuZmQ033sh6HbEjn7Q5EkBMGNGzGZbkHkS7+lXdTortFjzY2+0kiDBiMQOC0Gdb20WCnkIJICb0aV3H0yOUo5FI630IYTe7fh2J+iuTgYQeU86HnAjhCfI7NEcCiBBCGLGp6JCoY8ikCstjEvR7JgSWP9oPxSXxkbX3/w4rpcklMhT5dFz0yZ3dUdHiXD1CxJs6VeNn0aSqGal4ZFAbDLCpe3miZgwlgLioRwJPZidEvLvrshZuJ8HzpA1EiDghDbvxK0ELIBJAhPC6RK3+KE8StRHdlQBCRDWJaDYR/aL8r2Gw3ywiOkpE/9Vsb0ZEy4gol4imEVFabFLunPI+ZbwQIv64VQIZDWAuM7cCMFe5r+dFALfobH8ewCvM3BLAEQAjHEmlCxI0oyKESEBuBZAhACYrtycDuFZvJ2aeC6BQvY18ZcG+AD4P93whhPACK/nC5WO8vyaMWwGkLjPvVW7vA1A3gufWAnCUmf0LWO8C0NDOxAkhhNvqVPF+t2fHuvES0RwAep2ox6jvMDMTkWMNAEQ0EsBIAGjSpIlTLxNzdaqk40BhkdvJEEKE8PeBrfHCrC249eIsS8+/q1dzT3fhciyAMLPhostEtJ+I6jPzXiKqD+BABIc+BKA6EaUopZBGAHaHSMdEABMBIDs7O2Faqvu0roNpOTvdToYQIoR7erfEiEubIS3ZWmXPI1e2tTlF9nKrCms6gOHK7eEAvjH7RPZ1V5oPYKiV53vV365ojaxaFZGdVdPU/s9c197hFAmvSZjcTzmTnpIs3XhtNg7A5UT0C4D+yn0QUTYRvevfiYgWA/gMQD8i2kVEA5SHHgbwABHlwtcm8l5MU++A9g2rYcFDfVA1I9XU/qkWczQi/iTmpUckAlemMmHmQwCCuhgwcw6AO1X3exo8fxuAbo4lUAghRFgyF1Yce294NurG0QR1QojEIgEkjvVrG0nvZyGEsJdUpAshhLBEAogQQghLJIAIIYSwRAKIEHFCJmwWXiMBRAivk4EgwqMkgAghhLBEAogQQghLJIAIIYSwRAKIEEIISySACCGEsESmMhFChLX0kb6W17QQiUsCiBBxw72BIPWrVXDttYV3SZZCCI8jGQgiPEoCiBBCCEskgAghhLBEAogQQghLJIAIIYSwRAKIEEIISySACCGEsMSVAEJENYloNhH9ovyvYbDfLCI6SkT/1Wz/gIi2E9Ea5a9TbFIuROxlpPp+pl2zarqcEiECuVUCGQ1gLjO3AjBXua/nRQC3GDz2EDN3Uv7WOJFIIbygSkYqZt3XE6/8QfJJwlvcCiBDAExWbk8GcK3eTsw8F0BhrBIlhFe1qVcVGanJbidDiABuBZC6zLxXub0PQF0Lx3iWiNYR0StElG60ExGNJKIcIsrJz8+3lFghhBDBHAsgRDSHiDbo/A1R78fMjMgn+XkEQBsAXQHUBPCw0Y7MPJGZs5k5OzMzM9K3IYQQwoBjkykyc3+jx4hoPxHVZ+a9RFQfwIEIj+0vvRQR0fsAHowiqUIIISxwqwprOoDhyu3hAL6J5MlK0AEREXztJxtsTZ0QQoiw3Aog4wBcTkS/AOiv3AcRZRPRu/6diGgxgM8A9COiXUQ0QHnoEyJaD2A9gNoAnolp6oUQQrizHggzHwLQT2d7DoA7Vfd7Gjy/r3OpE0IIYYaMRBdCCGGJBBAhhBCWSAARQghhiQQQIYQQlkgAEUIIYYkEECGEEJZIABFCCGGJBBAhhBCWSAARQghhiQQQIYQQlkgAEUIIYYkrc2GVdxP+eCFSk8ntZAghRFQkgLhgYPt6bidBCCGiJlVYQgghLJEAIoQQwhIJIEIIISyRACKEEMISCSBCCCEskQAihBDCEgkgQgghLJEAIoQQwhJiZrfTEDNElA9gh8Wn1wZw0MbkeIm8t/iTqO8LkPfmRU2ZOVO7sVwFkGgQUQ4zZ7udDifIe4s/ifq+AHlv8USqsIQQQlgiAUQIIYQlEkDMm+h2Ahwk7y3+JOr7AuS9xQ1pAxFCCGGJlECEEEJYIgFECCGEJRJANIhoIBFtIaJcIhqt83g6EU1THl9GRFmxT2XkTLyv24gon4jWKH93upFOK4hoEhEdIKINBo8TEf1Lee/riKhLrNNohYn31ZuIClTnbGys02gVETUmovlE9DMRbSSiv+rsE6/nzcx7i9tzF4CZ5U/5A5AM4FcAzQGkAVgLoJ1mn3sATFBuDwMwze102/S+bgPwhttptfj+egHoAmCDweNXAvgOAAG4CMAyt9Ns0/vqDeC/bqfT4nurD6CLcrsKgK0638l4PW9m3lvcnjv1n5RAAnUDkMvM25j5DICpAIZo9hkCYLJy+3MA/YjI6wucm3lfcYuZFwE4HGKXIQA+ZJ+fAFQnovqxSZ11Jt5X3GLmvcy8SrldCGATgIaa3eL1vJl5bwlBAkighgB2qu7vQvCJL92HmYsBFACoFZPUWWfmfQHA75Wqgs+JqHFskhYTZt9/PLqYiNYS0XdEdL7bibFCqQbuDGCZ5qG4P28h3huQAOdOAojw+xZAFjN3BDAbZaUs4V2r4Juj6AIArwP42uX0RIyIKgP4AsB9zHzM7fTYKcx7i/tzB0gA0doNQJ3zbqRs092HiFIAVANwKCapsy7s+2LmQ8xcpNx9F8CFMUpbLJg5r3GHmY8x83Hl9kwAqURU2+VkmUZEqfBdYD9h5i91donb8xbuvcX7ufOTABJoBYBWRNSMiNLgaySfrtlnOoDhyu2hAOax0irmYWHfl6Zu+Rr46m0TxXQAtyq9ei4CUMDMe91OVLSIqJ6//Y2IusH3e/Z6ZgaAr4cVgPcAbGLm8Qa7xeV5M/Pe4vncqaW4nQAvYeZiIroXwPfw9VyaxMwbiegpADnMPB2+L8ZHRJQLXwPnMPdSbI7J9/UXIroGQDF87+s21xIcISL6D3y9WmoT0S4ATwBIBQBmngBgJnw9enIBnARwuzspjYyJ9zUUwP8RUTGAUwCGxUFmxq8HgFsArCeiNcq2RwE0AeL7vMHce4vnc1dKpjIRQghhiVRhCSGEsEQCiBBCCEskgAghhLBEAogQQghLJIAIIUSCCjchp2bfV1STO24loqNhnyO9sIRwFxFVB3ATM//b7bSIxEJEvQAch29OsfYRPO/PADoz8x2h9pMSiBDuqw7fLM9C2EpvQk4iakFEs4hoJREtJqI2Ok+9EcB/wh1fAogQ7hsHoIVSdfCi24kRCW8igD8z84UAHgQQUPIloqYAmgGYF+5AMhJdCPeNBtCemTu5nRCR2JQJHi8B8JlqFYp0zW7DAHzOzOfCHU8CiBBClB9JAI6GyawMAzDK7MGEEEKUA8q08tuJ6HqgdNngC/yPK+0hNQAsNXM8CSBCuK8QvqVPhbCVMiHnUgCtiWgXEY0AcDOAEUS0FsBGBK5OOgzAVLMTO0o3XiE8gIimAOgI4Dtmfsjt9AhhhgQQIYQQlkgVlhBCCEskgAghhLBEAogQQghLJIAIIYSwRAKIEEIISySACCGEsEQCiBBCCEv+H9KrBKAhFf84AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylabel('Амплитуда')\n",
    "plt.xlabel('t')\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xsit0zc9mgsa"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def entropy(labels):\n",
    "  entropies = []\n",
    "  final = []\n",
    "  vc = pd.Series(labels).value_counts(normalize=True, sort=False)\n",
    "  for i in vc:\n",
    "    entropies.append(i * np.log(i)/np.log(2))\n",
    "  threshold = (max(entropy(data)) - min(entropy(data))) * 0.5\n",
    "  for i in entropies: \n",
    "    if i < threshold:\n",
    "      final.append(i)\n",
    "  return final\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FL500QkGrpk9",
    "outputId": "40860a75-0c27-4932-8d87-9d931d641afc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00119019, -0.0022583 , -0.00219727, ...,  0.00418091,\n",
       "        0.00311279,  0.00125122], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3w0DHBPrtsj",
    "outputId": "37e450e4-ea22-438d-f1b2-19326a7c4845"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31479126,)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tzuQHphr65G"
   },
   "outputs": [],
   "source": [
    "# !apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFKvZ46Mrw4Z"
   },
   "outputs": [],
   "source": [
    "# hop length==number audio of frames between STFT columns. If unspecified, defaults win_length / 4.\n",
    "\n",
    "def slice_into_frames(amplitudes, window_length, hop_length):\n",
    "    return librosa.core.spectrum.util.frame(\n",
    "        np.pad(amplitudes, int(window_length // 2), mode='reflect'),\n",
    "        frame_length=window_length, hop_length=hop_length)\n",
    "    # выход: [window_length, num_windows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzyQznnhrxEs"
   },
   "outputs": [],
   "source": [
    "def get_STFT(amplitudes, window_length, hop_length):\n",
    "    \"\"\" Compute short-time Fourier Transform \"\"\"\n",
    "    # разбиваем амплитуды на пересекающиеся фреймы [window_length, num_frames]\n",
    "    frames = slice_into_frames(amplitudes, window_length, hop_length)\n",
    "\n",
    "    # получаем веса для Фурье, float[window_length]\n",
    "    fft_weights = librosa.core.spectrum.get_window('hann', window_length, fftbins=True)\n",
    "    \n",
    "    # применяем преобразование Фурье\n",
    "    stft = np.fft.rfft(frames * fft_weights[:, None], axis=0)\n",
    "    return stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LBDsQmIQrxQR"
   },
   "outputs": [],
   "source": [
    "# fmin == lowest frequency\n",
    "def get_melspectrogram(amplitudes, sample_rate=22050, n_mels=128,\n",
    "                       window_length=2048, hop_length=512, fmin=1, fmax=10002):\n",
    "\n",
    "   # оконное преобразование фурье \n",
    "    stft = get_STFT(amplitudes, window_length, hop_length)\n",
    "    # возводим в квадрат mel частоты и лоагрифмируем \n",
    "    spectrogram = np.log(stft ** 2)\n",
    "    # получаем из них спектральные коэффициенты с помощью косинусного дискретного преобразования \n",
    "    mel_basis = librosa.filters.mel(sample_rate, n_fft=window_length,\n",
    "                                    n_mels=n_mels, fmin=fmin, fmax=fmax)\n",
    "    \n",
    "    mel_spectrogram = np.dot(mel_basis, spectrogram)\n",
    "    return mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZRWxMQIMtfMR",
    "outputId": "a8a5057d-5e8d-44e2-c87c-8f9741d30d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41184431 points, 1867.774648526077 sec, sr 22050\n"
     ]
    }
   ],
   "source": [
    "amplitudes, sample_rate = librosa.load('ES2006d.Array1-01.wav')\n",
    "print(f\"{len(amplitudes)} points, {len(amplitudes) / sample_rate} sec, sr {sample_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "benVujlmM3vO"
   },
   "outputs": [],
   "source": [
    "# проверим на готовом методе получения спектограммы из библиотеке librosa\n",
    "spect_library = librosa.feature.melspectrogram(amplitudes, sr=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "1xq543nitOQd",
    "outputId": "b2434392-d07d-44dd-e91c-15c39d1d8a2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f824ea1e5d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD4AAAJCCAYAAACYvnTXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMMklEQVR4nO2cb2hd9RnHP981trXq2kS3kqmsyRBHBdEauogiQ2etndi9kNG+aaeOgm4wtxejpTAQ9kbdCyfKWhkdOrZadW4WQbrqhI3BWqP2T9o1bdqKtlSrDltQsFafvThP4klM0pPc3twkz/OBy/2d5/zOufeTe+5z7w38vjIzIvKVRj+BRpHi0UjxaKR4o5G0WFKPpF5Jq+v+eBPhc1zSNGA/cDNwBHgVWG5me+v1mBPlFV8I9JrZITM7BTwFLK3nA04U8YuBt0vbR7w2AEmrJHVJ6mpSU02X6kQRr4SZPW5mHWbWUesbdKKIHwUuLW1f4rW6MVHEXwUuk9QmaTqwDNhczwdsqufJq2JmpyX9FNgCTAM2mNmeej7mhPg4GwvT1GSf2WmN9fiJcqmPOykejRSPRopHI8WjkeLRSPFopHg0UjwaKR6NFI9GikcjxaOR4tFI8WikeDRSPBopHo0Uj0aKRyPFo5Hi0UjxaKR4NFI8GikejRSPRopHI8WjkeLROKO4pA2SjkvqLtVaJG2VdMDvm70uSY94zsMuSQtKx6z0+QckrSzVr5G02495RNKY14uOCjMb8QbcACwAuku1B4HVPl4NPODjJcCLgIBOYJvXW4BDft/s42bft93nyo+99UzPycz4CtOsyrxhvSpNgnmDxHuAVh+3Aj0+Xk8RajFgHrAcWF+qr/daK7CvVB8wr57iY10/PtfMjvn4HWCuj4fLehipfmSI+pBIWgWsAlCN7anm5mbFSzUui9DLGRGitlYwVvF3JbUC+P1xrw+X9TBS/ZIh6nVnrOKbgb7OvBJ4vlRf4d29Ezjhb4ktwCJJzf4JsAjY4vtOSur0br6idK76UqGxbQSOAZ9SvAfvBi4EXgYOAC8BLT5XwGPAQWA30FE6z11Ar9/uLNU7gG4/5lE8vqHezS0zIqKR4tFI8WikeDRSPBopHo0Uj0aKRyPFo5Hi0UjxaKR4NFI8GikejRSPRopHI8WjkeLRSPFopHg0UjwaKR6NFI9GikcjxaOR4tFI8WikeDRSPBopPhySLpX0iqS9kvZI+pnXJ3dcQoVFta3AAh9fAOwH5tPguIRxiUoY9Id4HriZBscljGtUgqR5wNXANhoQl9CQqARJ5wN/Ae4zs5PlfWbjE5dg4x2VIOkcCuk/mdlzXp7ccQkV3tMCngQeHlR/iIHN7UEff5+BzW17qbkdpmhszT7uSxoY3NyWNLy5AddTXMa7gB1+W0KD4xIyKmGM5De3aKR4NFI8GikejRSPRopHI8WjkeLRSPFopHg0UjwaKR6NFI9GikcjxaOR4tFI8WikeDRSPBopHo0Uj0aKRyPFo5Hi0UjxaKR4NFI8GikejRSPRooPh6SZkrZL2ukZEfd7vU3SNs912CRputdn+Hav759XOtcar/dIuqVUX+y1Xkmrz77mEFRcRn2+j8+hSAvoBJ4Glnl9HXCPj+8F1vl4GbDJx/OBncAMoI1i5fA0vx0E2oHpPmd+w5dRD/ojzAJeB74DvA80ef1aYIuPtwDX+rjJ5wlYA6wpnWuLH9d/rNcHzKuXeNXEgGmSdlCkAmz1V+hDMzvtU8q5Dv1ZEL7/BMVa89FmRwz1PFZJ6pLUZTUmM1QSN7PPzOwqihiDhcC3a3rUMWLjnRFReuAPgVcoLs85kvpSRcq5Dv1ZEL5/NvABo8+OqC8V3tdfA+b4+FzgX8BtwDMMbG73+vgnDGxuT/v4CgY2t0MUja3Jx2180dyuaHhzA64E3qDIiOgGfuX1dopQi17/I8zw+kzf7vX97aVzraXoDz2U0n0oMif2+7611ZpTZkSMifzmFo0Uj0aKRyPFo5Hi0UjxaKR4NFI8GikejRSPRopHI8WjkeLRSPFopHg0UjwaKR6NFI9GikcjxaOR4tFI8WikeDRSPBopHo0Uj0aKRyPFo5Hi0UjxM+GL59+Q9IJvT+2MiNKK318AfwZe8O2pnxFBsZj9ZeBG4AWKzIepnxEBPAz8Evjcty9kqmdESLoNOG5mr9X0SGcBO4sZEU1nnsJ1wO2SllCkAXwV+C2eEeGv6lAZEUcqZkQwQr1+jKohwHf5orlN7YyIEcQzI6IRZEbEGEnxaKR4NFI8GikejRSPRopHI8WjkeLRSPFopHg0UjwaKR6NFI9GikcjxaOR4tFI8WikeDRSPBopHo0Uj0aKRyPFo5Hi0UjxaKR4NFI8GikejRQfCUlvStotaYekLq+1SNoq6YDfN3tdkh7x2INdkhaUzrPS5x+QtLJUv8bP3+vH1rZGugoVF9O+CVw0qPYgsNrHq4EHSgtkX6RICegEtnm9hWLVcAvQ7ONm37fd58qPvfVMz2m8ohKGEu8BWn3cCvT4eD2wfPA8YDmwvlRf77VWYF+pPmBevcSrvscN+Luk1ySt8tpcMzvm43eAuT4ebSTCxT4eXP8SZzMqoUpiAMD1ZnZU0teBrZL2lXeamUmq+3psM3sceByKZdS1nKvSK25mR/3+OPBXYCHwrqRWAL8/7tOHi0QYqX7JEPW6UiUc4zxJF/SNgUVAN7AZ6OvMK4HnfbwZWOHdvRM44W+JLcAiSc3+CbCIIgblGHBSUqd38xWlc9WPCo2tnSK3YSewB48yoIg4eRk4ALwEtHhdwGMUsQe7gY7Sue6iiFDoBe4s1Tso/pgHgUehSDKoZ3PLqIRopHg0UjwaKR6NFI9GikcjxaOR4tFI8WikeDRSPBopHo0Uj0aKRyPFo5Hi0UjxaKR4NFI8GikejRSPRopHI8WjkeLRSPFopHg0UjwaKR6NFI9GikejakbEHEnPSton6b+Sro2SEfEE8GMfTwfmMNUzIoDZwGEGLW0mQEZEG/Ae8AdJb0j6vS+gn9QZEVXEm4AFwO/M7GrgI4pLux8rXqpxyYgwsw4z6xC1tYEq4keAI2a2zbefpfhDTO2MCDN7B3hb0uVeugnYy1TPiPCGcxXQBewC/kbRlTMjohFkRsQYSfFopHg0UjwaKR6NFI9GikcjxaOR4tFI8WikeDRSPBopHo0Uj0aKRyPFo5Hi0UjxaKR4NFI8GikejRSPRopHI8WjkeLRSPFopHg0UjwaKR6NFB8OSZdL2lG6nZR0X4iohNLi12kUi+S/yVSPShgkvgj4t02BqISmUV4gy4CNPm5IVAKwCkA1tqfKR0uaDtwOPDN4n9nUjEro41bgdTN717endlRCieV8cZlDkKiE84APgNmlWkYlNIKMShgjKR6NFI9GikcjxaOR4tFI8WikeDRSPBopHo0Uj0aKRyPFo5Hi0UjxaKR4NFI8GikejRSPRopHI8WjkeLRSPFopHg0UjwaKR6NFI9GikcjxaOR4tGoJC7p55L2SOqWtFHSTEltkrZ5rsMmX1+OpBm+3ev755XOs8brPZJuKdUXe61X0uqzLTkkFVYSXwwcBs717aeBH/n9Mq+tA+7x8b3AOh8vAzb5eD6wE5gBtFGsHJ7mt4NAOzDd58yv92riqpd6E3CupCZgFnAMuBF41vc/AfzAx0t9G99/k68LXwo8ZWafmNlhiqXUC/3Wa2aHzOwU8JTPrStnFDezo8BvgLcohE8ArwEfmtlpn1bOdejPgvD9JyjWmo82O+JLSFolqUtSl9WYzFAlB6aZ4hVoA75BsYh+cU2POkbGOyPie8BhM3vPzD4FngOuA+b4pQ8Dcx36syB8/2yKtIHRZkfUlSribwGdkmb5e/UmYC/wCnCHzxmcEdGXHXEH8A9PDdkMLPOu3wZcRhF88ypwmX9KTKdoiJvP9KQ+57NPqggOS8WMiPuBfRQ5Dn+k6Mzt/sR7KSJSZvjcmb7d6/vbS+dZS9HBeyil+1CkBe33fWsrPqePQmZESPrIzM4b6/H5zW0S8lwtB0/aS71WJvMrXhMpPtGQtEHScUndpVqLpNclnZL0saT7vT5sauCw1PJZWM8bcAOwAOgu1R6i+BbYTvGd4DjFr74hUwPPxq+zccfM/gn8b1D5h8AuMzsEbKAQXeq3J63gPxRfp1tHOv+EFR+Giyi+3UGRGjiLUf7C62OyifdjNX4OjzazsdG8D3wL+lMDP6b4JXcOo/yFN9le8WeAK/3X3V0UOZGbGT41cHga3b1H6OobKf7j8ynFe/Zuiv/k7ABOUbzav/a5w6YGTrlfZ7Uy2S71s0aKRyPFo5Hi0fg/iSIiBM1tS/kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10, 10])\n",
    "plt.imshow(spect_library.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9WpWMEEbp6Z",
    "outputId": "2f86b79e-a06b-4304-8d45-c8fa71e64e36"
   },
   "outputs": [],
   "source": [
    "# !pip3 install --upgrade speechrecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8yppp1Tc6-D",
    "outputId": "144fc411-eceb-4d70-d9ad-9f217121eab2"
   },
   "outputs": [],
   "source": [
    "# !pip install ibm_watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Arql3hbkcEwd",
    "outputId": "aca4c0f8-19cb-4c86-d679-e230ff551a96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess \n",
    "import os\n",
    "command = 'ffmpeg -i ES2006d.Array1-01.wav -vn -ar 44100 -ac 2 -b:a 192k audio.mp3'\n",
    "subprocess.call(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zZPINklcYsB",
    "outputId": "19c64cae-0018-4f21-9ef1-851566259dc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = 'ffmpeg -i audio.mp3 -f segment -segment_time 360 -c copy %03d.mp3'\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Waw5U6--dFoG"
   },
   "source": [
    "## Google speech to text <a class=\"anchor\" id=\"ch17\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djzg1pl7vps7",
    "outputId": "7bdbcf72-c58d-4d09-b587-1028e18eacec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/e1/7f5678cd94ec1234269d23756dbdaa4c8cfaed973412f88ae8adf7893a50/SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8MB)\n",
      "\u001b[K     |████████████████████████████████| 32.8MB 111kB/s \n",
      "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHAlFtPEvLJJ",
    "outputId": "1f9443f2-21c6-45ee-d157-1b2319bdfba0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not request results from Google Speech Recognition service; recognition connection failed: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()\n",
    "audio = sr.AudioFile('/content/ES2006d.Array1-01.wav')\n",
    "text_google = []\n",
    "with audio as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    audio = r.record(source)\n",
    "try:\n",
    "    print(\"Google Speech Recognition thinks you said \" + r.recognize_google(audio))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mgi0NneKvDtC",
    "outputId": "ad2cea3b-d405-4c62-ae36-32297f787b99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vY2IBOil8vF1",
    "outputId": "633ffeff-a9d6-4b3f-a743-fccdc06707ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not request results from Wit.ai service; recognition request failed: Bad Request\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "AUDIO_FILE = \"/content/ES2006d.Array1-01.wav\"\n",
    "WIT_AI_KEY = \"SVPUW2NGGISTKVCCZMUKH3LEJVJY5Q7I\" \n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "    audio = r.record(source) # Wit.ai keys are 32-character uppercase alphanumeric strings\n",
    "try:\n",
    "    print(\"Wit.ai thinks you said \" + r.recognize_wit(audio, key=WIT_AI_KEY))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Wit.ai could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Wit.ai service; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKUYtn_0y1oi"
   },
   "source": [
    "## wav2vec <a class=\"anchor\" id=\"ch18\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QphVP5PF_S44",
    "outputId": "7d0aaedd-2c6e-4e6d-9257-62162dd50a77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess \n",
    "import os\n",
    "command = 'ffmpeg -i /content/ES2009c.Array1-01.wav -vn -ar 44100 -ac 2 -b:a 192k audio.mp3'\n",
    "subprocess.call(command, shell=True)\n",
    "command = 'ffmpeg -i audio.mp3 -f segment -segment_time 10 -c copy %03d.mp3'\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "br6ePnE6_ZIF"
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "for filename in os.listdir('.'):\n",
    "    if filename.endswith(\".mp3\") and filename !='audio.mp3':\n",
    "        files.append(filename)\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gW0QOCsL1JpZ"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0KJR-mE41NWT"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "#Importing Pytorch\n",
    "import torch\n",
    "\n",
    "#Importing Wav2Vec\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StoX73JMy0rT",
    "outputId": "2acb3863-770f-4757-fc1d-4003e674ddd9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    }
   ],
   "source": [
    "audio, rate = librosa.load('/content/000.mp3', sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UHrzyS-1Xbl",
    "outputId": "66a0d725-fe39-4b8f-8251-3e940ad8b24a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:419: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  FutureWarning,\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POWQeiTW1bU5"
   },
   "outputs": [],
   "source": [
    "input_values = tokenizer(audio, return_tensors = \"pt\").input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShSekqwf7xDz",
    "outputId": "8ec16d3e-8d55-4fa4-8336-1bfa23f07bff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159887"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBujdaIs1fXu"
   },
   "outputs": [],
   "source": [
    "# Storing logits (non-normalized prediction values)\n",
    "\n",
    "logits = model(input_values).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKMaOA-t1kx-"
   },
   "outputs": [],
   "source": [
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = tokenizer.batch_decode(prediction)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYiZDZxINbBl",
    "outputId": "1ab14c3d-e7fd-4322-e94d-8c07d62c45d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000.mp3',\n",
       " '001.mp3',\n",
       " '002.mp3',\n",
       " '003.mp3',\n",
       " '004.mp3',\n",
       " '005.mp3',\n",
       " '006.mp3',\n",
       " '007.mp3',\n",
       " '008.mp3',\n",
       " '009.mp3',\n",
       " '010.mp3',\n",
       " '011.mp3',\n",
       " '012.mp3',\n",
       " '013.mp3',\n",
       " '014.mp3',\n",
       " '015.mp3',\n",
       " '016.mp3',\n",
       " '017.mp3',\n",
       " '018.mp3',\n",
       " '019.mp3',\n",
       " '020.mp3',\n",
       " '021.mp3',\n",
       " '022.mp3',\n",
       " '023.mp3',\n",
       " '024.mp3',\n",
       " '025.mp3',\n",
       " '026.mp3',\n",
       " '027.mp3',\n",
       " '028.mp3',\n",
       " '029.mp3',\n",
       " '030.mp3',\n",
       " '031.mp3',\n",
       " '032.mp3',\n",
       " '033.mp3',\n",
       " '034.mp3',\n",
       " '035.mp3',\n",
       " '036.mp3',\n",
       " '037.mp3',\n",
       " '038.mp3',\n",
       " '039.mp3',\n",
       " '040.mp3',\n",
       " '041.mp3',\n",
       " '042.mp3',\n",
       " '043.mp3',\n",
       " '044.mp3',\n",
       " '045.mp3',\n",
       " '046.mp3',\n",
       " '047.mp3',\n",
       " '048.mp3',\n",
       " '049.mp3',\n",
       " '050.mp3',\n",
       " '051.mp3',\n",
       " '052.mp3',\n",
       " '053.mp3',\n",
       " '054.mp3',\n",
       " '055.mp3',\n",
       " '056.mp3',\n",
       " '057.mp3',\n",
       " '058.mp3',\n",
       " '059.mp3',\n",
       " '060.mp3',\n",
       " '061.mp3',\n",
       " '062.mp3',\n",
       " '063.mp3',\n",
       " '064.mp3',\n",
       " '065.mp3',\n",
       " '066.mp3',\n",
       " '067.mp3',\n",
       " '068.mp3',\n",
       " '069.mp3',\n",
       " '070.mp3',\n",
       " '071.mp3',\n",
       " '072.mp3',\n",
       " '073.mp3',\n",
       " '074.mp3',\n",
       " '075.mp3',\n",
       " '076.mp3',\n",
       " '077.mp3',\n",
       " '078.mp3',\n",
       " '079.mp3',\n",
       " '080.mp3',\n",
       " '081.mp3',\n",
       " '082.mp3',\n",
       " '083.mp3',\n",
       " '084.mp3',\n",
       " '085.mp3',\n",
       " '086.mp3',\n",
       " '087.mp3',\n",
       " '088.mp3',\n",
       " '089.mp3',\n",
       " '090.mp3',\n",
       " '091.mp3',\n",
       " '092.mp3',\n",
       " '093.mp3',\n",
       " '094.mp3',\n",
       " '095.mp3',\n",
       " '096.mp3',\n",
       " '097.mp3',\n",
       " '098.mp3',\n",
       " '099.mp3',\n",
       " '100.mp3',\n",
       " '101.mp3',\n",
       " '102.mp3',\n",
       " '103.mp3',\n",
       " '104.mp3',\n",
       " '105.mp3',\n",
       " '106.mp3',\n",
       " '107.mp3',\n",
       " '108.mp3',\n",
       " '109.mp3',\n",
       " '110.mp3',\n",
       " '111.mp3',\n",
       " '112.mp3',\n",
       " '113.mp3',\n",
       " '114.mp3',\n",
       " '115.mp3',\n",
       " '116.mp3',\n",
       " '117.mp3',\n",
       " '118.mp3',\n",
       " '119.mp3',\n",
       " '120.mp3',\n",
       " '121.mp3',\n",
       " '122.mp3',\n",
       " '123.mp3',\n",
       " '124.mp3',\n",
       " '125.mp3',\n",
       " '126.mp3',\n",
       " '127.mp3',\n",
       " '128.mp3',\n",
       " '129.mp3',\n",
       " '130.mp3',\n",
       " '131.mp3',\n",
       " '132.mp3',\n",
       " '133.mp3',\n",
       " '134.mp3',\n",
       " '135.mp3',\n",
       " '136.mp3',\n",
       " '137.mp3',\n",
       " '138.mp3',\n",
       " '139.mp3',\n",
       " '140.mp3',\n",
       " '141.mp3',\n",
       " '142.mp3',\n",
       " '143.mp3',\n",
       " '144.mp3',\n",
       " '145.mp3',\n",
       " '146.mp3',\n",
       " '147.mp3',\n",
       " '148.mp3',\n",
       " '149.mp3',\n",
       " '150.mp3',\n",
       " '151.mp3',\n",
       " '152.mp3',\n",
       " '153.mp3',\n",
       " '154.mp3',\n",
       " '155.mp3',\n",
       " '156.mp3',\n",
       " '157.mp3',\n",
       " '158.mp3',\n",
       " '159.mp3',\n",
       " '160.mp3',\n",
       " '161.mp3',\n",
       " '162.mp3',\n",
       " '163.mp3',\n",
       " '164.mp3',\n",
       " '165.mp3',\n",
       " '166.mp3',\n",
       " '167.mp3',\n",
       " '168.mp3',\n",
       " '169.mp3',\n",
       " '170.mp3',\n",
       " '171.mp3',\n",
       " '172.mp3',\n",
       " '173.mp3',\n",
       " '174.mp3',\n",
       " '175.mp3',\n",
       " '176.mp3',\n",
       " '177.mp3',\n",
       " '178.mp3',\n",
       " '179.mp3',\n",
       " '180.mp3',\n",
       " '181.mp3',\n",
       " '182.mp3',\n",
       " '183.mp3',\n",
       " '184.mp3',\n",
       " '185.mp3',\n",
       " '186.mp3',\n",
       " '187.mp3',\n",
       " '188.mp3',\n",
       " '189.mp3',\n",
       " '190.mp3',\n",
       " '191.mp3',\n",
       " '192.mp3',\n",
       " '193.mp3',\n",
       " '194.mp3',\n",
       " '195.mp3']"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTP9YoqI2U0x",
    "outputId": "53e55243-9d90-4ed1-a2b3-9344a372de31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    }
   ],
   "source": [
    "results_facebook = []\n",
    "for filename in files:\n",
    "        audio, rate = librosa.load(filename, sr = 16000)\n",
    "        input_values = tokenizer(audio, return_tensors = \"pt\").input_values\n",
    "        logits = model(input_values).logits\n",
    "        prediction = torch.argmax(logits, dim = -1)\n",
    "        transcription = tokenizer.batch_decode(prediction)[0]\n",
    "        results_facebook.append(transcription.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUniVfKEKzpI"
   },
   "outputs": [],
   "source": [
    "results_facebook_ = []\n",
    "for i in results_facebook:\n",
    "  results_facebook_.append(i.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugNTMBK1LY6n"
   },
   "outputs": [],
   "source": [
    "text_str_facebook = ' '.join(results_facebook_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "h7gioU8eNL5D",
    "outputId": "29bb2630-7a21-4503-f726-4284476de3cc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"o o  angr me yo art selt an  rainas you o go all right mejuss howr parosir fool h right so on this meaning will be about the conceptual design tot as ma precisell conceptual design is sa just something important at we not do im ti scanava turningly abstract into slighting more concretein is meaning ideal we will come to some final decisions aover than it is for the prototat im right so an apoligise for the last meeting it was brought to my hension that i did not make the rules clear enough and so i will attempt to do so more accurately in paricular medi am there enough exulin watars good am so bsi ga worging to do is hassome presentat to get much at glast time im gaga throughyo i werotska firsis find mi ma i many old kolat what we know about im o iscussing lasting any possible directions and then we'll make some more decisions on a basinfirm up our idea how we want this romoo t look and work se perfect so without the further adea where alt go first to spikin ot o er sciding togoet it is eithera a going the row away erins good said the nathin ar partisipant to she mister berchasmen tyo let is nase a k mis a beastly woman has talkty about to day is am component design and it's bedn brouhts my attention now may be somewhat limited as welk you do because of would our manufacture offers so you baseley what are gon be doing tarue alike that a prits of rm control ca we've already kind of butteer this bot ranteand tip worty tellind proa have to reach some conclusions sometimes soon energy source on our manufacture offers of riety of energy sources you standard battery sor selvs our manufacture didn't say anything about lythium so we might have to l if we do go that room we may have to look elsewhere ah and also there's a cnetic energy possibility baselaed sigkay own the idea mov think that remote would create have energy to keep it running satrel huspry i don't know whether that would be powerful enough to illuminate a touchy soll have to look into that a the case we have a few options plastic rubber or wood ah and then as far as ways shaked we can do standard born flat wich repuled dun to curve dor very sexy duble curved tickles erry looking ot ah i imagine that we could specify ah i don't see you reason to go outside f that convention if three or four millianrs  m the buttons there are moltil scope buttons ail bfore manufacturer pla to use those who would have to use more chips now acostume and if we do go with rubber double curt case ah whap do ye use rubber bushbands bcause yeether buttons out could have hu with them ah and just e one out there ti screet iguas mn cheps which equas mi earop an one think that i neris is that most remods uperat on a and freenly ofred part of spectro so you notice when you push a byly mot you can't see anything coming out of it but in fac there's light coming out of youremot and ando the telligent condecti and if you what's a record you'red nake of ary bernie could ac jus sea li ah one thing tha i thought my interestingas to use part yu'se visible like commanded mil just kind as a fun ginick das he could actually see something coming out nnt pushed it course a happyer parlespection that would it damage to humano  io i is yore nox er we cold have to offer ons o prisicud select like yea i an trure that wu could do im me horse sai yo at's good to do yea just as a fon ginick just says parlaba ah then on to the circuit he wo down the euwse all soons the chip ah we're good to hony wear round te te a one one eih three five o findings o k we are very limited by what our cre manufactores can offer o and my question to all of you is she we looked ot the manufactories snak to what we have belll you dress yo sto champed wish i say shap aroun bu it with our tinecin traites that really if he's mocket an right that's my consent too  if we do go thel it the embarrer explained 'l hav to go asight kr my personal prefinces i'll ustrow ma carts on the table i think we shall figer the sourt o battery roo just can keep with ye environmentaly friendly thame that we have going on i like edyo the visible light signaling something te says apart and i was thinking about but's thinking at ways that we could produce the remote and of rie a different casin chails a suit different taste sonat so can fined by one style onsaysintly now say er the one ef re scote one and is a goobe wall en renne that situation n  call you mark it an pile in to try to see what kint before we lunch can me so one received aits and alshan ive actually there's i've got some mer sorjury and like what we're looking and trans in casey moree now aprojectiony madine goon play beforehand in orders decipher now great thet verymu in smerchers so i ge si makes as read y a kin i guess e because i fancy interesting things ene fassing did you knowii know what i's you earn it and right so hernt lookat trends scrat um he sas hooking at what's goming on ther in woll control market right now and what's going on other design fields to seese her whats whits trendy what's new what's happening um mokento all right now basically everybody says they want knewer fancier or more siting their sick itness boring norma old function all am that we need innovative design auctions and e neese to be an easy user in her face a the challenge is that current trensray now across the board in fashion in furniture in technology is a very organic for vegetable anthing nowi'm not saying we should have you know to made o shave remote controls anything but i think it is possible maybe to use i natural colors like if wood is an option that hole organicsly clean it vine thing it maybe so we can look into different ski aptions or if we can't afford this touch plaything er touched faced screane in her face am maybe having the images b specific lhy you could choose your mano bullets to be it's differes she he another name no egey haven't you you know what i mean tipto and apparently the feel of the next coup of years is spongy i not something ha at a i wut him deaf t is rundo if we can get around getting piling i thought may be a casing oction like at not like a skin but like a colder almost if he could do like in naither option or bod oction or something i should have mentioned is so as far as the rubber that we can use we k'se a ruber as parle case t has a consistency of those stress boyspeope might be notetoay togo querk um yat so something to set on frenounce so over all i think we should stick with what we're finding every's looking for easy euse technologic invative and this fancy knew i think praft the double curting and maybe dis rom roption is our best way to gope ma now um intervens olyto phis gratic for ya un well i don't spet dan if the touched screen thing isn't  nwork out for us that's really non iss you i like ced to of rever s you becaus it's tense thi say so t being durable somethingthat he can drop does he  her so many you go to so many houses is tis  sepret on not controls ain't you yo hint with dat te very much then would have the fault as you did we should haven't a doctor kiss ah i could think at goes against the whole fancy something do you mind bu w shalk in goin the thig gernala crowd a e and the at that's what i know sgrap fixbat said or compuners a just one olttis so itor interpase concept by your faithful user intervece egia so you don't use in er pace guises vascaly aspects of a comperisins that we can see or here or otherwise a perceive a commands to mechanisms that basically your usus to control the operate operate system  here's an series of different ral controls that areout on theamerica to day i think we're deckly trying to get away from this kind of look e a so the following are a bunch of different i interpase aa consepts a vace recognition we if we am actually have some new a information from our research designed tim but a get t that moment am so rboyce recognition stars up to about eighty speech sampems am anbasically record your own verbal labels can connect them to the real control now or design team research team has been all to you ah set up a system in which ah you can teach the rirma control whisk recognitioned system to prspan chi a with standard responses like you can say good morning a ruma control will say in h a female voice good morning joe am in fact we already have this for a copymaker line glass single people yehave a e marpange ro cho said gami wa am another concept is what to that apple has come up with the spinning wheel with a elsie to play likeon theaeyepods which a ture must be no ond  then we have the scroll bottle with intecated bush bot mon like a modern mos a bit bulky a bit crazy and don't think that's what we're necessarily going for and a some special component sa ideas like gob locking having they villated a block channels from for your children hem and a dedicated buttons for for commonly used achannels and even nat ideas like secure or hidden progamming but and again if we go with atsce nothin that's a big issue am and athis is canadea the big daddyar jloga athe jumble you ar sort of o control is almost impossib the misplace en as yet onseh again probably not what we're going for s mean my ideas here in the kind of where i think we're heading as something slightly lik to the i regular ey upon with a hard classic cat classic casing well i think some of the suggestions would come up with her definitely o very good ideas a changeable ca sincs  our designe team was possibly talking about including one extra face fight with the package akit of set the idea that you can change him you can tri changing a kindo get used to thinking of what may be buying another one which can ad value to our bottom wine a touchd ine fa i possibly having go two buttons being a stuck into the system so those don't move away from the screen the important ones like power volume and jump between channels um and of course our woys command system which ave talked a little bit about already and i the use of recognizable colors in shavesae recogniti of the feature san tittround so read for power whi airows wer different volume up downs and channels up and downs ane what not and a perhaps you an adding in some stupe lottl jokes with the boie recognition idea rnfrens it's my toasty maker that i got from my bank as jokes when it's ready yes the great and a bad sa botter pral for a o a good ideas good facts in o eh at to then neas a little doggl and just six up the sprrows you don to stand at and begins an a cateno right so go didn't all that sathi as im now can act come tos in decision sam tig we jus go while i'm not through the cnaba chab bau i'll me base on what natin presented as far as he athere is cossin benefits an i think i don't know what he guessin about the touch grait at this point i think it's a most markable feature just because it's so new and is something that is show nough in other places a can we really afordi cause it looks like thing be that would be a really main cost sorce of an right my estimate is that simeratu incorporate toh creen technologies an covses upwards aid seventeen fifty yero throu e mant and that shous nes weeness you guess were always the damper is on te en you industrial design lie now it's iin an our goal was to be under twelve fifth year we have to be in atweverty well i thouht there was so fux bility with um there is it's just it is a questionto jestii and how much o doesady gret the increase surprise to make money a from twelve si dif ye want to get at fift at hundredsof profet mergint a that would me  salin for twenty five she was by seventeen fifty about yue that's thirty five only so youhath come up with these mumbers a suf top ma head it is penting further hemounts  h ai funable  for him oh dogh i think that's aurd people would pay for if you're gen a paper an expensive high class remote you can't expect to do something that's true i isn't it w being aclassa john en and that's to be veiry young the puset of the market we're not going for mass an  mansails anyway we're going to make and e won wat ar talking about selling eight zillin  of these things we just couldn't no for twenty at your ows so we can cronly me shak the profit wers an rather th sether for twenty five sellin for thirty but that's endiit again ad stillwet no i say that we provisionally go at the taxscrare youreworry what was your bout manr or i'm thinking that ser definitely good idea inaow to thing that we can probably come up wi some sertva cheabera means to to go about this kin is tat you get my corners my cheav in the yell on the third floor ojustwhi we can't look at this other manufacturing out jennean get a o reas he per  it's true we can initially go i what we hav were you can find jusdin win any night thut we can have as very simple touch screen heu know is always the opportatit to daby about the size of the ey tought o whatever you o'o yere iguess we can play around a fit of bit ilands one say that theu case of the testian will be our a our main selly point here wuy i think t atwe really have two man salin one e jas ina cletter tais nan anned the voi strickin mein weally dicious and pretty thousand whistles cansr low the voice rak thing i mean iif were looking at bottom wine now were looking up in cossa savanteen to get tettian i think mater drop the wesser i can gase to sat between our deafinitely nou to be on us we have the cape we have the design in house i mean we've we've come of with us with just newwix we're using it burk off here machines already i can pass you on that yeu mail from my a guy and now guy down the hall sounds good act po waysint on otherwors back i think if wee we did b both the i see prassian cospin togotehead but just put it intoo it become the rolls riser for mo contrantents or tanks mean we we have to reflect back on what our markeet reserch jatson i and they said they ont voice recognition crsimet and thought of this little touch scream option but deat linkwe know the work at us there for rhich recognition so to say we had a techknology and we're not any use it even though we know it'll sall it's a calin think i can do that said langrily i can't go in to say now ere goin to stick no arm it you we now ye does have him both really a perhops i can't see how oodn i mean there's yeto the old affriswom you can have a fast you can have a cheap when you can have a qu pick two of thirty ye very can't cant can hav olf rar caus e iyes i be number of chepsley need to deal with each o function well if were it a pipati i so we have to pick two one or two aotherwise eamogisted just becane cossperhanded awhat which which do you suspect we should old who should alone to well we already have researched back ingwy sercoition you know hiskily solded but a i i i personally would tend to othe direction but if that was miss sall i think as we need to go at ten mame we can teale this touch screen for our next monel i would have to sid with that i think the voice recognitionis simply were to have the all this acknolegy and house it's ready to gets package ts what is a costuk like word is a cheaper who the yard to re the a touch screet nethin wel my pa itho is just off top my head keeping on bet i think the voice recognishouted they're both it they're both going to push the cross up replied tom since we already have the techknology had asked for the boy's recognition rogen had to do as much design work and sometimes design work as what pushed the osso where fewit aman daff way after yo with a lot and we're still not then youre to da with his barry is you knew is wuh either then begin to stick before yebore e guy he'll not always did and so all getting or  tod more or less yes think other two of  the boy's recognition wl be betteed an any tangleo rescoption wit yo ot right now we can have it on the market schooner riches all in all our best aption look i sortiy we wonl amit the custry in favor of wisrecognition noti noso and when are we can have beesick protentives coming up next that's youris a next tatrigt ye are alwors sigol tor out what what what else for ge to talk about men orittapayelater n extantan pigo are we going to talk now bot done temittya's arranged foanis a case wudis run thoug yahakana hum you discuss it in ther a lithia more a solar power would the solar power be enough to febl a goistr mitsha was chenestetic one with that be enough to fuel avoice recognition ruma oo the sole power dephlin wouldn be but i think just keep peoble from inanoyicus sometimes saw ow our fellows to snowround that we should install a small backat ary hu e just tecover those moments when whatever is the mud has a loks of bo such as even ther basement minlingwit the wouldnt we can't get an tea somethit at a race o having a shingerry sources probably it worse about the san is a so o coard calculator and you know how does this arealy require that much lihe cheered augustly little more like than calculatod but were not tacking ow a while it is at to be ou tacking some last er try staini cat way they got i'm going to do agree with everything that's been so i have to say though that another ideas come upon my head if we're really not a handling that promod control to a great extent we could poss i get away from the idea of having and held win control and maybe kind of half her round her in control the cantlis like caperwaers kin of a sweep little ot anything that sits undour table or semetingetor sak nmaspa thought why don't you away from hentill why its pen well if you don't mean to pick it up if you kind he is coming els trecking to shaking me technically anyway in your room and still do is job you think people are people at byrin moter they always get one use the worse ritinsionsis something they do sometimes ature any probably i think were bang on telling to more in just we sirk me should people like e want to work one mentally y i is lite earnt too wa rank but that's done that's so bother me if you look at the cowalogue from tices out a sharp remager whenever now they might have all like a who has an apple makes these really pretentious speakers wot the sablipher not clear and glad isn't now ny got th i turmiddle type of o stanier something why not have a little roundy cutathing it could still have the basif buttons on it om cause we're goin for basif function ality ci rarilias we it ba ye and maybe i ma new biton n so forth in yor arm use a jannel biton to skull for the mania if they want to recort corencial what every mett ats sonl i think you're on to something yes we to escape the traditionain shape of remote maybe something h looked slice on the tables would be good even though ann had held us in time figo thall about following applesly on beyind thinking of the airport no do you knon a nes it all podlookin thing esie yemeeted is although we do ev az eer calling she mention we need get away from the surgical wi kind of brusha an wen om thinking in tact rabet he could have a very tasteful on wood colore or all the time it of om connaborge still i main't yet i will always lince yet i like that i like that ideal lot am but see we can do as far as it goes and the athe material like a plassic and so forth we were discussing that being a uon make a rubber kind of softer feel yu ameal i like to filla tip on his pet is a bit givs just a bit youn't know something wore it's a aa more bis from a plassin passing cao tacked out wats to it we just cind of the swish you do yeh which is the next big thing so it after her if e i we ha yes if you can do it sqishy non remote control looking in remote control but di be feiry avin you just just put it glittre ta put it on that the night the cocker table mex an italian say bow him up ani don't like i ike gat im isga ah  ser dis guss ka don i guess well all that's going to be up i think if the run a bit over budger than might yo kay ha sorry banthia lack hem fromisi jn kassashs havnt been provided fish by my advinturs oon more anger to get us to and more  one more itin wy aha ha ron't a stami goffre meric an so we've re visited the touch screen and more or less you'll bat out an ithink so or more or less can w what were more less in agreement than we want to have a m a simple kind of function you know not twokomblax gray well when the majority people are only using the most primary funtiontle in e day besis although i'm not saying we she completely rule out major functionply should be secondary at least if not functionalyg and visually like those it shouldn't be right at maybe have made yor tings if n if we're nt go in the touch screen roote then we ken in am just in corporate may be something that folds out like way off to see a these country notes is the most basic functions of gair nissinting am swides down into violia th more coplicaates wonl do on to consider like an ipod screan which isn't a touch screan but you're still squirling through many ochins in think then we're hiddin our costa si o chairs we sa bos  dons and men the thing i  fore i have a none remote looking remill  you have awe te but none who can do sly at her compartment you know like i can sasiore a little vaguely avoidable type thing and ease to have a compartment in there or ino bu up a series of mel threeorful buttons with a many batton and then at science up and down ake a thing like onne lik got at he ne clare yet ais't mard mebbe plaer sll just have i a madian button on a side and then the ant foll luttons around the mas kind of he annever throe made like lat so rigin are we talking music ye are worcon bitons with oine teas rgoine teas score bitons reber bitons what seems i er it seems to me a we could justubi sick with the robert is for probaga to be used in some kind of a rober for the outside case an mellas mistake with that or think to a certain extent we have to stick with the tin of et a little be traditional on terms of the buttons and then and then make our uni e jurkis  ander gris well in those rays it just like four directions that ar that can use as many or channel in volumer hov e one do it our really birst at all end everysoere he got them tisn't he said on mose there yo own some stot like we're dealing with everydy realer in vabscase it's ot so manybays can one it what i agar om the very has cover this is well at sas be selli i o o morais good i y or to cart targas youth market oh especially now as eighteen thirty fivals being so as quatity of population perticularly intechological field sam to daco ratit acoun u ye right wont moral is covered moundid coverthink fo indyin for thoughts before we chank about doreparted or movenont ert well what are we actually doing what right i was just get step on to em ah how i wasn't in i wasn't alk my bed i'm sorry no no n bea yalwkawska besin tasks him h nextionner if an adny o fiva thout boo we go him go so have we said that we are going to go with different style cases for different people are we skungof warning it's very it's very part thing to predict because we have different cases and then my open remarket will bat ae sleep but he have son case and it doesn't go to on yewich waguste having mork asassa cosswas well then a gain colors wouldn't be so hardy dar you get out ar sinta i et em i a a capanateral wood collar like a skinin wod and now all in green or something idean that woldn't be so much mprompt and corporating in the colour of the rever out think and again c upping eymax kind of fer eye pod mackt apples o collar sceme yet tolly ye i think that's probably getter ill ga so it's work arde amultiboy case colors baasic wot the same matter ye adte same masic an on remote kind of remote design col i to oll the next meeding about half an hour im ho want thee id like nithin likey work on just a basic look and feel what can we accomplish given these grammars o sir sir gat this kind of a non remote remote brown what are abroad constrain it's before we'd design of pos ie and i'm long if you can so youre how how we best to lay out this idea of h simple design with the voice recognition ot den and also this kind of drop down or omiside can of manu octions simple somehow e work out how we can get this alks in the same place eh and if you can ject product of gaation tsumed pilots a stuff i did you gess to work together and making a put as ide im imusing protatihe guilding material aman rowmd it allso wot mispecific instructions will be seid you menhe coach as a tox so that's t start with renax tat all right mes the sin skad bobulis all right a yisit dirst is a go\""
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_str_facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zbpUa2-XLhkX",
    "outputId": "417b6bdc-57d8-47ac-c36d-c9a48adb77bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER facebook: 131.48404993065188\n"
     ]
    }
   ],
   "source": [
    "wer_facebook = wer(text_str_facebook, transcript_speech)\n",
    "print('WER facebook: {}'.format(wer_facebook))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_G9yw8Rqbswe"
   },
   "source": [
    "## IBM Watson <a class=\"anchor\" id=\"ch19\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RvyIGOrv2fye",
    "outputId": "4703feeb-f521-49f2-99b2-1d09e702c866"
   },
   "outputs": [],
   "source": [
    "# !pip install ibm_watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCOuwIUvbswf"
   },
   "outputs": [],
   "source": [
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ub1BruG5bswf"
   },
   "outputs": [],
   "source": [
    "apikey = 'wx9rd4_OMeYZpzOHBcfhDNXW5X6ECrfaU0u54fhwiY0M'\n",
    "url = 'https://api.eu-gb.speech-to-text.watson.cloud.ibm.com/instances/5019271f-5147-4778-835d-8c1fac38fee6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jo9L8o4Mbswf"
   },
   "outputs": [],
   "source": [
    "authenticator = IAMAuthenticator(apikey)\n",
    "stt = SpeechToTextV1(authenticator = authenticator)\n",
    "stt.set_service_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTvz9tpfbswg"
   },
   "outputs": [],
   "source": [
    "results_ibm = []\n",
    "for filename in files:\n",
    "    with open(filename, 'rb') as f:\n",
    "        res = stt.recognize(audio=f, content_type='audio/mp3', model='en-AU_NarrowbandModel', continuous=True, \\\n",
    "                           inactivity_timeout=360).get_result()\n",
    "        results_ibm.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLDO8NGzbswg"
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "for file in results_ibm:\n",
    "    for result in file['results']:\n",
    "        text.append(result['alternatives'][0]['transcript'].rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJkl7Mh8EhYr"
   },
   "outputs": [],
   "source": [
    "text_str = ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ljapv2e0DaTe",
    "outputId": "e4152651-230e-4a3e-dfa2-3cd46c67e4d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER IBM: 752.6385224274406\n"
     ]
    }
   ],
   "source": [
    "wer_ibm = wer(text_str, transcript_speech)\n",
    "print('WER IBM: {}'.format(wer_ibm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awTYlCCAbswg"
   },
   "source": [
    "## Метрики для распознавания речи <a class=\"anchor\" id=\"ch20\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGGXtWyzbswh",
    "outputId": "db0a8311-2131-4a2d-f891-aaa2e6e4aa24"
   },
   "outputs": [],
   "source": [
    "# !pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9Jyd8cjbswh"
   },
   "outputs": [],
   "source": [
    "import Levenshtein as Lev\n",
    "def wer(s1, s2): \n",
    "    b = set(s1.split() + s2.split()) \n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "    w1 = [chr(word2char[w]) for w in s1.split()]\n",
    "    w2 = [chr(word2char[w]) for w in s2.split()]\n",
    "    wer_lev = Lev.distance(''.join(w1), ''.join(w2)) \n",
    "    wer_inst = float(wer_lev)/len(s1.split()) * 100\n",
    "    return wer_inst\n",
    "def cer(s1, s2):\n",
    "    s1, s2, = s1.replace(' ', ''), s2.replace(' ', '')\n",
    "    cer_inst = float(Lev.distance(s1, s2)) / len(s1) * 100 \n",
    "    return cer_inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuP5zb9-ShUm"
   },
   "source": [
    "# Комбинация алгоритма распознавания речи и суммаризации <a class=\"anchor\" id=\"ch21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Stt_HdLXY4Fr"
   },
   "outputs": [],
   "source": [
    "test_ext = open('/content/ES2009c.extsumm.txt', \"r\", errors = 'ignore')\n",
    "human_ext = test_ext.read()\n",
    "test_abs = open('/content/ES2009c.abssumm.txt', \"r\", errors = 'ignore')\n",
    "human_abs = test_abs.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OmC6Q7bdLWuZ",
    "outputId": "ee118b3f-6c21-4a5d-d353-87375e8065da"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_str_facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTHvNS74SgoN"
   },
   "outputs": [],
   "source": [
    "# частотный подход и wav2vec\n",
    "final_sum_2_freq = summary_luhn(text_str_facebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJnExYXhYMFf",
    "outputId": "b8644c71-547a-428a-bc97-22ad74688f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luhn scores: [{'rouge-1': {'f': 0.28158457933283115, 'p': 0.7315716272600834, 'r': 0.17434537620152468}, 'rouge-2': {'f': 0.12533475854345016, 'p': 0.32590529247910865, 'r': 0.07758620689655173}, 'rouge-l': {'f': 0.33093524735212015, 'p': 0.49595687331536387, 'r': 0.2483130904183536}}]\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(final_sum_2_freq, human_ext)\n",
    "print('Luhn scores: {}'.format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ab8pe8yT35_X",
    "outputId": "6f714874-3f7b-4e27-f741-10035256ef96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwCkv7sbYrPZ",
    "outputId": "6b8e3766-cb96-4d1a-af5f-ca37dc1cfcda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2726342139657395\n",
      "0.005524861878453037\n"
     ]
    }
   ],
   "source": [
    "reference = preprocess_text_simple(human_ext)\n",
    "candidate = preprocess_text_simple(final_sum_2_freq)\n",
    "score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "print(score_together)\n",
    "print(bleu_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "Xd8TdCkDjEh8",
    "outputId": "c29d2672-3104-45ba-a0d4-20dd4e68531e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"shdie oiicious visant witli  ma here are repli gis o o oweryo soyo o yes think us  befort managincin ah so and then no wewere close is meeting aand oft if meetet weal o  lat a lech god oo ma a why a anna can you a door a pristalta you don have for olliver i a one at tay gain agan again my l iwork e tas ou bet go an  walo an able to n to wa i can dell tha abat mer a it my be may be cenente candyof thork bad or it may be con you to wid what if necessary am but i disdaine an present withsom by set a da ad a small bagof scrapes i honpy people disasking atat there remark a trall yeu seigh havits and what they want to know my control um it's haw igatyon asked he ive just got a white page tisnt at on it im bis clit saying that use is jerally disli it at a beal of yot to say ma oe sai an e may ogantis comoka asaays open it or fees wic teaf there my controls i'm seventy five yo senta cap set of uses fine mustwrite te tross eyway nam i hip said afbusist would spend more money when i are aout to trall little patsy  ta mat con crharls did not match while the uprit ing behavior of the usis seventy five cent of es e said as aperlot said eesirmy catrol quite frequently while i ought to tell me i thif you pe cent of yes i side that there any ye s ten cent of the battins 's ither bot fo rakentros    yes youe off me so we a for yo jus out all e te some men  tear the ou aac sha so lov o rtonality but the arylisis time that i need small part of that in un wo do you have the assir information on the reapon hond it e wet as yes ters mank maybe you can can set any mil to me layer or  yet j about yi  sa descay and there's a b dat paliti te different cuction or rit control an power and body selection areused a few times within this a prow ow chiles like he  r disis i is it dayaties an a and the same black channel settings oryer setting an used very afrequently an kelitex is used a fourteen times an the our so dis but not merely as much as the chances lectionsis on don't you think that this rebort is brought up is a annd ti ti fifty bsead at eas as youretought that the ragatar gets lost aball the time in the wayn yes i dont my har hat   tho they are a to come i av like itim in a re control what be very useful to bout of eases an thirty four per cent said i tight tilong the lantesar muc control the with things easy to ge stright away aro to pats iise it's easy to know an you turn you stady bob said said it to t o much time to land au guros nerestoni to moroonor and and thirty twenty six percent cents remork contrals a bab arsi i don't know ly it's got that fo coma at wonded me for asac hesasy o a brodis here fish short me  e was the gain of te dis mating te i will ah we shan toer attende with with ot wich lie sight to ah as i to er e joo first the i was tet for bet ti ty injury ie that i fingta are gly doctors doctor says tut is is the opinion of ter you to yeo es a abotote am and then it's tha denographic bright down may beyou cannave put this wepage on lion onte ah i should be abetact if i connot see you now your culness correcte ton loocan may be just o your tat ye aga into whipage and see yesified ain how though i sou yet many con connected you just to mention i o bag notes aof his meeting and i'll try to work him out and get himto yuk also make notes of the breeter's meeting and ah i was about to send him you wut then h i hat go to o sand meeting so you will get a to wor am shere your the secretary anser ye benny indeed am then i can connect is one  a por dea so these are important numbers that mathew and iny to take into account for oh arasnol it's por easier peope are yours nosday nowty mis is lebi he help yool haf a worked out tetergus ma u fo for presedations about teh about all yo de ditosk if to in a previous meaning ah we will ah in a minute we will a stark wits dem ah youill feen which order the landl tem off a then i will a bringinfom fom fm you qe yeris numbers us as to be astibut i cenning to account  fote both and hesenta face and the out froson desiing wone dak is anto talk about intstay is he because there are many numbers and we need to select to constraint ah our design bezon one is more important andyet and monday ther sday is tokhe that poor requirements i gote fonde acantenser i try to work amout to work quite abtract and o can av ma a n description about it sir about funcus and well just meeting we should be try to recha decision about t cru and pefutiality you mean the soshur tagedru yes i means well iga yes who are we going to it well to sali us al geycosf rigtin indeed i'm sa you conmistion in i mi contrall specher omissionin and he would pay himore for that and by tha pid with my easfol do you ho ande yes a sos ther wou don't do woudn't need any bitten an thou i w os go ther oben or beson speech rinkien i even for dressing adia most yer i think nowane not wet si while you and hav by thoughcants ii yes thingus as befort madasencan ah so and tenwewele close his meeting aand of if meeting weal a lav luk i o  may a why a anna can you a do yoa pris genalsa you don't have for tolisan e one a day fell it wont be a solution for on your remust av foldid lost i mean when as peterecommissioned thand ah it doesn't matter where it is my wallets who should be enranked  who maybe it can rech waltan produce sounds o fay where it is but did this are al quite fancy future i am not sure whether we will we can make this for fortwellof yeur of yer ifty hands nay can wed able to to right ack and tot bat abat mer hiase mybe maybe endento candeas tork body tor it may be cen you doide what if necessary am ti is and am presented with someberysetue gone and a small bagof scrape si hundy people disasking about there remark atrall useage habits and what they want know o control um it's ibic no in ase yo i've just got a whie page tisnt out on it um islit sighing that he is as gen dislike and of a deal i do't know where the state of the other spicual conmission is maybe you know pah but i de badly don't like taries there it's a very smallolcovlery very on gie dan ic on lie noing fot al why but i's quite noisy nhow there is the me y yenowin anyting not going to be does it so easy but shma es youly ispose you more for icolator do you have o waysborin sect  there miconjrolis i'm seventy five head sen gab sad abuses fine mustert markd te tross hadway non a hap sand of uses would spend more money when a remarkd to troll would look fancy cant ama contrals do not match while the uprit in behavior of the usic seventy five cent of ese sendays apalot said he e sermot cantrol quite breakently while i watch you tell me i think you be said of yos o say that theren years ten cent of the battens so iv got te racontol am oi no threnty to ye ed lateday to some morise may leg this is snatch of he mad a'm he would pipe e state your cognition in our riht control he'll pay mall for it and najig sant of the fifteen twenty five year old market said that they would pay more it goes down from their seventy six per cent for twenty five thirty five thirty ipcept e that he got to boy by am plenty two percent all forty fiv tomisi five an ten i seve rer maser my he required fo forgetwis word yet it really depends where work and be or in love of factionality tut really writs i tin that i news a small part of that  um do you have this  information on the weapon o  o weatonos es as man maybe can can send any mill to me layer i yet juaabout is si besqly an thee's a rectaf pality the different functions or rigt control and power and body in selection are unused a few times within this that afper out i'm charles lectin sivating wis brought out i'm troby toamet letter i think yes i e ye er er a as ein dellen that aishe is i is its gayatimes n and then ha in blak chalnels etdings o yer seading an  used very afrequently and kelidex is used a fourteen times and ow so disease but not nearly as much as the chales lactions is po ot king that this repo is brorn up is et a did t di to pesed o eases youre touht that the markgataw gets lost of all the time in tewn yes i gol my he obsertis the piggelog topping out there the difantern that is merthy as stopping tout there is the elsie des fraine that there's no they tidid a anean ungi o eh maybe yoas mildacai you givfer a fogeve your presentation a  mby ga i stay ot o comi av le etim in a re contral what be various fortl bat of he is and thirty four per sent tha tyces too long to tantesar  muc control tha wats likes easy to ge strie away orga to perhats is it's easy to know you terstenty bob said said it took too much time to land au guris jorston to oraga an and thirty twenty six percent sent from our control a bab asi i don'niw how we had got at from tomatt in hat won you me for i saw you an moretanyo you can hold e an your sfo e beg te cur chir ah yes ar you can you can take take my chair a so i think as everybody knows e am being industryor designer ana in this presentation a how is that for bet to fain oe othat i fing that are gle doctonsdoctor sas but its is the opinion of te yer do youisna that's a repis iser and then it sa a denographic bright down may meeyou cannot put this workidge on lion on te ah i shauld be able to if i not see now you cen disconnected a lok may be just o yor set yen yo an into whipige and see yasified a it how though i sou ye may yo think anhy pismut this quick presentation am is gonaffookers on in the working design althoug he we want contror an i'd like first togivagki ar simply intradiction how daes it work so that everybody knows even if you don't have ave an taking e backgrond a what is a pride i thing in the protectice ind porting so masically ah the bisic function of whom contries to send a message is to another system tat his fixed and  is ordinaras ye can connect this one howade so these are important numbers that matheu and i she took hi to a com for howavosoneaal its not easier  he pan yars n isdayd oty missus ledling bisaucefids an interated sicret the cip that penham bas messages uslia tuta inford bits in an ah to usin to face on for the chief acodinly the the messages i so my method for ah designing the athe work yesai ah yet first tthe main point is that i would wish to to make a ready function our product k ye is numbers us as to be as to be takening to account too for the both and yusenta face and ter fashan tine one day goes on to talk about but his interesting is the because there are many numbers and we need to select to constraint ah our design is on waton is more important yet and monday the day to he that i would prefer to have very functionar ah capabrility is weather than fancies ta that in fact is a deusanasn so for that yer as hesupuden to taking toof the usur requirements from the macketing aspeta ana and now to to you should ae re what are they confunction  place contror and i show you the ther working design so a i'm sag a conitionan in tat contral speech or phoenision and heli i am often at and by te people y yoself do do yo h on dat yes an soys ther we don't do we not need annew bitton on the re go aheade bei or bason speech rinkin i even call dressing idea at least ye i tan no one not let si while you and i thought you arge oh besicly ah here is relagu of what we want is a weont a un offbutton he can be a simple but is i important and so a iny willing ther tobors caners as well as other buttons that come after wigt so the cumpananzai quickly draw hele is that in this part you have the controled va lecender and another bout alligod it will be salution for from your remustav foldet loft i mean whe a pek recognition that ah then it doesn't matter where it is my walletz who should be enranged wo may be at cenry walton produce tons o fay where it is but id this are all quite fancy futrit i am not sure whether we will we can make this for for twelve years of year if yo had ny can we the receiver so that's my methodies aah would be to on my am would be to a gizander and choose the chips ande infered acompanante to bit the oncomfortabe in so of course we inadusources an a the receiver a receiver this is rely quikier is a i used up mia integmita yors bean tat o no way the state of the ots phich rur commision is maybe you kno al i bat pik it badly dont like veris there it's a very small covry very one giv e i sho blake no theye all i all why but it's quite noisy new there is the wa ye h yeo in anything going to be just it so easy but easuly itscose you mor as isalao it does will have some ways but in fact a am so what i had found an after aloth of working stree i had robethis i'd rother for you ithe sias ke ma la can be maybe too technical for you but he's very important for me yyou know  yoa lot tina e afama fofa wolf and  t's it so i won't gointo details about that but a these are my propences to use a anof conpinance eboram but i donoot know  tenty so ga a dos to some morise ma leatle this is snatch ofme mad im who had pie hi state recognition in i li oh good pay more for it an nijug sait of the fifteen twenty five year old market said that they would pay more it goes down from ther seventy six sent four twenty five thirty five thirty five cet thirty five forty five an twenty two pecent four forty five fifty five n ten i e xempary sere fi reclank edet wos wart yet everylthiyg depends where work enty and why do you want this concompany i mean ote cheap or are yey a reliable or your so the the macompenancio see here ah the cheapest i found an y you ave always are compromise with arida biti ana ati expensiv but ah del as not these one also rii r gabrel a so ye that's it for the working desire tha te nameis by that lam sule do tat at athank yes idid you get er er o o a ileli neine age aah i hope you gettng cure of you onawhat what a room would contror hes and ont o ani dignet to i contenance but maybe yer smorke and artinodded madivit o a cag my one market lak again o you ande nno no we wu la this is a preference but we can always change ah wat well thinking about a the dedisceemer about and says the thick at is  stopping that there th decanpan thatits merty has stopping that dar the elsiede esfrained that there's no fiti of mani o tat munin oi uh maybe a mildan you givfer er give your presentation wy gai stay no yeceneran receivee can you  pear ebectly at a the receiver if fort already indit elevation and we are not a able to change it or thoser yeu wisth the dapt to your toshe right i suppose there is a fenthat a way of communicating into le fisin sir yeru u za in for it fot a corp ah using  in for it anh antin quietly you can muva anmoe as faro the bek the cure cheer ah yes ow you can you can sake take my chair stands ino or so is you a erybody knows a i'm the industryor designer ana in this prison dition a and of course we g drive ap to that potopo that already exists an bet we what we can doir a ad ting the the chieps inside a twis the best a chips anna ioard boat of on o great take a wo ot yo don ye et yet ye i tiitis the dregonces yr of course youre ain't the chup yon mat o should be cat of his quick presetitionr am his genougfookis on the working design altho the in what contror and i'd like first to give a  a simple intradiction how does it work so that everybody knows even if you don't h a ve ticnic am background ah what is a pretty lathing inthe parectice and porte so basicly a the big function of homert cuntres to send ah messages to another system that is fixed and sonnigi o people lautatin hegan oo ma agai hat lifily defaint a remot a geman oicutes itself in the other t er sobitically dor through argood things so magy should think of ow cso we should hav hav at in jo vey jusn't i ave thet oaltedi in the next time a through the last or you can destei out o the an then so up irwins ta mat and in cini some worcockicyou dont better be near the yair yoar dao  another i te on mama i think ti source its anintibuted sicket the chip that hanom buz messages usually awoa infrod bits an the usunt it face monfor the chief an acodinmi the the messages why so my method for ah o designing the in the rokisi ah yet first the main point is that i would wish to to ma ready function or product my will will consider is fatet erdiernangress may men may we we can go to to your presentag as tait why i sum were yyust a foas is myo  i would prefer to have very functionar a capabrility is weather than fancies tas that in fact hes adusant as a work so for that yer as hes aculdnt to taking to other usa requirements from the tin aspet aai and now to to  wshould a re what ill d inconfunction  place fom mcomtor and i assow you tha the working design so a i now where the is olete sco i i ge de wont be mutbut oi went toe pope the giv without lost te thicknic i an so  what tankiats of all what i the user bo to do wi a mii en  i what i a i say owhat the user he is going to ti aban mesically ah here is relagur what we want is ah woon a on of butan can be ait simper but itsinsimportant and so a any wiling th toboschaners as well as other butsom that come after why so the cumpananzi quickly draw here is that in this part you have the comtrol a lesender an go the palas halt say that ma contiuly so by that port in that day bettegin thy dars i had he mettic o thetin he said anin my tet out e tan e col ma be corde that me and a gisin me it is fer eo a fele what is tilige te baa a a a  a dinning of wat ate visic e ibtane the message whith is exent et the dvi and and the recuer so that my method is ah would be to wor my anguld be to a design the and chuse the chicks on the iferit ahcompanante to beat the mon confor wine so of course we inad yosources and ara a the receiver or a receiver this is ri quikhe isan a you stup meo intrk me foryors be ont that aha i that ei ateca because at ee becas so as sound an la has said that his e beglady a jed ben things which are weoly te at at eve bego and have  eecame at  tosad questunetoe we have to sakelater but in the burnatenario it that it has at an ga ane tae t ea for and etend and massetiate ana so what iad found and after lot of working tree i hide robetis i d rother for you the si eskima ma kan be may be too technical for you but he's very important for me you know ge of my life apapa fo walkineand  it's it so i won't gointo detais aboe that but a these ar h my profeence is to use a the con of compliments an man dam so denderly i don't aw so fe go sor y but dam so there two kands up fe more offe at me in the household acted his own ears and i te e more fready hav ta say arn off but a ma oning change and kee for nopl  an mor than one be edoptiand and coseee for tampee ia tak no iven the one  or one e one din hi doction ins bartonidit and wit is ti cand and and why do you want mis goncoa i mean oti ke or argi a reliable what or your so the the maincomperencio see here ah the cipi i found an is yoov always a compromise with aridebiti an a aeighty sixpensiv but a t ill has not this one also ridi riebo ah so yet that's it for the roking desig to morrows you may tell contuc to cennas andbos oyocennas bs ooby fast tat and then said this a standard ondon without any magiting in e like it would a a a ded offi a him without anyits a day simplething and its me ite most and then the however a wat there redow bil tedilet usually it has almost atheqi go there and figting ten y has a opul nightme ai hope your getting ceer of you on awhat what even would contror he sa uo and as a dignata somtinance but maybe yes smorin an arking madivit a cantin teat byt on the market and lak agino you wante noo no  wu la this is a preference but we cant always cha h a what what e was thinking about it de de deskima about stal a and then you mad a mo o foupasfa the moi of drumping lake that so it had thus oiether standard a common befond democa rose and there a mocket and then it we did dendally used by the people and then a buzllet wen as i good avitically thing of hiving ther an a man for the ma se me sen thing rather e degeneraly i hebern i  pier anvectl at a the receiver is fort already in the televation and we are not erable to change it or thoser we mist adept to o to sheet wright i suppose there is a tentat ar way of communicating look a in ther yet who you za in forit pot e corp ah using ye inforid anah wektey te have on the at hat tevian that in molt bede o anro begos sir touthe geven that he dos mufandor and the pivy e goo bin ta a a to lether so that ther he good tan ame bo the make in te comin ti ter a y book bo o coasion tow that wlaxi gox ide many avesianity to separate say al my wone im i've got a basy our might w stantiges the challen asia and on didenita te of course we ged drad up to thet foot abo that already exists but we what we can do eser a adep ti the the cheip's inside a twis the best a chips ana intord boat yoo  o great i o bor o yo go be get et yi i i i i this wekon sus yen of course you ait the chut yooe mik you shu beka yet i isan't amy like a stitch on their might that says things te galles asty hours at night wich my youdeas a actaly am yeu could feel could think of fa having tab have a kive its worth ten if be cose of the meeu\""
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_str_facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "015ab8b34530459a98c99931cd80db4d",
      "4c2ce3ec146343ec9a3cc7ef53b7f3e6",
      "093d4050365445859bd40c1130b8082c",
      "c41e0e43ccee4b88a7ac0a98ee178d83",
      "e9f47c13f90146c39e024f9388a35a9b",
      "18beffb555ce4b23a4c6676fdec3d6ff",
      "52456dee26424db48bf99a445db0b7ea",
      "6fbbf84837004bd69cd12cdb9b4be13e",
      "373f2d0b9304407b890684e37f1da2b1",
      "14db0c66a5cd47f8883dbe52d5dd016e",
      "0d2987ff9c564f8a8e88fd838af52f91",
      "22e3601861bf47b885960505733ae04e",
      "de2e0d6d084b4a5aa70ca4db1ceaeb0f",
      "9d5fdb3902e3424983da832259acd90b",
      "d69b792a4d424ee3a14a05da4bc8f0c5",
      "961c70b366954778aa64521e207d5838",
      "142a925c00ea48b6b507fb505b1cb3fa",
      "4e7caa93377a4ac0b6f9aa0f732d846e",
      "1e0b5df63ad146ffab7f0561aa44fe55",
      "7be613290f4d4339802b59bcd09a5cbc",
      "2d87a2582d4d4fb0abe0a673c30b9726",
      "f44fdd752e5c49c281d59e94438e42ed",
      "3bc9f5351a894dd48d7fbbed369f04a7",
      "8423141979ef47d9857dfd9b0b3e07f1",
      "8e438f65b564472bb8df00b327f6a6b9",
      "836e4b9ac9b94e87bd88f91a98debe3f",
      "e42c9e30a0484374b7462d69617dc656",
      "7de905f600cf4fe0bf13425a1e3b3ea0",
      "011e96cab98b4dda925d5adf653f7b78",
      "88d9a3e4d6424913ac37e9d806134c19",
      "c902e075bcd7418bb113e4b0781934cf",
      "968804ae026c4b2eb9aa0ad17b405b83"
     ]
    },
    "id": "38AbVxsHVcUw",
    "outputId": "f48e6fdc-4125-4b44-c7e6-9b1887e984e4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015ab8b34530459a98c99931cd80db4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373f2d0b9304407b890684e37f1da2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467042463.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142a925c00ea48b6b507fb505b1cb3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e438f65b564472bb8df00b327f6a6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1382015.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XLNet\n",
    "model_xlnet = TransformerSummarizer(transformer_type=\"XLNet\",transformer_model_key=\"xlnet-base-cased\")\n",
    "full_abs_fin = ''.join(model_xlnet(text_str_facebook))\n",
    "print(full_abs_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "gu5XRxqDiHnb",
    "outputId": "20d4956d-df4b-4c4f-bec6-f510ae5fd157"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-b2d85d5ae7b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrouge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRouge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_abs_fin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman_abs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xlnet + wav2vec scores: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rouge/rouge.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_avg_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m_get_scores\u001b[0;34m(self, hyps, refs)\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mraw_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                     exclusive=self.exclusive)\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0msen_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(hyp, ref, **k)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mDEFAULT_METRICS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"rouge-1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rouge-2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rouge-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     AVAILABLE_METRICS = {\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;34m\"rouge-1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;34m\"rouge-2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;34m\"rouge-l\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rouge/rouge_score.py\u001b[0m in \u001b[0;36mrouge_n\u001b[0;34m(evaluated_sentences, reference_sentences, n, raw_results, exclusive)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \"\"\"\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluated_sentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hypothesis is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_sentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reference is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Hypothesis is empty."
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(full_abs_fin, human_abs)\n",
    "print('xlnet + wav2vec scores: {}'.format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSCJE944iK3E",
    "outputId": "559e0ae0-dce3-4011-98d4-41644db40e09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "reference = preprocess_text_simple(human_abs)\n",
    "candidate = preprocess_text_simple(full_abs_fin)\n",
    "score_together = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "print(score_together)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Summarization_methods_for_me_sr (2).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00107b9bd80a4708ab7603561c696296": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "011e96cab98b4dda925d5adf653f7b78": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "015ab8b34530459a98c99931cd80db4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_093d4050365445859bd40c1130b8082c",
       "IPY_MODEL_c41e0e43ccee4b88a7ac0a98ee178d83"
      ],
      "layout": "IPY_MODEL_4c2ce3ec146343ec9a3cc7ef53b7f3e6"
     }
    },
    "071b8f612462401d9a970b0abd19d80e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "093d4050365445859bd40c1130b8082c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18beffb555ce4b23a4c6676fdec3d6ff",
      "max": 760,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e9f47c13f90146c39e024f9388a35a9b",
      "value": 760
     }
    },
    "0ae3520789264d9fa3da4f9a4d255a5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0d2987ff9c564f8a8e88fd838af52f91": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d5fdb3902e3424983da832259acd90b",
      "max": 467042463,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de2e0d6d084b4a5aa70ca4db1ceaeb0f",
      "value": 467042463
     }
    },
    "10a5245500bc4f95817b00ebc0af4d70": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "141de01b4881492382a9800600622cd9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "142a925c00ea48b6b507fb505b1cb3fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e0b5df63ad146ffab7f0561aa44fe55",
       "IPY_MODEL_7be613290f4d4339802b59bcd09a5cbc"
      ],
      "layout": "IPY_MODEL_4e7caa93377a4ac0b6f9aa0f732d846e"
     }
    },
    "147e46798936490a917ce5cf2b2c9b62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14db0c66a5cd47f8883dbe52d5dd016e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14fd9c1a574b48e0a1780230ddc8b8ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4016c4f8b7344ba5b17413815eb61977",
      "placeholder": "​",
      "style": "IPY_MODEL_147e46798936490a917ce5cf2b2c9b62",
      "value": " 1.38M/1.38M [00:14&lt;00:00, 97.8kB/s]"
     }
    },
    "1841f119895c473786ff4adf68a0bb49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10a5245500bc4f95817b00ebc0af4d70",
      "placeholder": "​",
      "style": "IPY_MODEL_c82809532ead4f138911dd25b2d69f1f",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 1.95MB/s]"
     }
    },
    "18beffb555ce4b23a4c6676fdec3d6ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19624aa597a44bb2a5046a3b596ef9ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ab3ee790a56498e800681ddd172ba5c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c1eb4aa3c9744c694a70a63f9d520e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_141de01b4881492382a9800600622cd9",
      "placeholder": "​",
      "style": "IPY_MODEL_960a0b2f008d4ecf92971b45870bce31",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "1e0b5df63ad146ffab7f0561aa44fe55": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f44fdd752e5c49c281d59e94438e42ed",
      "max": 798011,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d87a2582d4d4fb0abe0a673c30b9726",
      "value": 798011
     }
    },
    "1ea0ab94c1dd4a739de7c2d6d47d80ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81c5e0ec7358422b84b3438f9eac6d64",
      "placeholder": "​",
      "style": "IPY_MODEL_59ba018eec7c497f8a1c49bd28dfab60",
      "value": " 718/718 [01:04&lt;00:00, 11.1B/s]"
     }
    },
    "22e3601861bf47b885960505733ae04e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_961c70b366954778aa64521e207d5838",
      "placeholder": "​",
      "style": "IPY_MODEL_d69b792a4d424ee3a14a05da4bc8f0c5",
      "value": " 467M/467M [01:03&lt;00:00, 7.41MB/s]"
     }
    },
    "2660203eb45241259a2f54fb4dae1287": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b369cd644e2e426081def3d61da7599a",
      "placeholder": "​",
      "style": "IPY_MODEL_071b8f612462401d9a970b0abd19d80e",
      "value": " 467M/467M [00:17&lt;00:00, 27.1MB/s]"
     }
    },
    "2772502f70f545439ac4aa4b35231213": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d87a2582d4d4fb0abe0a673c30b9726": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2e84676350724a8b95fd44a677739790": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32f237d7af1a475cbce8cf894c62d709": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34217d3e5fef458f8926401f4b20f387": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b34585c5368d4abbb5fecb945c36ed99",
       "IPY_MODEL_b4c543b0eb464266a49282e9e4e78418"
      ],
      "layout": "IPY_MODEL_931d193ae0214e758efd29e41626f90b"
     }
    },
    "373f2d0b9304407b890684e37f1da2b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d2987ff9c564f8a8e88fd838af52f91",
       "IPY_MODEL_22e3601861bf47b885960505733ae04e"
      ],
      "layout": "IPY_MODEL_14db0c66a5cd47f8883dbe52d5dd016e"
     }
    },
    "3bc9f5351a894dd48d7fbbed369f04a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3cee2c70c2c54552b08173da2b43bbec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d099d24ff2b45698e534449749b1848": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32f237d7af1a475cbce8cf894c62d709",
      "max": 718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_85f9ab0a563249d3a93809befdcf0a1a",
      "value": 718
     }
    },
    "4016c4f8b7344ba5b17413815eb61977": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4babc5cc0ef24f9686833cab4e113962": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9dfdaa37cdb54bfc9cafa79319704fe9",
       "IPY_MODEL_c897f7abf39f49e7824bb0c9f45ad7c1"
      ],
      "layout": "IPY_MODEL_6fb9d897c22d470db9e5951df85cf8ab"
     }
    },
    "4c15223e676742de9ef4ffee93a79d50": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8ca4ba425c2442ddb408f8f129d3ff83",
       "IPY_MODEL_b2528515b58c437c8bde2f394beab879"
      ],
      "layout": "IPY_MODEL_2e84676350724a8b95fd44a677739790"
     }
    },
    "4c2ce3ec146343ec9a3cc7ef53b7f3e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e7caa93377a4ac0b6f9aa0f732d846e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50261ef7495e4945a3872e0763d2e2f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6de0683e6879443990f9bc6c72701d93",
       "IPY_MODEL_2660203eb45241259a2f54fb4dae1287"
      ],
      "layout": "IPY_MODEL_86c08d5c47234b17af4f5d4aa2c6851a"
     }
    },
    "52456dee26424db48bf99a445db0b7ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "555a8a1bb11b49559e4dd19a6afc56d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a4bae3695754a0bad15cab7da5f7379",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5798a95b255343d9a8fb8d2759346b18",
      "value": 1
     }
    },
    "5798a95b255343d9a8fb8d2759346b18": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "59ba018eec7c497f8a1c49bd28dfab60": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62a772f051ae4210bb019c0ca598c2cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62bbb122f57c4d0a9222e07ec075c245": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69438792226a472095d2cd18c15e0c0e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bb846902712490586a40e2a06da019c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c23b18bea4841d0a6a61631ab238c95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6de0683e6879443990f9bc6c72701d93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6bb846902712490586a40e2a06da019c",
      "max": 467042463,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef9c691337e94ff9aed14caf9dc2a853",
      "value": 467042463
     }
    },
    "6de8d5ac9f6a4bcf974b4e59fe0f27b0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fb9d897c22d470db9e5951df85cf8ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fbbf84837004bd69cd12cdb9b4be13e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7559d35bc0384edea390bfdc74eb9b1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7be613290f4d4339802b59bcd09a5cbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8423141979ef47d9857dfd9b0b3e07f1",
      "placeholder": "​",
      "style": "IPY_MODEL_3bc9f5351a894dd48d7fbbed369f04a7",
      "value": " 798k/798k [00:46&lt;00:00, 17.1kB/s]"
     }
    },
    "7de905f600cf4fe0bf13425a1e3b3ea0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_968804ae026c4b2eb9aa0ad17b405b83",
      "placeholder": "​",
      "style": "IPY_MODEL_c902e075bcd7418bb113e4b0781934cf",
      "value": " 1.38M/1.38M [00:45&lt;00:00, 30.1kB/s]"
     }
    },
    "8035d2d9c4ba4934adb5bcd02a4ca1d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81c5e0ec7358422b84b3438f9eac6d64": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81fb4ea6cf1246d096c9ffa883fee037": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "836e4b9ac9b94e87bd88f91a98debe3f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8423141979ef47d9857dfd9b0b3e07f1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85f9ab0a563249d3a93809befdcf0a1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "86c08d5c47234b17af4f5d4aa2c6851a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88d9a3e4d6424913ac37e9d806134c19": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "891d1f193b1e4e19bd8a659c8afa9f2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3d099d24ff2b45698e534449749b1848",
       "IPY_MODEL_1ea0ab94c1dd4a739de7c2d6d47d80ad"
      ],
      "layout": "IPY_MODEL_c8d3dba8950647f78e42a0c6cfc16bde"
     }
    },
    "8ca4ba425c2442ddb408f8f129d3ff83": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c98fc626a6c4b6ca24fef5d49cd1c3d",
      "max": 798011,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec2ccccdb118404b8a440dd52051c86e",
      "value": 798011
     }
    },
    "8e438f65b564472bb8df00b327f6a6b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e42c9e30a0484374b7462d69617dc656",
       "IPY_MODEL_7de905f600cf4fe0bf13425a1e3b3ea0"
      ],
      "layout": "IPY_MODEL_836e4b9ac9b94e87bd88f91a98debe3f"
     }
    },
    "922f3ecc616144708f1179de850b9004": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "931d193ae0214e758efd29e41626f90b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "960a0b2f008d4ecf92971b45870bce31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "961c70b366954778aa64521e207d5838": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "968804ae026c4b2eb9aa0ad17b405b83": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98d407c4f98d446f91649abb973e7e70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be0cc8bf2946474092c2faa4e521866f",
      "placeholder": "​",
      "style": "IPY_MODEL_a145b6236efa46cf8b2b3fbf3f4a9a43",
      "value": " 1.04M/1.04M [00:01&lt;00:00, 876kB/s]"
     }
    },
    "9a4bae3695754a0bad15cab7da5f7379": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c98fc626a6c4b6ca24fef5d49cd1c3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d5fdb3902e3424983da832259acd90b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dfdaa37cdb54bfc9cafa79319704fe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7559d35bc0384edea390bfdc74eb9b1f",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ae3520789264d9fa3da4f9a4d255a5a",
      "value": 456318
     }
    },
    "a145b6236efa46cf8b2b3fbf3f4a9a43": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3d94fb508004f209b8c111f9d3d06f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5ccefeb6404490fb4c1f3c65c1d04af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0ef92e111da49b7975f2cfbc1b215db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c1eb4aa3c9744c694a70a63f9d520e0",
       "IPY_MODEL_555a8a1bb11b49559e4dd19a6afc56d8"
      ],
      "layout": "IPY_MODEL_3cee2c70c2c54552b08173da2b43bbec"
     }
    },
    "b2528515b58c437c8bde2f394beab879": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2772502f70f545439ac4aa4b35231213",
      "placeholder": "​",
      "style": "IPY_MODEL_81fb4ea6cf1246d096c9ffa883fee037",
      "value": " 798k/798k [00:14&lt;00:00, 53.6kB/s]"
     }
    },
    "b34585c5368d4abbb5fecb945c36ed99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3d94fb508004f209b8c111f9d3d06f0",
      "max": 760,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ee133ace14ed40509ba1a02fcbadd8f4",
      "value": 760
     }
    },
    "b369cd644e2e426081def3d61da7599a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4c543b0eb464266a49282e9e4e78418": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19624aa597a44bb2a5046a3b596ef9ff",
      "placeholder": "​",
      "style": "IPY_MODEL_bd70ec3d30444aed84eff7566adaf47f",
      "value": " 760/760 [02:49&lt;00:00, 4.48B/s]"
     }
    },
    "b9649c01a1d846c4a5f0975ef6e236c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e29e881d804d4703a828cc40e88cda67",
       "IPY_MODEL_98d407c4f98d446f91649abb973e7e70"
      ],
      "layout": "IPY_MODEL_c7749ca11e9d496cb33f04dfc2f7a7b3"
     }
    },
    "b9991e2d045a4601adde589d8266bd9a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcb274a7b3934d6faf868c6c87045e54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f819d6152cfe44bca8d8fbcfd4fe5198",
       "IPY_MODEL_c4652d164ada49ad882f4e7a15ec3be0"
      ],
      "layout": "IPY_MODEL_c71c0054b8994abfa6fcace945fcf5cf"
     }
    },
    "bd70ec3d30444aed84eff7566adaf47f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be0cc8bf2946474092c2faa4e521866f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c41e0e43ccee4b88a7ac0a98ee178d83": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fbbf84837004bd69cd12cdb9b4be13e",
      "placeholder": "​",
      "style": "IPY_MODEL_52456dee26424db48bf99a445db0b7ea",
      "value": " 760/760 [00:03&lt;00:00, 248B/s]"
     }
    },
    "c4652d164ada49ad882f4e7a15ec3be0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69438792226a472095d2cd18c15e0c0e",
      "placeholder": "​",
      "style": "IPY_MODEL_a5ccefeb6404490fb4c1f3c65c1d04af",
      "value": " 1.52G/1.52G [00:55&lt;00:00, 27.4MB/s]"
     }
    },
    "c605c3af29c04a23873ebe773ebc6838": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1c60283aec64252b995af76e1a0d403",
       "IPY_MODEL_1841f119895c473786ff4adf68a0bb49"
      ],
      "layout": "IPY_MODEL_8035d2d9c4ba4934adb5bcd02a4ca1d1"
     }
    },
    "c71c0054b8994abfa6fcace945fcf5cf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7749ca11e9d496cb33f04dfc2f7a7b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c82809532ead4f138911dd25b2d69f1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c897f7abf39f49e7824bb0c9f45ad7c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00107b9bd80a4708ab7603561c696296",
      "placeholder": "​",
      "style": "IPY_MODEL_db2b377166ed47739d21eaf982b901d7",
      "value": " 456k/456k [00:00&lt;00:00, 624kB/s]"
     }
    },
    "c8d3dba8950647f78e42a0c6cfc16bde": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c902e075bcd7418bb113e4b0781934cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9a64a646ed8450a9480f046bfa61d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d43f5e8d725f4aa2a90f3f90c8a111ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ea67009a4c03433aa209ba0aa6da41d0",
       "IPY_MODEL_14fd9c1a574b48e0a1780230ddc8b8ee"
      ],
      "layout": "IPY_MODEL_6de8d5ac9f6a4bcf974b4e59fe0f27b0"
     }
    },
    "d69b792a4d424ee3a14a05da4bc8f0c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db2b377166ed47739d21eaf982b901d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de2e0d6d084b4a5aa70ca4db1ceaeb0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e29e881d804d4703a828cc40e88cda67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62bbb122f57c4d0a9222e07ec075c245",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c23b18bea4841d0a6a61631ab238c95",
      "value": 1042301
     }
    },
    "e32c623da4124d95b5d2d7db13bc516a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e42c9e30a0484374b7462d69617dc656": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88d9a3e4d6424913ac37e9d806134c19",
      "max": 1382015,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_011e96cab98b4dda925d5adf653f7b78",
      "value": 1382015
     }
    },
    "e9f47c13f90146c39e024f9388a35a9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ea67009a4c03433aa209ba0aa6da41d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9991e2d045a4601adde589d8266bd9a",
      "max": 1382015,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c9a64a646ed8450a9480f046bfa61d65",
      "value": 1382015
     }
    },
    "ec2ccccdb118404b8a440dd52051c86e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ee133ace14ed40509ba1a02fcbadd8f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ef9c691337e94ff9aed14caf9dc2a853": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f1c60283aec64252b995af76e1a0d403": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62a772f051ae4210bb019c0ca598c2cc",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e32c623da4124d95b5d2d7db13bc516a",
      "value": 1355256
     }
    },
    "f44fdd752e5c49c281d59e94438e42ed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f819d6152cfe44bca8d8fbcfd4fe5198": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ab3ee790a56498e800681ddd172ba5c",
      "max": 1520013706,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_922f3ecc616144708f1179de850b9004",
      "value": 1520013706
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
